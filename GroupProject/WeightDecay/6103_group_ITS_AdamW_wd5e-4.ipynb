{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL7RQ4RQH1q8"
      },
      "source": [
        "Prep\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLPM1G2oyK_V",
        "outputId": "60028b4a-00d1-4122-bbab-58a620a9ab30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5aGTHRISo4o",
        "outputId": "89db6a3b-6c8d-4a20-eb57-96deda87748b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.14.1)\n",
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Collecting pytorch_msssim\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Collecting warmup-scheduler\n",
            "  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.59.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_msssim) (2.1.0+cu118)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (2.1.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_msssim) (1.3.0)\n",
            "Building wheels for collected packages: warmup-scheduler\n",
            "  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warmup-scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2968 sha256=c2e88f5dc27e4cd6b2804768cc4c4981eb898907c4b846508544cc04c447bece\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/01/9e/d1820991c32916e9808c940f572b462f3e46427f3e76c4d852\n",
            "Successfully built warmup-scheduler\n",
            "Installing collected packages: warmup-scheduler, einops, pytorch_msssim\n",
            "Successfully installed einops-0.7.0 pytorch_msssim-1.0.0 warmup-scheduler-0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboard einops scikit-image opencv-python pytorch_msssim warmup-scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhWsuX95jwvB"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/reside-indoor\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h78ryOOBvc2"
      },
      "source": [
        "Data Augment\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z9B1WKSCD5O"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as FUNCTIONAL\n",
        "\n",
        "\n",
        "class PairRandomCrop(transforms.RandomCrop):\n",
        "\n",
        "    def __call__(self, image, label):\n",
        "\n",
        "        if self.padding is not None:\n",
        "            image = FUNCTIONAL.pad(image, self.padding, self.fill, self.padding_mode)\n",
        "            label = FUNCTIONAL.pad(label, self.padding, self.fill, self.padding_mode)\n",
        "\n",
        "        # pad the width if needed\n",
        "        if self.pad_if_needed and image.size[0] < self.size[1]:\n",
        "            image = FUNCTIONAL.pad(image, (self.size[1] - image.size[0], 0), self.fill, self.padding_mode)\n",
        "            label = FUNCTIONAL.pad(label, (self.size[1] - label.size[0], 0), self.fill, self.padding_mode)\n",
        "        # pad the height if needed\n",
        "        if self.pad_if_needed and image.size[1] < self.size[0]:\n",
        "            image = FUNCTIONAL.pad(image, (0, self.size[0] - image.size[1]), self.fill, self.padding_mode)\n",
        "            label = FUNCTIONAL.pad(label, (0, self.size[0] - image.size[1]), self.fill, self.padding_mode)\n",
        "\n",
        "        i, j, h, w = self.get_params(image, self.size)\n",
        "\n",
        "        return FUNCTIONAL.crop(image, i, j, h, w), FUNCTIONAL.crop(label, i, j, h, w)\n",
        "\n",
        "\n",
        "class PairCompose(transforms.Compose):\n",
        "    def __call__(self, image, label):\n",
        "        for t in self.transforms:\n",
        "            image, label = t(image, label)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class PairRandomHorizontalFilp(transforms.RandomHorizontalFlip):\n",
        "    def __call__(self, img, label):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (PIL Image): Image to be flipped.\n",
        "\n",
        "        Returns:\n",
        "            PIL Image: Randomly flipped image.\n",
        "        \"\"\"\n",
        "        if random.random() < self.p:\n",
        "            return FUNCTIONAL.hflip(img), FUNCTIONAL.hflip(label)\n",
        "        return img, label\n",
        "\n",
        "\n",
        "class PairToTensor(transforms.ToTensor):\n",
        "    def __call__(self, pic, label):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Converted image.\n",
        "        \"\"\"\n",
        "        return FUNCTIONAL.to_tensor(pic), FUNCTIONAL.to_tensor(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik-THSPrBomo"
      },
      "source": [
        "Data Loader\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rFIJk2JBsbA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image as Image\n",
        "from torchvision.transforms import functional as Functional\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "def train_dataloader(path, batch_size=1, num_workers=0, use_transform=True): # we change batch size = 1, but the original batch size = 64\n",
        "    image_dir = os.path.join(path, 'train')\n",
        "\n",
        "    transform = None\n",
        "    if use_transform:\n",
        "        transform = PairCompose(\n",
        "            [\n",
        "                PairRandomCrop(256),\n",
        "                PairRandomHorizontalFilp(),\n",
        "                PairToTensor()\n",
        "            ]\n",
        "        )\n",
        "    dataloader = DataLoader(\n",
        "        DeblurDataset(image_dir, transform=transform),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def test_dataloader(path, batch_size=1, num_workers=0):\n",
        "    image_dir = os.path.join(path, 'test')\n",
        "    dataloader = DataLoader(\n",
        "        DeblurDataset(image_dir, is_test=True),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def valid_dataloader(path, batch_size=1, num_workers=0):\n",
        "    dataloader = DataLoader(\n",
        "        DeblurDataset(os.path.join(path, 'test')),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "class DeblurDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None, is_test=False):\n",
        "        self.image_dir = image_dir\n",
        "        self.image_list = os.listdir(os.path.join(image_dir, 'hazy/'))\n",
        "        self._check_image(self.image_list)\n",
        "        self.image_list.sort()\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(os.path.join(self.image_dir, 'hazy', self.image_list[idx]))\n",
        "        label = Image.open(os.path.join(self.image_dir, 'gt', self.image_list[idx].split('_')[0]+'.png'))\n",
        "\n",
        "        if self.transform:\n",
        "            image, label = self.transform(image, label)\n",
        "        else:\n",
        "            image = Functional.to_tensor(image)\n",
        "            label = Functional.to_tensor(label)\n",
        "        if self.is_test:\n",
        "            name = self.image_list[idx]\n",
        "            return image, label, name\n",
        "        return image, label\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_image(lst):\n",
        "        for x in lst:\n",
        "            splits = x.split('.')\n",
        "            if splits[-1] not in ['png', 'jpg', 'jpeg']:\n",
        "                raise ValueError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOmdMPEPBcqU"
      },
      "source": [
        "Utils\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3KXVt8fBgN_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Adder(object):\n",
        "    def __init__(self):\n",
        "        self.count = 0\n",
        "        self.num = float(0)\n",
        "\n",
        "    def reset(self):\n",
        "        self.count = 0\n",
        "        self.num = float(0)\n",
        "\n",
        "    def __call__(self, num):\n",
        "        self.count += 1\n",
        "        self.num += num\n",
        "\n",
        "    def average(self):\n",
        "        return self.num / self.count\n",
        "\n",
        "\n",
        "class Timer(object):\n",
        "    def __init__(self, option='s'):\n",
        "        self.tm = 0\n",
        "        self.option = option\n",
        "        if option == 's':\n",
        "            self.devider = 1\n",
        "        elif option == 'm':\n",
        "            self.devider = 60\n",
        "        else:\n",
        "            self.devider = 3600\n",
        "\n",
        "    def tic(self):\n",
        "        self.tm = time.time()\n",
        "\n",
        "    def toc(self):\n",
        "        return (time.time() - self.tm) / self.devider\n",
        "\n",
        "\n",
        "def check_lr(optimizer):\n",
        "    for i, param_group in enumerate(optimizer.param_groups):\n",
        "        lr = param_group['lr']\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuIwak2DBSmK"
      },
      "source": [
        "Eval\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQmJ-vK5BT4n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision.transforms import functional as F\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "import time\n",
        "from pytorch_msssim import ssim\n",
        "import torch.nn.functional as f\n",
        "\n",
        "from skimage import img_as_ubyte\n",
        "import cv2\n",
        "\n",
        "def _eval(model, args):\n",
        "    state_dict = torch.load(args.test_model)\n",
        "    model.load_state_dict(state_dict['model'])\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    dataloader = test_dataloader(args.data_dir, batch_size=1, num_workers=0)\n",
        "    torch.cuda.empty_cache()\n",
        "    adder = Adder()\n",
        "    model.eval()\n",
        "    factor = 32\n",
        "    with torch.no_grad():\n",
        "        psnr_adder = Adder()\n",
        "        ssim_adder = Adder()\n",
        "\n",
        "        for iter_idx, data in enumerate(dataloader):\n",
        "            input_img, label_img, name = data\n",
        "\n",
        "            input_img = input_img.to(device)\n",
        "\n",
        "            h, w = input_img.shape[2], input_img.shape[3]\n",
        "            H, W = ((h+factor)//factor)*factor, ((w+factor)//factor*factor)\n",
        "            padh = H-h if h%factor!=0 else 0\n",
        "            padw = W-w if w%factor!=0 else 0\n",
        "            input_img = f.pad(input_img, (0, padw, 0, padh), 'reflect')\n",
        "\n",
        "            tm = time.time()\n",
        "\n",
        "            pred = model(input_img)[2]\n",
        "            pred = pred[:,:,:h,:w]\n",
        "\n",
        "            elapsed = time.time() - tm\n",
        "            adder(elapsed)\n",
        "\n",
        "            pred_clip = torch.clamp(pred, 0, 1)\n",
        "\n",
        "            pred_numpy = pred_clip.squeeze(0).cpu().numpy()\n",
        "            label_numpy = label_img.squeeze(0).cpu().numpy()\n",
        "\n",
        "\n",
        "            label_img = (label_img).cuda()\n",
        "            psnr_val = 10 * torch.log10(1 / f.mse_loss(pred_clip, label_img))\n",
        "            down_ratio = max(1, round(min(H, W) / 256))\n",
        "            ssim_val = ssim(f.adaptive_avg_pool2d(pred_clip, (int(H / down_ratio), int(W / down_ratio))),\n",
        "                            f.adaptive_avg_pool2d(label_img, (int(H / down_ratio), int(W / down_ratio))),\n",
        "                            data_range=1, size_average=False)\n",
        "            print('%d iter PSNR_dehazing: %.2f ssim: %f' % (iter_idx + 1, psnr_val, ssim_val))\n",
        "            ssim_adder(ssim_val)\n",
        "\n",
        "            if args.save_image:\n",
        "                save_name = os.path.join(args.result_dir, name[0])\n",
        "                pred_clip += 0.5 / 255\n",
        "                pred = F.to_pil_image(pred_clip.squeeze(0).cpu(), 'RGB')\n",
        "                pred.save(save_name)\n",
        "\n",
        "            psnr_mimo = peak_signal_noise_ratio(pred_numpy, label_numpy, data_range=1)\n",
        "            psnr_adder(psnr_val)\n",
        "\n",
        "            print('%d iter PSNR: %.2f time: %f' % (iter_idx + 1, psnr_mimo, elapsed))\n",
        "\n",
        "        print('==========================================================')\n",
        "        print('The average PSNR is %.2f dB' % (psnr_adder.average()))\n",
        "        print('The average SSIM is %.5f dB' % (ssim_adder.average()))\n",
        "\n",
        "        print(\"Average time: %f\" % adder.average())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiBJcTJbCOcj"
      },
      "source": [
        "Layers\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qOrc8BLCPaH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class BasicConv(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, stride, bias=True, norm=False, relu=True, transpose=False):\n",
        "        super(BasicConv, self).__init__()\n",
        "        if bias and norm:\n",
        "            bias = False\n",
        "\n",
        "        padding = kernel_size // 2\n",
        "        layers = list()\n",
        "        if transpose:\n",
        "            padding = kernel_size // 2 -1\n",
        "            layers.append(nn.ConvTranspose2d(in_channel, out_channel, kernel_size, padding=padding, stride=stride, bias=bias))\n",
        "        else:\n",
        "            layers.append(\n",
        "                nn.Conv2d(in_channel, out_channel, kernel_size, padding=padding, stride=stride, bias=bias))\n",
        "        if norm:\n",
        "            layers.append(nn.BatchNorm2d(out_channel))\n",
        "        if relu:\n",
        "            layers.append(nn.GELU())\n",
        "        self.main = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, filter=False):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            BasicConv(in_channel, out_channel, kernel_size=3, stride=1, relu=True),\n",
        "            DeepPoolLayer(in_channel, out_channel) if filter else nn.Identity(),\n",
        "            BasicConv(out_channel, out_channel, kernel_size=3, stride=1, relu=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x) + x\n",
        "\n",
        "\n",
        "class DeepPoolLayer(nn.Module):\n",
        "    def __init__(self, k, k_out):\n",
        "        super(DeepPoolLayer, self).__init__()\n",
        "        self.pools_sizes = [8,4,2]\n",
        "        pools, convs, dynas = [],[],[]\n",
        "        for i in self.pools_sizes:\n",
        "            pools.append(nn.AvgPool2d(kernel_size=i, stride=i))\n",
        "            convs.append(nn.Conv2d(k, k, 3, 1, 1, bias=False))\n",
        "            dynas.append(dynamic_filter(inchannels=k, kernel_size=3))\n",
        "        self.pools = nn.ModuleList(pools)\n",
        "        self.convs = nn.ModuleList(convs)\n",
        "        self.dynas = nn.ModuleList(dynas)\n",
        "        self.relu = nn.GELU()\n",
        "        self.conv_sum = nn.Conv2d(k, k_out, 3, 1, 1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()\n",
        "        resl = x\n",
        "        for i in range(len(self.pools_sizes)):\n",
        "            if i == 0:\n",
        "                y = self.dynas[i](self.convs[i](self.pools[i](x)))\n",
        "            else:\n",
        "                y = self.dynas[i](self.convs[i](self.pools[i](x)+y_up))\n",
        "            resl = torch.add(resl, F.interpolate(y, x_size[2:], mode='bilinear', align_corners=True))\n",
        "            if i != len(self.pools_sizes)-1:\n",
        "                y_up = F.interpolate(y, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        resl = self.relu(resl)\n",
        "        resl = self.conv_sum(resl)\n",
        "\n",
        "        return resl\n",
        "\n",
        "class dynamic_filter(nn.Module):\n",
        "    def __init__(self, inchannels, kernel_size=3, stride=1, group=8):\n",
        "        super(dynamic_filter, self).__init__()\n",
        "\n",
        "        self.stride = stride\n",
        "        self.kernel_size = kernel_size\n",
        "        self.group = group\n",
        "\n",
        "        self.conv = nn.Conv2d(inchannels, group*kernel_size**2, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(group*kernel_size**2)\n",
        "        self.act = nn.Tanh()\n",
        "\n",
        "        nn.init.kaiming_normal_(self.conv.weight, mode='fan_out', nonlinearity='relu')\n",
        "        self.lamb_l = nn.Parameter(torch.zeros(inchannels), requires_grad=True)\n",
        "        self.lamb_h = nn.Parameter(torch.zeros(inchannels), requires_grad=True)\n",
        "        self.pad = nn.ReflectionPad2d(kernel_size//2)\n",
        "\n",
        "        self.ap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.inside_all = nn.Parameter(torch.zeros(inchannels,1,1), requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity_input = x\n",
        "        # the Conv_{3x3} layer in eq.3 is included in DeepPoolLayer.convs\n",
        "        low_filter = self.ap(x)\n",
        "        low_filter = self.conv(low_filter)\n",
        "        low_filter = self.bn(low_filter)\n",
        "\n",
        "        n, c, h, w = x.shape\n",
        "        x = F.unfold(self.pad(x), kernel_size=self.kernel_size).reshape(n, self.group, c//self.group, self.kernel_size**2, h*w)\n",
        "\n",
        "        n,c1,p,q = low_filter.shape\n",
        "        low_filter = low_filter.reshape(n, c1//self.kernel_size**2, self.kernel_size**2, p*q).unsqueeze(2)\n",
        "        low_filter = self.act(low_filter)\n",
        "        low_part = torch.sum(x * low_filter, dim=3).reshape(n, c, h, w)\n",
        "\n",
        "        # the variables here are slightly different from the paper: (code) --> (paper)\n",
        "        # low_filter --> A (eq.3)\n",
        "        # In Eq.7, X*A'= X*(A_{l} + WA_{h})\n",
        "        #              = X*A_{l} + WX*(A - A_{l})\n",
        "        #              = X*A_{l} + WX*A - WX*A_{l}\n",
        "        #              = WX*A - X*A_{l}(W-1)\n",
        "        # we substitute gap for A_{l} for simplicity, which is a coarser low-frequency filter\n",
        "        out_low = low_part * (self.inside_all + 1.) - self.inside_all * self.gap(identity_input)\n",
        "\n",
        "        out_low = out_low * self.lamb_l[None,:,None,None]\n",
        "        out_high = (identity_input) * (self.lamb_h[None,:,None,None] + 1.)\n",
        "\n",
        "        return out_low + out_high"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muFr7px4CKua"
      },
      "source": [
        "IRNeXt\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNdQN8JdCMEh"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EBlock(nn.Module):\n",
        "    def __init__(self, out_channel, num_res=8):\n",
        "        super(EBlock, self).__init__()\n",
        "\n",
        "        layers = [ResBlock(out_channel, out_channel) for _ in range(num_res-1)]\n",
        "        layers.append(ResBlock(out_channel, out_channel, filter=True))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class DBlock(nn.Module):\n",
        "    def __init__(self, channel, num_res=8):\n",
        "        super(DBlock, self).__init__()\n",
        "\n",
        "        layers = [ResBlock(channel, channel) for _ in range(num_res-1)]\n",
        "        layers.append(ResBlock(channel, channel, filter=True))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class SCM(nn.Module):\n",
        "    def __init__(self, out_plane):\n",
        "        super(SCM, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            BasicConv(3, out_plane//4, kernel_size=3, stride=1, relu=True),\n",
        "            BasicConv(out_plane // 4, out_plane // 2, kernel_size=1, stride=1, relu=True),\n",
        "            BasicConv(out_plane // 2, out_plane // 2, kernel_size=3, stride=1, relu=True),\n",
        "            BasicConv(out_plane // 2, out_plane, kernel_size=1, stride=1, relu=False),\n",
        "            nn.InstanceNorm2d(out_plane, affine=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.main(x)\n",
        "        return x\n",
        "\n",
        "class FAM(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(FAM, self).__init__()\n",
        "\n",
        "        self.merge = BasicConv(channel*2, channel, kernel_size=3, stride=1, relu=False)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        return self.merge(torch.cat([x1, x2], dim=1))\n",
        "\n",
        "class IRNeXt(nn.Module):\n",
        "    def __init__(self, num_res=4):\n",
        "        super(IRNeXt, self).__init__()\n",
        "\n",
        "        base_channel = 32\n",
        "        self.Encoder = nn.ModuleList([\n",
        "            EBlock(base_channel, num_res),\n",
        "            EBlock(base_channel*2, num_res),\n",
        "            EBlock(base_channel*4, num_res),\n",
        "        ])\n",
        "\n",
        "        self.feat_extract = nn.ModuleList([\n",
        "            BasicConv(3, base_channel, kernel_size=3, relu=True, stride=1),\n",
        "            BasicConv(base_channel, base_channel*2, kernel_size=3, relu=True, stride=2),\n",
        "            BasicConv(base_channel*2, base_channel*4, kernel_size=3, relu=True, stride=2),\n",
        "            BasicConv(base_channel*4, base_channel*2, kernel_size=4, relu=True, stride=2, transpose=True),\n",
        "            BasicConv(base_channel*2, base_channel, kernel_size=4, relu=True, stride=2, transpose=True),\n",
        "            BasicConv(base_channel, 3, kernel_size=3, relu=False, stride=1)\n",
        "        ])\n",
        "\n",
        "        self.Decoder = nn.ModuleList([\n",
        "            DBlock(base_channel * 4, num_res),\n",
        "            DBlock(base_channel * 2, num_res),\n",
        "            DBlock(base_channel, num_res)\n",
        "        ])\n",
        "\n",
        "        self.Convs = nn.ModuleList([\n",
        "            BasicConv(base_channel * 4, base_channel * 2, kernel_size=1, relu=True, stride=1),\n",
        "            BasicConv(base_channel * 2, base_channel, kernel_size=1, relu=True, stride=1),\n",
        "        ])\n",
        "\n",
        "        self.ConvsOut = nn.ModuleList(\n",
        "            [\n",
        "                BasicConv(base_channel * 4, 3, kernel_size=3, relu=False, stride=1),\n",
        "                BasicConv(base_channel * 2, 3, kernel_size=3, relu=False, stride=1),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.FAM1 = FAM(base_channel * 4)\n",
        "        self.SCM1 = SCM(base_channel * 4)\n",
        "        self.FAM2 = FAM(base_channel * 2)\n",
        "        self.SCM2 = SCM(base_channel * 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_2 = F.interpolate(x, scale_factor=0.5)\n",
        "        x_4 = F.interpolate(x_2, scale_factor=0.5)\n",
        "        z2 = self.SCM2(x_2)\n",
        "        z4 = self.SCM1(x_4)\n",
        "\n",
        "        outputs = list()\n",
        "        # 256\n",
        "        x_ = self.feat_extract[0](x)\n",
        "        res1 = self.Encoder[0](x_)\n",
        "        # 128\n",
        "        z = self.feat_extract[1](res1)\n",
        "        z = self.FAM2(z, z2)\n",
        "        res2 = self.Encoder[1](z)\n",
        "        # 64\n",
        "        z = self.feat_extract[2](res2)\n",
        "        z = self.FAM1(z, z4)\n",
        "        z = self.Encoder[2](z)\n",
        "\n",
        "        z = self.Decoder[0](z)\n",
        "        z_ = self.ConvsOut[0](z)\n",
        "        # 128\n",
        "        z = self.feat_extract[3](z)\n",
        "        outputs.append(z_+x_4)\n",
        "\n",
        "        z = torch.cat([z, res2], dim=1)\n",
        "        z = self.Convs[0](z)\n",
        "        z = self.Decoder[1](z)\n",
        "        z_ = self.ConvsOut[1](z)\n",
        "        # 256\n",
        "        z = self.feat_extract[4](z)\n",
        "        outputs.append(z_+x_2)\n",
        "\n",
        "        z = torch.cat([z, res1], dim=1)\n",
        "        z = self.Convs[1](z)\n",
        "        z = self.Decoder[2](z)\n",
        "        z = self.feat_extract[5](z)\n",
        "        outputs.append(z+x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "def build_net():\n",
        "    return IRNeXt()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ_iPV8xBg0K"
      },
      "source": [
        "Valid\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfAK2d13Bjq9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.transforms import functional as F\n",
        "import os\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "import torch.nn.functional as f\n",
        "\n",
        "\n",
        "def _valid(model, args, ep):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    its = valid_dataloader(args.data_dir, batch_size=1, num_workers=0)\n",
        "    model.eval()\n",
        "    psnr_adder = Adder()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        print('Start Evaluation')\n",
        "        factor = 32\n",
        "        for idx, data in enumerate(its):\n",
        "            input_img, label_img = data\n",
        "            input_img = input_img.to(device)\n",
        "\n",
        "            h, w = input_img.shape[2], input_img.shape[3]\n",
        "            H, W = ((h+factor)//factor)*factor, ((w+factor)//factor*factor)\n",
        "            padh = H-h if h%factor!=0 else 0\n",
        "            padw = W-w if w%factor!=0 else 0\n",
        "            input_img = f.pad(input_img, (0, padw, 0, padh), 'reflect')\n",
        "\n",
        "            if not os.path.exists(os.path.join(args.result_dir, '%d' % (ep))):\n",
        "                os.mkdir(os.path.join(args.result_dir, '%d' % (ep)))\n",
        "\n",
        "            pred = model(input_img)[2]\n",
        "            pred = pred[:,:,:h,:w]\n",
        "\n",
        "            pred_clip = torch.clamp(pred, 0, 1)\n",
        "            p_numpy = pred_clip.squeeze(0).cpu().numpy()\n",
        "            label_numpy = label_img.squeeze(0).cpu().numpy()\n",
        "\n",
        "            psnr = peak_signal_noise_ratio(p_numpy, label_numpy, data_range=1)\n",
        "\n",
        "            psnr_adder(psnr)\n",
        "            print('\\r%03d'%idx, end=' ')\n",
        "\n",
        "    print('\\n')\n",
        "    model.train()\n",
        "    return psnr_adder.average()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n87ZbXeBapS"
      },
      "source": [
        "TRAIN\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt9V7QBGBcGV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "from warmup_scheduler import GradualWarmupScheduler\n",
        "\n",
        "def _train(model, args):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    criterion = torch.nn.L1Loss()\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate, betas=(0.9, 0.999), eps=1e-8, weight_decay=args.weight_decay)\n",
        "    dataloader = train_dataloader(args.data_dir, args.batch_size, args.num_worker)\n",
        "    max_iter = len(dataloader)\n",
        "    warmup_epochs=3\n",
        "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.num_epoch-warmup_epochs, eta_min=1e-6)\n",
        "    scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=warmup_epochs, after_scheduler=scheduler_cosine)\n",
        "    scheduler.step()\n",
        "    epoch = 1\n",
        "    if args.resume:\n",
        "        state = torch.load(args.resume)\n",
        "        epoch = state['epoch']\n",
        "        optimizer.load_state_dict(state['optimizer'])\n",
        "        model.load_state_dict(state['model'])\n",
        "        print('Resume from %d'%epoch)\n",
        "        epoch += 1\n",
        "        for i in range(epoch-1):\n",
        "          scheduler.step()\n",
        "\n",
        "    writer = SummaryWriter()\n",
        "    epoch_pixel_adder = Adder()\n",
        "    epoch_fft_adder = Adder()\n",
        "    iter_pixel_adder = Adder()\n",
        "    iter_fft_adder = Adder()\n",
        "    epoch_timer = Timer('m')\n",
        "    iter_timer = Timer('m')\n",
        "    best_psnr=-1\n",
        "\n",
        "    for epoch_idx in range(epoch, args.num_epoch + 1):\n",
        "\n",
        "        epoch_timer.tic()\n",
        "        iter_timer.tic()\n",
        "        for iter_idx, batch_data in enumerate(dataloader):\n",
        "\n",
        "            input_img, label_img = batch_data\n",
        "            input_img = input_img.to(device)\n",
        "            label_img = label_img.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred_img = model(input_img)\n",
        "            label_img2 = F.interpolate(label_img, scale_factor=0.5, mode='bilinear')\n",
        "            label_img4 = F.interpolate(label_img, scale_factor=0.25, mode='bilinear')\n",
        "            l1 = criterion(pred_img[0], label_img4)\n",
        "            l2 = criterion(pred_img[1], label_img2)\n",
        "            l3 = criterion(pred_img[2], label_img)\n",
        "            loss_content = l1+l2+l3\n",
        "\n",
        "            label_fft1 = torch.fft.fft2(label_img4, dim=(-2,-1))\n",
        "            label_fft1 = torch.stack((label_fft1.real, label_fft1.imag), -1)\n",
        "\n",
        "            pred_fft1 = torch.fft.fft2(pred_img[0], dim=(-2,-1))\n",
        "            pred_fft1 = torch.stack((pred_fft1.real, pred_fft1.imag), -1)\n",
        "\n",
        "            label_fft2 = torch.fft.fft2(label_img2, dim=(-2,-1))\n",
        "            label_fft2 = torch.stack((label_fft2.real, label_fft2.imag), -1)\n",
        "\n",
        "            pred_fft2 = torch.fft.fft2(pred_img[1], dim=(-2,-1))\n",
        "            pred_fft2 = torch.stack((pred_fft2.real, pred_fft2.imag), -1)\n",
        "\n",
        "            label_fft3 = torch.fft.fft2(label_img, dim=(-2,-1))\n",
        "            label_fft3 = torch.stack((label_fft3.real, label_fft3.imag), -1)\n",
        "\n",
        "            pred_fft3 = torch.fft.fft2(pred_img[2], dim=(-2,-1))\n",
        "            pred_fft3 = torch.stack((pred_fft3.real, pred_fft3.imag), -1)\n",
        "\n",
        "            f1 = criterion(pred_fft1, label_fft1)\n",
        "            f2 = criterion(pred_fft2, label_fft2)\n",
        "            f3 = criterion(pred_fft3, label_fft3)\n",
        "            loss_fft = f1+f2+f3\n",
        "\n",
        "            loss = loss_content + 0.1 * loss_fft\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.001)\n",
        "            optimizer.step()\n",
        "\n",
        "            iter_pixel_adder(loss_content.item())\n",
        "            iter_fft_adder(loss_fft.item())\n",
        "\n",
        "            epoch_pixel_adder(loss_content.item())\n",
        "            epoch_fft_adder(loss_fft.item())\n",
        "\n",
        "            if (iter_idx + 1) % args.print_freq == 0:\n",
        "                print(\"Time: %7.4f Epoch: %03d Iter: %4d/%4d LR: %.10f Loss content: %7.4f Loss fft: %7.4f\" % (\n",
        "                    iter_timer.toc(), epoch_idx, iter_idx + 1, max_iter, scheduler.get_lr()[0], iter_pixel_adder.average(),\n",
        "                    iter_fft_adder.average()))\n",
        "                writer.add_scalar('Pixel Loss', iter_pixel_adder.average(), iter_idx + (epoch_idx-1)* max_iter)\n",
        "                writer.add_scalar('FFT Loss', iter_fft_adder.average(), iter_idx + (epoch_idx - 1) * max_iter)\n",
        "\n",
        "                iter_timer.tic()\n",
        "                iter_pixel_adder.reset()\n",
        "                iter_fft_adder.reset()\n",
        "        overwrite_name = os.path.join(args.model_save_dir, 'model.pkl')\n",
        "        torch.save({'model': model.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                    'epoch': epoch_idx}, overwrite_name)\n",
        "\n",
        "        if epoch_idx % args.save_freq == 0:\n",
        "            save_name = os.path.join(args.model_save_dir, 'model_%d.pkl' % epoch_idx)\n",
        "            torch.save({'model': model.state_dict()}, save_name)\n",
        "        print(\"EPOCH: %02d\\nElapsed time: %4.2f Epoch Pixel Loss: %7.4f Epoch FFT Loss: %7.4f\" % (\n",
        "            epoch_idx, epoch_timer.toc(), epoch_pixel_adder.average(), epoch_fft_adder.average()))\n",
        "        epoch_fft_adder.reset()\n",
        "        epoch_pixel_adder.reset()\n",
        "        scheduler.step()\n",
        "        if epoch_idx % args.valid_freq == 0:\n",
        "            val = _valid(model, args, epoch_idx)\n",
        "            print('%03d epoch \\n Average PSNR %.2f dB' % (epoch_idx, val))\n",
        "            writer.add_scalar('PSNR', val, epoch_idx)\n",
        "            if val >= best_psnr:\n",
        "                torch.save({'model': model.state_dict()}, os.path.join(args.model_save_dir, 'Best.pkl'))\n",
        "    save_name = os.path.join(args.model_save_dir, 'Final.pkl')\n",
        "    torch.save({'model': model.state_dict()}, save_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoDUXGBNBWr7"
      },
      "source": [
        "Main (train model)\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcF3qG8RSAcd",
        "outputId": "cd6aad42-dc41-4912-c630-19fefc912e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<__main__.Args object at 0x7fd867735360>\n",
            "IRNeXt(\n",
            "  (Encoder): ModuleList(\n",
            "    (0): EBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): EBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(64, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): EBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(128, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (feat_extract): ModuleList(\n",
            "    (0): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (1): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (2): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (3): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (4): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (5): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (Decoder): ModuleList(\n",
            "    (0): DBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(128, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): DBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(64, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): DBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (Convs): ModuleList(\n",
            "    (0): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (1): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ConvsOut): ModuleList(\n",
            "    (0): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (1): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (FAM1): FAM(\n",
            "    (merge): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (SCM1): SCM(\n",
            "    (main): Sequential(\n",
            "      (0): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (1): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (2): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (3): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "    )\n",
            "  )\n",
            "  (FAM2): FAM(\n",
            "    (merge): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (SCM2): SCM(\n",
            "    (main): Sequential(\n",
            "      (0): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (1): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (2): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (3): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Resume from 237\n",
            "Time:  0.1421 Epoch: 238 Iter:  100/3510 LR: 0.0000112743 Loss content:  0.0162 Loss fft:  0.8445\n",
            "Time:  0.1311 Epoch: 238 Iter:  200/3510 LR: 0.0000112743 Loss content:  0.0161 Loss fft:  0.8381\n",
            "Time:  0.1319 Epoch: 238 Iter:  300/3510 LR: 0.0000112743 Loss content:  0.0157 Loss fft:  0.8593\n",
            "Time:  0.1290 Epoch: 238 Iter:  400/3510 LR: 0.0000112743 Loss content:  0.0158 Loss fft:  0.8716\n",
            "Time:  0.1304 Epoch: 238 Iter:  500/3510 LR: 0.0000112743 Loss content:  0.0165 Loss fft:  0.8452\n",
            "Time:  0.1281 Epoch: 238 Iter:  600/3510 LR: 0.0000112743 Loss content:  0.0158 Loss fft:  0.8643\n",
            "Time:  0.1313 Epoch: 238 Iter:  700/3510 LR: 0.0000112743 Loss content:  0.0161 Loss fft:  0.8574\n",
            "Time:  0.1309 Epoch: 238 Iter:  800/3510 LR: 0.0000112743 Loss content:  0.0161 Loss fft:  0.8575\n",
            "Time:  0.1354 Epoch: 238 Iter:  900/3510 LR: 0.0000112743 Loss content:  0.0161 Loss fft:  0.8584\n",
            "Time:  0.1284 Epoch: 238 Iter: 1000/3510 LR: 0.0000112743 Loss content:  0.0159 Loss fft:  0.8482\n",
            "Time:  0.1277 Epoch: 238 Iter: 1100/3510 LR: 0.0000112743 Loss content:  0.0157 Loss fft:  0.8501\n",
            "Time:  0.1278 Epoch: 238 Iter: 1200/3510 LR: 0.0000112743 Loss content:  0.0164 Loss fft:  0.8618\n",
            "Time:  0.1296 Epoch: 238 Iter: 1300/3510 LR: 0.0000112743 Loss content:  0.0159 Loss fft:  0.8730\n",
            "Time:  0.1299 Epoch: 238 Iter: 1400/3510 LR: 0.0000112743 Loss content:  0.0163 Loss fft:  0.8669\n",
            "Time:  0.1317 Epoch: 238 Iter: 1500/3510 LR: 0.0000112743 Loss content:  0.0155 Loss fft:  0.8561\n",
            "Time:  0.1300 Epoch: 238 Iter: 1600/3510 LR: 0.0000112743 Loss content:  0.0165 Loss fft:  0.8745\n",
            "Time:  0.1271 Epoch: 238 Iter: 1700/3510 LR: 0.0000112743 Loss content:  0.0154 Loss fft:  0.8349\n",
            "Time:  0.1275 Epoch: 238 Iter: 1800/3510 LR: 0.0000112743 Loss content:  0.0157 Loss fft:  0.8619\n",
            "Time:  0.1327 Epoch: 238 Iter: 1900/3510 LR: 0.0000112743 Loss content:  0.0164 Loss fft:  0.8821\n",
            "Time:  0.1311 Epoch: 238 Iter: 2000/3510 LR: 0.0000112743 Loss content:  0.0156 Loss fft:  0.8551\n",
            "Time:  0.1305 Epoch: 238 Iter: 2100/3510 LR: 0.0000112743 Loss content:  0.0163 Loss fft:  0.8592\n",
            "Time:  0.1287 Epoch: 238 Iter: 2200/3510 LR: 0.0000112743 Loss content:  0.0162 Loss fft:  0.8597\n",
            "Time:  0.1293 Epoch: 238 Iter: 2300/3510 LR: 0.0000112743 Loss content:  0.0160 Loss fft:  0.8416\n",
            "Time:  0.1272 Epoch: 238 Iter: 2400/3510 LR: 0.0000112743 Loss content:  0.0161 Loss fft:  0.8412\n",
            "Time:  0.1292 Epoch: 238 Iter: 2500/3510 LR: 0.0000112743 Loss content:  0.0165 Loss fft:  0.8394\n",
            "Time:  0.1298 Epoch: 238 Iter: 2600/3510 LR: 0.0000112743 Loss content:  0.0155 Loss fft:  0.8457\n",
            "Time:  0.1306 Epoch: 238 Iter: 2700/3510 LR: 0.0000112743 Loss content:  0.0158 Loss fft:  0.8408\n",
            "Time:  0.1283 Epoch: 238 Iter: 2800/3510 LR: 0.0000112743 Loss content:  0.0151 Loss fft:  0.8541\n",
            "Time:  0.1295 Epoch: 238 Iter: 2900/3510 LR: 0.0000112743 Loss content:  0.0164 Loss fft:  0.8651\n",
            "Time:  0.1290 Epoch: 238 Iter: 3000/3510 LR: 0.0000112743 Loss content:  0.0150 Loss fft:  0.8478\n",
            "Time:  0.1303 Epoch: 238 Iter: 3100/3510 LR: 0.0000112743 Loss content:  0.0157 Loss fft:  0.8546\n",
            "Time:  0.1323 Epoch: 238 Iter: 3200/3510 LR: 0.0000112743 Loss content:  0.0165 Loss fft:  0.8670\n",
            "Time:  0.1306 Epoch: 238 Iter: 3300/3510 LR: 0.0000112743 Loss content:  0.0158 Loss fft:  0.8597\n",
            "Time:  0.1336 Epoch: 238 Iter: 3400/3510 LR: 0.0000112743 Loss content:  0.0161 Loss fft:  0.8579\n",
            "Time:  0.1336 Epoch: 238 Iter: 3500/3510 LR: 0.0000112743 Loss content:  0.0157 Loss fft:  0.8376\n",
            "EPOCH: 238\n",
            "Elapsed time: 4.59 Epoch Pixel Loss:  0.0160 Epoch FFT Loss:  0.8552\n",
            "Time:  0.1426 Epoch: 239 Iter:  100/3510 LR: 0.0000109572 Loss content:  0.0162 Loss fft:  0.8687\n",
            "Time:  0.1309 Epoch: 239 Iter:  200/3510 LR: 0.0000109572 Loss content:  0.0153 Loss fft:  0.8579\n",
            "Time:  0.1325 Epoch: 239 Iter:  300/3510 LR: 0.0000109572 Loss content:  0.0161 Loss fft:  0.8447\n",
            "Time:  0.1313 Epoch: 239 Iter:  400/3510 LR: 0.0000109572 Loss content:  0.0153 Loss fft:  0.8384\n",
            "Time:  0.1318 Epoch: 239 Iter:  500/3510 LR: 0.0000109572 Loss content:  0.0164 Loss fft:  0.8654\n",
            "Time:  0.1296 Epoch: 239 Iter:  600/3510 LR: 0.0000109572 Loss content:  0.0156 Loss fft:  0.8487\n",
            "Time:  0.1322 Epoch: 239 Iter:  700/3510 LR: 0.0000109572 Loss content:  0.0162 Loss fft:  0.8526\n",
            "Time:  0.1290 Epoch: 239 Iter:  800/3510 LR: 0.0000109572 Loss content:  0.0164 Loss fft:  0.8530\n",
            "Time:  0.1327 Epoch: 239 Iter:  900/3510 LR: 0.0000109572 Loss content:  0.0161 Loss fft:  0.8798\n",
            "Time:  0.1306 Epoch: 239 Iter: 1000/3510 LR: 0.0000109572 Loss content:  0.0161 Loss fft:  0.8477\n",
            "Time:  0.1331 Epoch: 239 Iter: 1100/3510 LR: 0.0000109572 Loss content:  0.0158 Loss fft:  0.8598\n",
            "Time:  0.1300 Epoch: 239 Iter: 1200/3510 LR: 0.0000109572 Loss content:  0.0153 Loss fft:  0.8340\n",
            "Time:  0.1345 Epoch: 239 Iter: 1300/3510 LR: 0.0000109572 Loss content:  0.0153 Loss fft:  0.8441\n",
            "Time:  0.1319 Epoch: 239 Iter: 1400/3510 LR: 0.0000109572 Loss content:  0.0158 Loss fft:  0.8479\n",
            "Time:  0.1338 Epoch: 239 Iter: 1500/3510 LR: 0.0000109572 Loss content:  0.0162 Loss fft:  0.8767\n",
            "Time:  0.1326 Epoch: 239 Iter: 1600/3510 LR: 0.0000109572 Loss content:  0.0167 Loss fft:  0.8604\n",
            "Time:  0.1315 Epoch: 239 Iter: 1700/3510 LR: 0.0000109572 Loss content:  0.0153 Loss fft:  0.8416\n",
            "Time:  0.1353 Epoch: 239 Iter: 1800/3510 LR: 0.0000109572 Loss content:  0.0163 Loss fft:  0.8313\n",
            "Time:  0.1355 Epoch: 239 Iter: 1900/3510 LR: 0.0000109572 Loss content:  0.0161 Loss fft:  0.8438\n",
            "Time:  0.1311 Epoch: 239 Iter: 2000/3510 LR: 0.0000109572 Loss content:  0.0157 Loss fft:  0.8591\n",
            "Time:  0.1319 Epoch: 239 Iter: 2100/3510 LR: 0.0000109572 Loss content:  0.0159 Loss fft:  0.8280\n",
            "Time:  0.1313 Epoch: 239 Iter: 2200/3510 LR: 0.0000109572 Loss content:  0.0159 Loss fft:  0.8411\n",
            "Time:  0.1311 Epoch: 239 Iter: 2300/3510 LR: 0.0000109572 Loss content:  0.0155 Loss fft:  0.8533\n",
            "Time:  0.1315 Epoch: 239 Iter: 2400/3510 LR: 0.0000109572 Loss content:  0.0155 Loss fft:  0.8540\n",
            "Time:  0.1335 Epoch: 239 Iter: 2500/3510 LR: 0.0000109572 Loss content:  0.0158 Loss fft:  0.8532\n",
            "Time:  0.1343 Epoch: 239 Iter: 2600/3510 LR: 0.0000109572 Loss content:  0.0168 Loss fft:  0.8657\n",
            "Time:  0.1309 Epoch: 239 Iter: 2700/3510 LR: 0.0000109572 Loss content:  0.0151 Loss fft:  0.8368\n",
            "Time:  0.1302 Epoch: 239 Iter: 2800/3510 LR: 0.0000109572 Loss content:  0.0153 Loss fft:  0.8258\n",
            "Time:  0.1294 Epoch: 239 Iter: 2900/3510 LR: 0.0000109572 Loss content:  0.0155 Loss fft:  0.8667\n",
            "Time:  0.1312 Epoch: 239 Iter: 3000/3510 LR: 0.0000109572 Loss content:  0.0153 Loss fft:  0.8450\n",
            "Time:  0.1303 Epoch: 239 Iter: 3100/3510 LR: 0.0000109572 Loss content:  0.0158 Loss fft:  0.8510\n",
            "Time:  0.1336 Epoch: 239 Iter: 3200/3510 LR: 0.0000109572 Loss content:  0.0162 Loss fft:  0.8690\n",
            "Time:  0.1331 Epoch: 239 Iter: 3300/3510 LR: 0.0000109572 Loss content:  0.0161 Loss fft:  0.8516\n",
            "Time:  0.1318 Epoch: 239 Iter: 3400/3510 LR: 0.0000109572 Loss content:  0.0161 Loss fft:  0.8749\n",
            "Time:  0.1320 Epoch: 239 Iter: 3500/3510 LR: 0.0000109572 Loss content:  0.0161 Loss fft:  0.8709\n",
            "EPOCH: 239\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0159 Epoch FFT Loss:  0.8529\n",
            "Time:  0.1408 Epoch: 240 Iter:  100/3510 LR: 0.0000106445 Loss content:  0.0152 Loss fft:  0.8373\n",
            "Time:  0.1306 Epoch: 240 Iter:  200/3510 LR: 0.0000106445 Loss content:  0.0162 Loss fft:  0.8611\n",
            "Time:  0.1342 Epoch: 240 Iter:  300/3510 LR: 0.0000106445 Loss content:  0.0157 Loss fft:  0.8446\n",
            "Time:  0.1323 Epoch: 240 Iter:  400/3510 LR: 0.0000106445 Loss content:  0.0165 Loss fft:  0.8591\n",
            "Time:  0.1305 Epoch: 240 Iter:  500/3510 LR: 0.0000106445 Loss content:  0.0156 Loss fft:  0.8697\n",
            "Time:  0.1379 Epoch: 240 Iter:  600/3510 LR: 0.0000106445 Loss content:  0.0157 Loss fft:  0.8473\n",
            "Time:  0.1320 Epoch: 240 Iter:  700/3510 LR: 0.0000106445 Loss content:  0.0156 Loss fft:  0.8647\n",
            "Time:  0.1331 Epoch: 240 Iter:  800/3510 LR: 0.0000106445 Loss content:  0.0159 Loss fft:  0.8515\n",
            "Time:  0.1294 Epoch: 240 Iter:  900/3510 LR: 0.0000106445 Loss content:  0.0165 Loss fft:  0.8836\n",
            "Time:  0.1310 Epoch: 240 Iter: 1000/3510 LR: 0.0000106445 Loss content:  0.0149 Loss fft:  0.8460\n",
            "Time:  0.1319 Epoch: 240 Iter: 1100/3510 LR: 0.0000106445 Loss content:  0.0160 Loss fft:  0.8483\n",
            "Time:  0.1340 Epoch: 240 Iter: 1200/3510 LR: 0.0000106445 Loss content:  0.0159 Loss fft:  0.8676\n",
            "Time:  0.1336 Epoch: 240 Iter: 1300/3510 LR: 0.0000106445 Loss content:  0.0161 Loss fft:  0.8606\n",
            "Time:  0.1326 Epoch: 240 Iter: 1400/3510 LR: 0.0000106445 Loss content:  0.0161 Loss fft:  0.8541\n",
            "Time:  0.1319 Epoch: 240 Iter: 1500/3510 LR: 0.0000106445 Loss content:  0.0158 Loss fft:  0.8455\n",
            "Time:  0.1338 Epoch: 240 Iter: 1600/3510 LR: 0.0000106445 Loss content:  0.0158 Loss fft:  0.8405\n",
            "Time:  0.1303 Epoch: 240 Iter: 1700/3510 LR: 0.0000106445 Loss content:  0.0159 Loss fft:  0.8706\n",
            "Time:  0.1338 Epoch: 240 Iter: 1800/3510 LR: 0.0000106445 Loss content:  0.0158 Loss fft:  0.8569\n",
            "Time:  0.1316 Epoch: 240 Iter: 1900/3510 LR: 0.0000106445 Loss content:  0.0156 Loss fft:  0.8588\n",
            "Time:  0.1293 Epoch: 240 Iter: 2000/3510 LR: 0.0000106445 Loss content:  0.0151 Loss fft:  0.8250\n",
            "Time:  0.1289 Epoch: 240 Iter: 2100/3510 LR: 0.0000106445 Loss content:  0.0164 Loss fft:  0.8239\n",
            "Time:  0.1311 Epoch: 240 Iter: 2200/3510 LR: 0.0000106445 Loss content:  0.0158 Loss fft:  0.8677\n",
            "Time:  0.1295 Epoch: 240 Iter: 2300/3510 LR: 0.0000106445 Loss content:  0.0157 Loss fft:  0.8504\n",
            "Time:  0.1305 Epoch: 240 Iter: 2400/3510 LR: 0.0000106445 Loss content:  0.0160 Loss fft:  0.8431\n",
            "Time:  0.1334 Epoch: 240 Iter: 2500/3510 LR: 0.0000106445 Loss content:  0.0166 Loss fft:  0.8603\n",
            "Time:  0.1327 Epoch: 240 Iter: 2600/3510 LR: 0.0000106445 Loss content:  0.0157 Loss fft:  0.8682\n",
            "Time:  0.1311 Epoch: 240 Iter: 2700/3510 LR: 0.0000106445 Loss content:  0.0156 Loss fft:  0.8630\n",
            "Time:  0.1337 Epoch: 240 Iter: 2800/3510 LR: 0.0000106445 Loss content:  0.0157 Loss fft:  0.8592\n",
            "Time:  0.1345 Epoch: 240 Iter: 2900/3510 LR: 0.0000106445 Loss content:  0.0155 Loss fft:  0.8423\n",
            "Time:  0.1308 Epoch: 240 Iter: 3000/3510 LR: 0.0000106445 Loss content:  0.0158 Loss fft:  0.8645\n",
            "Time:  0.1299 Epoch: 240 Iter: 3100/3510 LR: 0.0000106445 Loss content:  0.0156 Loss fft:  0.8645\n",
            "Time:  0.1299 Epoch: 240 Iter: 3200/3510 LR: 0.0000106445 Loss content:  0.0166 Loss fft:  0.8465\n",
            "Time:  0.1296 Epoch: 240 Iter: 3300/3510 LR: 0.0000106445 Loss content:  0.0158 Loss fft:  0.8505\n",
            "Time:  0.1321 Epoch: 240 Iter: 3400/3510 LR: 0.0000106445 Loss content:  0.0159 Loss fft:  0.8490\n",
            "Time:  0.1294 Epoch: 240 Iter: 3500/3510 LR: 0.0000106445 Loss content:  0.0156 Loss fft:  0.8628\n",
            "EPOCH: 240\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0158 Epoch FFT Loss:  0.8541\n",
            "Start Evaluation\n",
            "499 \n",
            "\n",
            "240 epoch \n",
            " Average PSNR 40.84 dB\n",
            "Time:  0.1427 Epoch: 241 Iter:  100/3510 LR: 0.0000103363 Loss content:  0.0155 Loss fft:  0.8375\n",
            "Time:  0.1328 Epoch: 241 Iter:  200/3510 LR: 0.0000103363 Loss content:  0.0153 Loss fft:  0.8591\n",
            "Time:  0.1304 Epoch: 241 Iter:  300/3510 LR: 0.0000103363 Loss content:  0.0159 Loss fft:  0.8512\n",
            "Time:  0.1319 Epoch: 241 Iter:  400/3510 LR: 0.0000103363 Loss content:  0.0156 Loss fft:  0.8591\n",
            "Time:  0.1322 Epoch: 241 Iter:  500/3510 LR: 0.0000103363 Loss content:  0.0163 Loss fft:  0.8595\n",
            "Time:  0.1327 Epoch: 241 Iter:  600/3510 LR: 0.0000103363 Loss content:  0.0152 Loss fft:  0.8279\n",
            "Time:  0.1323 Epoch: 241 Iter:  700/3510 LR: 0.0000103363 Loss content:  0.0158 Loss fft:  0.8600\n",
            "Time:  0.1348 Epoch: 241 Iter:  800/3510 LR: 0.0000103363 Loss content:  0.0159 Loss fft:  0.8459\n",
            "Time:  0.1334 Epoch: 241 Iter:  900/3510 LR: 0.0000103363 Loss content:  0.0153 Loss fft:  0.8437\n",
            "Time:  0.1327 Epoch: 241 Iter: 1000/3510 LR: 0.0000103363 Loss content:  0.0157 Loss fft:  0.8549\n",
            "Time:  0.1293 Epoch: 241 Iter: 1100/3510 LR: 0.0000103363 Loss content:  0.0157 Loss fft:  0.8530\n",
            "Time:  0.1310 Epoch: 241 Iter: 1200/3510 LR: 0.0000103363 Loss content:  0.0163 Loss fft:  0.8718\n",
            "Time:  0.1322 Epoch: 241 Iter: 1300/3510 LR: 0.0000103363 Loss content:  0.0156 Loss fft:  0.8658\n",
            "Time:  0.1336 Epoch: 241 Iter: 1400/3510 LR: 0.0000103363 Loss content:  0.0160 Loss fft:  0.8462\n",
            "Time:  0.1291 Epoch: 241 Iter: 1500/3510 LR: 0.0000103363 Loss content:  0.0164 Loss fft:  0.8553\n",
            "Time:  0.1386 Epoch: 241 Iter: 1600/3510 LR: 0.0000103363 Loss content:  0.0157 Loss fft:  0.8630\n",
            "Time:  0.1314 Epoch: 241 Iter: 1700/3510 LR: 0.0000103363 Loss content:  0.0159 Loss fft:  0.8658\n",
            "Time:  0.1317 Epoch: 241 Iter: 1800/3510 LR: 0.0000103363 Loss content:  0.0154 Loss fft:  0.8574\n",
            "Time:  0.1295 Epoch: 241 Iter: 1900/3510 LR: 0.0000103363 Loss content:  0.0159 Loss fft:  0.8536\n",
            "Time:  0.1333 Epoch: 241 Iter: 2000/3510 LR: 0.0000103363 Loss content:  0.0153 Loss fft:  0.8642\n",
            "Time:  0.1312 Epoch: 241 Iter: 2100/3510 LR: 0.0000103363 Loss content:  0.0157 Loss fft:  0.8414\n",
            "Time:  0.1304 Epoch: 241 Iter: 2200/3510 LR: 0.0000103363 Loss content:  0.0160 Loss fft:  0.8553\n",
            "Time:  0.1325 Epoch: 241 Iter: 2300/3510 LR: 0.0000103363 Loss content:  0.0156 Loss fft:  0.8382\n",
            "Time:  0.1307 Epoch: 241 Iter: 2400/3510 LR: 0.0000103363 Loss content:  0.0153 Loss fft:  0.8352\n",
            "Time:  0.1311 Epoch: 241 Iter: 2500/3510 LR: 0.0000103363 Loss content:  0.0157 Loss fft:  0.8566\n",
            "Time:  0.1317 Epoch: 241 Iter: 2600/3510 LR: 0.0000103363 Loss content:  0.0158 Loss fft:  0.8365\n",
            "Time:  0.1312 Epoch: 241 Iter: 2700/3510 LR: 0.0000103363 Loss content:  0.0153 Loss fft:  0.8601\n",
            "Time:  0.1296 Epoch: 241 Iter: 2800/3510 LR: 0.0000103363 Loss content:  0.0152 Loss fft:  0.8539\n",
            "Time:  0.1299 Epoch: 241 Iter: 2900/3510 LR: 0.0000103363 Loss content:  0.0152 Loss fft:  0.8644\n",
            "Time:  0.1289 Epoch: 241 Iter: 3000/3510 LR: 0.0000103363 Loss content:  0.0155 Loss fft:  0.8343\n",
            "Time:  0.1301 Epoch: 241 Iter: 3100/3510 LR: 0.0000103363 Loss content:  0.0155 Loss fft:  0.8656\n",
            "Time:  0.1278 Epoch: 241 Iter: 3200/3510 LR: 0.0000103363 Loss content:  0.0153 Loss fft:  0.8394\n",
            "Time:  0.1295 Epoch: 241 Iter: 3300/3510 LR: 0.0000103363 Loss content:  0.0166 Loss fft:  0.8710\n",
            "Time:  0.1325 Epoch: 241 Iter: 3400/3510 LR: 0.0000103363 Loss content:  0.0161 Loss fft:  0.8578\n",
            "Time:  0.1330 Epoch: 241 Iter: 3500/3510 LR: 0.0000103363 Loss content:  0.0158 Loss fft:  0.8452\n",
            "EPOCH: 241\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0157 Epoch FFT Loss:  0.8530\n",
            "Time:  0.1415 Epoch: 242 Iter:  100/3510 LR: 0.0000100326 Loss content:  0.0160 Loss fft:  0.8538\n",
            "Time:  0.1326 Epoch: 242 Iter:  200/3510 LR: 0.0000100326 Loss content:  0.0159 Loss fft:  0.8541\n",
            "Time:  0.1381 Epoch: 242 Iter:  300/3510 LR: 0.0000100326 Loss content:  0.0153 Loss fft:  0.8372\n",
            "Time:  0.1326 Epoch: 242 Iter:  400/3510 LR: 0.0000100326 Loss content:  0.0153 Loss fft:  0.8510\n",
            "Time:  0.1321 Epoch: 242 Iter:  500/3510 LR: 0.0000100326 Loss content:  0.0167 Loss fft:  0.8583\n",
            "Time:  0.1324 Epoch: 242 Iter:  600/3510 LR: 0.0000100326 Loss content:  0.0161 Loss fft:  0.8573\n",
            "Time:  0.1291 Epoch: 242 Iter:  700/3510 LR: 0.0000100326 Loss content:  0.0156 Loss fft:  0.8376\n",
            "Time:  0.1329 Epoch: 242 Iter:  800/3510 LR: 0.0000100326 Loss content:  0.0156 Loss fft:  0.8650\n",
            "Time:  0.1311 Epoch: 242 Iter:  900/3510 LR: 0.0000100326 Loss content:  0.0151 Loss fft:  0.8482\n",
            "Time:  0.1323 Epoch: 242 Iter: 1000/3510 LR: 0.0000100326 Loss content:  0.0158 Loss fft:  0.8475\n",
            "Time:  0.1300 Epoch: 242 Iter: 1100/3510 LR: 0.0000100326 Loss content:  0.0154 Loss fft:  0.8378\n",
            "Time:  0.1287 Epoch: 242 Iter: 1200/3510 LR: 0.0000100326 Loss content:  0.0152 Loss fft:  0.8439\n",
            "Time:  0.1287 Epoch: 242 Iter: 1300/3510 LR: 0.0000100326 Loss content:  0.0156 Loss fft:  0.8641\n",
            "Time:  0.1293 Epoch: 242 Iter: 1400/3510 LR: 0.0000100326 Loss content:  0.0153 Loss fft:  0.8598\n",
            "Time:  0.1330 Epoch: 242 Iter: 1500/3510 LR: 0.0000100326 Loss content:  0.0151 Loss fft:  0.8537\n",
            "Time:  0.1324 Epoch: 242 Iter: 1600/3510 LR: 0.0000100326 Loss content:  0.0158 Loss fft:  0.8531\n",
            "Time:  0.1314 Epoch: 242 Iter: 1700/3510 LR: 0.0000100326 Loss content:  0.0154 Loss fft:  0.8400\n",
            "Time:  0.1337 Epoch: 242 Iter: 1800/3510 LR: 0.0000100326 Loss content:  0.0162 Loss fft:  0.8585\n",
            "Time:  0.1329 Epoch: 242 Iter: 1900/3510 LR: 0.0000100326 Loss content:  0.0157 Loss fft:  0.8543\n",
            "Time:  0.1313 Epoch: 242 Iter: 2000/3510 LR: 0.0000100326 Loss content:  0.0158 Loss fft:  0.8475\n",
            "Time:  0.1338 Epoch: 242 Iter: 2100/3510 LR: 0.0000100326 Loss content:  0.0156 Loss fft:  0.8544\n",
            "Time:  0.1327 Epoch: 242 Iter: 2200/3510 LR: 0.0000100326 Loss content:  0.0161 Loss fft:  0.8559\n",
            "Time:  0.1328 Epoch: 242 Iter: 2300/3510 LR: 0.0000100326 Loss content:  0.0158 Loss fft:  0.8651\n",
            "Time:  0.1296 Epoch: 242 Iter: 2400/3510 LR: 0.0000100326 Loss content:  0.0156 Loss fft:  0.8566\n",
            "Time:  0.1336 Epoch: 242 Iter: 2500/3510 LR: 0.0000100326 Loss content:  0.0157 Loss fft:  0.8511\n",
            "Time:  0.1354 Epoch: 242 Iter: 2600/3510 LR: 0.0000100326 Loss content:  0.0154 Loss fft:  0.8545\n",
            "Time:  0.1319 Epoch: 242 Iter: 2700/3510 LR: 0.0000100326 Loss content:  0.0157 Loss fft:  0.8558\n",
            "Time:  0.1320 Epoch: 242 Iter: 2800/3510 LR: 0.0000100326 Loss content:  0.0157 Loss fft:  0.8391\n",
            "Time:  0.1305 Epoch: 242 Iter: 2900/3510 LR: 0.0000100326 Loss content:  0.0150 Loss fft:  0.8349\n",
            "Time:  0.1323 Epoch: 242 Iter: 3000/3510 LR: 0.0000100326 Loss content:  0.0156 Loss fft:  0.8557\n",
            "Time:  0.1325 Epoch: 242 Iter: 3100/3510 LR: 0.0000100326 Loss content:  0.0161 Loss fft:  0.8784\n",
            "Time:  0.1323 Epoch: 242 Iter: 3200/3510 LR: 0.0000100326 Loss content:  0.0151 Loss fft:  0.8352\n",
            "Time:  0.1334 Epoch: 242 Iter: 3300/3510 LR: 0.0000100326 Loss content:  0.0156 Loss fft:  0.8667\n",
            "Time:  0.1299 Epoch: 242 Iter: 3400/3510 LR: 0.0000100326 Loss content:  0.0159 Loss fft:  0.8532\n",
            "Time:  0.1337 Epoch: 242 Iter: 3500/3510 LR: 0.0000100326 Loss content:  0.0152 Loss fft:  0.8485\n",
            "EPOCH: 242\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0156 Epoch FFT Loss:  0.8522\n",
            "Time:  0.1413 Epoch: 243 Iter:  100/3510 LR: 0.0000097334 Loss content:  0.0157 Loss fft:  0.8583\n",
            "Time:  0.1313 Epoch: 243 Iter:  200/3510 LR: 0.0000097334 Loss content:  0.0157 Loss fft:  0.8791\n",
            "Time:  0.1331 Epoch: 243 Iter:  300/3510 LR: 0.0000097334 Loss content:  0.0161 Loss fft:  0.8410\n",
            "Time:  0.1331 Epoch: 243 Iter:  400/3510 LR: 0.0000097334 Loss content:  0.0155 Loss fft:  0.8400\n",
            "Time:  0.1321 Epoch: 243 Iter:  500/3510 LR: 0.0000097334 Loss content:  0.0158 Loss fft:  0.8714\n",
            "Time:  0.1323 Epoch: 243 Iter:  600/3510 LR: 0.0000097334 Loss content:  0.0158 Loss fft:  0.8697\n",
            "Time:  0.1319 Epoch: 243 Iter:  700/3510 LR: 0.0000097334 Loss content:  0.0159 Loss fft:  0.8497\n",
            "Time:  0.1308 Epoch: 243 Iter:  800/3510 LR: 0.0000097334 Loss content:  0.0160 Loss fft:  0.8795\n",
            "Time:  0.1323 Epoch: 243 Iter:  900/3510 LR: 0.0000097334 Loss content:  0.0155 Loss fft:  0.8597\n",
            "Time:  0.1321 Epoch: 243 Iter: 1000/3510 LR: 0.0000097334 Loss content:  0.0155 Loss fft:  0.8518\n",
            "Time:  0.1334 Epoch: 243 Iter: 1100/3510 LR: 0.0000097334 Loss content:  0.0152 Loss fft:  0.8509\n",
            "Time:  0.1318 Epoch: 243 Iter: 1200/3510 LR: 0.0000097334 Loss content:  0.0153 Loss fft:  0.8415\n",
            "Time:  0.1384 Epoch: 243 Iter: 1300/3510 LR: 0.0000097334 Loss content:  0.0156 Loss fft:  0.8519\n",
            "Time:  0.1321 Epoch: 243 Iter: 1400/3510 LR: 0.0000097334 Loss content:  0.0157 Loss fft:  0.8521\n",
            "Time:  0.1335 Epoch: 243 Iter: 1500/3510 LR: 0.0000097334 Loss content:  0.0155 Loss fft:  0.8628\n",
            "Time:  0.1309 Epoch: 243 Iter: 1600/3510 LR: 0.0000097334 Loss content:  0.0161 Loss fft:  0.8734\n",
            "Time:  0.1327 Epoch: 243 Iter: 1700/3510 LR: 0.0000097334 Loss content:  0.0159 Loss fft:  0.8507\n",
            "Time:  0.1312 Epoch: 243 Iter: 1800/3510 LR: 0.0000097334 Loss content:  0.0155 Loss fft:  0.8465\n",
            "Time:  0.1337 Epoch: 243 Iter: 1900/3510 LR: 0.0000097334 Loss content:  0.0154 Loss fft:  0.8507\n",
            "Time:  0.1305 Epoch: 243 Iter: 2000/3510 LR: 0.0000097334 Loss content:  0.0153 Loss fft:  0.8538\n",
            "Time:  0.1318 Epoch: 243 Iter: 2100/3510 LR: 0.0000097334 Loss content:  0.0152 Loss fft:  0.8353\n",
            "Time:  0.1284 Epoch: 243 Iter: 2200/3510 LR: 0.0000097334 Loss content:  0.0157 Loss fft:  0.8398\n",
            "Time:  0.1339 Epoch: 243 Iter: 2300/3510 LR: 0.0000097334 Loss content:  0.0150 Loss fft:  0.8464\n",
            "Time:  0.1311 Epoch: 243 Iter: 2400/3510 LR: 0.0000097334 Loss content:  0.0154 Loss fft:  0.8522\n",
            "Time:  0.1339 Epoch: 243 Iter: 2500/3510 LR: 0.0000097334 Loss content:  0.0151 Loss fft:  0.8576\n",
            "Time:  0.1310 Epoch: 243 Iter: 2600/3510 LR: 0.0000097334 Loss content:  0.0153 Loss fft:  0.8448\n",
            "Time:  0.1327 Epoch: 243 Iter: 2700/3510 LR: 0.0000097334 Loss content:  0.0153 Loss fft:  0.8553\n",
            "Time:  0.1308 Epoch: 243 Iter: 2800/3510 LR: 0.0000097334 Loss content:  0.0155 Loss fft:  0.8487\n",
            "Time:  0.1325 Epoch: 243 Iter: 2900/3510 LR: 0.0000097334 Loss content:  0.0154 Loss fft:  0.8458\n",
            "Time:  0.1310 Epoch: 243 Iter: 3000/3510 LR: 0.0000097334 Loss content:  0.0153 Loss fft:  0.8349\n",
            "Time:  0.1317 Epoch: 243 Iter: 3100/3510 LR: 0.0000097334 Loss content:  0.0151 Loss fft:  0.8222\n",
            "Time:  0.1303 Epoch: 243 Iter: 3200/3510 LR: 0.0000097334 Loss content:  0.0160 Loss fft:  0.8871\n",
            "Time:  0.1302 Epoch: 243 Iter: 3300/3510 LR: 0.0000097334 Loss content:  0.0165 Loss fft:  0.8675\n",
            "Time:  0.1296 Epoch: 243 Iter: 3400/3510 LR: 0.0000097334 Loss content:  0.0156 Loss fft:  0.8404\n",
            "Time:  0.1313 Epoch: 243 Iter: 3500/3510 LR: 0.0000097334 Loss content:  0.0153 Loss fft:  0.8506\n",
            "EPOCH: 243\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0156 Epoch FFT Loss:  0.8532\n",
            "Time:  0.1415 Epoch: 244 Iter:  100/3510 LR: 0.0000094387 Loss content:  0.0153 Loss fft:  0.8491\n",
            "Time:  0.1337 Epoch: 244 Iter:  200/3510 LR: 0.0000094387 Loss content:  0.0156 Loss fft:  0.8640\n",
            "Time:  0.1313 Epoch: 244 Iter:  300/3510 LR: 0.0000094387 Loss content:  0.0156 Loss fft:  0.8589\n",
            "Time:  0.1310 Epoch: 244 Iter:  400/3510 LR: 0.0000094387 Loss content:  0.0152 Loss fft:  0.8354\n",
            "Time:  0.1312 Epoch: 244 Iter:  500/3510 LR: 0.0000094387 Loss content:  0.0157 Loss fft:  0.8522\n",
            "Time:  0.1289 Epoch: 244 Iter:  600/3510 LR: 0.0000094387 Loss content:  0.0159 Loss fft:  0.8588\n",
            "Time:  0.1329 Epoch: 244 Iter:  700/3510 LR: 0.0000094387 Loss content:  0.0158 Loss fft:  0.8639\n",
            "Time:  0.1310 Epoch: 244 Iter:  800/3510 LR: 0.0000094387 Loss content:  0.0156 Loss fft:  0.8495\n",
            "Time:  0.1322 Epoch: 244 Iter:  900/3510 LR: 0.0000094387 Loss content:  0.0158 Loss fft:  0.8565\n",
            "Time:  0.1280 Epoch: 244 Iter: 1000/3510 LR: 0.0000094387 Loss content:  0.0155 Loss fft:  0.8481\n",
            "Time:  0.1327 Epoch: 244 Iter: 1100/3510 LR: 0.0000094387 Loss content:  0.0150 Loss fft:  0.8454\n",
            "Time:  0.1321 Epoch: 244 Iter: 1200/3510 LR: 0.0000094387 Loss content:  0.0157 Loss fft:  0.8336\n",
            "Time:  0.1307 Epoch: 244 Iter: 1300/3510 LR: 0.0000094387 Loss content:  0.0150 Loss fft:  0.8268\n",
            "Time:  0.1312 Epoch: 244 Iter: 1400/3510 LR: 0.0000094387 Loss content:  0.0161 Loss fft:  0.8340\n",
            "Time:  0.1300 Epoch: 244 Iter: 1500/3510 LR: 0.0000094387 Loss content:  0.0155 Loss fft:  0.8435\n",
            "Time:  0.1312 Epoch: 244 Iter: 1600/3510 LR: 0.0000094387 Loss content:  0.0152 Loss fft:  0.8497\n",
            "Time:  0.1294 Epoch: 244 Iter: 1700/3510 LR: 0.0000094387 Loss content:  0.0157 Loss fft:  0.8534\n",
            "Time:  0.1287 Epoch: 244 Iter: 1800/3510 LR: 0.0000094387 Loss content:  0.0150 Loss fft:  0.8567\n",
            "Time:  0.1282 Epoch: 244 Iter: 1900/3510 LR: 0.0000094387 Loss content:  0.0160 Loss fft:  0.8770\n",
            "Time:  0.1315 Epoch: 244 Iter: 2000/3510 LR: 0.0000094387 Loss content:  0.0152 Loss fft:  0.8514\n",
            "Time:  0.1303 Epoch: 244 Iter: 2100/3510 LR: 0.0000094387 Loss content:  0.0157 Loss fft:  0.8616\n",
            "Time:  0.1328 Epoch: 244 Iter: 2200/3510 LR: 0.0000094387 Loss content:  0.0160 Loss fft:  0.8448\n",
            "Time:  0.1303 Epoch: 244 Iter: 2300/3510 LR: 0.0000094387 Loss content:  0.0159 Loss fft:  0.8482\n",
            "Time:  0.1380 Epoch: 244 Iter: 2400/3510 LR: 0.0000094387 Loss content:  0.0159 Loss fft:  0.8651\n",
            "Time:  0.1347 Epoch: 244 Iter: 2500/3510 LR: 0.0000094387 Loss content:  0.0156 Loss fft:  0.8559\n",
            "Time:  0.1303 Epoch: 244 Iter: 2600/3510 LR: 0.0000094387 Loss content:  0.0152 Loss fft:  0.8262\n",
            "Time:  0.1322 Epoch: 244 Iter: 2700/3510 LR: 0.0000094387 Loss content:  0.0151 Loss fft:  0.8471\n",
            "Time:  0.1281 Epoch: 244 Iter: 2800/3510 LR: 0.0000094387 Loss content:  0.0153 Loss fft:  0.8389\n",
            "Time:  0.1302 Epoch: 244 Iter: 2900/3510 LR: 0.0000094387 Loss content:  0.0159 Loss fft:  0.8528\n",
            "Time:  0.1312 Epoch: 244 Iter: 3000/3510 LR: 0.0000094387 Loss content:  0.0153 Loss fft:  0.8371\n",
            "Time:  0.1315 Epoch: 244 Iter: 3100/3510 LR: 0.0000094387 Loss content:  0.0157 Loss fft:  0.8456\n",
            "Time:  0.1313 Epoch: 244 Iter: 3200/3510 LR: 0.0000094387 Loss content:  0.0152 Loss fft:  0.8475\n",
            "Time:  0.1331 Epoch: 244 Iter: 3300/3510 LR: 0.0000094387 Loss content:  0.0154 Loss fft:  0.8476\n",
            "Time:  0.1310 Epoch: 244 Iter: 3400/3510 LR: 0.0000094387 Loss content:  0.0158 Loss fft:  0.8591\n",
            "Time:  0.1307 Epoch: 244 Iter: 3500/3510 LR: 0.0000094387 Loss content:  0.0153 Loss fft:  0.8436\n",
            "EPOCH: 244\n",
            "Elapsed time: 4.62 Epoch Pixel Loss:  0.0155 Epoch FFT Loss:  0.8494\n",
            "Time:  0.1406 Epoch: 245 Iter:  100/3510 LR: 0.0000091487 Loss content:  0.0155 Loss fft:  0.8573\n",
            "Time:  0.1310 Epoch: 245 Iter:  200/3510 LR: 0.0000091487 Loss content:  0.0156 Loss fft:  0.8598\n",
            "Time:  0.1302 Epoch: 245 Iter:  300/3510 LR: 0.0000091487 Loss content:  0.0161 Loss fft:  0.8599\n",
            "Time:  0.1292 Epoch: 245 Iter:  400/3510 LR: 0.0000091487 Loss content:  0.0155 Loss fft:  0.8567\n",
            "Time:  0.1299 Epoch: 245 Iter:  500/3510 LR: 0.0000091487 Loss content:  0.0150 Loss fft:  0.8460\n",
            "Time:  0.1289 Epoch: 245 Iter:  600/3510 LR: 0.0000091487 Loss content:  0.0158 Loss fft:  0.8492\n",
            "Time:  0.1325 Epoch: 245 Iter:  700/3510 LR: 0.0000091487 Loss content:  0.0156 Loss fft:  0.8426\n",
            "Time:  0.1298 Epoch: 245 Iter:  800/3510 LR: 0.0000091487 Loss content:  0.0154 Loss fft:  0.8346\n",
            "Time:  0.1311 Epoch: 245 Iter:  900/3510 LR: 0.0000091487 Loss content:  0.0155 Loss fft:  0.8520\n",
            "Time:  0.1318 Epoch: 245 Iter: 1000/3510 LR: 0.0000091487 Loss content:  0.0155 Loss fft:  0.8513\n",
            "Time:  0.1296 Epoch: 245 Iter: 1100/3510 LR: 0.0000091487 Loss content:  0.0146 Loss fft:  0.8242\n",
            "Time:  0.1362 Epoch: 245 Iter: 1200/3510 LR: 0.0000091487 Loss content:  0.0154 Loss fft:  0.8380\n",
            "Time:  0.1313 Epoch: 245 Iter: 1300/3510 LR: 0.0000091487 Loss content:  0.0154 Loss fft:  0.8326\n",
            "Time:  0.1325 Epoch: 245 Iter: 1400/3510 LR: 0.0000091487 Loss content:  0.0158 Loss fft:  0.8577\n",
            "Time:  0.1301 Epoch: 245 Iter: 1500/3510 LR: 0.0000091487 Loss content:  0.0156 Loss fft:  0.8627\n",
            "Time:  0.1309 Epoch: 245 Iter: 1600/3510 LR: 0.0000091487 Loss content:  0.0160 Loss fft:  0.8557\n",
            "Time:  0.1277 Epoch: 245 Iter: 1700/3510 LR: 0.0000091487 Loss content:  0.0157 Loss fft:  0.8413\n",
            "Time:  0.1340 Epoch: 245 Iter: 1800/3510 LR: 0.0000091487 Loss content:  0.0149 Loss fft:  0.8444\n",
            "Time:  0.1336 Epoch: 245 Iter: 1900/3510 LR: 0.0000091487 Loss content:  0.0155 Loss fft:  0.8367\n",
            "Time:  0.1319 Epoch: 245 Iter: 2000/3510 LR: 0.0000091487 Loss content:  0.0161 Loss fft:  0.8465\n",
            "Time:  0.1307 Epoch: 245 Iter: 2100/3510 LR: 0.0000091487 Loss content:  0.0154 Loss fft:  0.8380\n",
            "Time:  0.1314 Epoch: 245 Iter: 2200/3510 LR: 0.0000091487 Loss content:  0.0155 Loss fft:  0.8525\n",
            "Time:  0.1324 Epoch: 245 Iter: 2300/3510 LR: 0.0000091487 Loss content:  0.0158 Loss fft:  0.8645\n",
            "Time:  0.1311 Epoch: 245 Iter: 2400/3510 LR: 0.0000091487 Loss content:  0.0154 Loss fft:  0.8542\n",
            "Time:  0.1323 Epoch: 245 Iter: 2500/3510 LR: 0.0000091487 Loss content:  0.0159 Loss fft:  0.8305\n",
            "Time:  0.1322 Epoch: 245 Iter: 2600/3510 LR: 0.0000091487 Loss content:  0.0154 Loss fft:  0.8574\n",
            "Time:  0.1324 Epoch: 245 Iter: 2700/3510 LR: 0.0000091487 Loss content:  0.0156 Loss fft:  0.8595\n",
            "Time:  0.1291 Epoch: 245 Iter: 2800/3510 LR: 0.0000091487 Loss content:  0.0156 Loss fft:  0.8589\n",
            "Time:  0.1314 Epoch: 245 Iter: 2900/3510 LR: 0.0000091487 Loss content:  0.0151 Loss fft:  0.8569\n",
            "Time:  0.1325 Epoch: 245 Iter: 3000/3510 LR: 0.0000091487 Loss content:  0.0158 Loss fft:  0.8606\n",
            "Time:  0.1323 Epoch: 245 Iter: 3100/3510 LR: 0.0000091487 Loss content:  0.0163 Loss fft:  0.8404\n",
            "Time:  0.1309 Epoch: 245 Iter: 3200/3510 LR: 0.0000091487 Loss content:  0.0155 Loss fft:  0.8342\n",
            "Time:  0.1321 Epoch: 245 Iter: 3300/3510 LR: 0.0000091487 Loss content:  0.0151 Loss fft:  0.8393\n",
            "Time:  0.1325 Epoch: 245 Iter: 3400/3510 LR: 0.0000091487 Loss content:  0.0155 Loss fft:  0.8581\n",
            "Time:  0.1386 Epoch: 245 Iter: 3500/3510 LR: 0.0000091487 Loss content:  0.0161 Loss fft:  0.8617\n",
            "EPOCH: 245\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0155 Epoch FFT Loss:  0.8490\n",
            "Time:  0.1429 Epoch: 246 Iter:  100/3510 LR: 0.0000088633 Loss content:  0.0159 Loss fft:  0.8427\n",
            "Time:  0.1332 Epoch: 246 Iter:  200/3510 LR: 0.0000088633 Loss content:  0.0156 Loss fft:  0.8477\n",
            "Time:  0.1319 Epoch: 246 Iter:  300/3510 LR: 0.0000088633 Loss content:  0.0156 Loss fft:  0.8529\n",
            "Time:  0.1314 Epoch: 246 Iter:  400/3510 LR: 0.0000088633 Loss content:  0.0153 Loss fft:  0.8451\n",
            "Time:  0.1297 Epoch: 246 Iter:  500/3510 LR: 0.0000088633 Loss content:  0.0158 Loss fft:  0.8601\n",
            "Time:  0.1302 Epoch: 246 Iter:  600/3510 LR: 0.0000088633 Loss content:  0.0154 Loss fft:  0.8581\n",
            "Time:  0.1292 Epoch: 246 Iter:  700/3510 LR: 0.0000088633 Loss content:  0.0156 Loss fft:  0.8468\n",
            "Time:  0.1314 Epoch: 246 Iter:  800/3510 LR: 0.0000088633 Loss content:  0.0161 Loss fft:  0.8687\n",
            "Time:  0.1280 Epoch: 246 Iter:  900/3510 LR: 0.0000088633 Loss content:  0.0158 Loss fft:  0.8511\n",
            "Time:  0.1312 Epoch: 246 Iter: 1000/3510 LR: 0.0000088633 Loss content:  0.0163 Loss fft:  0.8546\n",
            "Time:  0.1326 Epoch: 246 Iter: 1100/3510 LR: 0.0000088633 Loss content:  0.0158 Loss fft:  0.8688\n",
            "Time:  0.1306 Epoch: 246 Iter: 1200/3510 LR: 0.0000088633 Loss content:  0.0146 Loss fft:  0.8514\n",
            "Time:  0.1285 Epoch: 246 Iter: 1300/3510 LR: 0.0000088633 Loss content:  0.0158 Loss fft:  0.8397\n",
            "Time:  0.1318 Epoch: 246 Iter: 1400/3510 LR: 0.0000088633 Loss content:  0.0158 Loss fft:  0.8707\n",
            "Time:  0.1340 Epoch: 246 Iter: 1500/3510 LR: 0.0000088633 Loss content:  0.0148 Loss fft:  0.8497\n",
            "Time:  0.1325 Epoch: 246 Iter: 1600/3510 LR: 0.0000088633 Loss content:  0.0151 Loss fft:  0.8233\n",
            "Time:  0.1327 Epoch: 246 Iter: 1700/3510 LR: 0.0000088633 Loss content:  0.0151 Loss fft:  0.8263\n",
            "Time:  0.1310 Epoch: 246 Iter: 1800/3510 LR: 0.0000088633 Loss content:  0.0156 Loss fft:  0.8358\n",
            "Time:  0.1318 Epoch: 246 Iter: 1900/3510 LR: 0.0000088633 Loss content:  0.0158 Loss fft:  0.8433\n",
            "Time:  0.1277 Epoch: 246 Iter: 2000/3510 LR: 0.0000088633 Loss content:  0.0151 Loss fft:  0.8314\n",
            "Time:  0.1303 Epoch: 246 Iter: 2100/3510 LR: 0.0000088633 Loss content:  0.0151 Loss fft:  0.8484\n",
            "Time:  0.1288 Epoch: 246 Iter: 2200/3510 LR: 0.0000088633 Loss content:  0.0154 Loss fft:  0.8320\n",
            "Time:  0.1362 Epoch: 246 Iter: 2300/3510 LR: 0.0000088633 Loss content:  0.0151 Loss fft:  0.8513\n",
            "Time:  0.1296 Epoch: 246 Iter: 2400/3510 LR: 0.0000088633 Loss content:  0.0157 Loss fft:  0.8638\n",
            "Time:  0.1326 Epoch: 246 Iter: 2500/3510 LR: 0.0000088633 Loss content:  0.0155 Loss fft:  0.8555\n",
            "Time:  0.1306 Epoch: 246 Iter: 2600/3510 LR: 0.0000088633 Loss content:  0.0146 Loss fft:  0.8364\n",
            "Time:  0.1300 Epoch: 246 Iter: 2700/3510 LR: 0.0000088633 Loss content:  0.0158 Loss fft:  0.8561\n",
            "Time:  0.1306 Epoch: 246 Iter: 2800/3510 LR: 0.0000088633 Loss content:  0.0154 Loss fft:  0.8657\n",
            "Time:  0.1294 Epoch: 246 Iter: 2900/3510 LR: 0.0000088633 Loss content:  0.0154 Loss fft:  0.8455\n",
            "Time:  0.1325 Epoch: 246 Iter: 3000/3510 LR: 0.0000088633 Loss content:  0.0157 Loss fft:  0.8714\n",
            "Time:  0.1288 Epoch: 246 Iter: 3100/3510 LR: 0.0000088633 Loss content:  0.0160 Loss fft:  0.8612\n",
            "Time:  0.1296 Epoch: 246 Iter: 3200/3510 LR: 0.0000088633 Loss content:  0.0153 Loss fft:  0.8448\n",
            "Time:  0.1301 Epoch: 246 Iter: 3300/3510 LR: 0.0000088633 Loss content:  0.0156 Loss fft:  0.8576\n",
            "Time:  0.1314 Epoch: 246 Iter: 3400/3510 LR: 0.0000088633 Loss content:  0.0153 Loss fft:  0.8299\n",
            "Time:  0.1300 Epoch: 246 Iter: 3500/3510 LR: 0.0000088633 Loss content:  0.0150 Loss fft:  0.8425\n",
            "EPOCH: 246\n",
            "Elapsed time: 4.61 Epoch Pixel Loss:  0.0155 Epoch FFT Loss:  0.8494\n",
            "Time:  0.1392 Epoch: 247 Iter:  100/3510 LR: 0.0000085825 Loss content:  0.0156 Loss fft:  0.8574\n",
            "Time:  0.1288 Epoch: 247 Iter:  200/3510 LR: 0.0000085825 Loss content:  0.0149 Loss fft:  0.8423\n",
            "Time:  0.1323 Epoch: 247 Iter:  300/3510 LR: 0.0000085825 Loss content:  0.0150 Loss fft:  0.8493\n",
            "Time:  0.1303 Epoch: 247 Iter:  400/3510 LR: 0.0000085825 Loss content:  0.0156 Loss fft:  0.8349\n",
            "Time:  0.1300 Epoch: 247 Iter:  500/3510 LR: 0.0000085825 Loss content:  0.0160 Loss fft:  0.8594\n",
            "Time:  0.1306 Epoch: 247 Iter:  600/3510 LR: 0.0000085825 Loss content:  0.0147 Loss fft:  0.8501\n",
            "Time:  0.1294 Epoch: 247 Iter:  700/3510 LR: 0.0000085825 Loss content:  0.0157 Loss fft:  0.8486\n",
            "Time:  0.1324 Epoch: 247 Iter:  800/3510 LR: 0.0000085825 Loss content:  0.0154 Loss fft:  0.8230\n",
            "Time:  0.1320 Epoch: 247 Iter:  900/3510 LR: 0.0000085825 Loss content:  0.0160 Loss fft:  0.8510\n",
            "Time:  0.1377 Epoch: 247 Iter: 1000/3510 LR: 0.0000085825 Loss content:  0.0156 Loss fft:  0.8410\n",
            "Time:  0.1328 Epoch: 247 Iter: 1100/3510 LR: 0.0000085825 Loss content:  0.0158 Loss fft:  0.8553\n",
            "Time:  0.1288 Epoch: 247 Iter: 1200/3510 LR: 0.0000085825 Loss content:  0.0151 Loss fft:  0.8493\n",
            "Time:  0.1294 Epoch: 247 Iter: 1300/3510 LR: 0.0000085825 Loss content:  0.0153 Loss fft:  0.8390\n",
            "Time:  0.1291 Epoch: 247 Iter: 1400/3510 LR: 0.0000085825 Loss content:  0.0156 Loss fft:  0.8544\n",
            "Time:  0.1303 Epoch: 247 Iter: 1500/3510 LR: 0.0000085825 Loss content:  0.0155 Loss fft:  0.8454\n",
            "Time:  0.1286 Epoch: 247 Iter: 1600/3510 LR: 0.0000085825 Loss content:  0.0153 Loss fft:  0.8528\n",
            "Time:  0.1297 Epoch: 247 Iter: 1700/3510 LR: 0.0000085825 Loss content:  0.0155 Loss fft:  0.8504\n",
            "Time:  0.1329 Epoch: 247 Iter: 1800/3510 LR: 0.0000085825 Loss content:  0.0153 Loss fft:  0.8476\n",
            "Time:  0.1304 Epoch: 247 Iter: 1900/3510 LR: 0.0000085825 Loss content:  0.0154 Loss fft:  0.8651\n",
            "Time:  0.1296 Epoch: 247 Iter: 2000/3510 LR: 0.0000085825 Loss content:  0.0152 Loss fft:  0.8482\n",
            "Time:  0.1316 Epoch: 247 Iter: 2100/3510 LR: 0.0000085825 Loss content:  0.0154 Loss fft:  0.8434\n",
            "Time:  0.1294 Epoch: 247 Iter: 2200/3510 LR: 0.0000085825 Loss content:  0.0150 Loss fft:  0.8325\n",
            "Time:  0.1306 Epoch: 247 Iter: 2300/3510 LR: 0.0000085825 Loss content:  0.0155 Loss fft:  0.8383\n",
            "Time:  0.1284 Epoch: 247 Iter: 2400/3510 LR: 0.0000085825 Loss content:  0.0152 Loss fft:  0.8370\n",
            "Time:  0.1323 Epoch: 247 Iter: 2500/3510 LR: 0.0000085825 Loss content:  0.0146 Loss fft:  0.8155\n",
            "Time:  0.1338 Epoch: 247 Iter: 2600/3510 LR: 0.0000085825 Loss content:  0.0156 Loss fft:  0.8523\n",
            "Time:  0.1307 Epoch: 247 Iter: 2700/3510 LR: 0.0000085825 Loss content:  0.0153 Loss fft:  0.8315\n",
            "Time:  0.1318 Epoch: 247 Iter: 2800/3510 LR: 0.0000085825 Loss content:  0.0150 Loss fft:  0.8545\n",
            "Time:  0.1306 Epoch: 247 Iter: 2900/3510 LR: 0.0000085825 Loss content:  0.0155 Loss fft:  0.8533\n",
            "Time:  0.1335 Epoch: 247 Iter: 3000/3510 LR: 0.0000085825 Loss content:  0.0152 Loss fft:  0.8481\n",
            "Time:  0.1298 Epoch: 247 Iter: 3100/3510 LR: 0.0000085825 Loss content:  0.0153 Loss fft:  0.8520\n",
            "Time:  0.1322 Epoch: 247 Iter: 3200/3510 LR: 0.0000085825 Loss content:  0.0158 Loss fft:  0.8583\n",
            "Time:  0.1342 Epoch: 247 Iter: 3300/3510 LR: 0.0000085825 Loss content:  0.0155 Loss fft:  0.8579\n",
            "Time:  0.1359 Epoch: 247 Iter: 3400/3510 LR: 0.0000085825 Loss content:  0.0161 Loss fft:  0.8550\n",
            "Time:  0.1317 Epoch: 247 Iter: 3500/3510 LR: 0.0000085825 Loss content:  0.0147 Loss fft:  0.8464\n",
            "EPOCH: 247\n",
            "Elapsed time: 4.62 Epoch Pixel Loss:  0.0154 Epoch FFT Loss:  0.8467\n",
            "Time:  0.1429 Epoch: 248 Iter:  100/3510 LR: 0.0000083065 Loss content:  0.0150 Loss fft:  0.8390\n",
            "Time:  0.1307 Epoch: 248 Iter:  200/3510 LR: 0.0000083065 Loss content:  0.0151 Loss fft:  0.8376\n",
            "Time:  0.1292 Epoch: 248 Iter:  300/3510 LR: 0.0000083065 Loss content:  0.0160 Loss fft:  0.8267\n",
            "Time:  0.1307 Epoch: 248 Iter:  400/3510 LR: 0.0000083065 Loss content:  0.0150 Loss fft:  0.8621\n",
            "Time:  0.1288 Epoch: 248 Iter:  500/3510 LR: 0.0000083065 Loss content:  0.0145 Loss fft:  0.8249\n",
            "Time:  0.1314 Epoch: 248 Iter:  600/3510 LR: 0.0000083065 Loss content:  0.0151 Loss fft:  0.8348\n",
            "Time:  0.1331 Epoch: 248 Iter:  700/3510 LR: 0.0000083065 Loss content:  0.0147 Loss fft:  0.8390\n",
            "Time:  0.1326 Epoch: 248 Iter:  800/3510 LR: 0.0000083065 Loss content:  0.0150 Loss fft:  0.8618\n",
            "Time:  0.1317 Epoch: 248 Iter:  900/3510 LR: 0.0000083065 Loss content:  0.0150 Loss fft:  0.8347\n",
            "Time:  0.1330 Epoch: 248 Iter: 1000/3510 LR: 0.0000083065 Loss content:  0.0162 Loss fft:  0.8774\n",
            "Time:  0.1322 Epoch: 248 Iter: 1100/3510 LR: 0.0000083065 Loss content:  0.0151 Loss fft:  0.8446\n",
            "Time:  0.1288 Epoch: 248 Iter: 1200/3510 LR: 0.0000083065 Loss content:  0.0150 Loss fft:  0.8508\n",
            "Time:  0.1328 Epoch: 248 Iter: 1300/3510 LR: 0.0000083065 Loss content:  0.0150 Loss fft:  0.8361\n",
            "Time:  0.1296 Epoch: 248 Iter: 1400/3510 LR: 0.0000083065 Loss content:  0.0153 Loss fft:  0.8510\n",
            "Time:  0.1285 Epoch: 248 Iter: 1500/3510 LR: 0.0000083065 Loss content:  0.0155 Loss fft:  0.8582\n",
            "Time:  0.1279 Epoch: 248 Iter: 1600/3510 LR: 0.0000083065 Loss content:  0.0152 Loss fft:  0.8419\n",
            "Time:  0.1331 Epoch: 248 Iter: 1700/3510 LR: 0.0000083065 Loss content:  0.0153 Loss fft:  0.8577\n",
            "Time:  0.1345 Epoch: 248 Iter: 1800/3510 LR: 0.0000083065 Loss content:  0.0152 Loss fft:  0.8438\n",
            "Time:  0.1302 Epoch: 248 Iter: 1900/3510 LR: 0.0000083065 Loss content:  0.0154 Loss fft:  0.8498\n",
            "Time:  0.1325 Epoch: 248 Iter: 2000/3510 LR: 0.0000083065 Loss content:  0.0160 Loss fft:  0.8538\n",
            "Time:  0.1320 Epoch: 248 Iter: 2100/3510 LR: 0.0000083065 Loss content:  0.0153 Loss fft:  0.8537\n",
            "Time:  0.1395 Epoch: 248 Iter: 2200/3510 LR: 0.0000083065 Loss content:  0.0154 Loss fft:  0.8461\n",
            "Time:  0.1303 Epoch: 248 Iter: 2300/3510 LR: 0.0000083065 Loss content:  0.0158 Loss fft:  0.8609\n",
            "Time:  0.1336 Epoch: 248 Iter: 2400/3510 LR: 0.0000083065 Loss content:  0.0152 Loss fft:  0.8452\n",
            "Time:  0.1301 Epoch: 248 Iter: 2500/3510 LR: 0.0000083065 Loss content:  0.0151 Loss fft:  0.8522\n",
            "Time:  0.1325 Epoch: 248 Iter: 2600/3510 LR: 0.0000083065 Loss content:  0.0152 Loss fft:  0.8459\n",
            "Time:  0.1296 Epoch: 248 Iter: 2700/3510 LR: 0.0000083065 Loss content:  0.0153 Loss fft:  0.8460\n",
            "Time:  0.1322 Epoch: 248 Iter: 2800/3510 LR: 0.0000083065 Loss content:  0.0148 Loss fft:  0.8408\n",
            "Time:  0.1316 Epoch: 248 Iter: 2900/3510 LR: 0.0000083065 Loss content:  0.0154 Loss fft:  0.8514\n",
            "Time:  0.1351 Epoch: 248 Iter: 3000/3510 LR: 0.0000083065 Loss content:  0.0152 Loss fft:  0.8581\n",
            "Time:  0.1326 Epoch: 248 Iter: 3100/3510 LR: 0.0000083065 Loss content:  0.0151 Loss fft:  0.8619\n",
            "Time:  0.1312 Epoch: 248 Iter: 3200/3510 LR: 0.0000083065 Loss content:  0.0151 Loss fft:  0.8411\n",
            "Time:  0.1346 Epoch: 248 Iter: 3300/3510 LR: 0.0000083065 Loss content:  0.0161 Loss fft:  0.8536\n",
            "Time:  0.1309 Epoch: 248 Iter: 3400/3510 LR: 0.0000083065 Loss content:  0.0155 Loss fft:  0.8237\n",
            "Time:  0.1319 Epoch: 248 Iter: 3500/3510 LR: 0.0000083065 Loss content:  0.0150 Loss fft:  0.8357\n",
            "EPOCH: 248\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0153 Epoch FFT Loss:  0.8469\n",
            "Time:  0.1407 Epoch: 249 Iter:  100/3510 LR: 0.0000080352 Loss content:  0.0150 Loss fft:  0.8355\n",
            "Time:  0.1346 Epoch: 249 Iter:  200/3510 LR: 0.0000080352 Loss content:  0.0150 Loss fft:  0.8463\n",
            "Time:  0.1345 Epoch: 249 Iter:  300/3510 LR: 0.0000080352 Loss content:  0.0155 Loss fft:  0.8561\n",
            "Time:  0.1335 Epoch: 249 Iter:  400/3510 LR: 0.0000080352 Loss content:  0.0153 Loss fft:  0.8437\n",
            "Time:  0.1341 Epoch: 249 Iter:  500/3510 LR: 0.0000080352 Loss content:  0.0151 Loss fft:  0.8590\n",
            "Time:  0.1336 Epoch: 249 Iter:  600/3510 LR: 0.0000080352 Loss content:  0.0155 Loss fft:  0.8569\n",
            "Time:  0.1286 Epoch: 249 Iter:  700/3510 LR: 0.0000080352 Loss content:  0.0151 Loss fft:  0.8393\n",
            "Time:  0.1319 Epoch: 249 Iter:  800/3510 LR: 0.0000080352 Loss content:  0.0151 Loss fft:  0.8472\n",
            "Time:  0.1391 Epoch: 249 Iter:  900/3510 LR: 0.0000080352 Loss content:  0.0150 Loss fft:  0.8274\n",
            "Time:  0.1310 Epoch: 249 Iter: 1000/3510 LR: 0.0000080352 Loss content:  0.0152 Loss fft:  0.8432\n",
            "Time:  0.1308 Epoch: 249 Iter: 1100/3510 LR: 0.0000080352 Loss content:  0.0150 Loss fft:  0.8477\n",
            "Time:  0.1302 Epoch: 249 Iter: 1200/3510 LR: 0.0000080352 Loss content:  0.0156 Loss fft:  0.8385\n",
            "Time:  0.1329 Epoch: 249 Iter: 1300/3510 LR: 0.0000080352 Loss content:  0.0154 Loss fft:  0.8464\n",
            "Time:  0.1321 Epoch: 249 Iter: 1400/3510 LR: 0.0000080352 Loss content:  0.0155 Loss fft:  0.8481\n",
            "Time:  0.1286 Epoch: 249 Iter: 1500/3510 LR: 0.0000080352 Loss content:  0.0152 Loss fft:  0.8352\n",
            "Time:  0.1311 Epoch: 249 Iter: 1600/3510 LR: 0.0000080352 Loss content:  0.0155 Loss fft:  0.8578\n",
            "Time:  0.1334 Epoch: 249 Iter: 1700/3510 LR: 0.0000080352 Loss content:  0.0147 Loss fft:  0.8417\n",
            "Time:  0.1308 Epoch: 249 Iter: 1800/3510 LR: 0.0000080352 Loss content:  0.0153 Loss fft:  0.8308\n",
            "Time:  0.1280 Epoch: 249 Iter: 1900/3510 LR: 0.0000080352 Loss content:  0.0156 Loss fft:  0.8299\n",
            "Time:  0.1311 Epoch: 249 Iter: 2000/3510 LR: 0.0000080352 Loss content:  0.0152 Loss fft:  0.8470\n",
            "Time:  0.1305 Epoch: 249 Iter: 2100/3510 LR: 0.0000080352 Loss content:  0.0156 Loss fft:  0.8614\n",
            "Time:  0.1308 Epoch: 249 Iter: 2200/3510 LR: 0.0000080352 Loss content:  0.0152 Loss fft:  0.8459\n",
            "Time:  0.1304 Epoch: 249 Iter: 2300/3510 LR: 0.0000080352 Loss content:  0.0148 Loss fft:  0.8531\n",
            "Time:  0.1297 Epoch: 249 Iter: 2400/3510 LR: 0.0000080352 Loss content:  0.0152 Loss fft:  0.8551\n",
            "Time:  0.1319 Epoch: 249 Iter: 2500/3510 LR: 0.0000080352 Loss content:  0.0147 Loss fft:  0.8304\n",
            "Time:  0.1338 Epoch: 249 Iter: 2600/3510 LR: 0.0000080352 Loss content:  0.0154 Loss fft:  0.8662\n",
            "Time:  0.1317 Epoch: 249 Iter: 2700/3510 LR: 0.0000080352 Loss content:  0.0159 Loss fft:  0.8768\n",
            "Time:  0.1326 Epoch: 249 Iter: 2800/3510 LR: 0.0000080352 Loss content:  0.0151 Loss fft:  0.8465\n",
            "Time:  0.1311 Epoch: 249 Iter: 2900/3510 LR: 0.0000080352 Loss content:  0.0152 Loss fft:  0.8684\n",
            "Time:  0.1303 Epoch: 249 Iter: 3000/3510 LR: 0.0000080352 Loss content:  0.0162 Loss fft:  0.8798\n",
            "Time:  0.1326 Epoch: 249 Iter: 3100/3510 LR: 0.0000080352 Loss content:  0.0154 Loss fft:  0.8340\n",
            "Time:  0.1286 Epoch: 249 Iter: 3200/3510 LR: 0.0000080352 Loss content:  0.0154 Loss fft:  0.8392\n",
            "Time:  0.1358 Epoch: 249 Iter: 3300/3510 LR: 0.0000080352 Loss content:  0.0149 Loss fft:  0.8379\n",
            "Time:  0.1315 Epoch: 249 Iter: 3400/3510 LR: 0.0000080352 Loss content:  0.0149 Loss fft:  0.8455\n",
            "Time:  0.1305 Epoch: 249 Iter: 3500/3510 LR: 0.0000080352 Loss content:  0.0151 Loss fft:  0.8390\n",
            "EPOCH: 249\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0152 Epoch FFT Loss:  0.8474\n",
            "Time:  0.1424 Epoch: 250 Iter:  100/3510 LR: 0.0000077686 Loss content:  0.0152 Loss fft:  0.8613\n",
            "Time:  0.1317 Epoch: 250 Iter:  200/3510 LR: 0.0000077686 Loss content:  0.0148 Loss fft:  0.8456\n",
            "Time:  0.1326 Epoch: 250 Iter:  300/3510 LR: 0.0000077686 Loss content:  0.0152 Loss fft:  0.8429\n",
            "Time:  0.1305 Epoch: 250 Iter:  400/3510 LR: 0.0000077686 Loss content:  0.0157 Loss fft:  0.8573\n",
            "Time:  0.1324 Epoch: 250 Iter:  500/3510 LR: 0.0000077686 Loss content:  0.0146 Loss fft:  0.8333\n",
            "Time:  0.1285 Epoch: 250 Iter:  600/3510 LR: 0.0000077686 Loss content:  0.0152 Loss fft:  0.8424\n",
            "Time:  0.1332 Epoch: 250 Iter:  700/3510 LR: 0.0000077686 Loss content:  0.0156 Loss fft:  0.8623\n",
            "Time:  0.1334 Epoch: 250 Iter:  800/3510 LR: 0.0000077686 Loss content:  0.0154 Loss fft:  0.8494\n",
            "Time:  0.1334 Epoch: 250 Iter:  900/3510 LR: 0.0000077686 Loss content:  0.0154 Loss fft:  0.8733\n",
            "Time:  0.1308 Epoch: 250 Iter: 1000/3510 LR: 0.0000077686 Loss content:  0.0148 Loss fft:  0.8385\n",
            "Time:  0.1317 Epoch: 250 Iter: 1100/3510 LR: 0.0000077686 Loss content:  0.0157 Loss fft:  0.8618\n",
            "Time:  0.1295 Epoch: 250 Iter: 1200/3510 LR: 0.0000077686 Loss content:  0.0151 Loss fft:  0.8324\n",
            "Time:  0.1308 Epoch: 250 Iter: 1300/3510 LR: 0.0000077686 Loss content:  0.0155 Loss fft:  0.8526\n",
            "Time:  0.1308 Epoch: 250 Iter: 1400/3510 LR: 0.0000077686 Loss content:  0.0147 Loss fft:  0.8298\n",
            "Time:  0.1297 Epoch: 250 Iter: 1500/3510 LR: 0.0000077686 Loss content:  0.0157 Loss fft:  0.8452\n",
            "Time:  0.1305 Epoch: 250 Iter: 1600/3510 LR: 0.0000077686 Loss content:  0.0152 Loss fft:  0.8570\n",
            "Time:  0.1313 Epoch: 250 Iter: 1700/3510 LR: 0.0000077686 Loss content:  0.0153 Loss fft:  0.8461\n",
            "Time:  0.1300 Epoch: 250 Iter: 1800/3510 LR: 0.0000077686 Loss content:  0.0152 Loss fft:  0.8686\n",
            "Time:  0.1303 Epoch: 250 Iter: 1900/3510 LR: 0.0000077686 Loss content:  0.0151 Loss fft:  0.8326\n",
            "Time:  0.1371 Epoch: 250 Iter: 2000/3510 LR: 0.0000077686 Loss content:  0.0151 Loss fft:  0.8490\n",
            "Time:  0.1305 Epoch: 250 Iter: 2100/3510 LR: 0.0000077686 Loss content:  0.0156 Loss fft:  0.8555\n",
            "Time:  0.1319 Epoch: 250 Iter: 2200/3510 LR: 0.0000077686 Loss content:  0.0153 Loss fft:  0.8486\n",
            "Time:  0.1314 Epoch: 250 Iter: 2300/3510 LR: 0.0000077686 Loss content:  0.0147 Loss fft:  0.8442\n",
            "Time:  0.1292 Epoch: 250 Iter: 2400/3510 LR: 0.0000077686 Loss content:  0.0158 Loss fft:  0.8288\n",
            "Time:  0.1284 Epoch: 250 Iter: 2500/3510 LR: 0.0000077686 Loss content:  0.0151 Loss fft:  0.8669\n",
            "Time:  0.1277 Epoch: 250 Iter: 2600/3510 LR: 0.0000077686 Loss content:  0.0153 Loss fft:  0.8409\n",
            "Time:  0.1286 Epoch: 250 Iter: 2700/3510 LR: 0.0000077686 Loss content:  0.0149 Loss fft:  0.8440\n",
            "Time:  0.1279 Epoch: 250 Iter: 2800/3510 LR: 0.0000077686 Loss content:  0.0146 Loss fft:  0.8150\n",
            "Time:  0.1285 Epoch: 250 Iter: 2900/3510 LR: 0.0000077686 Loss content:  0.0156 Loss fft:  0.8540\n",
            "Time:  0.1279 Epoch: 250 Iter: 3000/3510 LR: 0.0000077686 Loss content:  0.0147 Loss fft:  0.8223\n",
            "Time:  0.1327 Epoch: 250 Iter: 3100/3510 LR: 0.0000077686 Loss content:  0.0154 Loss fft:  0.8388\n",
            "Time:  0.1323 Epoch: 250 Iter: 3200/3510 LR: 0.0000077686 Loss content:  0.0159 Loss fft:  0.8443\n",
            "Time:  0.1305 Epoch: 250 Iter: 3300/3510 LR: 0.0000077686 Loss content:  0.0153 Loss fft:  0.8366\n",
            "Time:  0.1339 Epoch: 250 Iter: 3400/3510 LR: 0.0000077686 Loss content:  0.0154 Loss fft:  0.8665\n",
            "Time:  0.1318 Epoch: 250 Iter: 3500/3510 LR: 0.0000077686 Loss content:  0.0156 Loss fft:  0.8317\n",
            "EPOCH: 250\n",
            "Elapsed time: 4.62 Epoch Pixel Loss:  0.0153 Epoch FFT Loss:  0.8464\n",
            "Start Evaluation\n",
            "499 \n",
            "\n",
            "250 epoch \n",
            " Average PSNR 40.80 dB\n",
            "Time:  0.1417 Epoch: 251 Iter:  100/3510 LR: 0.0000075068 Loss content:  0.0157 Loss fft:  0.8565\n",
            "Time:  0.1305 Epoch: 251 Iter:  200/3510 LR: 0.0000075068 Loss content:  0.0152 Loss fft:  0.8397\n",
            "Time:  0.1335 Epoch: 251 Iter:  300/3510 LR: 0.0000075068 Loss content:  0.0148 Loss fft:  0.8436\n",
            "Time:  0.1329 Epoch: 251 Iter:  400/3510 LR: 0.0000075068 Loss content:  0.0152 Loss fft:  0.8418\n",
            "Time:  0.1282 Epoch: 251 Iter:  500/3510 LR: 0.0000075068 Loss content:  0.0157 Loss fft:  0.8555\n",
            "Time:  0.1326 Epoch: 251 Iter:  600/3510 LR: 0.0000075068 Loss content:  0.0147 Loss fft:  0.8514\n",
            "Time:  0.1319 Epoch: 251 Iter:  700/3510 LR: 0.0000075068 Loss content:  0.0153 Loss fft:  0.8538\n",
            "Time:  0.1396 Epoch: 251 Iter:  800/3510 LR: 0.0000075068 Loss content:  0.0145 Loss fft:  0.8595\n",
            "Time:  0.1351 Epoch: 251 Iter:  900/3510 LR: 0.0000075068 Loss content:  0.0153 Loss fft:  0.8430\n",
            "Time:  0.1322 Epoch: 251 Iter: 1000/3510 LR: 0.0000075068 Loss content:  0.0155 Loss fft:  0.8328\n",
            "Time:  0.1310 Epoch: 251 Iter: 1100/3510 LR: 0.0000075068 Loss content:  0.0149 Loss fft:  0.8584\n",
            "Time:  0.1313 Epoch: 251 Iter: 1200/3510 LR: 0.0000075068 Loss content:  0.0150 Loss fft:  0.8533\n",
            "Time:  0.1287 Epoch: 251 Iter: 1300/3510 LR: 0.0000075068 Loss content:  0.0152 Loss fft:  0.8400\n",
            "Time:  0.1304 Epoch: 251 Iter: 1400/3510 LR: 0.0000075068 Loss content:  0.0155 Loss fft:  0.8378\n",
            "Time:  0.1317 Epoch: 251 Iter: 1500/3510 LR: 0.0000075068 Loss content:  0.0150 Loss fft:  0.8517\n",
            "Time:  0.1318 Epoch: 251 Iter: 1600/3510 LR: 0.0000075068 Loss content:  0.0158 Loss fft:  0.8619\n",
            "Time:  0.1321 Epoch: 251 Iter: 1700/3510 LR: 0.0000075068 Loss content:  0.0153 Loss fft:  0.8531\n",
            "Time:  0.1288 Epoch: 251 Iter: 1800/3510 LR: 0.0000075068 Loss content:  0.0161 Loss fft:  0.8603\n",
            "Time:  0.1332 Epoch: 251 Iter: 1900/3510 LR: 0.0000075068 Loss content:  0.0154 Loss fft:  0.8438\n",
            "Time:  0.1307 Epoch: 251 Iter: 2000/3510 LR: 0.0000075068 Loss content:  0.0148 Loss fft:  0.8211\n",
            "Time:  0.1321 Epoch: 251 Iter: 2100/3510 LR: 0.0000075068 Loss content:  0.0153 Loss fft:  0.8460\n",
            "Time:  0.1293 Epoch: 251 Iter: 2200/3510 LR: 0.0000075068 Loss content:  0.0153 Loss fft:  0.8394\n",
            "Time:  0.1292 Epoch: 251 Iter: 2300/3510 LR: 0.0000075068 Loss content:  0.0154 Loss fft:  0.8628\n",
            "Time:  0.1290 Epoch: 251 Iter: 2400/3510 LR: 0.0000075068 Loss content:  0.0158 Loss fft:  0.8628\n",
            "Time:  0.1316 Epoch: 251 Iter: 2500/3510 LR: 0.0000075068 Loss content:  0.0149 Loss fft:  0.8502\n",
            "Time:  0.1329 Epoch: 251 Iter: 2600/3510 LR: 0.0000075068 Loss content:  0.0153 Loss fft:  0.8564\n",
            "Time:  0.1316 Epoch: 251 Iter: 2700/3510 LR: 0.0000075068 Loss content:  0.0153 Loss fft:  0.8364\n",
            "Time:  0.1333 Epoch: 251 Iter: 2800/3510 LR: 0.0000075068 Loss content:  0.0147 Loss fft:  0.8355\n",
            "Time:  0.1334 Epoch: 251 Iter: 2900/3510 LR: 0.0000075068 Loss content:  0.0151 Loss fft:  0.8423\n",
            "Time:  0.1330 Epoch: 251 Iter: 3000/3510 LR: 0.0000075068 Loss content:  0.0144 Loss fft:  0.8218\n",
            "Time:  0.1306 Epoch: 251 Iter: 3100/3510 LR: 0.0000075068 Loss content:  0.0147 Loss fft:  0.8516\n",
            "Time:  0.1341 Epoch: 251 Iter: 3200/3510 LR: 0.0000075068 Loss content:  0.0150 Loss fft:  0.8400\n",
            "Time:  0.1302 Epoch: 251 Iter: 3300/3510 LR: 0.0000075068 Loss content:  0.0159 Loss fft:  0.8739\n",
            "Time:  0.1326 Epoch: 251 Iter: 3400/3510 LR: 0.0000075068 Loss content:  0.0145 Loss fft:  0.8251\n",
            "Time:  0.1350 Epoch: 251 Iter: 3500/3510 LR: 0.0000075068 Loss content:  0.0150 Loss fft:  0.8259\n",
            "EPOCH: 251\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0152 Epoch FFT Loss:  0.8466\n",
            "Time:  0.1398 Epoch: 252 Iter:  100/3510 LR: 0.0000072498 Loss content:  0.0154 Loss fft:  0.8678\n",
            "Time:  0.1337 Epoch: 252 Iter:  200/3510 LR: 0.0000072498 Loss content:  0.0153 Loss fft:  0.8635\n",
            "Time:  0.1314 Epoch: 252 Iter:  300/3510 LR: 0.0000072498 Loss content:  0.0147 Loss fft:  0.8375\n",
            "Time:  0.1321 Epoch: 252 Iter:  400/3510 LR: 0.0000072498 Loss content:  0.0148 Loss fft:  0.8528\n",
            "Time:  0.1297 Epoch: 252 Iter:  500/3510 LR: 0.0000072498 Loss content:  0.0149 Loss fft:  0.8501\n",
            "Time:  0.1321 Epoch: 252 Iter:  600/3510 LR: 0.0000072498 Loss content:  0.0158 Loss fft:  0.8592\n",
            "Time:  0.1333 Epoch: 252 Iter:  700/3510 LR: 0.0000072498 Loss content:  0.0150 Loss fft:  0.8335\n",
            "Time:  0.1312 Epoch: 252 Iter:  800/3510 LR: 0.0000072498 Loss content:  0.0154 Loss fft:  0.8464\n",
            "Time:  0.1315 Epoch: 252 Iter:  900/3510 LR: 0.0000072498 Loss content:  0.0150 Loss fft:  0.8608\n",
            "Time:  0.1319 Epoch: 252 Iter: 1000/3510 LR: 0.0000072498 Loss content:  0.0148 Loss fft:  0.8091\n",
            "Time:  0.1316 Epoch: 252 Iter: 1100/3510 LR: 0.0000072498 Loss content:  0.0149 Loss fft:  0.8514\n",
            "Time:  0.1291 Epoch: 252 Iter: 1200/3510 LR: 0.0000072498 Loss content:  0.0160 Loss fft:  0.8596\n",
            "Time:  0.1322 Epoch: 252 Iter: 1300/3510 LR: 0.0000072498 Loss content:  0.0150 Loss fft:  0.8321\n",
            "Time:  0.1300 Epoch: 252 Iter: 1400/3510 LR: 0.0000072498 Loss content:  0.0152 Loss fft:  0.8526\n",
            "Time:  0.1314 Epoch: 252 Iter: 1500/3510 LR: 0.0000072498 Loss content:  0.0150 Loss fft:  0.8322\n",
            "Time:  0.1295 Epoch: 252 Iter: 1600/3510 LR: 0.0000072498 Loss content:  0.0148 Loss fft:  0.8486\n",
            "Time:  0.1317 Epoch: 252 Iter: 1700/3510 LR: 0.0000072498 Loss content:  0.0152 Loss fft:  0.8520\n",
            "Time:  0.1323 Epoch: 252 Iter: 1800/3510 LR: 0.0000072498 Loss content:  0.0150 Loss fft:  0.8465\n",
            "Time:  0.1361 Epoch: 252 Iter: 1900/3510 LR: 0.0000072498 Loss content:  0.0152 Loss fft:  0.8391\n",
            "Time:  0.1310 Epoch: 252 Iter: 2000/3510 LR: 0.0000072498 Loss content:  0.0150 Loss fft:  0.8343\n",
            "Time:  0.1315 Epoch: 252 Iter: 2100/3510 LR: 0.0000072498 Loss content:  0.0157 Loss fft:  0.8500\n",
            "Time:  0.1330 Epoch: 252 Iter: 2200/3510 LR: 0.0000072498 Loss content:  0.0143 Loss fft:  0.8137\n",
            "Time:  0.1313 Epoch: 252 Iter: 2300/3510 LR: 0.0000072498 Loss content:  0.0152 Loss fft:  0.8549\n",
            "Time:  0.1333 Epoch: 252 Iter: 2400/3510 LR: 0.0000072498 Loss content:  0.0157 Loss fft:  0.8094\n",
            "Time:  0.1328 Epoch: 252 Iter: 2500/3510 LR: 0.0000072498 Loss content:  0.0151 Loss fft:  0.8353\n",
            "Time:  0.1322 Epoch: 252 Iter: 2600/3510 LR: 0.0000072498 Loss content:  0.0155 Loss fft:  0.8673\n",
            "Time:  0.1302 Epoch: 252 Iter: 2700/3510 LR: 0.0000072498 Loss content:  0.0148 Loss fft:  0.8423\n",
            "Time:  0.1317 Epoch: 252 Iter: 2800/3510 LR: 0.0000072498 Loss content:  0.0149 Loss fft:  0.8440\n",
            "Time:  0.1329 Epoch: 252 Iter: 2900/3510 LR: 0.0000072498 Loss content:  0.0146 Loss fft:  0.8573\n",
            "Time:  0.1319 Epoch: 252 Iter: 3000/3510 LR: 0.0000072498 Loss content:  0.0152 Loss fft:  0.8533\n",
            "Time:  0.1351 Epoch: 252 Iter: 3100/3510 LR: 0.0000072498 Loss content:  0.0150 Loss fft:  0.8267\n",
            "Time:  0.1336 Epoch: 252 Iter: 3200/3510 LR: 0.0000072498 Loss content:  0.0154 Loss fft:  0.8498\n",
            "Time:  0.1317 Epoch: 252 Iter: 3300/3510 LR: 0.0000072498 Loss content:  0.0155 Loss fft:  0.8616\n",
            "Time:  0.1302 Epoch: 252 Iter: 3400/3510 LR: 0.0000072498 Loss content:  0.0149 Loss fft:  0.8552\n",
            "Time:  0.1304 Epoch: 252 Iter: 3500/3510 LR: 0.0000072498 Loss content:  0.0151 Loss fft:  0.8453\n",
            "EPOCH: 252\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0151 Epoch FFT Loss:  0.8456\n",
            "Time:  0.1395 Epoch: 253 Iter:  100/3510 LR: 0.0000069976 Loss content:  0.0151 Loss fft:  0.8565\n",
            "Time:  0.1331 Epoch: 253 Iter:  200/3510 LR: 0.0000069976 Loss content:  0.0148 Loss fft:  0.8433\n",
            "Time:  0.1328 Epoch: 253 Iter:  300/3510 LR: 0.0000069976 Loss content:  0.0148 Loss fft:  0.8475\n",
            "Time:  0.1300 Epoch: 253 Iter:  400/3510 LR: 0.0000069976 Loss content:  0.0145 Loss fft:  0.8435\n",
            "Time:  0.1314 Epoch: 253 Iter:  500/3510 LR: 0.0000069976 Loss content:  0.0150 Loss fft:  0.8295\n",
            "Time:  0.1361 Epoch: 253 Iter:  600/3510 LR: 0.0000069976 Loss content:  0.0151 Loss fft:  0.8551\n",
            "Time:  0.1303 Epoch: 253 Iter:  700/3510 LR: 0.0000069976 Loss content:  0.0153 Loss fft:  0.8517\n",
            "Time:  0.1304 Epoch: 253 Iter:  800/3510 LR: 0.0000069976 Loss content:  0.0151 Loss fft:  0.8391\n",
            "Time:  0.1315 Epoch: 253 Iter:  900/3510 LR: 0.0000069976 Loss content:  0.0158 Loss fft:  0.8395\n",
            "Time:  0.1329 Epoch: 253 Iter: 1000/3510 LR: 0.0000069976 Loss content:  0.0147 Loss fft:  0.8416\n",
            "Time:  0.1313 Epoch: 253 Iter: 1100/3510 LR: 0.0000069976 Loss content:  0.0151 Loss fft:  0.8325\n",
            "Time:  0.1284 Epoch: 253 Iter: 1200/3510 LR: 0.0000069976 Loss content:  0.0152 Loss fft:  0.8489\n",
            "Time:  0.1299 Epoch: 253 Iter: 1300/3510 LR: 0.0000069976 Loss content:  0.0148 Loss fft:  0.8370\n",
            "Time:  0.1318 Epoch: 253 Iter: 1400/3510 LR: 0.0000069976 Loss content:  0.0148 Loss fft:  0.8336\n",
            "Time:  0.1285 Epoch: 253 Iter: 1500/3510 LR: 0.0000069976 Loss content:  0.0153 Loss fft:  0.8412\n",
            "Time:  0.1319 Epoch: 253 Iter: 1600/3510 LR: 0.0000069976 Loss content:  0.0151 Loss fft:  0.8416\n",
            "Time:  0.1338 Epoch: 253 Iter: 1700/3510 LR: 0.0000069976 Loss content:  0.0148 Loss fft:  0.8416\n",
            "Time:  0.1314 Epoch: 253 Iter: 1800/3510 LR: 0.0000069976 Loss content:  0.0146 Loss fft:  0.8491\n",
            "Time:  0.1301 Epoch: 253 Iter: 1900/3510 LR: 0.0000069976 Loss content:  0.0151 Loss fft:  0.8510\n",
            "Time:  0.1329 Epoch: 253 Iter: 2000/3510 LR: 0.0000069976 Loss content:  0.0154 Loss fft:  0.8506\n",
            "Time:  0.1327 Epoch: 253 Iter: 2100/3510 LR: 0.0000069976 Loss content:  0.0147 Loss fft:  0.8482\n",
            "Time:  0.1331 Epoch: 253 Iter: 2200/3510 LR: 0.0000069976 Loss content:  0.0149 Loss fft:  0.8380\n",
            "Time:  0.1309 Epoch: 253 Iter: 2300/3510 LR: 0.0000069976 Loss content:  0.0148 Loss fft:  0.8445\n",
            "Time:  0.1298 Epoch: 253 Iter: 2400/3510 LR: 0.0000069976 Loss content:  0.0156 Loss fft:  0.8523\n",
            "Time:  0.1315 Epoch: 253 Iter: 2500/3510 LR: 0.0000069976 Loss content:  0.0151 Loss fft:  0.8449\n",
            "Time:  0.1323 Epoch: 253 Iter: 2600/3510 LR: 0.0000069976 Loss content:  0.0150 Loss fft:  0.8464\n",
            "Time:  0.1316 Epoch: 253 Iter: 2700/3510 LR: 0.0000069976 Loss content:  0.0152 Loss fft:  0.8549\n",
            "Time:  0.1314 Epoch: 253 Iter: 2800/3510 LR: 0.0000069976 Loss content:  0.0146 Loss fft:  0.8319\n",
            "Time:  0.1344 Epoch: 253 Iter: 2900/3510 LR: 0.0000069976 Loss content:  0.0152 Loss fft:  0.8664\n",
            "Time:  0.1351 Epoch: 253 Iter: 3000/3510 LR: 0.0000069976 Loss content:  0.0154 Loss fft:  0.8533\n",
            "Time:  0.1342 Epoch: 253 Iter: 3100/3510 LR: 0.0000069976 Loss content:  0.0155 Loss fft:  0.8488\n",
            "Time:  0.1283 Epoch: 253 Iter: 3200/3510 LR: 0.0000069976 Loss content:  0.0151 Loss fft:  0.8396\n",
            "Time:  0.1301 Epoch: 253 Iter: 3300/3510 LR: 0.0000069976 Loss content:  0.0149 Loss fft:  0.8382\n",
            "Time:  0.1314 Epoch: 253 Iter: 3400/3510 LR: 0.0000069976 Loss content:  0.0152 Loss fft:  0.8389\n",
            "Time:  0.1313 Epoch: 253 Iter: 3500/3510 LR: 0.0000069976 Loss content:  0.0153 Loss fft:  0.8490\n",
            "EPOCH: 253\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0150 Epoch FFT Loss:  0.8447\n",
            "Time:  0.1419 Epoch: 254 Iter:  100/3510 LR: 0.0000067503 Loss content:  0.0146 Loss fft:  0.8316\n",
            "Time:  0.1302 Epoch: 254 Iter:  200/3510 LR: 0.0000067503 Loss content:  0.0148 Loss fft:  0.8295\n",
            "Time:  0.1318 Epoch: 254 Iter:  300/3510 LR: 0.0000067503 Loss content:  0.0147 Loss fft:  0.8477\n",
            "Time:  0.1344 Epoch: 254 Iter:  400/3510 LR: 0.0000067503 Loss content:  0.0154 Loss fft:  0.8477\n",
            "Time:  0.1327 Epoch: 254 Iter:  500/3510 LR: 0.0000067503 Loss content:  0.0151 Loss fft:  0.8500\n",
            "Time:  0.1318 Epoch: 254 Iter:  600/3510 LR: 0.0000067503 Loss content:  0.0151 Loss fft:  0.8296\n",
            "Time:  0.1317 Epoch: 254 Iter:  700/3510 LR: 0.0000067503 Loss content:  0.0146 Loss fft:  0.8530\n",
            "Time:  0.1317 Epoch: 254 Iter:  800/3510 LR: 0.0000067503 Loss content:  0.0147 Loss fft:  0.8382\n",
            "Time:  0.1315 Epoch: 254 Iter:  900/3510 LR: 0.0000067503 Loss content:  0.0151 Loss fft:  0.8615\n",
            "Time:  0.1308 Epoch: 254 Iter: 1000/3510 LR: 0.0000067503 Loss content:  0.0155 Loss fft:  0.8353\n",
            "Time:  0.1314 Epoch: 254 Iter: 1100/3510 LR: 0.0000067503 Loss content:  0.0148 Loss fft:  0.8481\n",
            "Time:  0.1332 Epoch: 254 Iter: 1200/3510 LR: 0.0000067503 Loss content:  0.0151 Loss fft:  0.8491\n",
            "Time:  0.1319 Epoch: 254 Iter: 1300/3510 LR: 0.0000067503 Loss content:  0.0151 Loss fft:  0.8429\n",
            "Time:  0.1334 Epoch: 254 Iter: 1400/3510 LR: 0.0000067503 Loss content:  0.0152 Loss fft:  0.8516\n",
            "Time:  0.1314 Epoch: 254 Iter: 1500/3510 LR: 0.0000067503 Loss content:  0.0148 Loss fft:  0.8377\n",
            "Time:  0.1313 Epoch: 254 Iter: 1600/3510 LR: 0.0000067503 Loss content:  0.0154 Loss fft:  0.8377\n",
            "Time:  0.1318 Epoch: 254 Iter: 1700/3510 LR: 0.0000067503 Loss content:  0.0144 Loss fft:  0.8368\n",
            "Time:  0.1353 Epoch: 254 Iter: 1800/3510 LR: 0.0000067503 Loss content:  0.0157 Loss fft:  0.8495\n",
            "Time:  0.1309 Epoch: 254 Iter: 1900/3510 LR: 0.0000067503 Loss content:  0.0152 Loss fft:  0.8282\n",
            "Time:  0.1316 Epoch: 254 Iter: 2000/3510 LR: 0.0000067503 Loss content:  0.0150 Loss fft:  0.8455\n",
            "Time:  0.1315 Epoch: 254 Iter: 2100/3510 LR: 0.0000067503 Loss content:  0.0145 Loss fft:  0.8622\n",
            "Time:  0.1315 Epoch: 254 Iter: 2200/3510 LR: 0.0000067503 Loss content:  0.0141 Loss fft:  0.8383\n",
            "Time:  0.1339 Epoch: 254 Iter: 2300/3510 LR: 0.0000067503 Loss content:  0.0155 Loss fft:  0.8693\n",
            "Time:  0.1307 Epoch: 254 Iter: 2400/3510 LR: 0.0000067503 Loss content:  0.0154 Loss fft:  0.8478\n",
            "Time:  0.1344 Epoch: 254 Iter: 2500/3510 LR: 0.0000067503 Loss content:  0.0155 Loss fft:  0.8719\n",
            "Time:  0.1324 Epoch: 254 Iter: 2600/3510 LR: 0.0000067503 Loss content:  0.0155 Loss fft:  0.8412\n",
            "Time:  0.1329 Epoch: 254 Iter: 2700/3510 LR: 0.0000067503 Loss content:  0.0151 Loss fft:  0.8292\n",
            "Time:  0.1309 Epoch: 254 Iter: 2800/3510 LR: 0.0000067503 Loss content:  0.0150 Loss fft:  0.8426\n",
            "Time:  0.1335 Epoch: 254 Iter: 2900/3510 LR: 0.0000067503 Loss content:  0.0147 Loss fft:  0.8359\n",
            "Time:  0.1308 Epoch: 254 Iter: 3000/3510 LR: 0.0000067503 Loss content:  0.0147 Loss fft:  0.8340\n",
            "Time:  0.1318 Epoch: 254 Iter: 3100/3510 LR: 0.0000067503 Loss content:  0.0147 Loss fft:  0.8325\n",
            "Time:  0.1334 Epoch: 254 Iter: 3200/3510 LR: 0.0000067503 Loss content:  0.0144 Loss fft:  0.8320\n",
            "Time:  0.1290 Epoch: 254 Iter: 3300/3510 LR: 0.0000067503 Loss content:  0.0150 Loss fft:  0.8454\n",
            "Time:  0.1319 Epoch: 254 Iter: 3400/3510 LR: 0.0000067503 Loss content:  0.0148 Loss fft:  0.8348\n",
            "Time:  0.1306 Epoch: 254 Iter: 3500/3510 LR: 0.0000067503 Loss content:  0.0153 Loss fft:  0.8347\n",
            "EPOCH: 254\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0150 Epoch FFT Loss:  0.8431\n",
            "Time:  0.1413 Epoch: 255 Iter:  100/3510 LR: 0.0000065080 Loss content:  0.0146 Loss fft:  0.8423\n",
            "Time:  0.1320 Epoch: 255 Iter:  200/3510 LR: 0.0000065080 Loss content:  0.0150 Loss fft:  0.8395\n",
            "Time:  0.1305 Epoch: 255 Iter:  300/3510 LR: 0.0000065080 Loss content:  0.0147 Loss fft:  0.8264\n",
            "Time:  0.1334 Epoch: 255 Iter:  400/3510 LR: 0.0000065080 Loss content:  0.0156 Loss fft:  0.8745\n",
            "Time:  0.1359 Epoch: 255 Iter:  500/3510 LR: 0.0000065080 Loss content:  0.0150 Loss fft:  0.8319\n",
            "Time:  0.1300 Epoch: 255 Iter:  600/3510 LR: 0.0000065080 Loss content:  0.0146 Loss fft:  0.8329\n",
            "Time:  0.1317 Epoch: 255 Iter:  700/3510 LR: 0.0000065080 Loss content:  0.0147 Loss fft:  0.8417\n",
            "Time:  0.1335 Epoch: 255 Iter:  800/3510 LR: 0.0000065080 Loss content:  0.0149 Loss fft:  0.8580\n",
            "Time:  0.1325 Epoch: 255 Iter:  900/3510 LR: 0.0000065080 Loss content:  0.0147 Loss fft:  0.8349\n",
            "Time:  0.1301 Epoch: 255 Iter: 1000/3510 LR: 0.0000065080 Loss content:  0.0149 Loss fft:  0.8295\n",
            "Time:  0.1302 Epoch: 255 Iter: 1100/3510 LR: 0.0000065080 Loss content:  0.0151 Loss fft:  0.8371\n",
            "Time:  0.1344 Epoch: 255 Iter: 1200/3510 LR: 0.0000065080 Loss content:  0.0156 Loss fft:  0.8554\n",
            "Time:  0.1324 Epoch: 255 Iter: 1300/3510 LR: 0.0000065080 Loss content:  0.0147 Loss fft:  0.8396\n",
            "Time:  0.1321 Epoch: 255 Iter: 1400/3510 LR: 0.0000065080 Loss content:  0.0154 Loss fft:  0.8435\n",
            "Time:  0.1339 Epoch: 255 Iter: 1500/3510 LR: 0.0000065080 Loss content:  0.0152 Loss fft:  0.8538\n",
            "Time:  0.1315 Epoch: 255 Iter: 1600/3510 LR: 0.0000065080 Loss content:  0.0150 Loss fft:  0.8348\n",
            "Time:  0.1322 Epoch: 255 Iter: 1700/3510 LR: 0.0000065080 Loss content:  0.0157 Loss fft:  0.8442\n",
            "Time:  0.1309 Epoch: 255 Iter: 1800/3510 LR: 0.0000065080 Loss content:  0.0145 Loss fft:  0.8240\n",
            "Time:  0.1344 Epoch: 255 Iter: 1900/3510 LR: 0.0000065080 Loss content:  0.0148 Loss fft:  0.8433\n",
            "Time:  0.1321 Epoch: 255 Iter: 2000/3510 LR: 0.0000065080 Loss content:  0.0153 Loss fft:  0.8633\n",
            "Time:  0.1302 Epoch: 255 Iter: 2100/3510 LR: 0.0000065080 Loss content:  0.0153 Loss fft:  0.8427\n",
            "Time:  0.1304 Epoch: 255 Iter: 2200/3510 LR: 0.0000065080 Loss content:  0.0146 Loss fft:  0.8212\n",
            "Time:  0.1321 Epoch: 255 Iter: 2300/3510 LR: 0.0000065080 Loss content:  0.0153 Loss fft:  0.8360\n",
            "Time:  0.1314 Epoch: 255 Iter: 2400/3510 LR: 0.0000065080 Loss content:  0.0149 Loss fft:  0.8327\n",
            "Time:  0.1326 Epoch: 255 Iter: 2500/3510 LR: 0.0000065080 Loss content:  0.0151 Loss fft:  0.8695\n",
            "Time:  0.1312 Epoch: 255 Iter: 2600/3510 LR: 0.0000065080 Loss content:  0.0151 Loss fft:  0.8378\n",
            "Time:  0.1318 Epoch: 255 Iter: 2700/3510 LR: 0.0000065080 Loss content:  0.0148 Loss fft:  0.8348\n",
            "Time:  0.1332 Epoch: 255 Iter: 2800/3510 LR: 0.0000065080 Loss content:  0.0149 Loss fft:  0.8407\n",
            "Time:  0.1356 Epoch: 255 Iter: 2900/3510 LR: 0.0000065080 Loss content:  0.0149 Loss fft:  0.8612\n",
            "Time:  0.1310 Epoch: 255 Iter: 3000/3510 LR: 0.0000065080 Loss content:  0.0149 Loss fft:  0.8280\n",
            "Time:  0.1315 Epoch: 255 Iter: 3100/3510 LR: 0.0000065080 Loss content:  0.0151 Loss fft:  0.8661\n",
            "Time:  0.1309 Epoch: 255 Iter: 3200/3510 LR: 0.0000065080 Loss content:  0.0148 Loss fft:  0.8286\n",
            "Time:  0.1309 Epoch: 255 Iter: 3300/3510 LR: 0.0000065080 Loss content:  0.0155 Loss fft:  0.8640\n",
            "Time:  0.1299 Epoch: 255 Iter: 3400/3510 LR: 0.0000065080 Loss content:  0.0150 Loss fft:  0.8635\n",
            "Time:  0.1315 Epoch: 255 Iter: 3500/3510 LR: 0.0000065080 Loss content:  0.0153 Loss fft:  0.8640\n",
            "EPOCH: 255\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0150 Epoch FFT Loss:  0.8438\n",
            "Time:  0.1410 Epoch: 256 Iter:  100/3510 LR: 0.0000062705 Loss content:  0.0146 Loss fft:  0.8570\n",
            "Time:  0.1346 Epoch: 256 Iter:  200/3510 LR: 0.0000062705 Loss content:  0.0148 Loss fft:  0.8524\n",
            "Time:  0.1325 Epoch: 256 Iter:  300/3510 LR: 0.0000062705 Loss content:  0.0141 Loss fft:  0.8287\n",
            "Time:  0.1328 Epoch: 256 Iter:  400/3510 LR: 0.0000062705 Loss content:  0.0150 Loss fft:  0.8452\n",
            "Time:  0.1293 Epoch: 256 Iter:  500/3510 LR: 0.0000062705 Loss content:  0.0149 Loss fft:  0.8579\n",
            "Time:  0.1303 Epoch: 256 Iter:  600/3510 LR: 0.0000062705 Loss content:  0.0151 Loss fft:  0.8457\n",
            "Time:  0.1329 Epoch: 256 Iter:  700/3510 LR: 0.0000062705 Loss content:  0.0147 Loss fft:  0.8331\n",
            "Time:  0.1315 Epoch: 256 Iter:  800/3510 LR: 0.0000062705 Loss content:  0.0154 Loss fft:  0.8479\n",
            "Time:  0.1326 Epoch: 256 Iter:  900/3510 LR: 0.0000062705 Loss content:  0.0150 Loss fft:  0.8375\n",
            "Time:  0.1302 Epoch: 256 Iter: 1000/3510 LR: 0.0000062705 Loss content:  0.0151 Loss fft:  0.8385\n",
            "Time:  0.1319 Epoch: 256 Iter: 1100/3510 LR: 0.0000062705 Loss content:  0.0153 Loss fft:  0.8321\n",
            "Time:  0.1301 Epoch: 256 Iter: 1200/3510 LR: 0.0000062705 Loss content:  0.0147 Loss fft:  0.8407\n",
            "Time:  0.1306 Epoch: 256 Iter: 1300/3510 LR: 0.0000062705 Loss content:  0.0155 Loss fft:  0.8367\n",
            "Time:  0.1324 Epoch: 256 Iter: 1400/3510 LR: 0.0000062705 Loss content:  0.0149 Loss fft:  0.8591\n",
            "Time:  0.1320 Epoch: 256 Iter: 1500/3510 LR: 0.0000062705 Loss content:  0.0153 Loss fft:  0.8507\n",
            "Time:  0.1362 Epoch: 256 Iter: 1600/3510 LR: 0.0000062705 Loss content:  0.0149 Loss fft:  0.8521\n",
            "Time:  0.1290 Epoch: 256 Iter: 1700/3510 LR: 0.0000062705 Loss content:  0.0153 Loss fft:  0.8485\n",
            "Time:  0.1303 Epoch: 256 Iter: 1800/3510 LR: 0.0000062705 Loss content:  0.0145 Loss fft:  0.8349\n",
            "Time:  0.1299 Epoch: 256 Iter: 1900/3510 LR: 0.0000062705 Loss content:  0.0144 Loss fft:  0.8380\n",
            "Time:  0.1300 Epoch: 256 Iter: 2000/3510 LR: 0.0000062705 Loss content:  0.0146 Loss fft:  0.8332\n",
            "Time:  0.1304 Epoch: 256 Iter: 2100/3510 LR: 0.0000062705 Loss content:  0.0148 Loss fft:  0.8397\n",
            "Time:  0.1320 Epoch: 256 Iter: 2200/3510 LR: 0.0000062705 Loss content:  0.0155 Loss fft:  0.8568\n",
            "Time:  0.1304 Epoch: 256 Iter: 2300/3510 LR: 0.0000062705 Loss content:  0.0154 Loss fft:  0.8513\n",
            "Time:  0.1315 Epoch: 256 Iter: 2400/3510 LR: 0.0000062705 Loss content:  0.0144 Loss fft:  0.8350\n",
            "Time:  0.1317 Epoch: 256 Iter: 2500/3510 LR: 0.0000062705 Loss content:  0.0148 Loss fft:  0.8408\n",
            "Time:  0.1313 Epoch: 256 Iter: 2600/3510 LR: 0.0000062705 Loss content:  0.0151 Loss fft:  0.8355\n",
            "Time:  0.1320 Epoch: 256 Iter: 2700/3510 LR: 0.0000062705 Loss content:  0.0154 Loss fft:  0.8429\n",
            "Time:  0.1313 Epoch: 256 Iter: 2800/3510 LR: 0.0000062705 Loss content:  0.0146 Loss fft:  0.8218\n",
            "Time:  0.1309 Epoch: 256 Iter: 2900/3510 LR: 0.0000062705 Loss content:  0.0146 Loss fft:  0.8091\n",
            "Time:  0.1309 Epoch: 256 Iter: 3000/3510 LR: 0.0000062705 Loss content:  0.0151 Loss fft:  0.8428\n",
            "Time:  0.1320 Epoch: 256 Iter: 3100/3510 LR: 0.0000062705 Loss content:  0.0148 Loss fft:  0.8402\n",
            "Time:  0.1295 Epoch: 256 Iter: 3200/3510 LR: 0.0000062705 Loss content:  0.0146 Loss fft:  0.8419\n",
            "Time:  0.1310 Epoch: 256 Iter: 3300/3510 LR: 0.0000062705 Loss content:  0.0148 Loss fft:  0.8330\n",
            "Time:  0.1312 Epoch: 256 Iter: 3400/3510 LR: 0.0000062705 Loss content:  0.0156 Loss fft:  0.8458\n",
            "Time:  0.1311 Epoch: 256 Iter: 3500/3510 LR: 0.0000062705 Loss content:  0.0146 Loss fft:  0.8372\n",
            "EPOCH: 256\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0149 Epoch FFT Loss:  0.8413\n",
            "Time:  0.1411 Epoch: 257 Iter:  100/3510 LR: 0.0000060380 Loss content:  0.0149 Loss fft:  0.8357\n",
            "Time:  0.1336 Epoch: 257 Iter:  200/3510 LR: 0.0000060380 Loss content:  0.0151 Loss fft:  0.8502\n",
            "Time:  0.1328 Epoch: 257 Iter:  300/3510 LR: 0.0000060380 Loss content:  0.0150 Loss fft:  0.8446\n",
            "Time:  0.1374 Epoch: 257 Iter:  400/3510 LR: 0.0000060380 Loss content:  0.0149 Loss fft:  0.8382\n",
            "Time:  0.1317 Epoch: 257 Iter:  500/3510 LR: 0.0000060380 Loss content:  0.0151 Loss fft:  0.8493\n",
            "Time:  0.1286 Epoch: 257 Iter:  600/3510 LR: 0.0000060380 Loss content:  0.0155 Loss fft:  0.8386\n",
            "Time:  0.1292 Epoch: 257 Iter:  700/3510 LR: 0.0000060380 Loss content:  0.0148 Loss fft:  0.8425\n",
            "Time:  0.1283 Epoch: 257 Iter:  800/3510 LR: 0.0000060380 Loss content:  0.0151 Loss fft:  0.8567\n",
            "Time:  0.1311 Epoch: 257 Iter:  900/3510 LR: 0.0000060380 Loss content:  0.0148 Loss fft:  0.8607\n",
            "Time:  0.1288 Epoch: 257 Iter: 1000/3510 LR: 0.0000060380 Loss content:  0.0145 Loss fft:  0.8349\n",
            "Time:  0.1353 Epoch: 257 Iter: 1100/3510 LR: 0.0000060380 Loss content:  0.0150 Loss fft:  0.8555\n",
            "Time:  0.1322 Epoch: 257 Iter: 1200/3510 LR: 0.0000060380 Loss content:  0.0151 Loss fft:  0.8653\n",
            "Time:  0.1329 Epoch: 257 Iter: 1300/3510 LR: 0.0000060380 Loss content:  0.0148 Loss fft:  0.8430\n",
            "Time:  0.1321 Epoch: 257 Iter: 1400/3510 LR: 0.0000060380 Loss content:  0.0142 Loss fft:  0.8332\n",
            "Time:  0.1317 Epoch: 257 Iter: 1500/3510 LR: 0.0000060380 Loss content:  0.0149 Loss fft:  0.8310\n",
            "Time:  0.1322 Epoch: 257 Iter: 1600/3510 LR: 0.0000060380 Loss content:  0.0144 Loss fft:  0.8199\n",
            "Time:  0.1299 Epoch: 257 Iter: 1700/3510 LR: 0.0000060380 Loss content:  0.0148 Loss fft:  0.8374\n",
            "Time:  0.1311 Epoch: 257 Iter: 1800/3510 LR: 0.0000060380 Loss content:  0.0150 Loss fft:  0.8437\n",
            "Time:  0.1299 Epoch: 257 Iter: 1900/3510 LR: 0.0000060380 Loss content:  0.0148 Loss fft:  0.8347\n",
            "Time:  0.1323 Epoch: 257 Iter: 2000/3510 LR: 0.0000060380 Loss content:  0.0148 Loss fft:  0.8319\n",
            "Time:  0.1327 Epoch: 257 Iter: 2100/3510 LR: 0.0000060380 Loss content:  0.0147 Loss fft:  0.8183\n",
            "Time:  0.1353 Epoch: 257 Iter: 2200/3510 LR: 0.0000060380 Loss content:  0.0150 Loss fft:  0.8332\n",
            "Time:  0.1338 Epoch: 257 Iter: 2300/3510 LR: 0.0000060380 Loss content:  0.0148 Loss fft:  0.8351\n",
            "Time:  0.1337 Epoch: 257 Iter: 2400/3510 LR: 0.0000060380 Loss content:  0.0152 Loss fft:  0.8424\n",
            "Time:  0.1313 Epoch: 257 Iter: 2500/3510 LR: 0.0000060380 Loss content:  0.0151 Loss fft:  0.8647\n",
            "Time:  0.1295 Epoch: 257 Iter: 2600/3510 LR: 0.0000060380 Loss content:  0.0149 Loss fft:  0.8300\n",
            "Time:  0.1312 Epoch: 257 Iter: 2700/3510 LR: 0.0000060380 Loss content:  0.0154 Loss fft:  0.8419\n",
            "Time:  0.1364 Epoch: 257 Iter: 2800/3510 LR: 0.0000060380 Loss content:  0.0147 Loss fft:  0.8171\n",
            "Time:  0.1319 Epoch: 257 Iter: 2900/3510 LR: 0.0000060380 Loss content:  0.0148 Loss fft:  0.8511\n",
            "Time:  0.1342 Epoch: 257 Iter: 3000/3510 LR: 0.0000060380 Loss content:  0.0150 Loss fft:  0.8504\n",
            "Time:  0.1308 Epoch: 257 Iter: 3100/3510 LR: 0.0000060380 Loss content:  0.0151 Loss fft:  0.8577\n",
            "Time:  0.1301 Epoch: 257 Iter: 3200/3510 LR: 0.0000060380 Loss content:  0.0152 Loss fft:  0.8641\n",
            "Time:  0.1308 Epoch: 257 Iter: 3300/3510 LR: 0.0000060380 Loss content:  0.0148 Loss fft:  0.8304\n",
            "Time:  0.1309 Epoch: 257 Iter: 3400/3510 LR: 0.0000060380 Loss content:  0.0148 Loss fft:  0.8364\n",
            "Time:  0.1316 Epoch: 257 Iter: 3500/3510 LR: 0.0000060380 Loss content:  0.0145 Loss fft:  0.8184\n",
            "EPOCH: 257\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0149 Epoch FFT Loss:  0.8411\n",
            "Time:  0.1401 Epoch: 258 Iter:  100/3510 LR: 0.0000058104 Loss content:  0.0146 Loss fft:  0.8209\n",
            "Time:  0.1321 Epoch: 258 Iter:  200/3510 LR: 0.0000058104 Loss content:  0.0148 Loss fft:  0.8359\n",
            "Time:  0.1300 Epoch: 258 Iter:  300/3510 LR: 0.0000058104 Loss content:  0.0150 Loss fft:  0.8524\n",
            "Time:  0.1309 Epoch: 258 Iter:  400/3510 LR: 0.0000058104 Loss content:  0.0152 Loss fft:  0.8653\n",
            "Time:  0.1315 Epoch: 258 Iter:  500/3510 LR: 0.0000058104 Loss content:  0.0144 Loss fft:  0.8256\n",
            "Time:  0.1305 Epoch: 258 Iter:  600/3510 LR: 0.0000058104 Loss content:  0.0146 Loss fft:  0.8248\n",
            "Time:  0.1319 Epoch: 258 Iter:  700/3510 LR: 0.0000058104 Loss content:  0.0149 Loss fft:  0.8577\n",
            "Time:  0.1312 Epoch: 258 Iter:  800/3510 LR: 0.0000058104 Loss content:  0.0148 Loss fft:  0.8588\n",
            "Time:  0.1326 Epoch: 258 Iter:  900/3510 LR: 0.0000058104 Loss content:  0.0146 Loss fft:  0.8274\n",
            "Time:  0.1322 Epoch: 258 Iter: 1000/3510 LR: 0.0000058104 Loss content:  0.0147 Loss fft:  0.8256\n",
            "Time:  0.1289 Epoch: 258 Iter: 1100/3510 LR: 0.0000058104 Loss content:  0.0156 Loss fft:  0.8558\n",
            "Time:  0.1317 Epoch: 258 Iter: 1200/3510 LR: 0.0000058104 Loss content:  0.0155 Loss fft:  0.8514\n",
            "Time:  0.1338 Epoch: 258 Iter: 1300/3510 LR: 0.0000058104 Loss content:  0.0154 Loss fft:  0.8660\n",
            "Time:  0.1305 Epoch: 258 Iter: 1400/3510 LR: 0.0000058104 Loss content:  0.0146 Loss fft:  0.8318\n",
            "Time:  0.1345 Epoch: 258 Iter: 1500/3510 LR: 0.0000058104 Loss content:  0.0145 Loss fft:  0.8343\n",
            "Time:  0.1321 Epoch: 258 Iter: 1600/3510 LR: 0.0000058104 Loss content:  0.0153 Loss fft:  0.8662\n",
            "Time:  0.1323 Epoch: 258 Iter: 1700/3510 LR: 0.0000058104 Loss content:  0.0147 Loss fft:  0.8304\n",
            "Time:  0.1307 Epoch: 258 Iter: 1800/3510 LR: 0.0000058104 Loss content:  0.0145 Loss fft:  0.8245\n",
            "Time:  0.1311 Epoch: 258 Iter: 1900/3510 LR: 0.0000058104 Loss content:  0.0141 Loss fft:  0.8278\n",
            "Time:  0.1311 Epoch: 258 Iter: 2000/3510 LR: 0.0000058104 Loss content:  0.0142 Loss fft:  0.8288\n",
            "Time:  0.1315 Epoch: 258 Iter: 2100/3510 LR: 0.0000058104 Loss content:  0.0146 Loss fft:  0.8253\n",
            "Time:  0.1325 Epoch: 258 Iter: 2200/3510 LR: 0.0000058104 Loss content:  0.0150 Loss fft:  0.8579\n",
            "Time:  0.1323 Epoch: 258 Iter: 2300/3510 LR: 0.0000058104 Loss content:  0.0150 Loss fft:  0.8391\n",
            "Time:  0.1297 Epoch: 258 Iter: 2400/3510 LR: 0.0000058104 Loss content:  0.0148 Loss fft:  0.8491\n",
            "Time:  0.1311 Epoch: 258 Iter: 2500/3510 LR: 0.0000058104 Loss content:  0.0151 Loss fft:  0.8365\n",
            "Time:  0.1285 Epoch: 258 Iter: 2600/3510 LR: 0.0000058104 Loss content:  0.0149 Loss fft:  0.8440\n",
            "Time:  0.1289 Epoch: 258 Iter: 2700/3510 LR: 0.0000058104 Loss content:  0.0151 Loss fft:  0.8664\n",
            "Time:  0.1276 Epoch: 258 Iter: 2800/3510 LR: 0.0000058104 Loss content:  0.0146 Loss fft:  0.8338\n",
            "Time:  0.1299 Epoch: 258 Iter: 2900/3510 LR: 0.0000058104 Loss content:  0.0152 Loss fft:  0.8475\n",
            "Time:  0.1289 Epoch: 258 Iter: 3000/3510 LR: 0.0000058104 Loss content:  0.0149 Loss fft:  0.8484\n",
            "Time:  0.1310 Epoch: 258 Iter: 3100/3510 LR: 0.0000058104 Loss content:  0.0152 Loss fft:  0.8373\n",
            "Time:  0.1297 Epoch: 258 Iter: 3200/3510 LR: 0.0000058104 Loss content:  0.0147 Loss fft:  0.8249\n",
            "Time:  0.1286 Epoch: 258 Iter: 3300/3510 LR: 0.0000058104 Loss content:  0.0149 Loss fft:  0.8208\n",
            "Time:  0.1279 Epoch: 258 Iter: 3400/3510 LR: 0.0000058104 Loss content:  0.0147 Loss fft:  0.8290\n",
            "Time:  0.1281 Epoch: 258 Iter: 3500/3510 LR: 0.0000058104 Loss content:  0.0158 Loss fft:  0.8533\n",
            "EPOCH: 258\n",
            "Elapsed time: 4.61 Epoch Pixel Loss:  0.0149 Epoch FFT Loss:  0.8407\n",
            "Time:  0.1420 Epoch: 259 Iter:  100/3510 LR: 0.0000055879 Loss content:  0.0146 Loss fft:  0.8285\n",
            "Time:  0.1319 Epoch: 259 Iter:  200/3510 LR: 0.0000055879 Loss content:  0.0146 Loss fft:  0.8381\n",
            "Time:  0.1360 Epoch: 259 Iter:  300/3510 LR: 0.0000055879 Loss content:  0.0149 Loss fft:  0.8324\n",
            "Time:  0.1289 Epoch: 259 Iter:  400/3510 LR: 0.0000055879 Loss content:  0.0143 Loss fft:  0.8315\n",
            "Time:  0.1347 Epoch: 259 Iter:  500/3510 LR: 0.0000055879 Loss content:  0.0151 Loss fft:  0.8271\n",
            "Time:  0.1307 Epoch: 259 Iter:  600/3510 LR: 0.0000055879 Loss content:  0.0147 Loss fft:  0.8408\n",
            "Time:  0.1298 Epoch: 259 Iter:  700/3510 LR: 0.0000055879 Loss content:  0.0154 Loss fft:  0.8500\n",
            "Time:  0.1320 Epoch: 259 Iter:  800/3510 LR: 0.0000055879 Loss content:  0.0150 Loss fft:  0.8464\n",
            "Time:  0.1313 Epoch: 259 Iter:  900/3510 LR: 0.0000055879 Loss content:  0.0148 Loss fft:  0.8465\n",
            "Time:  0.1322 Epoch: 259 Iter: 1000/3510 LR: 0.0000055879 Loss content:  0.0149 Loss fft:  0.8473\n",
            "Time:  0.1307 Epoch: 259 Iter: 1100/3510 LR: 0.0000055879 Loss content:  0.0146 Loss fft:  0.8445\n",
            "Time:  0.1300 Epoch: 259 Iter: 1200/3510 LR: 0.0000055879 Loss content:  0.0151 Loss fft:  0.8567\n",
            "Time:  0.1298 Epoch: 259 Iter: 1300/3510 LR: 0.0000055879 Loss content:  0.0144 Loss fft:  0.8331\n",
            "Time:  0.1311 Epoch: 259 Iter: 1400/3510 LR: 0.0000055879 Loss content:  0.0150 Loss fft:  0.8446\n",
            "Time:  0.1317 Epoch: 259 Iter: 1500/3510 LR: 0.0000055879 Loss content:  0.0145 Loss fft:  0.8495\n",
            "Time:  0.1325 Epoch: 259 Iter: 1600/3510 LR: 0.0000055879 Loss content:  0.0147 Loss fft:  0.8663\n",
            "Time:  0.1322 Epoch: 259 Iter: 1700/3510 LR: 0.0000055879 Loss content:  0.0148 Loss fft:  0.8427\n",
            "Time:  0.1330 Epoch: 259 Iter: 1800/3510 LR: 0.0000055879 Loss content:  0.0148 Loss fft:  0.8347\n",
            "Time:  0.1296 Epoch: 259 Iter: 1900/3510 LR: 0.0000055879 Loss content:  0.0144 Loss fft:  0.8247\n",
            "Time:  0.1288 Epoch: 259 Iter: 2000/3510 LR: 0.0000055879 Loss content:  0.0154 Loss fft:  0.8628\n",
            "Time:  0.1318 Epoch: 259 Iter: 2100/3510 LR: 0.0000055879 Loss content:  0.0148 Loss fft:  0.8432\n",
            "Time:  0.1317 Epoch: 259 Iter: 2200/3510 LR: 0.0000055879 Loss content:  0.0148 Loss fft:  0.8321\n",
            "Time:  0.1317 Epoch: 259 Iter: 2300/3510 LR: 0.0000055879 Loss content:  0.0146 Loss fft:  0.8368\n",
            "Time:  0.1300 Epoch: 259 Iter: 2400/3510 LR: 0.0000055879 Loss content:  0.0143 Loss fft:  0.8253\n",
            "Time:  0.1323 Epoch: 259 Iter: 2500/3510 LR: 0.0000055879 Loss content:  0.0148 Loss fft:  0.8369\n",
            "Time:  0.1306 Epoch: 259 Iter: 2600/3510 LR: 0.0000055879 Loss content:  0.0147 Loss fft:  0.8448\n",
            "Time:  0.1348 Epoch: 259 Iter: 2700/3510 LR: 0.0000055879 Loss content:  0.0151 Loss fft:  0.8521\n",
            "Time:  0.1320 Epoch: 259 Iter: 2800/3510 LR: 0.0000055879 Loss content:  0.0151 Loss fft:  0.8422\n",
            "Time:  0.1293 Epoch: 259 Iter: 2900/3510 LR: 0.0000055879 Loss content:  0.0149 Loss fft:  0.8582\n",
            "Time:  0.1302 Epoch: 259 Iter: 3000/3510 LR: 0.0000055879 Loss content:  0.0142 Loss fft:  0.8200\n",
            "Time:  0.1297 Epoch: 259 Iter: 3100/3510 LR: 0.0000055879 Loss content:  0.0142 Loss fft:  0.8396\n",
            "Time:  0.1333 Epoch: 259 Iter: 3200/3510 LR: 0.0000055879 Loss content:  0.0152 Loss fft:  0.8455\n",
            "Time:  0.1286 Epoch: 259 Iter: 3300/3510 LR: 0.0000055879 Loss content:  0.0152 Loss fft:  0.8537\n",
            "Time:  0.1322 Epoch: 259 Iter: 3400/3510 LR: 0.0000055879 Loss content:  0.0147 Loss fft:  0.8350\n",
            "Time:  0.1316 Epoch: 259 Iter: 3500/3510 LR: 0.0000055879 Loss content:  0.0153 Loss fft:  0.8392\n",
            "EPOCH: 259\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0148 Epoch FFT Loss:  0.8415\n",
            "Time:  0.1433 Epoch: 260 Iter:  100/3510 LR: 0.0000053704 Loss content:  0.0147 Loss fft:  0.8503\n",
            "Time:  0.1321 Epoch: 260 Iter:  200/3510 LR: 0.0000053704 Loss content:  0.0147 Loss fft:  0.8476\n",
            "Time:  0.1306 Epoch: 260 Iter:  300/3510 LR: 0.0000053704 Loss content:  0.0149 Loss fft:  0.8396\n",
            "Time:  0.1321 Epoch: 260 Iter:  400/3510 LR: 0.0000053704 Loss content:  0.0149 Loss fft:  0.8388\n",
            "Time:  0.1312 Epoch: 260 Iter:  500/3510 LR: 0.0000053704 Loss content:  0.0152 Loss fft:  0.8839\n",
            "Time:  0.1298 Epoch: 260 Iter:  600/3510 LR: 0.0000053704 Loss content:  0.0147 Loss fft:  0.8370\n",
            "Time:  0.1280 Epoch: 260 Iter:  700/3510 LR: 0.0000053704 Loss content:  0.0146 Loss fft:  0.8407\n",
            "Time:  0.1321 Epoch: 260 Iter:  800/3510 LR: 0.0000053704 Loss content:  0.0148 Loss fft:  0.8509\n",
            "Time:  0.1295 Epoch: 260 Iter:  900/3510 LR: 0.0000053704 Loss content:  0.0150 Loss fft:  0.8457\n",
            "Time:  0.1320 Epoch: 260 Iter: 1000/3510 LR: 0.0000053704 Loss content:  0.0149 Loss fft:  0.8338\n",
            "Time:  0.1297 Epoch: 260 Iter: 1100/3510 LR: 0.0000053704 Loss content:  0.0144 Loss fft:  0.8335\n",
            "Time:  0.1305 Epoch: 260 Iter: 1200/3510 LR: 0.0000053704 Loss content:  0.0148 Loss fft:  0.8283\n",
            "Time:  0.1308 Epoch: 260 Iter: 1300/3510 LR: 0.0000053704 Loss content:  0.0150 Loss fft:  0.8282\n",
            "Time:  0.1285 Epoch: 260 Iter: 1400/3510 LR: 0.0000053704 Loss content:  0.0144 Loss fft:  0.8346\n",
            "Time:  0.1353 Epoch: 260 Iter: 1500/3510 LR: 0.0000053704 Loss content:  0.0148 Loss fft:  0.8326\n",
            "Time:  0.1283 Epoch: 260 Iter: 1600/3510 LR: 0.0000053704 Loss content:  0.0146 Loss fft:  0.8395\n",
            "Time:  0.1286 Epoch: 260 Iter: 1700/3510 LR: 0.0000053704 Loss content:  0.0147 Loss fft:  0.8401\n",
            "Time:  0.1312 Epoch: 260 Iter: 1800/3510 LR: 0.0000053704 Loss content:  0.0145 Loss fft:  0.8477\n",
            "Time:  0.1324 Epoch: 260 Iter: 1900/3510 LR: 0.0000053704 Loss content:  0.0146 Loss fft:  0.8405\n",
            "Time:  0.1334 Epoch: 260 Iter: 2000/3510 LR: 0.0000053704 Loss content:  0.0144 Loss fft:  0.8282\n",
            "Time:  0.1311 Epoch: 260 Iter: 2100/3510 LR: 0.0000053704 Loss content:  0.0147 Loss fft:  0.8425\n",
            "Time:  0.1301 Epoch: 260 Iter: 2200/3510 LR: 0.0000053704 Loss content:  0.0150 Loss fft:  0.8286\n",
            "Time:  0.1301 Epoch: 260 Iter: 2300/3510 LR: 0.0000053704 Loss content:  0.0145 Loss fft:  0.8414\n",
            "Time:  0.1333 Epoch: 260 Iter: 2400/3510 LR: 0.0000053704 Loss content:  0.0147 Loss fft:  0.8394\n",
            "Time:  0.1308 Epoch: 260 Iter: 2500/3510 LR: 0.0000053704 Loss content:  0.0146 Loss fft:  0.8273\n",
            "Time:  0.1305 Epoch: 260 Iter: 2600/3510 LR: 0.0000053704 Loss content:  0.0149 Loss fft:  0.8366\n",
            "Time:  0.1299 Epoch: 260 Iter: 2700/3510 LR: 0.0000053704 Loss content:  0.0149 Loss fft:  0.8353\n",
            "Time:  0.1318 Epoch: 260 Iter: 2800/3510 LR: 0.0000053704 Loss content:  0.0145 Loss fft:  0.8371\n",
            "Time:  0.1331 Epoch: 260 Iter: 2900/3510 LR: 0.0000053704 Loss content:  0.0152 Loss fft:  0.8422\n",
            "Time:  0.1340 Epoch: 260 Iter: 3000/3510 LR: 0.0000053704 Loss content:  0.0149 Loss fft:  0.8334\n",
            "Time:  0.1316 Epoch: 260 Iter: 3100/3510 LR: 0.0000053704 Loss content:  0.0147 Loss fft:  0.8319\n",
            "Time:  0.1317 Epoch: 260 Iter: 3200/3510 LR: 0.0000053704 Loss content:  0.0147 Loss fft:  0.8456\n",
            "Time:  0.1317 Epoch: 260 Iter: 3300/3510 LR: 0.0000053704 Loss content:  0.0139 Loss fft:  0.8266\n",
            "Time:  0.1343 Epoch: 260 Iter: 3400/3510 LR: 0.0000053704 Loss content:  0.0147 Loss fft:  0.8479\n",
            "Time:  0.1327 Epoch: 260 Iter: 3500/3510 LR: 0.0000053704 Loss content:  0.0149 Loss fft:  0.8273\n",
            "EPOCH: 260\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0147 Epoch FFT Loss:  0.8390\n",
            "Start Evaluation\n",
            "499 \n",
            "\n",
            "260 epoch \n",
            " Average PSNR 40.91 dB\n",
            "Time:  0.1391 Epoch: 261 Iter:  100/3510 LR: 0.0000051579 Loss content:  0.0145 Loss fft:  0.8355\n",
            "Time:  0.1365 Epoch: 261 Iter:  200/3510 LR: 0.0000051579 Loss content:  0.0144 Loss fft:  0.8432\n",
            "Time:  0.1339 Epoch: 261 Iter:  300/3510 LR: 0.0000051579 Loss content:  0.0149 Loss fft:  0.8440\n",
            "Time:  0.1307 Epoch: 261 Iter:  400/3510 LR: 0.0000051579 Loss content:  0.0143 Loss fft:  0.8265\n",
            "Time:  0.1300 Epoch: 261 Iter:  500/3510 LR: 0.0000051579 Loss content:  0.0149 Loss fft:  0.8459\n",
            "Time:  0.1302 Epoch: 261 Iter:  600/3510 LR: 0.0000051579 Loss content:  0.0144 Loss fft:  0.8413\n",
            "Time:  0.1328 Epoch: 261 Iter:  700/3510 LR: 0.0000051579 Loss content:  0.0147 Loss fft:  0.8237\n",
            "Time:  0.1309 Epoch: 261 Iter:  800/3510 LR: 0.0000051579 Loss content:  0.0142 Loss fft:  0.8379\n",
            "Time:  0.1321 Epoch: 261 Iter:  900/3510 LR: 0.0000051579 Loss content:  0.0140 Loss fft:  0.8223\n",
            "Time:  0.1351 Epoch: 261 Iter: 1000/3510 LR: 0.0000051579 Loss content:  0.0146 Loss fft:  0.8288\n",
            "Time:  0.1337 Epoch: 261 Iter: 1100/3510 LR: 0.0000051579 Loss content:  0.0146 Loss fft:  0.8584\n",
            "Time:  0.1300 Epoch: 261 Iter: 1200/3510 LR: 0.0000051579 Loss content:  0.0150 Loss fft:  0.8460\n",
            "Time:  0.1338 Epoch: 261 Iter: 1300/3510 LR: 0.0000051579 Loss content:  0.0147 Loss fft:  0.8318\n",
            "Time:  0.1345 Epoch: 261 Iter: 1400/3510 LR: 0.0000051579 Loss content:  0.0156 Loss fft:  0.8569\n",
            "Time:  0.1300 Epoch: 261 Iter: 1500/3510 LR: 0.0000051579 Loss content:  0.0155 Loss fft:  0.8619\n",
            "Time:  0.1311 Epoch: 261 Iter: 1600/3510 LR: 0.0000051579 Loss content:  0.0149 Loss fft:  0.8188\n",
            "Time:  0.1324 Epoch: 261 Iter: 1700/3510 LR: 0.0000051579 Loss content:  0.0146 Loss fft:  0.8532\n",
            "Time:  0.1325 Epoch: 261 Iter: 1800/3510 LR: 0.0000051579 Loss content:  0.0144 Loss fft:  0.8402\n",
            "Time:  0.1304 Epoch: 261 Iter: 1900/3510 LR: 0.0000051579 Loss content:  0.0143 Loss fft:  0.8518\n",
            "Time:  0.1317 Epoch: 261 Iter: 2000/3510 LR: 0.0000051579 Loss content:  0.0145 Loss fft:  0.8373\n",
            "Time:  0.1301 Epoch: 261 Iter: 2100/3510 LR: 0.0000051579 Loss content:  0.0146 Loss fft:  0.8487\n",
            "Time:  0.1318 Epoch: 261 Iter: 2200/3510 LR: 0.0000051579 Loss content:  0.0151 Loss fft:  0.8330\n",
            "Time:  0.1318 Epoch: 261 Iter: 2300/3510 LR: 0.0000051579 Loss content:  0.0144 Loss fft:  0.8272\n",
            "Time:  0.1302 Epoch: 261 Iter: 2400/3510 LR: 0.0000051579 Loss content:  0.0148 Loss fft:  0.8317\n",
            "Time:  0.1318 Epoch: 261 Iter: 2500/3510 LR: 0.0000051579 Loss content:  0.0155 Loss fft:  0.8547\n",
            "Time:  0.1356 Epoch: 261 Iter: 2600/3510 LR: 0.0000051579 Loss content:  0.0154 Loss fft:  0.8252\n",
            "Time:  0.1335 Epoch: 261 Iter: 2700/3510 LR: 0.0000051579 Loss content:  0.0147 Loss fft:  0.8388\n",
            "Time:  0.1294 Epoch: 261 Iter: 2800/3510 LR: 0.0000051579 Loss content:  0.0148 Loss fft:  0.8529\n",
            "Time:  0.1326 Epoch: 261 Iter: 2900/3510 LR: 0.0000051579 Loss content:  0.0148 Loss fft:  0.8582\n",
            "Time:  0.1300 Epoch: 261 Iter: 3000/3510 LR: 0.0000051579 Loss content:  0.0148 Loss fft:  0.8489\n",
            "Time:  0.1313 Epoch: 261 Iter: 3100/3510 LR: 0.0000051579 Loss content:  0.0145 Loss fft:  0.8401\n",
            "Time:  0.1281 Epoch: 261 Iter: 3200/3510 LR: 0.0000051579 Loss content:  0.0150 Loss fft:  0.8428\n",
            "Time:  0.1290 Epoch: 261 Iter: 3300/3510 LR: 0.0000051579 Loss content:  0.0149 Loss fft:  0.8484\n",
            "Time:  0.1313 Epoch: 261 Iter: 3400/3510 LR: 0.0000051579 Loss content:  0.0151 Loss fft:  0.8564\n",
            "Time:  0.1328 Epoch: 261 Iter: 3500/3510 LR: 0.0000051579 Loss content:  0.0149 Loss fft:  0.8333\n",
            "EPOCH: 261\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0148 Epoch FFT Loss:  0.8415\n",
            "Time:  0.1438 Epoch: 262 Iter:  100/3510 LR: 0.0000049505 Loss content:  0.0144 Loss fft:  0.8449\n",
            "Time:  0.1333 Epoch: 262 Iter:  200/3510 LR: 0.0000049505 Loss content:  0.0150 Loss fft:  0.8478\n",
            "Time:  0.1317 Epoch: 262 Iter:  300/3510 LR: 0.0000049505 Loss content:  0.0149 Loss fft:  0.8410\n",
            "Time:  0.1295 Epoch: 262 Iter:  400/3510 LR: 0.0000049505 Loss content:  0.0145 Loss fft:  0.8501\n",
            "Time:  0.1332 Epoch: 262 Iter:  500/3510 LR: 0.0000049505 Loss content:  0.0146 Loss fft:  0.8504\n",
            "Time:  0.1301 Epoch: 262 Iter:  600/3510 LR: 0.0000049505 Loss content:  0.0146 Loss fft:  0.8629\n",
            "Time:  0.1335 Epoch: 262 Iter:  700/3510 LR: 0.0000049505 Loss content:  0.0148 Loss fft:  0.8224\n",
            "Time:  0.1336 Epoch: 262 Iter:  800/3510 LR: 0.0000049505 Loss content:  0.0142 Loss fft:  0.8197\n",
            "Time:  0.1328 Epoch: 262 Iter:  900/3510 LR: 0.0000049505 Loss content:  0.0152 Loss fft:  0.8457\n",
            "Time:  0.1316 Epoch: 262 Iter: 1000/3510 LR: 0.0000049505 Loss content:  0.0147 Loss fft:  0.8326\n",
            "Time:  0.1304 Epoch: 262 Iter: 1100/3510 LR: 0.0000049505 Loss content:  0.0147 Loss fft:  0.8393\n",
            "Time:  0.1312 Epoch: 262 Iter: 1200/3510 LR: 0.0000049505 Loss content:  0.0142 Loss fft:  0.8344\n",
            "Time:  0.1375 Epoch: 262 Iter: 1300/3510 LR: 0.0000049505 Loss content:  0.0148 Loss fft:  0.8446\n",
            "Time:  0.1326 Epoch: 262 Iter: 1400/3510 LR: 0.0000049505 Loss content:  0.0144 Loss fft:  0.8217\n",
            "Time:  0.1316 Epoch: 262 Iter: 1500/3510 LR: 0.0000049505 Loss content:  0.0148 Loss fft:  0.8418\n",
            "Time:  0.1330 Epoch: 262 Iter: 1600/3510 LR: 0.0000049505 Loss content:  0.0143 Loss fft:  0.8369\n",
            "Time:  0.1296 Epoch: 262 Iter: 1700/3510 LR: 0.0000049505 Loss content:  0.0147 Loss fft:  0.8365\n",
            "Time:  0.1331 Epoch: 262 Iter: 1800/3510 LR: 0.0000049505 Loss content:  0.0146 Loss fft:  0.8288\n",
            "Time:  0.1329 Epoch: 262 Iter: 1900/3510 LR: 0.0000049505 Loss content:  0.0145 Loss fft:  0.8456\n",
            "Time:  0.1315 Epoch: 262 Iter: 2000/3510 LR: 0.0000049505 Loss content:  0.0147 Loss fft:  0.8378\n",
            "Time:  0.1315 Epoch: 262 Iter: 2100/3510 LR: 0.0000049505 Loss content:  0.0143 Loss fft:  0.8339\n",
            "Time:  0.1319 Epoch: 262 Iter: 2200/3510 LR: 0.0000049505 Loss content:  0.0146 Loss fft:  0.8424\n",
            "Time:  0.1332 Epoch: 262 Iter: 2300/3510 LR: 0.0000049505 Loss content:  0.0147 Loss fft:  0.8419\n",
            "Time:  0.1313 Epoch: 262 Iter: 2400/3510 LR: 0.0000049505 Loss content:  0.0149 Loss fft:  0.8507\n",
            "Time:  0.1309 Epoch: 262 Iter: 2500/3510 LR: 0.0000049505 Loss content:  0.0146 Loss fft:  0.8350\n",
            "Time:  0.1315 Epoch: 262 Iter: 2600/3510 LR: 0.0000049505 Loss content:  0.0144 Loss fft:  0.8232\n",
            "Time:  0.1330 Epoch: 262 Iter: 2700/3510 LR: 0.0000049505 Loss content:  0.0150 Loss fft:  0.8554\n",
            "Time:  0.1311 Epoch: 262 Iter: 2800/3510 LR: 0.0000049505 Loss content:  0.0148 Loss fft:  0.8467\n",
            "Time:  0.1325 Epoch: 262 Iter: 2900/3510 LR: 0.0000049505 Loss content:  0.0150 Loss fft:  0.8550\n",
            "Time:  0.1314 Epoch: 262 Iter: 3000/3510 LR: 0.0000049505 Loss content:  0.0141 Loss fft:  0.8239\n",
            "Time:  0.1338 Epoch: 262 Iter: 3100/3510 LR: 0.0000049505 Loss content:  0.0149 Loss fft:  0.8487\n",
            "Time:  0.1316 Epoch: 262 Iter: 3200/3510 LR: 0.0000049505 Loss content:  0.0146 Loss fft:  0.8346\n",
            "Time:  0.1337 Epoch: 262 Iter: 3300/3510 LR: 0.0000049505 Loss content:  0.0153 Loss fft:  0.8584\n",
            "Time:  0.1327 Epoch: 262 Iter: 3400/3510 LR: 0.0000049505 Loss content:  0.0145 Loss fft:  0.8535\n",
            "Time:  0.1285 Epoch: 262 Iter: 3500/3510 LR: 0.0000049505 Loss content:  0.0146 Loss fft:  0.8246\n",
            "EPOCH: 262\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0147 Epoch FFT Loss:  0.8401\n",
            "Time:  0.1482 Epoch: 263 Iter:  100/3510 LR: 0.0000047482 Loss content:  0.0142 Loss fft:  0.8215\n",
            "Time:  0.1291 Epoch: 263 Iter:  200/3510 LR: 0.0000047482 Loss content:  0.0145 Loss fft:  0.8462\n",
            "Time:  0.1299 Epoch: 263 Iter:  300/3510 LR: 0.0000047482 Loss content:  0.0148 Loss fft:  0.8402\n",
            "Time:  0.1335 Epoch: 263 Iter:  400/3510 LR: 0.0000047482 Loss content:  0.0144 Loss fft:  0.8250\n",
            "Time:  0.1317 Epoch: 263 Iter:  500/3510 LR: 0.0000047482 Loss content:  0.0146 Loss fft:  0.8469\n",
            "Time:  0.1315 Epoch: 263 Iter:  600/3510 LR: 0.0000047482 Loss content:  0.0144 Loss fft:  0.8255\n",
            "Time:  0.1325 Epoch: 263 Iter:  700/3510 LR: 0.0000047482 Loss content:  0.0143 Loss fft:  0.8207\n",
            "Time:  0.1341 Epoch: 263 Iter:  800/3510 LR: 0.0000047482 Loss content:  0.0145 Loss fft:  0.8255\n",
            "Time:  0.1291 Epoch: 263 Iter:  900/3510 LR: 0.0000047482 Loss content:  0.0142 Loss fft:  0.8268\n",
            "Time:  0.1331 Epoch: 263 Iter: 1000/3510 LR: 0.0000047482 Loss content:  0.0150 Loss fft:  0.8613\n",
            "Time:  0.1321 Epoch: 263 Iter: 1100/3510 LR: 0.0000047482 Loss content:  0.0147 Loss fft:  0.8442\n",
            "Time:  0.1314 Epoch: 263 Iter: 1200/3510 LR: 0.0000047482 Loss content:  0.0147 Loss fft:  0.8419\n",
            "Time:  0.1301 Epoch: 263 Iter: 1300/3510 LR: 0.0000047482 Loss content:  0.0149 Loss fft:  0.8143\n",
            "Time:  0.1324 Epoch: 263 Iter: 1400/3510 LR: 0.0000047482 Loss content:  0.0140 Loss fft:  0.8284\n",
            "Time:  0.1308 Epoch: 263 Iter: 1500/3510 LR: 0.0000047482 Loss content:  0.0148 Loss fft:  0.8465\n",
            "Time:  0.1317 Epoch: 263 Iter: 1600/3510 LR: 0.0000047482 Loss content:  0.0149 Loss fft:  0.8580\n",
            "Time:  0.1318 Epoch: 263 Iter: 1700/3510 LR: 0.0000047482 Loss content:  0.0143 Loss fft:  0.8298\n",
            "Time:  0.1294 Epoch: 263 Iter: 1800/3510 LR: 0.0000047482 Loss content:  0.0142 Loss fft:  0.8298\n",
            "Time:  0.1322 Epoch: 263 Iter: 1900/3510 LR: 0.0000047482 Loss content:  0.0152 Loss fft:  0.8741\n",
            "Time:  0.1327 Epoch: 263 Iter: 2000/3510 LR: 0.0000047482 Loss content:  0.0148 Loss fft:  0.8247\n",
            "Time:  0.1315 Epoch: 263 Iter: 2100/3510 LR: 0.0000047482 Loss content:  0.0145 Loss fft:  0.8307\n",
            "Time:  0.1321 Epoch: 263 Iter: 2200/3510 LR: 0.0000047482 Loss content:  0.0146 Loss fft:  0.8428\n",
            "Time:  0.1329 Epoch: 263 Iter: 2300/3510 LR: 0.0000047482 Loss content:  0.0142 Loss fft:  0.8244\n",
            "Time:  0.1333 Epoch: 263 Iter: 2400/3510 LR: 0.0000047482 Loss content:  0.0143 Loss fft:  0.8482\n",
            "Time:  0.1357 Epoch: 263 Iter: 2500/3510 LR: 0.0000047482 Loss content:  0.0147 Loss fft:  0.8512\n",
            "Time:  0.1317 Epoch: 263 Iter: 2600/3510 LR: 0.0000047482 Loss content:  0.0146 Loss fft:  0.8533\n",
            "Time:  0.1297 Epoch: 263 Iter: 2700/3510 LR: 0.0000047482 Loss content:  0.0151 Loss fft:  0.8531\n",
            "Time:  0.1314 Epoch: 263 Iter: 2800/3510 LR: 0.0000047482 Loss content:  0.0156 Loss fft:  0.8617\n",
            "Time:  0.1300 Epoch: 263 Iter: 2900/3510 LR: 0.0000047482 Loss content:  0.0142 Loss fft:  0.8306\n",
            "Time:  0.1315 Epoch: 263 Iter: 3000/3510 LR: 0.0000047482 Loss content:  0.0147 Loss fft:  0.8360\n",
            "Time:  0.1294 Epoch: 263 Iter: 3100/3510 LR: 0.0000047482 Loss content:  0.0146 Loss fft:  0.8429\n",
            "Time:  0.1316 Epoch: 263 Iter: 3200/3510 LR: 0.0000047482 Loss content:  0.0147 Loss fft:  0.8414\n",
            "Time:  0.1346 Epoch: 263 Iter: 3300/3510 LR: 0.0000047482 Loss content:  0.0147 Loss fft:  0.8308\n",
            "Time:  0.1296 Epoch: 263 Iter: 3400/3510 LR: 0.0000047482 Loss content:  0.0151 Loss fft:  0.8428\n",
            "Time:  0.1294 Epoch: 263 Iter: 3500/3510 LR: 0.0000047482 Loss content:  0.0149 Loss fft:  0.8329\n",
            "EPOCH: 263\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0146 Epoch FFT Loss:  0.8385\n",
            "Time:  0.1393 Epoch: 264 Iter:  100/3510 LR: 0.0000045510 Loss content:  0.0150 Loss fft:  0.8249\n",
            "Time:  0.1327 Epoch: 264 Iter:  200/3510 LR: 0.0000045510 Loss content:  0.0141 Loss fft:  0.8347\n",
            "Time:  0.1329 Epoch: 264 Iter:  300/3510 LR: 0.0000045510 Loss content:  0.0147 Loss fft:  0.8420\n",
            "Time:  0.1286 Epoch: 264 Iter:  400/3510 LR: 0.0000045510 Loss content:  0.0140 Loss fft:  0.8338\n",
            "Time:  0.1317 Epoch: 264 Iter:  500/3510 LR: 0.0000045510 Loss content:  0.0145 Loss fft:  0.8188\n",
            "Time:  0.1317 Epoch: 264 Iter:  600/3510 LR: 0.0000045510 Loss content:  0.0152 Loss fft:  0.8253\n",
            "Time:  0.1311 Epoch: 264 Iter:  700/3510 LR: 0.0000045510 Loss content:  0.0145 Loss fft:  0.8314\n",
            "Time:  0.1337 Epoch: 264 Iter:  800/3510 LR: 0.0000045510 Loss content:  0.0146 Loss fft:  0.8302\n",
            "Time:  0.1331 Epoch: 264 Iter:  900/3510 LR: 0.0000045510 Loss content:  0.0150 Loss fft:  0.8579\n",
            "Time:  0.1307 Epoch: 264 Iter: 1000/3510 LR: 0.0000045510 Loss content:  0.0142 Loss fft:  0.8294\n",
            "Time:  0.1318 Epoch: 264 Iter: 1100/3510 LR: 0.0000045510 Loss content:  0.0148 Loss fft:  0.8608\n",
            "Time:  0.1299 Epoch: 264 Iter: 1200/3510 LR: 0.0000045510 Loss content:  0.0141 Loss fft:  0.8290\n",
            "Time:  0.1372 Epoch: 264 Iter: 1300/3510 LR: 0.0000045510 Loss content:  0.0147 Loss fft:  0.8492\n",
            "Time:  0.1311 Epoch: 264 Iter: 1400/3510 LR: 0.0000045510 Loss content:  0.0149 Loss fft:  0.8486\n",
            "Time:  0.1333 Epoch: 264 Iter: 1500/3510 LR: 0.0000045510 Loss content:  0.0143 Loss fft:  0.8173\n",
            "Time:  0.1314 Epoch: 264 Iter: 1600/3510 LR: 0.0000045510 Loss content:  0.0148 Loss fft:  0.8597\n",
            "Time:  0.1317 Epoch: 264 Iter: 1700/3510 LR: 0.0000045510 Loss content:  0.0147 Loss fft:  0.8268\n",
            "Time:  0.1309 Epoch: 264 Iter: 1800/3510 LR: 0.0000045510 Loss content:  0.0144 Loss fft:  0.8336\n",
            "Time:  0.1331 Epoch: 264 Iter: 1900/3510 LR: 0.0000045510 Loss content:  0.0146 Loss fft:  0.8585\n",
            "Time:  0.1327 Epoch: 264 Iter: 2000/3510 LR: 0.0000045510 Loss content:  0.0147 Loss fft:  0.8423\n",
            "Time:  0.1343 Epoch: 264 Iter: 2100/3510 LR: 0.0000045510 Loss content:  0.0143 Loss fft:  0.8348\n",
            "Time:  0.1336 Epoch: 264 Iter: 2200/3510 LR: 0.0000045510 Loss content:  0.0148 Loss fft:  0.8569\n",
            "Time:  0.1296 Epoch: 264 Iter: 2300/3510 LR: 0.0000045510 Loss content:  0.0144 Loss fft:  0.8248\n",
            "Time:  0.1342 Epoch: 264 Iter: 2400/3510 LR: 0.0000045510 Loss content:  0.0147 Loss fft:  0.8386\n",
            "Time:  0.1308 Epoch: 264 Iter: 2500/3510 LR: 0.0000045510 Loss content:  0.0150 Loss fft:  0.8703\n",
            "Time:  0.1336 Epoch: 264 Iter: 2600/3510 LR: 0.0000045510 Loss content:  0.0148 Loss fft:  0.8370\n",
            "Time:  0.1289 Epoch: 264 Iter: 2700/3510 LR: 0.0000045510 Loss content:  0.0150 Loss fft:  0.8515\n",
            "Time:  0.1324 Epoch: 264 Iter: 2800/3510 LR: 0.0000045510 Loss content:  0.0146 Loss fft:  0.8552\n",
            "Time:  0.1308 Epoch: 264 Iter: 2900/3510 LR: 0.0000045510 Loss content:  0.0151 Loss fft:  0.8307\n",
            "Time:  0.1308 Epoch: 264 Iter: 3000/3510 LR: 0.0000045510 Loss content:  0.0144 Loss fft:  0.8223\n",
            "Time:  0.1304 Epoch: 264 Iter: 3100/3510 LR: 0.0000045510 Loss content:  0.0146 Loss fft:  0.8346\n",
            "Time:  0.1308 Epoch: 264 Iter: 3200/3510 LR: 0.0000045510 Loss content:  0.0147 Loss fft:  0.8447\n",
            "Time:  0.1316 Epoch: 264 Iter: 3300/3510 LR: 0.0000045510 Loss content:  0.0145 Loss fft:  0.8302\n",
            "Time:  0.1298 Epoch: 264 Iter: 3400/3510 LR: 0.0000045510 Loss content:  0.0145 Loss fft:  0.8340\n",
            "Time:  0.1327 Epoch: 264 Iter: 3500/3510 LR: 0.0000045510 Loss content:  0.0143 Loss fft:  0.8256\n",
            "EPOCH: 264\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0146 Epoch FFT Loss:  0.8386\n",
            "Time:  0.1419 Epoch: 265 Iter:  100/3510 LR: 0.0000043590 Loss content:  0.0147 Loss fft:  0.8492\n",
            "Time:  0.1331 Epoch: 265 Iter:  200/3510 LR: 0.0000043590 Loss content:  0.0148 Loss fft:  0.8394\n",
            "Time:  0.1321 Epoch: 265 Iter:  300/3510 LR: 0.0000043590 Loss content:  0.0147 Loss fft:  0.8556\n",
            "Time:  0.1297 Epoch: 265 Iter:  400/3510 LR: 0.0000043590 Loss content:  0.0146 Loss fft:  0.8318\n",
            "Time:  0.1327 Epoch: 265 Iter:  500/3510 LR: 0.0000043590 Loss content:  0.0148 Loss fft:  0.8474\n",
            "Time:  0.1333 Epoch: 265 Iter:  600/3510 LR: 0.0000043590 Loss content:  0.0147 Loss fft:  0.8445\n",
            "Time:  0.1319 Epoch: 265 Iter:  700/3510 LR: 0.0000043590 Loss content:  0.0143 Loss fft:  0.8327\n",
            "Time:  0.1291 Epoch: 265 Iter:  800/3510 LR: 0.0000043590 Loss content:  0.0146 Loss fft:  0.8408\n",
            "Time:  0.1332 Epoch: 265 Iter:  900/3510 LR: 0.0000043590 Loss content:  0.0147 Loss fft:  0.8259\n",
            "Time:  0.1293 Epoch: 265 Iter: 1000/3510 LR: 0.0000043590 Loss content:  0.0146 Loss fft:  0.8201\n",
            "Time:  0.1308 Epoch: 265 Iter: 1100/3510 LR: 0.0000043590 Loss content:  0.0146 Loss fft:  0.8402\n",
            "Time:  0.1300 Epoch: 265 Iter: 1200/3510 LR: 0.0000043590 Loss content:  0.0143 Loss fft:  0.8205\n",
            "Time:  0.1301 Epoch: 265 Iter: 1300/3510 LR: 0.0000043590 Loss content:  0.0148 Loss fft:  0.8288\n",
            "Time:  0.1291 Epoch: 265 Iter: 1400/3510 LR: 0.0000043590 Loss content:  0.0148 Loss fft:  0.8406\n",
            "Time:  0.1286 Epoch: 265 Iter: 1500/3510 LR: 0.0000043590 Loss content:  0.0155 Loss fft:  0.8478\n",
            "Time:  0.1336 Epoch: 265 Iter: 1600/3510 LR: 0.0000043590 Loss content:  0.0144 Loss fft:  0.8355\n",
            "Time:  0.1313 Epoch: 265 Iter: 1700/3510 LR: 0.0000043590 Loss content:  0.0140 Loss fft:  0.8209\n",
            "Time:  0.1333 Epoch: 265 Iter: 1800/3510 LR: 0.0000043590 Loss content:  0.0148 Loss fft:  0.8382\n",
            "Time:  0.1277 Epoch: 265 Iter: 1900/3510 LR: 0.0000043590 Loss content:  0.0145 Loss fft:  0.8417\n",
            "Time:  0.1305 Epoch: 265 Iter: 2000/3510 LR: 0.0000043590 Loss content:  0.0142 Loss fft:  0.8357\n",
            "Time:  0.1327 Epoch: 265 Iter: 2100/3510 LR: 0.0000043590 Loss content:  0.0148 Loss fft:  0.8203\n",
            "Time:  0.1319 Epoch: 265 Iter: 2200/3510 LR: 0.0000043590 Loss content:  0.0143 Loss fft:  0.8517\n",
            "Time:  0.1293 Epoch: 265 Iter: 2300/3510 LR: 0.0000043590 Loss content:  0.0146 Loss fft:  0.8413\n",
            "Time:  0.1351 Epoch: 265 Iter: 2400/3510 LR: 0.0000043590 Loss content:  0.0148 Loss fft:  0.8429\n",
            "Time:  0.1318 Epoch: 265 Iter: 2500/3510 LR: 0.0000043590 Loss content:  0.0149 Loss fft:  0.8329\n",
            "Time:  0.1301 Epoch: 265 Iter: 2600/3510 LR: 0.0000043590 Loss content:  0.0145 Loss fft:  0.8365\n",
            "Time:  0.1278 Epoch: 265 Iter: 2700/3510 LR: 0.0000043590 Loss content:  0.0143 Loss fft:  0.8313\n",
            "Time:  0.1313 Epoch: 265 Iter: 2800/3510 LR: 0.0000043590 Loss content:  0.0143 Loss fft:  0.8474\n",
            "Time:  0.1299 Epoch: 265 Iter: 2900/3510 LR: 0.0000043590 Loss content:  0.0146 Loss fft:  0.8381\n",
            "Time:  0.1286 Epoch: 265 Iter: 3000/3510 LR: 0.0000043590 Loss content:  0.0146 Loss fft:  0.8436\n",
            "Time:  0.1291 Epoch: 265 Iter: 3100/3510 LR: 0.0000043590 Loss content:  0.0146 Loss fft:  0.8409\n",
            "Time:  0.1293 Epoch: 265 Iter: 3200/3510 LR: 0.0000043590 Loss content:  0.0146 Loss fft:  0.8342\n",
            "Time:  0.1338 Epoch: 265 Iter: 3300/3510 LR: 0.0000043590 Loss content:  0.0142 Loss fft:  0.8365\n",
            "Time:  0.1296 Epoch: 265 Iter: 3400/3510 LR: 0.0000043590 Loss content:  0.0147 Loss fft:  0.8564\n",
            "Time:  0.1311 Epoch: 265 Iter: 3500/3510 LR: 0.0000043590 Loss content:  0.0146 Loss fft:  0.8363\n",
            "EPOCH: 265\n",
            "Elapsed time: 4.61 Epoch Pixel Loss:  0.0146 Epoch FFT Loss:  0.8382\n",
            "Time:  0.1423 Epoch: 266 Iter:  100/3510 LR: 0.0000041721 Loss content:  0.0148 Loss fft:  0.8543\n",
            "Time:  0.1312 Epoch: 266 Iter:  200/3510 LR: 0.0000041721 Loss content:  0.0146 Loss fft:  0.8409\n",
            "Time:  0.1320 Epoch: 266 Iter:  300/3510 LR: 0.0000041721 Loss content:  0.0148 Loss fft:  0.8416\n",
            "Time:  0.1304 Epoch: 266 Iter:  400/3510 LR: 0.0000041721 Loss content:  0.0148 Loss fft:  0.8442\n",
            "Time:  0.1327 Epoch: 266 Iter:  500/3510 LR: 0.0000041721 Loss content:  0.0144 Loss fft:  0.8300\n",
            "Time:  0.1298 Epoch: 266 Iter:  600/3510 LR: 0.0000041721 Loss content:  0.0147 Loss fft:  0.8451\n",
            "Time:  0.1307 Epoch: 266 Iter:  700/3510 LR: 0.0000041721 Loss content:  0.0143 Loss fft:  0.8480\n",
            "Time:  0.1318 Epoch: 266 Iter:  800/3510 LR: 0.0000041721 Loss content:  0.0142 Loss fft:  0.8407\n",
            "Time:  0.1318 Epoch: 266 Iter:  900/3510 LR: 0.0000041721 Loss content:  0.0143 Loss fft:  0.8290\n",
            "Time:  0.1341 Epoch: 266 Iter: 1000/3510 LR: 0.0000041721 Loss content:  0.0151 Loss fft:  0.8337\n",
            "Time:  0.1295 Epoch: 266 Iter: 1100/3510 LR: 0.0000041721 Loss content:  0.0147 Loss fft:  0.8424\n",
            "Time:  0.1359 Epoch: 266 Iter: 1200/3510 LR: 0.0000041721 Loss content:  0.0144 Loss fft:  0.8337\n",
            "Time:  0.1310 Epoch: 266 Iter: 1300/3510 LR: 0.0000041721 Loss content:  0.0143 Loss fft:  0.8165\n",
            "Time:  0.1322 Epoch: 266 Iter: 1400/3510 LR: 0.0000041721 Loss content:  0.0146 Loss fft:  0.8457\n",
            "Time:  0.1300 Epoch: 266 Iter: 1500/3510 LR: 0.0000041721 Loss content:  0.0142 Loss fft:  0.8215\n",
            "Time:  0.1297 Epoch: 266 Iter: 1600/3510 LR: 0.0000041721 Loss content:  0.0145 Loss fft:  0.8449\n",
            "Time:  0.1286 Epoch: 266 Iter: 1700/3510 LR: 0.0000041721 Loss content:  0.0144 Loss fft:  0.8287\n",
            "Time:  0.1312 Epoch: 266 Iter: 1800/3510 LR: 0.0000041721 Loss content:  0.0141 Loss fft:  0.8336\n",
            "Time:  0.1322 Epoch: 266 Iter: 1900/3510 LR: 0.0000041721 Loss content:  0.0144 Loss fft:  0.8458\n",
            "Time:  0.1322 Epoch: 266 Iter: 2000/3510 LR: 0.0000041721 Loss content:  0.0146 Loss fft:  0.8274\n",
            "Time:  0.1331 Epoch: 266 Iter: 2100/3510 LR: 0.0000041721 Loss content:  0.0142 Loss fft:  0.8175\n",
            "Time:  0.1307 Epoch: 266 Iter: 2200/3510 LR: 0.0000041721 Loss content:  0.0144 Loss fft:  0.8485\n",
            "Time:  0.1305 Epoch: 266 Iter: 2300/3510 LR: 0.0000041721 Loss content:  0.0142 Loss fft:  0.8268\n",
            "Time:  0.1317 Epoch: 266 Iter: 2400/3510 LR: 0.0000041721 Loss content:  0.0146 Loss fft:  0.8537\n",
            "Time:  0.1324 Epoch: 266 Iter: 2500/3510 LR: 0.0000041721 Loss content:  0.0146 Loss fft:  0.8433\n",
            "Time:  0.1295 Epoch: 266 Iter: 2600/3510 LR: 0.0000041721 Loss content:  0.0148 Loss fft:  0.8366\n",
            "Time:  0.1317 Epoch: 266 Iter: 2700/3510 LR: 0.0000041721 Loss content:  0.0150 Loss fft:  0.8399\n",
            "Time:  0.1312 Epoch: 266 Iter: 2800/3510 LR: 0.0000041721 Loss content:  0.0140 Loss fft:  0.8189\n",
            "Time:  0.1300 Epoch: 266 Iter: 2900/3510 LR: 0.0000041721 Loss content:  0.0145 Loss fft:  0.8453\n",
            "Time:  0.1275 Epoch: 266 Iter: 3000/3510 LR: 0.0000041721 Loss content:  0.0142 Loss fft:  0.8368\n",
            "Time:  0.1300 Epoch: 266 Iter: 3100/3510 LR: 0.0000041721 Loss content:  0.0146 Loss fft:  0.8219\n",
            "Time:  0.1316 Epoch: 266 Iter: 3200/3510 LR: 0.0000041721 Loss content:  0.0143 Loss fft:  0.8368\n",
            "Time:  0.1349 Epoch: 266 Iter: 3300/3510 LR: 0.0000041721 Loss content:  0.0145 Loss fft:  0.8265\n",
            "Time:  0.1318 Epoch: 266 Iter: 3400/3510 LR: 0.0000041721 Loss content:  0.0144 Loss fft:  0.8532\n",
            "Time:  0.1289 Epoch: 266 Iter: 3500/3510 LR: 0.0000041721 Loss content:  0.0145 Loss fft:  0.8407\n",
            "EPOCH: 266\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0145 Epoch FFT Loss:  0.8371\n",
            "Time:  0.1421 Epoch: 267 Iter:  100/3510 LR: 0.0000039904 Loss content:  0.0143 Loss fft:  0.8440\n",
            "Time:  0.1331 Epoch: 267 Iter:  200/3510 LR: 0.0000039904 Loss content:  0.0146 Loss fft:  0.8489\n",
            "Time:  0.1333 Epoch: 267 Iter:  300/3510 LR: 0.0000039904 Loss content:  0.0144 Loss fft:  0.8435\n",
            "Time:  0.1329 Epoch: 267 Iter:  400/3510 LR: 0.0000039904 Loss content:  0.0144 Loss fft:  0.8307\n",
            "Time:  0.1315 Epoch: 267 Iter:  500/3510 LR: 0.0000039904 Loss content:  0.0143 Loss fft:  0.8367\n",
            "Time:  0.1318 Epoch: 267 Iter:  600/3510 LR: 0.0000039904 Loss content:  0.0147 Loss fft:  0.8321\n",
            "Time:  0.1297 Epoch: 267 Iter:  700/3510 LR: 0.0000039904 Loss content:  0.0145 Loss fft:  0.8305\n",
            "Time:  0.1299 Epoch: 267 Iter:  800/3510 LR: 0.0000039904 Loss content:  0.0140 Loss fft:  0.8337\n",
            "Time:  0.1307 Epoch: 267 Iter:  900/3510 LR: 0.0000039904 Loss content:  0.0145 Loss fft:  0.8657\n",
            "Time:  0.1285 Epoch: 267 Iter: 1000/3510 LR: 0.0000039904 Loss content:  0.0145 Loss fft:  0.8298\n",
            "Time:  0.1298 Epoch: 267 Iter: 1100/3510 LR: 0.0000039904 Loss content:  0.0140 Loss fft:  0.8307\n",
            "Time:  0.1308 Epoch: 267 Iter: 1200/3510 LR: 0.0000039904 Loss content:  0.0146 Loss fft:  0.8400\n",
            "Time:  0.1298 Epoch: 267 Iter: 1300/3510 LR: 0.0000039904 Loss content:  0.0152 Loss fft:  0.8302\n",
            "Time:  0.1320 Epoch: 267 Iter: 1400/3510 LR: 0.0000039904 Loss content:  0.0147 Loss fft:  0.8370\n",
            "Time:  0.1282 Epoch: 267 Iter: 1500/3510 LR: 0.0000039904 Loss content:  0.0149 Loss fft:  0.8257\n",
            "Time:  0.1288 Epoch: 267 Iter: 1600/3510 LR: 0.0000039904 Loss content:  0.0145 Loss fft:  0.8133\n",
            "Time:  0.1292 Epoch: 267 Iter: 1700/3510 LR: 0.0000039904 Loss content:  0.0142 Loss fft:  0.8361\n",
            "Time:  0.1299 Epoch: 267 Iter: 1800/3510 LR: 0.0000039904 Loss content:  0.0146 Loss fft:  0.8489\n",
            "Time:  0.1324 Epoch: 267 Iter: 1900/3510 LR: 0.0000039904 Loss content:  0.0145 Loss fft:  0.8317\n",
            "Time:  0.1333 Epoch: 267 Iter: 2000/3510 LR: 0.0000039904 Loss content:  0.0142 Loss fft:  0.8174\n",
            "Time:  0.1323 Epoch: 267 Iter: 2100/3510 LR: 0.0000039904 Loss content:  0.0148 Loss fft:  0.8387\n",
            "Time:  0.1309 Epoch: 267 Iter: 2200/3510 LR: 0.0000039904 Loss content:  0.0148 Loss fft:  0.8490\n",
            "Time:  0.1305 Epoch: 267 Iter: 2300/3510 LR: 0.0000039904 Loss content:  0.0145 Loss fft:  0.8339\n",
            "Time:  0.1357 Epoch: 267 Iter: 2400/3510 LR: 0.0000039904 Loss content:  0.0153 Loss fft:  0.8504\n",
            "Time:  0.1328 Epoch: 267 Iter: 2500/3510 LR: 0.0000039904 Loss content:  0.0142 Loss fft:  0.8338\n",
            "Time:  0.1324 Epoch: 267 Iter: 2600/3510 LR: 0.0000039904 Loss content:  0.0146 Loss fft:  0.8427\n",
            "Time:  0.1312 Epoch: 267 Iter: 2700/3510 LR: 0.0000039904 Loss content:  0.0143 Loss fft:  0.8234\n",
            "Time:  0.1288 Epoch: 267 Iter: 2800/3510 LR: 0.0000039904 Loss content:  0.0145 Loss fft:  0.8367\n",
            "Time:  0.1283 Epoch: 267 Iter: 2900/3510 LR: 0.0000039904 Loss content:  0.0144 Loss fft:  0.8342\n",
            "Time:  0.1295 Epoch: 267 Iter: 3000/3510 LR: 0.0000039904 Loss content:  0.0146 Loss fft:  0.8787\n",
            "Time:  0.1298 Epoch: 267 Iter: 3100/3510 LR: 0.0000039904 Loss content:  0.0142 Loss fft:  0.8197\n",
            "Time:  0.1326 Epoch: 267 Iter: 3200/3510 LR: 0.0000039904 Loss content:  0.0147 Loss fft:  0.8458\n",
            "Time:  0.1316 Epoch: 267 Iter: 3300/3510 LR: 0.0000039904 Loss content:  0.0148 Loss fft:  0.8384\n",
            "Time:  0.1321 Epoch: 267 Iter: 3400/3510 LR: 0.0000039904 Loss content:  0.0146 Loss fft:  0.8386\n",
            "Time:  0.1284 Epoch: 267 Iter: 3500/3510 LR: 0.0000039904 Loss content:  0.0145 Loss fft:  0.8461\n",
            "EPOCH: 267\n",
            "Elapsed time: 4.61 Epoch Pixel Loss:  0.0145 Epoch FFT Loss:  0.8374\n",
            "Time:  0.1419 Epoch: 268 Iter:  100/3510 LR: 0.0000038140 Loss content:  0.0140 Loss fft:  0.8244\n",
            "Time:  0.1313 Epoch: 268 Iter:  200/3510 LR: 0.0000038140 Loss content:  0.0145 Loss fft:  0.8282\n",
            "Time:  0.1307 Epoch: 268 Iter:  300/3510 LR: 0.0000038140 Loss content:  0.0143 Loss fft:  0.8355\n",
            "Time:  0.1335 Epoch: 268 Iter:  400/3510 LR: 0.0000038140 Loss content:  0.0148 Loss fft:  0.8252\n",
            "Time:  0.1323 Epoch: 268 Iter:  500/3510 LR: 0.0000038140 Loss content:  0.0146 Loss fft:  0.8312\n",
            "Time:  0.1308 Epoch: 268 Iter:  600/3510 LR: 0.0000038140 Loss content:  0.0145 Loss fft:  0.8453\n",
            "Time:  0.1313 Epoch: 268 Iter:  700/3510 LR: 0.0000038140 Loss content:  0.0144 Loss fft:  0.8414\n",
            "Time:  0.1318 Epoch: 268 Iter:  800/3510 LR: 0.0000038140 Loss content:  0.0143 Loss fft:  0.8258\n",
            "Time:  0.1348 Epoch: 268 Iter:  900/3510 LR: 0.0000038140 Loss content:  0.0149 Loss fft:  0.8304\n",
            "Time:  0.1322 Epoch: 268 Iter: 1000/3510 LR: 0.0000038140 Loss content:  0.0148 Loss fft:  0.8382\n",
            "Time:  0.1300 Epoch: 268 Iter: 1100/3510 LR: 0.0000038140 Loss content:  0.0146 Loss fft:  0.8305\n",
            "Time:  0.1380 Epoch: 268 Iter: 1200/3510 LR: 0.0000038140 Loss content:  0.0141 Loss fft:  0.8270\n",
            "Time:  0.1295 Epoch: 268 Iter: 1300/3510 LR: 0.0000038140 Loss content:  0.0143 Loss fft:  0.8146\n",
            "Time:  0.1292 Epoch: 268 Iter: 1400/3510 LR: 0.0000038140 Loss content:  0.0146 Loss fft:  0.8493\n",
            "Time:  0.1312 Epoch: 268 Iter: 1500/3510 LR: 0.0000038140 Loss content:  0.0145 Loss fft:  0.8342\n",
            "Time:  0.1317 Epoch: 268 Iter: 1600/3510 LR: 0.0000038140 Loss content:  0.0148 Loss fft:  0.8393\n",
            "Time:  0.1300 Epoch: 268 Iter: 1700/3510 LR: 0.0000038140 Loss content:  0.0144 Loss fft:  0.8255\n",
            "Time:  0.1299 Epoch: 268 Iter: 1800/3510 LR: 0.0000038140 Loss content:  0.0148 Loss fft:  0.8220\n",
            "Time:  0.1326 Epoch: 268 Iter: 1900/3510 LR: 0.0000038140 Loss content:  0.0140 Loss fft:  0.8343\n",
            "Time:  0.1307 Epoch: 268 Iter: 2000/3510 LR: 0.0000038140 Loss content:  0.0144 Loss fft:  0.8318\n",
            "Time:  0.1301 Epoch: 268 Iter: 2100/3510 LR: 0.0000038140 Loss content:  0.0151 Loss fft:  0.8629\n",
            "Time:  0.1279 Epoch: 268 Iter: 2200/3510 LR: 0.0000038140 Loss content:  0.0146 Loss fft:  0.8454\n",
            "Time:  0.1288 Epoch: 268 Iter: 2300/3510 LR: 0.0000038140 Loss content:  0.0144 Loss fft:  0.8389\n",
            "Time:  0.1285 Epoch: 268 Iter: 2400/3510 LR: 0.0000038140 Loss content:  0.0142 Loss fft:  0.8178\n",
            "Time:  0.1281 Epoch: 268 Iter: 2500/3510 LR: 0.0000038140 Loss content:  0.0144 Loss fft:  0.8358\n",
            "Time:  0.1278 Epoch: 268 Iter: 2600/3510 LR: 0.0000038140 Loss content:  0.0143 Loss fft:  0.8396\n",
            "Time:  0.1289 Epoch: 268 Iter: 2700/3510 LR: 0.0000038140 Loss content:  0.0145 Loss fft:  0.8461\n",
            "Time:  0.1296 Epoch: 268 Iter: 2800/3510 LR: 0.0000038140 Loss content:  0.0140 Loss fft:  0.8210\n",
            "Time:  0.1315 Epoch: 268 Iter: 2900/3510 LR: 0.0000038140 Loss content:  0.0151 Loss fft:  0.8801\n",
            "Time:  0.1306 Epoch: 268 Iter: 3000/3510 LR: 0.0000038140 Loss content:  0.0144 Loss fft:  0.8521\n",
            "Time:  0.1338 Epoch: 268 Iter: 3100/3510 LR: 0.0000038140 Loss content:  0.0142 Loss fft:  0.8355\n",
            "Time:  0.1335 Epoch: 268 Iter: 3200/3510 LR: 0.0000038140 Loss content:  0.0138 Loss fft:  0.8146\n",
            "Time:  0.1330 Epoch: 268 Iter: 3300/3510 LR: 0.0000038140 Loss content:  0.0145 Loss fft:  0.8398\n",
            "Time:  0.1332 Epoch: 268 Iter: 3400/3510 LR: 0.0000038140 Loss content:  0.0145 Loss fft:  0.8347\n",
            "Time:  0.1370 Epoch: 268 Iter: 3500/3510 LR: 0.0000038140 Loss content:  0.0142 Loss fft:  0.8488\n",
            "EPOCH: 268\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0144 Epoch FFT Loss:  0.8359\n",
            "Time:  0.1424 Epoch: 269 Iter:  100/3510 LR: 0.0000036427 Loss content:  0.0141 Loss fft:  0.8442\n",
            "Time:  0.1287 Epoch: 269 Iter:  200/3510 LR: 0.0000036427 Loss content:  0.0149 Loss fft:  0.8600\n",
            "Time:  0.1292 Epoch: 269 Iter:  300/3510 LR: 0.0000036427 Loss content:  0.0148 Loss fft:  0.8535\n",
            "Time:  0.1316 Epoch: 269 Iter:  400/3510 LR: 0.0000036427 Loss content:  0.0144 Loss fft:  0.8452\n",
            "Time:  0.1282 Epoch: 269 Iter:  500/3510 LR: 0.0000036427 Loss content:  0.0149 Loss fft:  0.8567\n",
            "Time:  0.1302 Epoch: 269 Iter:  600/3510 LR: 0.0000036427 Loss content:  0.0143 Loss fft:  0.8322\n",
            "Time:  0.1325 Epoch: 269 Iter:  700/3510 LR: 0.0000036427 Loss content:  0.0146 Loss fft:  0.8350\n",
            "Time:  0.1330 Epoch: 269 Iter:  800/3510 LR: 0.0000036427 Loss content:  0.0140 Loss fft:  0.8111\n",
            "Time:  0.1323 Epoch: 269 Iter:  900/3510 LR: 0.0000036427 Loss content:  0.0145 Loss fft:  0.8321\n",
            "Time:  0.1295 Epoch: 269 Iter: 1000/3510 LR: 0.0000036427 Loss content:  0.0143 Loss fft:  0.8369\n",
            "Time:  0.1299 Epoch: 269 Iter: 1100/3510 LR: 0.0000036427 Loss content:  0.0143 Loss fft:  0.8129\n",
            "Time:  0.1306 Epoch: 269 Iter: 1200/3510 LR: 0.0000036427 Loss content:  0.0144 Loss fft:  0.8568\n",
            "Time:  0.1314 Epoch: 269 Iter: 1300/3510 LR: 0.0000036427 Loss content:  0.0145 Loss fft:  0.8201\n",
            "Time:  0.1305 Epoch: 269 Iter: 1400/3510 LR: 0.0000036427 Loss content:  0.0143 Loss fft:  0.8322\n",
            "Time:  0.1344 Epoch: 269 Iter: 1500/3510 LR: 0.0000036427 Loss content:  0.0140 Loss fft:  0.8282\n",
            "Time:  0.1326 Epoch: 269 Iter: 1600/3510 LR: 0.0000036427 Loss content:  0.0141 Loss fft:  0.8441\n",
            "Time:  0.1331 Epoch: 269 Iter: 1700/3510 LR: 0.0000036427 Loss content:  0.0144 Loss fft:  0.8537\n",
            "Time:  0.1329 Epoch: 269 Iter: 1800/3510 LR: 0.0000036427 Loss content:  0.0141 Loss fft:  0.8300\n",
            "Time:  0.1319 Epoch: 269 Iter: 1900/3510 LR: 0.0000036427 Loss content:  0.0145 Loss fft:  0.8559\n",
            "Time:  0.1317 Epoch: 269 Iter: 2000/3510 LR: 0.0000036427 Loss content:  0.0147 Loss fft:  0.8211\n",
            "Time:  0.1302 Epoch: 269 Iter: 2100/3510 LR: 0.0000036427 Loss content:  0.0147 Loss fft:  0.8493\n",
            "Time:  0.1323 Epoch: 269 Iter: 2200/3510 LR: 0.0000036427 Loss content:  0.0146 Loss fft:  0.8372\n",
            "Time:  0.1400 Epoch: 269 Iter: 2300/3510 LR: 0.0000036427 Loss content:  0.0147 Loss fft:  0.8138\n",
            "Time:  0.1320 Epoch: 269 Iter: 2400/3510 LR: 0.0000036427 Loss content:  0.0142 Loss fft:  0.8216\n",
            "Time:  0.1337 Epoch: 269 Iter: 2500/3510 LR: 0.0000036427 Loss content:  0.0150 Loss fft:  0.8422\n",
            "Time:  0.1299 Epoch: 269 Iter: 2600/3510 LR: 0.0000036427 Loss content:  0.0146 Loss fft:  0.8325\n",
            "Time:  0.1301 Epoch: 269 Iter: 2700/3510 LR: 0.0000036427 Loss content:  0.0141 Loss fft:  0.8069\n",
            "Time:  0.1328 Epoch: 269 Iter: 2800/3510 LR: 0.0000036427 Loss content:  0.0141 Loss fft:  0.8223\n",
            "Time:  0.1313 Epoch: 269 Iter: 2900/3510 LR: 0.0000036427 Loss content:  0.0143 Loss fft:  0.8304\n",
            "Time:  0.1323 Epoch: 269 Iter: 3000/3510 LR: 0.0000036427 Loss content:  0.0142 Loss fft:  0.8338\n",
            "Time:  0.1300 Epoch: 269 Iter: 3100/3510 LR: 0.0000036427 Loss content:  0.0145 Loss fft:  0.8265\n",
            "Time:  0.1301 Epoch: 269 Iter: 3200/3510 LR: 0.0000036427 Loss content:  0.0146 Loss fft:  0.8584\n",
            "Time:  0.1298 Epoch: 269 Iter: 3300/3510 LR: 0.0000036427 Loss content:  0.0153 Loss fft:  0.8403\n",
            "Time:  0.1304 Epoch: 269 Iter: 3400/3510 LR: 0.0000036427 Loss content:  0.0149 Loss fft:  0.8460\n",
            "Time:  0.1314 Epoch: 269 Iter: 3500/3510 LR: 0.0000036427 Loss content:  0.0147 Loss fft:  0.8470\n",
            "EPOCH: 269\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0145 Epoch FFT Loss:  0.8361\n",
            "Time:  0.1449 Epoch: 270 Iter:  100/3510 LR: 0.0000034767 Loss content:  0.0144 Loss fft:  0.8268\n",
            "Time:  0.1322 Epoch: 270 Iter:  200/3510 LR: 0.0000034767 Loss content:  0.0145 Loss fft:  0.8498\n",
            "Time:  0.1320 Epoch: 270 Iter:  300/3510 LR: 0.0000034767 Loss content:  0.0141 Loss fft:  0.8310\n",
            "Time:  0.1333 Epoch: 270 Iter:  400/3510 LR: 0.0000034767 Loss content:  0.0139 Loss fft:  0.8274\n",
            "Time:  0.1344 Epoch: 270 Iter:  500/3510 LR: 0.0000034767 Loss content:  0.0143 Loss fft:  0.8170\n",
            "Time:  0.1309 Epoch: 270 Iter:  600/3510 LR: 0.0000034767 Loss content:  0.0141 Loss fft:  0.8307\n",
            "Time:  0.1308 Epoch: 270 Iter:  700/3510 LR: 0.0000034767 Loss content:  0.0137 Loss fft:  0.8318\n",
            "Time:  0.1306 Epoch: 270 Iter:  800/3510 LR: 0.0000034767 Loss content:  0.0153 Loss fft:  0.8535\n",
            "Time:  0.1314 Epoch: 270 Iter:  900/3510 LR: 0.0000034767 Loss content:  0.0140 Loss fft:  0.8227\n",
            "Time:  0.1327 Epoch: 270 Iter: 1000/3510 LR: 0.0000034767 Loss content:  0.0144 Loss fft:  0.8207\n",
            "Time:  0.1384 Epoch: 270 Iter: 1100/3510 LR: 0.0000034767 Loss content:  0.0142 Loss fft:  0.8436\n",
            "Time:  0.1302 Epoch: 270 Iter: 1200/3510 LR: 0.0000034767 Loss content:  0.0146 Loss fft:  0.8375\n",
            "Time:  0.1306 Epoch: 270 Iter: 1300/3510 LR: 0.0000034767 Loss content:  0.0147 Loss fft:  0.8329\n",
            "Time:  0.1332 Epoch: 270 Iter: 1400/3510 LR: 0.0000034767 Loss content:  0.0144 Loss fft:  0.8200\n",
            "Time:  0.1319 Epoch: 270 Iter: 1500/3510 LR: 0.0000034767 Loss content:  0.0148 Loss fft:  0.8492\n",
            "Time:  0.1302 Epoch: 270 Iter: 1600/3510 LR: 0.0000034767 Loss content:  0.0143 Loss fft:  0.8308\n",
            "Time:  0.1323 Epoch: 270 Iter: 1700/3510 LR: 0.0000034767 Loss content:  0.0141 Loss fft:  0.8230\n",
            "Time:  0.1317 Epoch: 270 Iter: 1800/3510 LR: 0.0000034767 Loss content:  0.0145 Loss fft:  0.8313\n",
            "Time:  0.1296 Epoch: 270 Iter: 1900/3510 LR: 0.0000034767 Loss content:  0.0141 Loss fft:  0.8467\n",
            "Time:  0.1316 Epoch: 270 Iter: 2000/3510 LR: 0.0000034767 Loss content:  0.0142 Loss fft:  0.8282\n",
            "Time:  0.1316 Epoch: 270 Iter: 2100/3510 LR: 0.0000034767 Loss content:  0.0144 Loss fft:  0.8376\n",
            "Time:  0.1314 Epoch: 270 Iter: 2200/3510 LR: 0.0000034767 Loss content:  0.0145 Loss fft:  0.8364\n",
            "Time:  0.1287 Epoch: 270 Iter: 2300/3510 LR: 0.0000034767 Loss content:  0.0142 Loss fft:  0.8353\n",
            "Time:  0.1290 Epoch: 270 Iter: 2400/3510 LR: 0.0000034767 Loss content:  0.0144 Loss fft:  0.8296\n",
            "Time:  0.1288 Epoch: 270 Iter: 2500/3510 LR: 0.0000034767 Loss content:  0.0144 Loss fft:  0.8292\n",
            "Time:  0.1325 Epoch: 270 Iter: 2600/3510 LR: 0.0000034767 Loss content:  0.0144 Loss fft:  0.8424\n",
            "Time:  0.1313 Epoch: 270 Iter: 2700/3510 LR: 0.0000034767 Loss content:  0.0144 Loss fft:  0.8631\n",
            "Time:  0.1321 Epoch: 270 Iter: 2800/3510 LR: 0.0000034767 Loss content:  0.0145 Loss fft:  0.8540\n",
            "Time:  0.1313 Epoch: 270 Iter: 2900/3510 LR: 0.0000034767 Loss content:  0.0145 Loss fft:  0.8467\n",
            "Time:  0.1311 Epoch: 270 Iter: 3000/3510 LR: 0.0000034767 Loss content:  0.0142 Loss fft:  0.8405\n",
            "Time:  0.1298 Epoch: 270 Iter: 3100/3510 LR: 0.0000034767 Loss content:  0.0145 Loss fft:  0.8264\n",
            "Time:  0.1334 Epoch: 270 Iter: 3200/3510 LR: 0.0000034767 Loss content:  0.0147 Loss fft:  0.8363\n",
            "Time:  0.1327 Epoch: 270 Iter: 3300/3510 LR: 0.0000034767 Loss content:  0.0149 Loss fft:  0.8461\n",
            "Time:  0.1327 Epoch: 270 Iter: 3400/3510 LR: 0.0000034767 Loss content:  0.0142 Loss fft:  0.8359\n",
            "Time:  0.1366 Epoch: 270 Iter: 3500/3510 LR: 0.0000034767 Loss content:  0.0144 Loss fft:  0.8580\n",
            "EPOCH: 270\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0144 Epoch FFT Loss:  0.8366\n",
            "Start Evaluation\n",
            "499 \n",
            "\n",
            "270 epoch \n",
            " Average PSNR 40.96 dB\n",
            "Time:  0.1409 Epoch: 271 Iter:  100/3510 LR: 0.0000033159 Loss content:  0.0149 Loss fft:  0.8441\n",
            "Time:  0.1300 Epoch: 271 Iter:  200/3510 LR: 0.0000033159 Loss content:  0.0144 Loss fft:  0.8329\n",
            "Time:  0.1324 Epoch: 271 Iter:  300/3510 LR: 0.0000033159 Loss content:  0.0144 Loss fft:  0.8381\n",
            "Time:  0.1312 Epoch: 271 Iter:  400/3510 LR: 0.0000033159 Loss content:  0.0145 Loss fft:  0.8369\n",
            "Time:  0.1321 Epoch: 271 Iter:  500/3510 LR: 0.0000033159 Loss content:  0.0141 Loss fft:  0.8361\n",
            "Time:  0.1304 Epoch: 271 Iter:  600/3510 LR: 0.0000033159 Loss content:  0.0143 Loss fft:  0.8324\n",
            "Time:  0.1312 Epoch: 271 Iter:  700/3510 LR: 0.0000033159 Loss content:  0.0140 Loss fft:  0.8227\n",
            "Time:  0.1290 Epoch: 271 Iter:  800/3510 LR: 0.0000033159 Loss content:  0.0140 Loss fft:  0.8418\n",
            "Time:  0.1336 Epoch: 271 Iter:  900/3510 LR: 0.0000033159 Loss content:  0.0142 Loss fft:  0.8207\n",
            "Time:  0.1327 Epoch: 271 Iter: 1000/3510 LR: 0.0000033159 Loss content:  0.0145 Loss fft:  0.8360\n",
            "Time:  0.1332 Epoch: 271 Iter: 1100/3510 LR: 0.0000033159 Loss content:  0.0146 Loss fft:  0.8562\n",
            "Time:  0.1339 Epoch: 271 Iter: 1200/3510 LR: 0.0000033159 Loss content:  0.0142 Loss fft:  0.8362\n",
            "Time:  0.1300 Epoch: 271 Iter: 1300/3510 LR: 0.0000033159 Loss content:  0.0140 Loss fft:  0.8176\n",
            "Time:  0.1324 Epoch: 271 Iter: 1400/3510 LR: 0.0000033159 Loss content:  0.0143 Loss fft:  0.8403\n",
            "Time:  0.1320 Epoch: 271 Iter: 1500/3510 LR: 0.0000033159 Loss content:  0.0144 Loss fft:  0.8406\n",
            "Time:  0.1322 Epoch: 271 Iter: 1600/3510 LR: 0.0000033159 Loss content:  0.0141 Loss fft:  0.8145\n",
            "Time:  0.1282 Epoch: 271 Iter: 1700/3510 LR: 0.0000033159 Loss content:  0.0143 Loss fft:  0.8335\n",
            "Time:  0.1336 Epoch: 271 Iter: 1800/3510 LR: 0.0000033159 Loss content:  0.0149 Loss fft:  0.8571\n",
            "Time:  0.1317 Epoch: 271 Iter: 1900/3510 LR: 0.0000033159 Loss content:  0.0143 Loss fft:  0.8324\n",
            "Time:  0.1295 Epoch: 271 Iter: 2000/3510 LR: 0.0000033159 Loss content:  0.0141 Loss fft:  0.8356\n",
            "Time:  0.1319 Epoch: 271 Iter: 2100/3510 LR: 0.0000033159 Loss content:  0.0137 Loss fft:  0.8356\n",
            "Time:  0.1373 Epoch: 271 Iter: 2200/3510 LR: 0.0000033159 Loss content:  0.0142 Loss fft:  0.8415\n",
            "Time:  0.1333 Epoch: 271 Iter: 2300/3510 LR: 0.0000033159 Loss content:  0.0147 Loss fft:  0.8575\n",
            "Time:  0.1333 Epoch: 271 Iter: 2400/3510 LR: 0.0000033159 Loss content:  0.0141 Loss fft:  0.8332\n",
            "Time:  0.1337 Epoch: 271 Iter: 2500/3510 LR: 0.0000033159 Loss content:  0.0144 Loss fft:  0.8241\n",
            "Time:  0.1322 Epoch: 271 Iter: 2600/3510 LR: 0.0000033159 Loss content:  0.0145 Loss fft:  0.8353\n",
            "Time:  0.1320 Epoch: 271 Iter: 2700/3510 LR: 0.0000033159 Loss content:  0.0142 Loss fft:  0.8401\n",
            "Time:  0.1313 Epoch: 271 Iter: 2800/3510 LR: 0.0000033159 Loss content:  0.0146 Loss fft:  0.8447\n",
            "Time:  0.1327 Epoch: 271 Iter: 2900/3510 LR: 0.0000033159 Loss content:  0.0141 Loss fft:  0.8357\n",
            "Time:  0.1314 Epoch: 271 Iter: 3000/3510 LR: 0.0000033159 Loss content:  0.0146 Loss fft:  0.8415\n",
            "Time:  0.1335 Epoch: 271 Iter: 3100/3510 LR: 0.0000033159 Loss content:  0.0145 Loss fft:  0.8297\n",
            "Time:  0.1325 Epoch: 271 Iter: 3200/3510 LR: 0.0000033159 Loss content:  0.0145 Loss fft:  0.8322\n",
            "Time:  0.1301 Epoch: 271 Iter: 3300/3510 LR: 0.0000033159 Loss content:  0.0143 Loss fft:  0.8219\n",
            "Time:  0.1321 Epoch: 271 Iter: 3400/3510 LR: 0.0000033159 Loss content:  0.0148 Loss fft:  0.8342\n",
            "Time:  0.1310 Epoch: 271 Iter: 3500/3510 LR: 0.0000033159 Loss content:  0.0141 Loss fft:  0.8355\n",
            "EPOCH: 271\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0143 Epoch FFT Loss:  0.8355\n",
            "Time:  0.1425 Epoch: 272 Iter:  100/3510 LR: 0.0000031604 Loss content:  0.0142 Loss fft:  0.8092\n",
            "Time:  0.1319 Epoch: 272 Iter:  200/3510 LR: 0.0000031604 Loss content:  0.0139 Loss fft:  0.8493\n",
            "Time:  0.1304 Epoch: 272 Iter:  300/3510 LR: 0.0000031604 Loss content:  0.0138 Loss fft:  0.8060\n",
            "Time:  0.1304 Epoch: 272 Iter:  400/3510 LR: 0.0000031604 Loss content:  0.0144 Loss fft:  0.8292\n",
            "Time:  0.1349 Epoch: 272 Iter:  500/3510 LR: 0.0000031604 Loss content:  0.0144 Loss fft:  0.8331\n",
            "Time:  0.1327 Epoch: 272 Iter:  600/3510 LR: 0.0000031604 Loss content:  0.0142 Loss fft:  0.8200\n",
            "Time:  0.1320 Epoch: 272 Iter:  700/3510 LR: 0.0000031604 Loss content:  0.0144 Loss fft:  0.8472\n",
            "Time:  0.1318 Epoch: 272 Iter:  800/3510 LR: 0.0000031604 Loss content:  0.0141 Loss fft:  0.8278\n",
            "Time:  0.1309 Epoch: 272 Iter:  900/3510 LR: 0.0000031604 Loss content:  0.0149 Loss fft:  0.8353\n",
            "Time:  0.1379 Epoch: 272 Iter: 1000/3510 LR: 0.0000031604 Loss content:  0.0141 Loss fft:  0.8255\n",
            "Time:  0.1309 Epoch: 272 Iter: 1100/3510 LR: 0.0000031604 Loss content:  0.0145 Loss fft:  0.8343\n",
            "Time:  0.1290 Epoch: 272 Iter: 1200/3510 LR: 0.0000031604 Loss content:  0.0142 Loss fft:  0.8212\n",
            "Time:  0.1323 Epoch: 272 Iter: 1300/3510 LR: 0.0000031604 Loss content:  0.0143 Loss fft:  0.8351\n",
            "Time:  0.1313 Epoch: 272 Iter: 1400/3510 LR: 0.0000031604 Loss content:  0.0144 Loss fft:  0.8355\n",
            "Time:  0.1304 Epoch: 272 Iter: 1500/3510 LR: 0.0000031604 Loss content:  0.0150 Loss fft:  0.8496\n",
            "Time:  0.1339 Epoch: 272 Iter: 1600/3510 LR: 0.0000031604 Loss content:  0.0142 Loss fft:  0.8235\n",
            "Time:  0.1331 Epoch: 272 Iter: 1700/3510 LR: 0.0000031604 Loss content:  0.0145 Loss fft:  0.8322\n",
            "Time:  0.1323 Epoch: 272 Iter: 1800/3510 LR: 0.0000031604 Loss content:  0.0148 Loss fft:  0.8495\n",
            "Time:  0.1303 Epoch: 272 Iter: 1900/3510 LR: 0.0000031604 Loss content:  0.0145 Loss fft:  0.8511\n",
            "Time:  0.1323 Epoch: 272 Iter: 2000/3510 LR: 0.0000031604 Loss content:  0.0145 Loss fft:  0.8412\n",
            "Time:  0.1323 Epoch: 272 Iter: 2100/3510 LR: 0.0000031604 Loss content:  0.0141 Loss fft:  0.8567\n",
            "Time:  0.1303 Epoch: 272 Iter: 2200/3510 LR: 0.0000031604 Loss content:  0.0151 Loss fft:  0.8520\n",
            "Time:  0.1303 Epoch: 272 Iter: 2300/3510 LR: 0.0000031604 Loss content:  0.0143 Loss fft:  0.8318\n",
            "Time:  0.1337 Epoch: 272 Iter: 2400/3510 LR: 0.0000031604 Loss content:  0.0144 Loss fft:  0.8481\n",
            "Time:  0.1327 Epoch: 272 Iter: 2500/3510 LR: 0.0000031604 Loss content:  0.0144 Loss fft:  0.8418\n",
            "Time:  0.1304 Epoch: 272 Iter: 2600/3510 LR: 0.0000031604 Loss content:  0.0141 Loss fft:  0.8439\n",
            "Time:  0.1304 Epoch: 272 Iter: 2700/3510 LR: 0.0000031604 Loss content:  0.0140 Loss fft:  0.8287\n",
            "Time:  0.1309 Epoch: 272 Iter: 2800/3510 LR: 0.0000031604 Loss content:  0.0136 Loss fft:  0.8250\n",
            "Time:  0.1302 Epoch: 272 Iter: 2900/3510 LR: 0.0000031604 Loss content:  0.0146 Loss fft:  0.8411\n",
            "Time:  0.1326 Epoch: 272 Iter: 3000/3510 LR: 0.0000031604 Loss content:  0.0140 Loss fft:  0.8178\n",
            "Time:  0.1291 Epoch: 272 Iter: 3100/3510 LR: 0.0000031604 Loss content:  0.0145 Loss fft:  0.8359\n",
            "Time:  0.1316 Epoch: 272 Iter: 3200/3510 LR: 0.0000031604 Loss content:  0.0147 Loss fft:  0.8269\n",
            "Time:  0.1297 Epoch: 272 Iter: 3300/3510 LR: 0.0000031604 Loss content:  0.0142 Loss fft:  0.8341\n",
            "Time:  0.1320 Epoch: 272 Iter: 3400/3510 LR: 0.0000031604 Loss content:  0.0143 Loss fft:  0.8510\n",
            "Time:  0.1310 Epoch: 272 Iter: 3500/3510 LR: 0.0000031604 Loss content:  0.0148 Loss fft:  0.8229\n",
            "EPOCH: 272\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0144 Epoch FFT Loss:  0.8349\n",
            "Time:  0.1415 Epoch: 273 Iter:  100/3510 LR: 0.0000030103 Loss content:  0.0142 Loss fft:  0.8405\n",
            "Time:  0.1308 Epoch: 273 Iter:  200/3510 LR: 0.0000030103 Loss content:  0.0144 Loss fft:  0.8368\n",
            "Time:  0.1297 Epoch: 273 Iter:  300/3510 LR: 0.0000030103 Loss content:  0.0148 Loss fft:  0.8600\n",
            "Time:  0.1313 Epoch: 273 Iter:  400/3510 LR: 0.0000030103 Loss content:  0.0142 Loss fft:  0.8436\n",
            "Time:  0.1302 Epoch: 273 Iter:  500/3510 LR: 0.0000030103 Loss content:  0.0143 Loss fft:  0.8281\n",
            "Time:  0.1331 Epoch: 273 Iter:  600/3510 LR: 0.0000030103 Loss content:  0.0144 Loss fft:  0.8488\n",
            "Time:  0.1328 Epoch: 273 Iter:  700/3510 LR: 0.0000030103 Loss content:  0.0145 Loss fft:  0.8313\n",
            "Time:  0.1314 Epoch: 273 Iter:  800/3510 LR: 0.0000030103 Loss content:  0.0137 Loss fft:  0.8415\n",
            "Time:  0.1312 Epoch: 273 Iter:  900/3510 LR: 0.0000030103 Loss content:  0.0147 Loss fft:  0.8646\n",
            "Time:  0.1331 Epoch: 273 Iter: 1000/3510 LR: 0.0000030103 Loss content:  0.0137 Loss fft:  0.8134\n",
            "Time:  0.1297 Epoch: 273 Iter: 1100/3510 LR: 0.0000030103 Loss content:  0.0140 Loss fft:  0.8180\n",
            "Time:  0.1320 Epoch: 273 Iter: 1200/3510 LR: 0.0000030103 Loss content:  0.0138 Loss fft:  0.8368\n",
            "Time:  0.1346 Epoch: 273 Iter: 1300/3510 LR: 0.0000030103 Loss content:  0.0150 Loss fft:  0.8469\n",
            "Time:  0.1315 Epoch: 273 Iter: 1400/3510 LR: 0.0000030103 Loss content:  0.0138 Loss fft:  0.8140\n",
            "Time:  0.1329 Epoch: 273 Iter: 1500/3510 LR: 0.0000030103 Loss content:  0.0139 Loss fft:  0.8295\n",
            "Time:  0.1311 Epoch: 273 Iter: 1600/3510 LR: 0.0000030103 Loss content:  0.0144 Loss fft:  0.8170\n",
            "Time:  0.1328 Epoch: 273 Iter: 1700/3510 LR: 0.0000030103 Loss content:  0.0146 Loss fft:  0.8551\n",
            "Time:  0.1341 Epoch: 273 Iter: 1800/3510 LR: 0.0000030103 Loss content:  0.0145 Loss fft:  0.8509\n",
            "Time:  0.1356 Epoch: 273 Iter: 1900/3510 LR: 0.0000030103 Loss content:  0.0139 Loss fft:  0.8238\n",
            "Time:  0.1321 Epoch: 273 Iter: 2000/3510 LR: 0.0000030103 Loss content:  0.0141 Loss fft:  0.8222\n",
            "Time:  0.1303 Epoch: 273 Iter: 2100/3510 LR: 0.0000030103 Loss content:  0.0140 Loss fft:  0.8383\n",
            "Time:  0.1383 Epoch: 273 Iter: 2200/3510 LR: 0.0000030103 Loss content:  0.0140 Loss fft:  0.8185\n",
            "Time:  0.1283 Epoch: 273 Iter: 2300/3510 LR: 0.0000030103 Loss content:  0.0139 Loss fft:  0.8240\n",
            "Time:  0.1318 Epoch: 273 Iter: 2400/3510 LR: 0.0000030103 Loss content:  0.0139 Loss fft:  0.8206\n",
            "Time:  0.1324 Epoch: 273 Iter: 2500/3510 LR: 0.0000030103 Loss content:  0.0148 Loss fft:  0.8538\n",
            "Time:  0.1337 Epoch: 273 Iter: 2600/3510 LR: 0.0000030103 Loss content:  0.0147 Loss fft:  0.8331\n",
            "Time:  0.1345 Epoch: 273 Iter: 2700/3510 LR: 0.0000030103 Loss content:  0.0145 Loss fft:  0.8447\n",
            "Time:  0.1332 Epoch: 273 Iter: 2800/3510 LR: 0.0000030103 Loss content:  0.0148 Loss fft:  0.8454\n",
            "Time:  0.1330 Epoch: 273 Iter: 2900/3510 LR: 0.0000030103 Loss content:  0.0145 Loss fft:  0.8242\n",
            "Time:  0.1316 Epoch: 273 Iter: 3000/3510 LR: 0.0000030103 Loss content:  0.0143 Loss fft:  0.8300\n",
            "Time:  0.1319 Epoch: 273 Iter: 3100/3510 LR: 0.0000030103 Loss content:  0.0151 Loss fft:  0.8644\n",
            "Time:  0.1296 Epoch: 273 Iter: 3200/3510 LR: 0.0000030103 Loss content:  0.0147 Loss fft:  0.8513\n",
            "Time:  0.1324 Epoch: 273 Iter: 3300/3510 LR: 0.0000030103 Loss content:  0.0146 Loss fft:  0.8288\n",
            "Time:  0.1294 Epoch: 273 Iter: 3400/3510 LR: 0.0000030103 Loss content:  0.0143 Loss fft:  0.8279\n",
            "Time:  0.1293 Epoch: 273 Iter: 3500/3510 LR: 0.0000030103 Loss content:  0.0148 Loss fft:  0.8295\n",
            "EPOCH: 273\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0143 Epoch FFT Loss:  0.8357\n",
            "Time:  0.1414 Epoch: 274 Iter:  100/3510 LR: 0.0000028654 Loss content:  0.0144 Loss fft:  0.8525\n",
            "Time:  0.1335 Epoch: 274 Iter:  200/3510 LR: 0.0000028654 Loss content:  0.0146 Loss fft:  0.8721\n",
            "Time:  0.1312 Epoch: 274 Iter:  300/3510 LR: 0.0000028654 Loss content:  0.0139 Loss fft:  0.8136\n",
            "Time:  0.1322 Epoch: 274 Iter:  400/3510 LR: 0.0000028654 Loss content:  0.0140 Loss fft:  0.8192\n",
            "Time:  0.1329 Epoch: 274 Iter:  500/3510 LR: 0.0000028654 Loss content:  0.0143 Loss fft:  0.8386\n",
            "Time:  0.1328 Epoch: 274 Iter:  600/3510 LR: 0.0000028654 Loss content:  0.0143 Loss fft:  0.8388\n",
            "Time:  0.1323 Epoch: 274 Iter:  700/3510 LR: 0.0000028654 Loss content:  0.0148 Loss fft:  0.8326\n",
            "Time:  0.1312 Epoch: 274 Iter:  800/3510 LR: 0.0000028654 Loss content:  0.0143 Loss fft:  0.8517\n",
            "Time:  0.1384 Epoch: 274 Iter:  900/3510 LR: 0.0000028654 Loss content:  0.0136 Loss fft:  0.8197\n",
            "Time:  0.1329 Epoch: 274 Iter: 1000/3510 LR: 0.0000028654 Loss content:  0.0145 Loss fft:  0.8442\n",
            "Time:  0.1317 Epoch: 274 Iter: 1100/3510 LR: 0.0000028654 Loss content:  0.0141 Loss fft:  0.8054\n",
            "Time:  0.1315 Epoch: 274 Iter: 1200/3510 LR: 0.0000028654 Loss content:  0.0143 Loss fft:  0.8427\n",
            "Time:  0.1301 Epoch: 274 Iter: 1300/3510 LR: 0.0000028654 Loss content:  0.0145 Loss fft:  0.8303\n",
            "Time:  0.1319 Epoch: 274 Iter: 1400/3510 LR: 0.0000028654 Loss content:  0.0142 Loss fft:  0.8037\n",
            "Time:  0.1326 Epoch: 274 Iter: 1500/3510 LR: 0.0000028654 Loss content:  0.0146 Loss fft:  0.8310\n",
            "Time:  0.1329 Epoch: 274 Iter: 1600/3510 LR: 0.0000028654 Loss content:  0.0139 Loss fft:  0.8273\n",
            "Time:  0.1326 Epoch: 274 Iter: 1700/3510 LR: 0.0000028654 Loss content:  0.0143 Loss fft:  0.8519\n",
            "Time:  0.1330 Epoch: 274 Iter: 1800/3510 LR: 0.0000028654 Loss content:  0.0135 Loss fft:  0.8135\n",
            "Time:  0.1312 Epoch: 274 Iter: 1900/3510 LR: 0.0000028654 Loss content:  0.0141 Loss fft:  0.8102\n",
            "Time:  0.1317 Epoch: 274 Iter: 2000/3510 LR: 0.0000028654 Loss content:  0.0145 Loss fft:  0.8379\n",
            "Time:  0.1311 Epoch: 274 Iter: 2100/3510 LR: 0.0000028654 Loss content:  0.0146 Loss fft:  0.8522\n",
            "Time:  0.1318 Epoch: 274 Iter: 2200/3510 LR: 0.0000028654 Loss content:  0.0140 Loss fft:  0.8321\n",
            "Time:  0.1314 Epoch: 274 Iter: 2300/3510 LR: 0.0000028654 Loss content:  0.0147 Loss fft:  0.8494\n",
            "Time:  0.1316 Epoch: 274 Iter: 2400/3510 LR: 0.0000028654 Loss content:  0.0145 Loss fft:  0.8216\n",
            "Time:  0.1318 Epoch: 274 Iter: 2500/3510 LR: 0.0000028654 Loss content:  0.0146 Loss fft:  0.8496\n",
            "Time:  0.1289 Epoch: 274 Iter: 2600/3510 LR: 0.0000028654 Loss content:  0.0141 Loss fft:  0.8398\n",
            "Time:  0.1305 Epoch: 274 Iter: 2700/3510 LR: 0.0000028654 Loss content:  0.0139 Loss fft:  0.8415\n",
            "Time:  0.1313 Epoch: 274 Iter: 2800/3510 LR: 0.0000028654 Loss content:  0.0148 Loss fft:  0.8232\n",
            "Time:  0.1311 Epoch: 274 Iter: 2900/3510 LR: 0.0000028654 Loss content:  0.0148 Loss fft:  0.8360\n",
            "Time:  0.1294 Epoch: 274 Iter: 3000/3510 LR: 0.0000028654 Loss content:  0.0144 Loss fft:  0.8367\n",
            "Time:  0.1305 Epoch: 274 Iter: 3100/3510 LR: 0.0000028654 Loss content:  0.0141 Loss fft:  0.8307\n",
            "Time:  0.1293 Epoch: 274 Iter: 3200/3510 LR: 0.0000028654 Loss content:  0.0145 Loss fft:  0.8431\n",
            "Time:  0.1330 Epoch: 274 Iter: 3300/3510 LR: 0.0000028654 Loss content:  0.0146 Loss fft:  0.8329\n",
            "Time:  0.1281 Epoch: 274 Iter: 3400/3510 LR: 0.0000028654 Loss content:  0.0139 Loss fft:  0.8329\n",
            "Time:  0.1313 Epoch: 274 Iter: 3500/3510 LR: 0.0000028654 Loss content:  0.0142 Loss fft:  0.8332\n",
            "EPOCH: 274\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0143 Epoch FFT Loss:  0.8341\n",
            "Time:  0.1421 Epoch: 275 Iter:  100/3510 LR: 0.0000027259 Loss content:  0.0138 Loss fft:  0.8282\n",
            "Time:  0.1284 Epoch: 275 Iter:  200/3510 LR: 0.0000027259 Loss content:  0.0138 Loss fft:  0.8063\n",
            "Time:  0.1324 Epoch: 275 Iter:  300/3510 LR: 0.0000027259 Loss content:  0.0144 Loss fft:  0.8363\n",
            "Time:  0.1333 Epoch: 275 Iter:  400/3510 LR: 0.0000027259 Loss content:  0.0138 Loss fft:  0.8159\n",
            "Time:  0.1344 Epoch: 275 Iter:  500/3510 LR: 0.0000027259 Loss content:  0.0147 Loss fft:  0.8518\n",
            "Time:  0.1298 Epoch: 275 Iter:  600/3510 LR: 0.0000027259 Loss content:  0.0150 Loss fft:  0.8625\n",
            "Time:  0.1299 Epoch: 275 Iter:  700/3510 LR: 0.0000027259 Loss content:  0.0143 Loss fft:  0.8474\n",
            "Time:  0.1307 Epoch: 275 Iter:  800/3510 LR: 0.0000027259 Loss content:  0.0137 Loss fft:  0.8268\n",
            "Time:  0.1307 Epoch: 275 Iter:  900/3510 LR: 0.0000027259 Loss content:  0.0142 Loss fft:  0.8365\n",
            "Time:  0.1315 Epoch: 275 Iter: 1000/3510 LR: 0.0000027259 Loss content:  0.0143 Loss fft:  0.8393\n",
            "Time:  0.1308 Epoch: 275 Iter: 1100/3510 LR: 0.0000027259 Loss content:  0.0141 Loss fft:  0.8162\n",
            "Time:  0.1353 Epoch: 275 Iter: 1200/3510 LR: 0.0000027259 Loss content:  0.0144 Loss fft:  0.8520\n",
            "Time:  0.1356 Epoch: 275 Iter: 1300/3510 LR: 0.0000027259 Loss content:  0.0140 Loss fft:  0.8437\n",
            "Time:  0.1311 Epoch: 275 Iter: 1400/3510 LR: 0.0000027259 Loss content:  0.0143 Loss fft:  0.8415\n",
            "Time:  0.1317 Epoch: 275 Iter: 1500/3510 LR: 0.0000027259 Loss content:  0.0147 Loss fft:  0.8502\n",
            "Time:  0.1332 Epoch: 275 Iter: 1600/3510 LR: 0.0000027259 Loss content:  0.0140 Loss fft:  0.8251\n",
            "Time:  0.1308 Epoch: 275 Iter: 1700/3510 LR: 0.0000027259 Loss content:  0.0139 Loss fft:  0.8025\n",
            "Time:  0.1318 Epoch: 275 Iter: 1800/3510 LR: 0.0000027259 Loss content:  0.0138 Loss fft:  0.8169\n",
            "Time:  0.1322 Epoch: 275 Iter: 1900/3510 LR: 0.0000027259 Loss content:  0.0142 Loss fft:  0.8437\n",
            "Time:  0.1354 Epoch: 275 Iter: 2000/3510 LR: 0.0000027259 Loss content:  0.0141 Loss fft:  0.8351\n",
            "Time:  0.1391 Epoch: 275 Iter: 2100/3510 LR: 0.0000027259 Loss content:  0.0139 Loss fft:  0.8375\n",
            "Time:  0.1294 Epoch: 275 Iter: 2200/3510 LR: 0.0000027259 Loss content:  0.0142 Loss fft:  0.8016\n",
            "Time:  0.1286 Epoch: 275 Iter: 2300/3510 LR: 0.0000027259 Loss content:  0.0143 Loss fft:  0.8239\n",
            "Time:  0.1284 Epoch: 275 Iter: 2400/3510 LR: 0.0000027259 Loss content:  0.0141 Loss fft:  0.8235\n",
            "Time:  0.1336 Epoch: 275 Iter: 2500/3510 LR: 0.0000027259 Loss content:  0.0148 Loss fft:  0.8598\n",
            "Time:  0.1301 Epoch: 275 Iter: 2600/3510 LR: 0.0000027259 Loss content:  0.0144 Loss fft:  0.8442\n",
            "Time:  0.1322 Epoch: 275 Iter: 2700/3510 LR: 0.0000027259 Loss content:  0.0143 Loss fft:  0.8490\n",
            "Time:  0.1302 Epoch: 275 Iter: 2800/3510 LR: 0.0000027259 Loss content:  0.0143 Loss fft:  0.8487\n",
            "Time:  0.1325 Epoch: 275 Iter: 2900/3510 LR: 0.0000027259 Loss content:  0.0147 Loss fft:  0.8454\n",
            "Time:  0.1316 Epoch: 275 Iter: 3000/3510 LR: 0.0000027259 Loss content:  0.0150 Loss fft:  0.8359\n",
            "Time:  0.1326 Epoch: 275 Iter: 3100/3510 LR: 0.0000027259 Loss content:  0.0142 Loss fft:  0.8421\n",
            "Time:  0.1328 Epoch: 275 Iter: 3200/3510 LR: 0.0000027259 Loss content:  0.0142 Loss fft:  0.8195\n",
            "Time:  0.1324 Epoch: 275 Iter: 3300/3510 LR: 0.0000027259 Loss content:  0.0143 Loss fft:  0.8466\n",
            "Time:  0.1314 Epoch: 275 Iter: 3400/3510 LR: 0.0000027259 Loss content:  0.0138 Loss fft:  0.8167\n",
            "Time:  0.1312 Epoch: 275 Iter: 3500/3510 LR: 0.0000027259 Loss content:  0.0135 Loss fft:  0.8232\n",
            "EPOCH: 275\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0142 Epoch FFT Loss:  0.8342\n",
            "Time:  0.1425 Epoch: 276 Iter:  100/3510 LR: 0.0000025917 Loss content:  0.0143 Loss fft:  0.8457\n",
            "Time:  0.1338 Epoch: 276 Iter:  200/3510 LR: 0.0000025917 Loss content:  0.0144 Loss fft:  0.8664\n",
            "Time:  0.1302 Epoch: 276 Iter:  300/3510 LR: 0.0000025917 Loss content:  0.0143 Loss fft:  0.8164\n",
            "Time:  0.1332 Epoch: 276 Iter:  400/3510 LR: 0.0000025917 Loss content:  0.0141 Loss fft:  0.8327\n",
            "Time:  0.1282 Epoch: 276 Iter:  500/3510 LR: 0.0000025917 Loss content:  0.0138 Loss fft:  0.8165\n",
            "Time:  0.1309 Epoch: 276 Iter:  600/3510 LR: 0.0000025917 Loss content:  0.0140 Loss fft:  0.8303\n",
            "Time:  0.1303 Epoch: 276 Iter:  700/3510 LR: 0.0000025917 Loss content:  0.0145 Loss fft:  0.8449\n",
            "Time:  0.1319 Epoch: 276 Iter:  800/3510 LR: 0.0000025917 Loss content:  0.0143 Loss fft:  0.8288\n",
            "Time:  0.1358 Epoch: 276 Iter:  900/3510 LR: 0.0000025917 Loss content:  0.0142 Loss fft:  0.8255\n",
            "Time:  0.1334 Epoch: 276 Iter: 1000/3510 LR: 0.0000025917 Loss content:  0.0146 Loss fft:  0.8347\n",
            "Time:  0.1318 Epoch: 276 Iter: 1100/3510 LR: 0.0000025917 Loss content:  0.0142 Loss fft:  0.8350\n",
            "Time:  0.1311 Epoch: 276 Iter: 1200/3510 LR: 0.0000025917 Loss content:  0.0146 Loss fft:  0.8401\n",
            "Time:  0.1346 Epoch: 276 Iter: 1300/3510 LR: 0.0000025917 Loss content:  0.0145 Loss fft:  0.8503\n",
            "Time:  0.1308 Epoch: 276 Iter: 1400/3510 LR: 0.0000025917 Loss content:  0.0145 Loss fft:  0.8347\n",
            "Time:  0.1347 Epoch: 276 Iter: 1500/3510 LR: 0.0000025917 Loss content:  0.0142 Loss fft:  0.8160\n",
            "Time:  0.1321 Epoch: 276 Iter: 1600/3510 LR: 0.0000025917 Loss content:  0.0142 Loss fft:  0.8421\n",
            "Time:  0.1315 Epoch: 276 Iter: 1700/3510 LR: 0.0000025917 Loss content:  0.0146 Loss fft:  0.8254\n",
            "Time:  0.1291 Epoch: 276 Iter: 1800/3510 LR: 0.0000025917 Loss content:  0.0134 Loss fft:  0.8024\n",
            "Time:  0.1335 Epoch: 276 Iter: 1900/3510 LR: 0.0000025917 Loss content:  0.0145 Loss fft:  0.8405\n",
            "Time:  0.1316 Epoch: 276 Iter: 2000/3510 LR: 0.0000025917 Loss content:  0.0144 Loss fft:  0.8363\n",
            "Time:  0.1336 Epoch: 276 Iter: 2100/3510 LR: 0.0000025917 Loss content:  0.0143 Loss fft:  0.8296\n",
            "Time:  0.1323 Epoch: 276 Iter: 2200/3510 LR: 0.0000025917 Loss content:  0.0140 Loss fft:  0.8285\n",
            "Time:  0.1345 Epoch: 276 Iter: 2300/3510 LR: 0.0000025917 Loss content:  0.0141 Loss fft:  0.8418\n",
            "Time:  0.1327 Epoch: 276 Iter: 2400/3510 LR: 0.0000025917 Loss content:  0.0139 Loss fft:  0.8172\n",
            "Time:  0.1318 Epoch: 276 Iter: 2500/3510 LR: 0.0000025917 Loss content:  0.0142 Loss fft:  0.8513\n",
            "Time:  0.1339 Epoch: 276 Iter: 2600/3510 LR: 0.0000025917 Loss content:  0.0144 Loss fft:  0.8316\n",
            "Time:  0.1318 Epoch: 276 Iter: 2700/3510 LR: 0.0000025917 Loss content:  0.0136 Loss fft:  0.8394\n",
            "Time:  0.1312 Epoch: 276 Iter: 2800/3510 LR: 0.0000025917 Loss content:  0.0144 Loss fft:  0.8527\n",
            "Time:  0.1295 Epoch: 276 Iter: 2900/3510 LR: 0.0000025917 Loss content:  0.0139 Loss fft:  0.8431\n",
            "Time:  0.1328 Epoch: 276 Iter: 3000/3510 LR: 0.0000025917 Loss content:  0.0139 Loss fft:  0.8059\n",
            "Time:  0.1316 Epoch: 276 Iter: 3100/3510 LR: 0.0000025917 Loss content:  0.0142 Loss fft:  0.8430\n",
            "Time:  0.1352 Epoch: 276 Iter: 3200/3510 LR: 0.0000025917 Loss content:  0.0143 Loss fft:  0.8523\n",
            "Time:  0.1310 Epoch: 276 Iter: 3300/3510 LR: 0.0000025917 Loss content:  0.0143 Loss fft:  0.8211\n",
            "Time:  0.1306 Epoch: 276 Iter: 3400/3510 LR: 0.0000025917 Loss content:  0.0139 Loss fft:  0.8102\n",
            "Time:  0.1332 Epoch: 276 Iter: 3500/3510 LR: 0.0000025917 Loss content:  0.0140 Loss fft:  0.8202\n",
            "EPOCH: 276\n",
            "Elapsed time: 4.66 Epoch Pixel Loss:  0.0142 Epoch FFT Loss:  0.8329\n",
            "Time:  0.1391 Epoch: 277 Iter:  100/3510 LR: 0.0000024628 Loss content:  0.0139 Loss fft:  0.8411\n",
            "Time:  0.1310 Epoch: 277 Iter:  200/3510 LR: 0.0000024628 Loss content:  0.0143 Loss fft:  0.8222\n",
            "Time:  0.1296 Epoch: 277 Iter:  300/3510 LR: 0.0000024628 Loss content:  0.0141 Loss fft:  0.8201\n",
            "Time:  0.1312 Epoch: 277 Iter:  400/3510 LR: 0.0000024628 Loss content:  0.0142 Loss fft:  0.8448\n",
            "Time:  0.1293 Epoch: 277 Iter:  500/3510 LR: 0.0000024628 Loss content:  0.0139 Loss fft:  0.8078\n",
            "Time:  0.1289 Epoch: 277 Iter:  600/3510 LR: 0.0000024628 Loss content:  0.0137 Loss fft:  0.8270\n",
            "Time:  0.1296 Epoch: 277 Iter:  700/3510 LR: 0.0000024628 Loss content:  0.0146 Loss fft:  0.8502\n",
            "Time:  0.1309 Epoch: 277 Iter:  800/3510 LR: 0.0000024628 Loss content:  0.0143 Loss fft:  0.8291\n",
            "Time:  0.1324 Epoch: 277 Iter:  900/3510 LR: 0.0000024628 Loss content:  0.0142 Loss fft:  0.8454\n",
            "Time:  0.1306 Epoch: 277 Iter: 1000/3510 LR: 0.0000024628 Loss content:  0.0141 Loss fft:  0.8177\n",
            "Time:  0.1341 Epoch: 277 Iter: 1100/3510 LR: 0.0000024628 Loss content:  0.0144 Loss fft:  0.8480\n",
            "Time:  0.1312 Epoch: 277 Iter: 1200/3510 LR: 0.0000024628 Loss content:  0.0141 Loss fft:  0.8318\n",
            "Time:  0.1323 Epoch: 277 Iter: 1300/3510 LR: 0.0000024628 Loss content:  0.0140 Loss fft:  0.8086\n",
            "Time:  0.1298 Epoch: 277 Iter: 1400/3510 LR: 0.0000024628 Loss content:  0.0143 Loss fft:  0.8347\n",
            "Time:  0.1329 Epoch: 277 Iter: 1500/3510 LR: 0.0000024628 Loss content:  0.0141 Loss fft:  0.8161\n",
            "Time:  0.1292 Epoch: 277 Iter: 1600/3510 LR: 0.0000024628 Loss content:  0.0144 Loss fft:  0.8529\n",
            "Time:  0.1325 Epoch: 277 Iter: 1700/3510 LR: 0.0000024628 Loss content:  0.0142 Loss fft:  0.8437\n",
            "Time:  0.1338 Epoch: 277 Iter: 1800/3510 LR: 0.0000024628 Loss content:  0.0141 Loss fft:  0.8137\n",
            "Time:  0.1304 Epoch: 277 Iter: 1900/3510 LR: 0.0000024628 Loss content:  0.0143 Loss fft:  0.8374\n",
            "Time:  0.1377 Epoch: 277 Iter: 2000/3510 LR: 0.0000024628 Loss content:  0.0141 Loss fft:  0.8221\n",
            "Time:  0.1340 Epoch: 277 Iter: 2100/3510 LR: 0.0000024628 Loss content:  0.0143 Loss fft:  0.8355\n",
            "Time:  0.1324 Epoch: 277 Iter: 2200/3510 LR: 0.0000024628 Loss content:  0.0140 Loss fft:  0.8295\n",
            "Time:  0.1309 Epoch: 277 Iter: 2300/3510 LR: 0.0000024628 Loss content:  0.0146 Loss fft:  0.8515\n",
            "Time:  0.1329 Epoch: 277 Iter: 2400/3510 LR: 0.0000024628 Loss content:  0.0140 Loss fft:  0.8299\n",
            "Time:  0.1349 Epoch: 277 Iter: 2500/3510 LR: 0.0000024628 Loss content:  0.0146 Loss fft:  0.8373\n",
            "Time:  0.1318 Epoch: 277 Iter: 2600/3510 LR: 0.0000024628 Loss content:  0.0142 Loss fft:  0.8531\n",
            "Time:  0.1309 Epoch: 277 Iter: 2700/3510 LR: 0.0000024628 Loss content:  0.0146 Loss fft:  0.8510\n",
            "Time:  0.1304 Epoch: 277 Iter: 2800/3510 LR: 0.0000024628 Loss content:  0.0142 Loss fft:  0.8219\n",
            "Time:  0.1324 Epoch: 277 Iter: 2900/3510 LR: 0.0000024628 Loss content:  0.0143 Loss fft:  0.8293\n",
            "Time:  0.1299 Epoch: 277 Iter: 3000/3510 LR: 0.0000024628 Loss content:  0.0139 Loss fft:  0.8265\n",
            "Time:  0.1324 Epoch: 277 Iter: 3100/3510 LR: 0.0000024628 Loss content:  0.0143 Loss fft:  0.8385\n",
            "Time:  0.1308 Epoch: 277 Iter: 3200/3510 LR: 0.0000024628 Loss content:  0.0141 Loss fft:  0.8243\n",
            "Time:  0.1303 Epoch: 277 Iter: 3300/3510 LR: 0.0000024628 Loss content:  0.0147 Loss fft:  0.8407\n",
            "Time:  0.1303 Epoch: 277 Iter: 3400/3510 LR: 0.0000024628 Loss content:  0.0144 Loss fft:  0.8375\n",
            "Time:  0.1296 Epoch: 277 Iter: 3500/3510 LR: 0.0000024628 Loss content:  0.0143 Loss fft:  0.8333\n",
            "EPOCH: 277\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0142 Epoch FFT Loss:  0.8329\n",
            "Time:  0.1395 Epoch: 278 Iter:  100/3510 LR: 0.0000023394 Loss content:  0.0150 Loss fft:  0.8333\n",
            "Time:  0.1348 Epoch: 278 Iter:  200/3510 LR: 0.0000023394 Loss content:  0.0140 Loss fft:  0.8365\n",
            "Time:  0.1307 Epoch: 278 Iter:  300/3510 LR: 0.0000023394 Loss content:  0.0146 Loss fft:  0.8291\n",
            "Time:  0.1329 Epoch: 278 Iter:  400/3510 LR: 0.0000023394 Loss content:  0.0136 Loss fft:  0.8041\n",
            "Time:  0.1331 Epoch: 278 Iter:  500/3510 LR: 0.0000023394 Loss content:  0.0142 Loss fft:  0.8312\n",
            "Time:  0.1359 Epoch: 278 Iter:  600/3510 LR: 0.0000023394 Loss content:  0.0138 Loss fft:  0.8147\n",
            "Time:  0.1337 Epoch: 278 Iter:  700/3510 LR: 0.0000023394 Loss content:  0.0138 Loss fft:  0.8348\n",
            "Time:  0.1349 Epoch: 278 Iter:  800/3510 LR: 0.0000023394 Loss content:  0.0143 Loss fft:  0.8287\n",
            "Time:  0.1342 Epoch: 278 Iter:  900/3510 LR: 0.0000023394 Loss content:  0.0141 Loss fft:  0.8389\n",
            "Time:  0.1312 Epoch: 278 Iter: 1000/3510 LR: 0.0000023394 Loss content:  0.0143 Loss fft:  0.8299\n",
            "Time:  0.1325 Epoch: 278 Iter: 1100/3510 LR: 0.0000023394 Loss content:  0.0137 Loss fft:  0.8265\n",
            "Time:  0.1317 Epoch: 278 Iter: 1200/3510 LR: 0.0000023394 Loss content:  0.0140 Loss fft:  0.8389\n",
            "Time:  0.1303 Epoch: 278 Iter: 1300/3510 LR: 0.0000023394 Loss content:  0.0140 Loss fft:  0.8265\n",
            "Time:  0.1315 Epoch: 278 Iter: 1400/3510 LR: 0.0000023394 Loss content:  0.0141 Loss fft:  0.8287\n",
            "Time:  0.1346 Epoch: 278 Iter: 1500/3510 LR: 0.0000023394 Loss content:  0.0141 Loss fft:  0.8192\n",
            "Time:  0.1318 Epoch: 278 Iter: 1600/3510 LR: 0.0000023394 Loss content:  0.0140 Loss fft:  0.8483\n",
            "Time:  0.1319 Epoch: 278 Iter: 1700/3510 LR: 0.0000023394 Loss content:  0.0141 Loss fft:  0.8450\n",
            "Time:  0.1323 Epoch: 278 Iter: 1800/3510 LR: 0.0000023394 Loss content:  0.0141 Loss fft:  0.8184\n",
            "Time:  0.1307 Epoch: 278 Iter: 1900/3510 LR: 0.0000023394 Loss content:  0.0138 Loss fft:  0.8350\n",
            "Time:  0.1315 Epoch: 278 Iter: 2000/3510 LR: 0.0000023394 Loss content:  0.0148 Loss fft:  0.8469\n",
            "Time:  0.1301 Epoch: 278 Iter: 2100/3510 LR: 0.0000023394 Loss content:  0.0141 Loss fft:  0.8362\n",
            "Time:  0.1330 Epoch: 278 Iter: 2200/3510 LR: 0.0000023394 Loss content:  0.0142 Loss fft:  0.8335\n",
            "Time:  0.1335 Epoch: 278 Iter: 2300/3510 LR: 0.0000023394 Loss content:  0.0148 Loss fft:  0.8237\n",
            "Time:  0.1336 Epoch: 278 Iter: 2400/3510 LR: 0.0000023394 Loss content:  0.0139 Loss fft:  0.8363\n",
            "Time:  0.1328 Epoch: 278 Iter: 2500/3510 LR: 0.0000023394 Loss content:  0.0146 Loss fft:  0.8434\n",
            "Time:  0.1301 Epoch: 278 Iter: 2600/3510 LR: 0.0000023394 Loss content:  0.0140 Loss fft:  0.8416\n",
            "Time:  0.1321 Epoch: 278 Iter: 2700/3510 LR: 0.0000023394 Loss content:  0.0140 Loss fft:  0.8442\n",
            "Time:  0.1288 Epoch: 278 Iter: 2800/3510 LR: 0.0000023394 Loss content:  0.0141 Loss fft:  0.8137\n",
            "Time:  0.1297 Epoch: 278 Iter: 2900/3510 LR: 0.0000023394 Loss content:  0.0145 Loss fft:  0.8145\n",
            "Time:  0.1285 Epoch: 278 Iter: 3000/3510 LR: 0.0000023394 Loss content:  0.0140 Loss fft:  0.8348\n",
            "Time:  0.1333 Epoch: 278 Iter: 3100/3510 LR: 0.0000023394 Loss content:  0.0141 Loss fft:  0.8319\n",
            "Time:  0.1350 Epoch: 278 Iter: 3200/3510 LR: 0.0000023394 Loss content:  0.0142 Loss fft:  0.8419\n",
            "Time:  0.1333 Epoch: 278 Iter: 3300/3510 LR: 0.0000023394 Loss content:  0.0140 Loss fft:  0.8401\n",
            "Time:  0.1297 Epoch: 278 Iter: 3400/3510 LR: 0.0000023394 Loss content:  0.0145 Loss fft:  0.8392\n",
            "Time:  0.1303 Epoch: 278 Iter: 3500/3510 LR: 0.0000023394 Loss content:  0.0143 Loss fft:  0.8313\n",
            "EPOCH: 278\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0142 Epoch FFT Loss:  0.8324\n",
            "Time:  0.1427 Epoch: 279 Iter:  100/3510 LR: 0.0000022213 Loss content:  0.0136 Loss fft:  0.8349\n",
            "Time:  0.1304 Epoch: 279 Iter:  200/3510 LR: 0.0000022213 Loss content:  0.0146 Loss fft:  0.8542\n",
            "Time:  0.1322 Epoch: 279 Iter:  300/3510 LR: 0.0000022213 Loss content:  0.0137 Loss fft:  0.8163\n",
            "Time:  0.1303 Epoch: 279 Iter:  400/3510 LR: 0.0000022213 Loss content:  0.0146 Loss fft:  0.8394\n",
            "Time:  0.1319 Epoch: 279 Iter:  500/3510 LR: 0.0000022213 Loss content:  0.0142 Loss fft:  0.8497\n",
            "Time:  0.1315 Epoch: 279 Iter:  600/3510 LR: 0.0000022213 Loss content:  0.0145 Loss fft:  0.8264\n",
            "Time:  0.1316 Epoch: 279 Iter:  700/3510 LR: 0.0000022213 Loss content:  0.0147 Loss fft:  0.8550\n",
            "Time:  0.1320 Epoch: 279 Iter:  800/3510 LR: 0.0000022213 Loss content:  0.0136 Loss fft:  0.8176\n",
            "Time:  0.1337 Epoch: 279 Iter:  900/3510 LR: 0.0000022213 Loss content:  0.0146 Loss fft:  0.8534\n",
            "Time:  0.1336 Epoch: 279 Iter: 1000/3510 LR: 0.0000022213 Loss content:  0.0139 Loss fft:  0.8183\n",
            "Time:  0.1304 Epoch: 279 Iter: 1100/3510 LR: 0.0000022213 Loss content:  0.0141 Loss fft:  0.8311\n",
            "Time:  0.1327 Epoch: 279 Iter: 1200/3510 LR: 0.0000022213 Loss content:  0.0135 Loss fft:  0.8225\n",
            "Time:  0.1304 Epoch: 279 Iter: 1300/3510 LR: 0.0000022213 Loss content:  0.0145 Loss fft:  0.8235\n",
            "Time:  0.1318 Epoch: 279 Iter: 1400/3510 LR: 0.0000022213 Loss content:  0.0137 Loss fft:  0.8216\n",
            "Time:  0.1315 Epoch: 279 Iter: 1500/3510 LR: 0.0000022213 Loss content:  0.0146 Loss fft:  0.8345\n",
            "Time:  0.1316 Epoch: 279 Iter: 1600/3510 LR: 0.0000022213 Loss content:  0.0137 Loss fft:  0.8063\n",
            "Time:  0.1331 Epoch: 279 Iter: 1700/3510 LR: 0.0000022213 Loss content:  0.0137 Loss fft:  0.8181\n",
            "Time:  0.1305 Epoch: 279 Iter: 1800/3510 LR: 0.0000022213 Loss content:  0.0142 Loss fft:  0.8287\n",
            "Time:  0.1319 Epoch: 279 Iter: 1900/3510 LR: 0.0000022213 Loss content:  0.0141 Loss fft:  0.8551\n",
            "Time:  0.1395 Epoch: 279 Iter: 2000/3510 LR: 0.0000022213 Loss content:  0.0142 Loss fft:  0.8364\n",
            "Time:  0.1305 Epoch: 279 Iter: 2100/3510 LR: 0.0000022213 Loss content:  0.0140 Loss fft:  0.8291\n",
            "Time:  0.1310 Epoch: 279 Iter: 2200/3510 LR: 0.0000022213 Loss content:  0.0142 Loss fft:  0.8210\n",
            "Time:  0.1322 Epoch: 279 Iter: 2300/3510 LR: 0.0000022213 Loss content:  0.0144 Loss fft:  0.8482\n",
            "Time:  0.1310 Epoch: 279 Iter: 2400/3510 LR: 0.0000022213 Loss content:  0.0148 Loss fft:  0.8567\n",
            "Time:  0.1303 Epoch: 279 Iter: 2500/3510 LR: 0.0000022213 Loss content:  0.0143 Loss fft:  0.8498\n",
            "Time:  0.1291 Epoch: 279 Iter: 2600/3510 LR: 0.0000022213 Loss content:  0.0141 Loss fft:  0.8160\n",
            "Time:  0.1298 Epoch: 279 Iter: 2700/3510 LR: 0.0000022213 Loss content:  0.0143 Loss fft:  0.8679\n",
            "Time:  0.1314 Epoch: 279 Iter: 2800/3510 LR: 0.0000022213 Loss content:  0.0137 Loss fft:  0.8202\n",
            "Time:  0.1336 Epoch: 279 Iter: 2900/3510 LR: 0.0000022213 Loss content:  0.0140 Loss fft:  0.8297\n",
            "Time:  0.1336 Epoch: 279 Iter: 3000/3510 LR: 0.0000022213 Loss content:  0.0147 Loss fft:  0.8497\n",
            "Time:  0.1319 Epoch: 279 Iter: 3100/3510 LR: 0.0000022213 Loss content:  0.0139 Loss fft:  0.8347\n",
            "Time:  0.1339 Epoch: 279 Iter: 3200/3510 LR: 0.0000022213 Loss content:  0.0143 Loss fft:  0.8436\n",
            "Time:  0.1317 Epoch: 279 Iter: 3300/3510 LR: 0.0000022213 Loss content:  0.0142 Loss fft:  0.8376\n",
            "Time:  0.1344 Epoch: 279 Iter: 3400/3510 LR: 0.0000022213 Loss content:  0.0142 Loss fft:  0.8531\n",
            "Time:  0.1307 Epoch: 279 Iter: 3500/3510 LR: 0.0000022213 Loss content:  0.0143 Loss fft:  0.8368\n",
            "EPOCH: 279\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0141 Epoch FFT Loss:  0.8351\n",
            "Time:  0.1416 Epoch: 280 Iter:  100/3510 LR: 0.0000021086 Loss content:  0.0143 Loss fft:  0.8347\n",
            "Time:  0.1335 Epoch: 280 Iter:  200/3510 LR: 0.0000021086 Loss content:  0.0148 Loss fft:  0.8647\n",
            "Time:  0.1313 Epoch: 280 Iter:  300/3510 LR: 0.0000021086 Loss content:  0.0139 Loss fft:  0.8099\n",
            "Time:  0.1324 Epoch: 280 Iter:  400/3510 LR: 0.0000021086 Loss content:  0.0142 Loss fft:  0.8520\n",
            "Time:  0.1312 Epoch: 280 Iter:  500/3510 LR: 0.0000021086 Loss content:  0.0140 Loss fft:  0.8372\n",
            "Time:  0.1307 Epoch: 280 Iter:  600/3510 LR: 0.0000021086 Loss content:  0.0139 Loss fft:  0.8301\n",
            "Time:  0.1345 Epoch: 280 Iter:  700/3510 LR: 0.0000021086 Loss content:  0.0140 Loss fft:  0.8465\n",
            "Time:  0.1291 Epoch: 280 Iter:  800/3510 LR: 0.0000021086 Loss content:  0.0139 Loss fft:  0.8400\n",
            "Time:  0.1295 Epoch: 280 Iter:  900/3510 LR: 0.0000021086 Loss content:  0.0141 Loss fft:  0.8422\n",
            "Time:  0.1314 Epoch: 280 Iter: 1000/3510 LR: 0.0000021086 Loss content:  0.0141 Loss fft:  0.8380\n",
            "Time:  0.1303 Epoch: 280 Iter: 1100/3510 LR: 0.0000021086 Loss content:  0.0141 Loss fft:  0.8221\n",
            "Time:  0.1310 Epoch: 280 Iter: 1200/3510 LR: 0.0000021086 Loss content:  0.0142 Loss fft:  0.8326\n",
            "Time:  0.1302 Epoch: 280 Iter: 1300/3510 LR: 0.0000021086 Loss content:  0.0142 Loss fft:  0.8331\n",
            "Time:  0.1304 Epoch: 280 Iter: 1400/3510 LR: 0.0000021086 Loss content:  0.0144 Loss fft:  0.8552\n",
            "Time:  0.1326 Epoch: 280 Iter: 1500/3510 LR: 0.0000021086 Loss content:  0.0144 Loss fft:  0.8297\n",
            "Time:  0.1322 Epoch: 280 Iter: 1600/3510 LR: 0.0000021086 Loss content:  0.0147 Loss fft:  0.8298\n",
            "Time:  0.1337 Epoch: 280 Iter: 1700/3510 LR: 0.0000021086 Loss content:  0.0145 Loss fft:  0.8388\n",
            "Time:  0.1286 Epoch: 280 Iter: 1800/3510 LR: 0.0000021086 Loss content:  0.0144 Loss fft:  0.8309\n",
            "Time:  0.1338 Epoch: 280 Iter: 1900/3510 LR: 0.0000021086 Loss content:  0.0144 Loss fft:  0.8322\n",
            "Time:  0.1323 Epoch: 280 Iter: 2000/3510 LR: 0.0000021086 Loss content:  0.0137 Loss fft:  0.8275\n",
            "Time:  0.1320 Epoch: 280 Iter: 2100/3510 LR: 0.0000021086 Loss content:  0.0141 Loss fft:  0.8234\n",
            "Time:  0.1314 Epoch: 280 Iter: 2200/3510 LR: 0.0000021086 Loss content:  0.0140 Loss fft:  0.8398\n",
            "Time:  0.1333 Epoch: 280 Iter: 2300/3510 LR: 0.0000021086 Loss content:  0.0140 Loss fft:  0.8398\n",
            "Time:  0.1327 Epoch: 280 Iter: 2400/3510 LR: 0.0000021086 Loss content:  0.0140 Loss fft:  0.8353\n",
            "Time:  0.1322 Epoch: 280 Iter: 2500/3510 LR: 0.0000021086 Loss content:  0.0143 Loss fft:  0.8380\n",
            "Time:  0.1323 Epoch: 280 Iter: 2600/3510 LR: 0.0000021086 Loss content:  0.0143 Loss fft:  0.8276\n",
            "Time:  0.1322 Epoch: 280 Iter: 2700/3510 LR: 0.0000021086 Loss content:  0.0142 Loss fft:  0.8211\n",
            "Time:  0.1327 Epoch: 280 Iter: 2800/3510 LR: 0.0000021086 Loss content:  0.0143 Loss fft:  0.8536\n",
            "Time:  0.1297 Epoch: 280 Iter: 2900/3510 LR: 0.0000021086 Loss content:  0.0140 Loss fft:  0.8306\n",
            "Time:  0.1325 Epoch: 280 Iter: 3000/3510 LR: 0.0000021086 Loss content:  0.0138 Loss fft:  0.8289\n",
            "Time:  0.1359 Epoch: 280 Iter: 3100/3510 LR: 0.0000021086 Loss content:  0.0144 Loss fft:  0.8586\n",
            "Time:  0.1320 Epoch: 280 Iter: 3200/3510 LR: 0.0000021086 Loss content:  0.0139 Loss fft:  0.8124\n",
            "Time:  0.1327 Epoch: 280 Iter: 3300/3510 LR: 0.0000021086 Loss content:  0.0142 Loss fft:  0.8131\n",
            "Time:  0.1321 Epoch: 280 Iter: 3400/3510 LR: 0.0000021086 Loss content:  0.0135 Loss fft:  0.8088\n",
            "Time:  0.1345 Epoch: 280 Iter: 3500/3510 LR: 0.0000021086 Loss content:  0.0141 Loss fft:  0.8421\n",
            "EPOCH: 280\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0142 Epoch FFT Loss:  0.8346\n",
            "Start Evaluation\n",
            "499 \n",
            "\n",
            "280 epoch \n",
            " Average PSNR 40.98 dB\n",
            "Time:  0.1434 Epoch: 281 Iter:  100/3510 LR: 0.0000020014 Loss content:  0.0143 Loss fft:  0.8351\n",
            "Time:  0.1300 Epoch: 281 Iter:  200/3510 LR: 0.0000020014 Loss content:  0.0148 Loss fft:  0.8494\n",
            "Time:  0.1318 Epoch: 281 Iter:  300/3510 LR: 0.0000020014 Loss content:  0.0145 Loss fft:  0.8458\n",
            "Time:  0.1308 Epoch: 281 Iter:  400/3510 LR: 0.0000020014 Loss content:  0.0142 Loss fft:  0.8227\n",
            "Time:  0.1327 Epoch: 281 Iter:  500/3510 LR: 0.0000020014 Loss content:  0.0142 Loss fft:  0.8248\n",
            "Time:  0.1294 Epoch: 281 Iter:  600/3510 LR: 0.0000020014 Loss content:  0.0139 Loss fft:  0.8365\n",
            "Time:  0.1319 Epoch: 281 Iter:  700/3510 LR: 0.0000020014 Loss content:  0.0144 Loss fft:  0.8450\n",
            "Time:  0.1323 Epoch: 281 Iter:  800/3510 LR: 0.0000020014 Loss content:  0.0146 Loss fft:  0.8516\n",
            "Time:  0.1310 Epoch: 281 Iter:  900/3510 LR: 0.0000020014 Loss content:  0.0135 Loss fft:  0.8133\n",
            "Time:  0.1286 Epoch: 281 Iter: 1000/3510 LR: 0.0000020014 Loss content:  0.0144 Loss fft:  0.8372\n",
            "Time:  0.1334 Epoch: 281 Iter: 1100/3510 LR: 0.0000020014 Loss content:  0.0142 Loss fft:  0.8391\n",
            "Time:  0.1334 Epoch: 281 Iter: 1200/3510 LR: 0.0000020014 Loss content:  0.0140 Loss fft:  0.8100\n",
            "Time:  0.1313 Epoch: 281 Iter: 1300/3510 LR: 0.0000020014 Loss content:  0.0139 Loss fft:  0.7960\n",
            "Time:  0.1323 Epoch: 281 Iter: 1400/3510 LR: 0.0000020014 Loss content:  0.0141 Loss fft:  0.8506\n",
            "Time:  0.1328 Epoch: 281 Iter: 1500/3510 LR: 0.0000020014 Loss content:  0.0142 Loss fft:  0.8174\n",
            "Time:  0.1327 Epoch: 281 Iter: 1600/3510 LR: 0.0000020014 Loss content:  0.0143 Loss fft:  0.8246\n",
            "Time:  0.1308 Epoch: 281 Iter: 1700/3510 LR: 0.0000020014 Loss content:  0.0141 Loss fft:  0.8392\n",
            "Time:  0.1286 Epoch: 281 Iter: 1800/3510 LR: 0.0000020014 Loss content:  0.0141 Loss fft:  0.8326\n",
            "Time:  0.1371 Epoch: 281 Iter: 1900/3510 LR: 0.0000020014 Loss content:  0.0145 Loss fft:  0.8361\n",
            "Time:  0.1326 Epoch: 281 Iter: 2000/3510 LR: 0.0000020014 Loss content:  0.0144 Loss fft:  0.8498\n",
            "Time:  0.1298 Epoch: 281 Iter: 2100/3510 LR: 0.0000020014 Loss content:  0.0141 Loss fft:  0.8370\n",
            "Time:  0.1308 Epoch: 281 Iter: 2200/3510 LR: 0.0000020014 Loss content:  0.0143 Loss fft:  0.8397\n",
            "Time:  0.1308 Epoch: 281 Iter: 2300/3510 LR: 0.0000020014 Loss content:  0.0140 Loss fft:  0.8380\n",
            "Time:  0.1361 Epoch: 281 Iter: 2400/3510 LR: 0.0000020014 Loss content:  0.0143 Loss fft:  0.8287\n",
            "Time:  0.1327 Epoch: 281 Iter: 2500/3510 LR: 0.0000020014 Loss content:  0.0140 Loss fft:  0.8289\n",
            "Time:  0.1316 Epoch: 281 Iter: 2600/3510 LR: 0.0000020014 Loss content:  0.0142 Loss fft:  0.8504\n",
            "Time:  0.1341 Epoch: 281 Iter: 2700/3510 LR: 0.0000020014 Loss content:  0.0134 Loss fft:  0.8113\n",
            "Time:  0.1358 Epoch: 281 Iter: 2800/3510 LR: 0.0000020014 Loss content:  0.0144 Loss fft:  0.8414\n",
            "Time:  0.1323 Epoch: 281 Iter: 2900/3510 LR: 0.0000020014 Loss content:  0.0139 Loss fft:  0.8146\n",
            "Time:  0.1307 Epoch: 281 Iter: 3000/3510 LR: 0.0000020014 Loss content:  0.0140 Loss fft:  0.8382\n",
            "Time:  0.1343 Epoch: 281 Iter: 3100/3510 LR: 0.0000020014 Loss content:  0.0143 Loss fft:  0.8400\n",
            "Time:  0.1351 Epoch: 281 Iter: 3200/3510 LR: 0.0000020014 Loss content:  0.0144 Loss fft:  0.8332\n",
            "Time:  0.1325 Epoch: 281 Iter: 3300/3510 LR: 0.0000020014 Loss content:  0.0142 Loss fft:  0.8330\n",
            "Time:  0.1326 Epoch: 281 Iter: 3400/3510 LR: 0.0000020014 Loss content:  0.0144 Loss fft:  0.8384\n",
            "Time:  0.1294 Epoch: 281 Iter: 3500/3510 LR: 0.0000020014 Loss content:  0.0140 Loss fft:  0.8310\n",
            "EPOCH: 281\n",
            "Elapsed time: 4.66 Epoch Pixel Loss:  0.0142 Epoch FFT Loss:  0.8330\n",
            "Time:  0.1432 Epoch: 282 Iter:  100/3510 LR: 0.0000018995 Loss content:  0.0138 Loss fft:  0.8347\n",
            "Time:  0.1290 Epoch: 282 Iter:  200/3510 LR: 0.0000018995 Loss content:  0.0142 Loss fft:  0.8337\n",
            "Time:  0.1300 Epoch: 282 Iter:  300/3510 LR: 0.0000018995 Loss content:  0.0139 Loss fft:  0.8198\n",
            "Time:  0.1332 Epoch: 282 Iter:  400/3510 LR: 0.0000018995 Loss content:  0.0142 Loss fft:  0.8318\n",
            "Time:  0.1322 Epoch: 282 Iter:  500/3510 LR: 0.0000018995 Loss content:  0.0141 Loss fft:  0.8299\n",
            "Time:  0.1308 Epoch: 282 Iter:  600/3510 LR: 0.0000018995 Loss content:  0.0144 Loss fft:  0.8310\n",
            "Time:  0.1412 Epoch: 282 Iter:  700/3510 LR: 0.0000018995 Loss content:  0.0145 Loss fft:  0.8134\n",
            "Time:  0.1354 Epoch: 282 Iter:  800/3510 LR: 0.0000018995 Loss content:  0.0138 Loss fft:  0.8266\n",
            "Time:  0.1299 Epoch: 282 Iter:  900/3510 LR: 0.0000018995 Loss content:  0.0140 Loss fft:  0.8295\n",
            "Time:  0.1310 Epoch: 282 Iter: 1000/3510 LR: 0.0000018995 Loss content:  0.0141 Loss fft:  0.8537\n",
            "Time:  0.1315 Epoch: 282 Iter: 1100/3510 LR: 0.0000018995 Loss content:  0.0138 Loss fft:  0.8202\n",
            "Time:  0.1343 Epoch: 282 Iter: 1200/3510 LR: 0.0000018995 Loss content:  0.0141 Loss fft:  0.8464\n",
            "Time:  0.1282 Epoch: 282 Iter: 1300/3510 LR: 0.0000018995 Loss content:  0.0147 Loss fft:  0.8548\n",
            "Time:  0.1322 Epoch: 282 Iter: 1400/3510 LR: 0.0000018995 Loss content:  0.0140 Loss fft:  0.8325\n",
            "Time:  0.1332 Epoch: 282 Iter: 1500/3510 LR: 0.0000018995 Loss content:  0.0135 Loss fft:  0.8329\n",
            "Time:  0.1329 Epoch: 282 Iter: 1600/3510 LR: 0.0000018995 Loss content:  0.0138 Loss fft:  0.8330\n",
            "Time:  0.1325 Epoch: 282 Iter: 1700/3510 LR: 0.0000018995 Loss content:  0.0145 Loss fft:  0.8391\n",
            "Time:  0.1311 Epoch: 282 Iter: 1800/3510 LR: 0.0000018995 Loss content:  0.0140 Loss fft:  0.8271\n",
            "Time:  0.1300 Epoch: 282 Iter: 1900/3510 LR: 0.0000018995 Loss content:  0.0140 Loss fft:  0.8360\n",
            "Time:  0.1284 Epoch: 282 Iter: 2000/3510 LR: 0.0000018995 Loss content:  0.0138 Loss fft:  0.8155\n",
            "Time:  0.1307 Epoch: 282 Iter: 2100/3510 LR: 0.0000018995 Loss content:  0.0137 Loss fft:  0.8070\n",
            "Time:  0.1286 Epoch: 282 Iter: 2200/3510 LR: 0.0000018995 Loss content:  0.0139 Loss fft:  0.8414\n",
            "Time:  0.1302 Epoch: 282 Iter: 2300/3510 LR: 0.0000018995 Loss content:  0.0142 Loss fft:  0.8505\n",
            "Time:  0.1285 Epoch: 282 Iter: 2400/3510 LR: 0.0000018995 Loss content:  0.0141 Loss fft:  0.8388\n",
            "Time:  0.1314 Epoch: 282 Iter: 2500/3510 LR: 0.0000018995 Loss content:  0.0138 Loss fft:  0.8225\n",
            "Time:  0.1314 Epoch: 282 Iter: 2600/3510 LR: 0.0000018995 Loss content:  0.0142 Loss fft:  0.8243\n",
            "Time:  0.1312 Epoch: 282 Iter: 2700/3510 LR: 0.0000018995 Loss content:  0.0141 Loss fft:  0.8272\n",
            "Time:  0.1288 Epoch: 282 Iter: 2800/3510 LR: 0.0000018995 Loss content:  0.0135 Loss fft:  0.8187\n",
            "Time:  0.1279 Epoch: 282 Iter: 2900/3510 LR: 0.0000018995 Loss content:  0.0140 Loss fft:  0.8167\n",
            "Time:  0.1321 Epoch: 282 Iter: 3000/3510 LR: 0.0000018995 Loss content:  0.0143 Loss fft:  0.8324\n",
            "Time:  0.1359 Epoch: 282 Iter: 3100/3510 LR: 0.0000018995 Loss content:  0.0143 Loss fft:  0.8393\n",
            "Time:  0.1310 Epoch: 282 Iter: 3200/3510 LR: 0.0000018995 Loss content:  0.0136 Loss fft:  0.8394\n",
            "Time:  0.1293 Epoch: 282 Iter: 3300/3510 LR: 0.0000018995 Loss content:  0.0138 Loss fft:  0.8298\n",
            "Time:  0.1323 Epoch: 282 Iter: 3400/3510 LR: 0.0000018995 Loss content:  0.0143 Loss fft:  0.8372\n",
            "Time:  0.1308 Epoch: 282 Iter: 3500/3510 LR: 0.0000018995 Loss content:  0.0142 Loss fft:  0.8162\n",
            "EPOCH: 282\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0140 Epoch FFT Loss:  0.8313\n",
            "Time:  0.1408 Epoch: 283 Iter:  100/3510 LR: 0.0000018031 Loss content:  0.0143 Loss fft:  0.8341\n",
            "Time:  0.1312 Epoch: 283 Iter:  200/3510 LR: 0.0000018031 Loss content:  0.0139 Loss fft:  0.8184\n",
            "Time:  0.1293 Epoch: 283 Iter:  300/3510 LR: 0.0000018031 Loss content:  0.0142 Loss fft:  0.8262\n",
            "Time:  0.1299 Epoch: 283 Iter:  400/3510 LR: 0.0000018031 Loss content:  0.0144 Loss fft:  0.8332\n",
            "Time:  0.1301 Epoch: 283 Iter:  500/3510 LR: 0.0000018031 Loss content:  0.0141 Loss fft:  0.8350\n",
            "Time:  0.1320 Epoch: 283 Iter:  600/3510 LR: 0.0000018031 Loss content:  0.0142 Loss fft:  0.8460\n",
            "Time:  0.1327 Epoch: 283 Iter:  700/3510 LR: 0.0000018031 Loss content:  0.0139 Loss fft:  0.8348\n",
            "Time:  0.1310 Epoch: 283 Iter:  800/3510 LR: 0.0000018031 Loss content:  0.0140 Loss fft:  0.8150\n",
            "Time:  0.1282 Epoch: 283 Iter:  900/3510 LR: 0.0000018031 Loss content:  0.0140 Loss fft:  0.8556\n",
            "Time:  0.1327 Epoch: 283 Iter: 1000/3510 LR: 0.0000018031 Loss content:  0.0143 Loss fft:  0.8418\n",
            "Time:  0.1337 Epoch: 283 Iter: 1100/3510 LR: 0.0000018031 Loss content:  0.0141 Loss fft:  0.8489\n",
            "Time:  0.1323 Epoch: 283 Iter: 1200/3510 LR: 0.0000018031 Loss content:  0.0143 Loss fft:  0.8570\n",
            "Time:  0.1305 Epoch: 283 Iter: 1300/3510 LR: 0.0000018031 Loss content:  0.0141 Loss fft:  0.8216\n",
            "Time:  0.1314 Epoch: 283 Iter: 1400/3510 LR: 0.0000018031 Loss content:  0.0143 Loss fft:  0.8521\n",
            "Time:  0.1328 Epoch: 283 Iter: 1500/3510 LR: 0.0000018031 Loss content:  0.0147 Loss fft:  0.8448\n",
            "Time:  0.1301 Epoch: 283 Iter: 1600/3510 LR: 0.0000018031 Loss content:  0.0145 Loss fft:  0.8396\n",
            "Time:  0.1307 Epoch: 283 Iter: 1700/3510 LR: 0.0000018031 Loss content:  0.0134 Loss fft:  0.8408\n",
            "Time:  0.1376 Epoch: 283 Iter: 1800/3510 LR: 0.0000018031 Loss content:  0.0135 Loss fft:  0.8192\n",
            "Time:  0.1344 Epoch: 283 Iter: 1900/3510 LR: 0.0000018031 Loss content:  0.0140 Loss fft:  0.8352\n",
            "Time:  0.1331 Epoch: 283 Iter: 2000/3510 LR: 0.0000018031 Loss content:  0.0136 Loss fft:  0.8134\n",
            "Time:  0.1321 Epoch: 283 Iter: 2100/3510 LR: 0.0000018031 Loss content:  0.0138 Loss fft:  0.8365\n",
            "Time:  0.1328 Epoch: 283 Iter: 2200/3510 LR: 0.0000018031 Loss content:  0.0142 Loss fft:  0.8368\n",
            "Time:  0.1323 Epoch: 283 Iter: 2300/3510 LR: 0.0000018031 Loss content:  0.0141 Loss fft:  0.8218\n",
            "Time:  0.1311 Epoch: 283 Iter: 2400/3510 LR: 0.0000018031 Loss content:  0.0136 Loss fft:  0.8107\n",
            "Time:  0.1327 Epoch: 283 Iter: 2500/3510 LR: 0.0000018031 Loss content:  0.0144 Loss fft:  0.8389\n",
            "Time:  0.1311 Epoch: 283 Iter: 2600/3510 LR: 0.0000018031 Loss content:  0.0143 Loss fft:  0.8462\n",
            "Time:  0.1325 Epoch: 283 Iter: 2700/3510 LR: 0.0000018031 Loss content:  0.0139 Loss fft:  0.8264\n",
            "Time:  0.1323 Epoch: 283 Iter: 2800/3510 LR: 0.0000018031 Loss content:  0.0140 Loss fft:  0.8250\n",
            "Time:  0.1325 Epoch: 283 Iter: 2900/3510 LR: 0.0000018031 Loss content:  0.0138 Loss fft:  0.8356\n",
            "Time:  0.1326 Epoch: 283 Iter: 3000/3510 LR: 0.0000018031 Loss content:  0.0143 Loss fft:  0.8137\n",
            "Time:  0.1295 Epoch: 283 Iter: 3100/3510 LR: 0.0000018031 Loss content:  0.0139 Loss fft:  0.8565\n",
            "Time:  0.1312 Epoch: 283 Iter: 3200/3510 LR: 0.0000018031 Loss content:  0.0139 Loss fft:  0.8516\n",
            "Time:  0.1309 Epoch: 283 Iter: 3300/3510 LR: 0.0000018031 Loss content:  0.0144 Loss fft:  0.8197\n",
            "Time:  0.1344 Epoch: 283 Iter: 3400/3510 LR: 0.0000018031 Loss content:  0.0141 Loss fft:  0.8179\n",
            "Time:  0.1298 Epoch: 283 Iter: 3500/3510 LR: 0.0000018031 Loss content:  0.0141 Loss fft:  0.8154\n",
            "EPOCH: 283\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0141 Epoch FFT Loss:  0.8332\n",
            "Time:  0.1404 Epoch: 284 Iter:  100/3510 LR: 0.0000017122 Loss content:  0.0141 Loss fft:  0.8333\n",
            "Time:  0.1339 Epoch: 284 Iter:  200/3510 LR: 0.0000017122 Loss content:  0.0141 Loss fft:  0.8397\n",
            "Time:  0.1294 Epoch: 284 Iter:  300/3510 LR: 0.0000017122 Loss content:  0.0140 Loss fft:  0.8319\n",
            "Time:  0.1285 Epoch: 284 Iter:  400/3510 LR: 0.0000017122 Loss content:  0.0136 Loss fft:  0.8243\n",
            "Time:  0.1280 Epoch: 284 Iter:  500/3510 LR: 0.0000017122 Loss content:  0.0138 Loss fft:  0.8298\n",
            "Time:  0.1378 Epoch: 284 Iter:  600/3510 LR: 0.0000017122 Loss content:  0.0145 Loss fft:  0.8541\n",
            "Time:  0.1334 Epoch: 284 Iter:  700/3510 LR: 0.0000017122 Loss content:  0.0140 Loss fft:  0.8451\n",
            "Time:  0.1329 Epoch: 284 Iter:  800/3510 LR: 0.0000017122 Loss content:  0.0140 Loss fft:  0.7986\n",
            "Time:  0.1307 Epoch: 284 Iter:  900/3510 LR: 0.0000017122 Loss content:  0.0142 Loss fft:  0.8340\n",
            "Time:  0.1304 Epoch: 284 Iter: 1000/3510 LR: 0.0000017122 Loss content:  0.0135 Loss fft:  0.8056\n",
            "Time:  0.1302 Epoch: 284 Iter: 1100/3510 LR: 0.0000017122 Loss content:  0.0143 Loss fft:  0.8440\n",
            "Time:  0.1309 Epoch: 284 Iter: 1200/3510 LR: 0.0000017122 Loss content:  0.0139 Loss fft:  0.8506\n",
            "Time:  0.1302 Epoch: 284 Iter: 1300/3510 LR: 0.0000017122 Loss content:  0.0139 Loss fft:  0.8450\n",
            "Time:  0.1318 Epoch: 284 Iter: 1400/3510 LR: 0.0000017122 Loss content:  0.0142 Loss fft:  0.8374\n",
            "Time:  0.1325 Epoch: 284 Iter: 1500/3510 LR: 0.0000017122 Loss content:  0.0143 Loss fft:  0.8486\n",
            "Time:  0.1317 Epoch: 284 Iter: 1600/3510 LR: 0.0000017122 Loss content:  0.0142 Loss fft:  0.8326\n",
            "Time:  0.1299 Epoch: 284 Iter: 1700/3510 LR: 0.0000017122 Loss content:  0.0141 Loss fft:  0.8404\n",
            "Time:  0.1317 Epoch: 284 Iter: 1800/3510 LR: 0.0000017122 Loss content:  0.0136 Loss fft:  0.8235\n",
            "Time:  0.1307 Epoch: 284 Iter: 1900/3510 LR: 0.0000017122 Loss content:  0.0142 Loss fft:  0.8446\n",
            "Time:  0.1305 Epoch: 284 Iter: 2000/3510 LR: 0.0000017122 Loss content:  0.0143 Loss fft:  0.8269\n",
            "Time:  0.1313 Epoch: 284 Iter: 2100/3510 LR: 0.0000017122 Loss content:  0.0143 Loss fft:  0.8510\n",
            "Time:  0.1327 Epoch: 284 Iter: 2200/3510 LR: 0.0000017122 Loss content:  0.0138 Loss fft:  0.8245\n",
            "Time:  0.1308 Epoch: 284 Iter: 2300/3510 LR: 0.0000017122 Loss content:  0.0139 Loss fft:  0.8227\n",
            "Time:  0.1332 Epoch: 284 Iter: 2400/3510 LR: 0.0000017122 Loss content:  0.0138 Loss fft:  0.8226\n",
            "Time:  0.1301 Epoch: 284 Iter: 2500/3510 LR: 0.0000017122 Loss content:  0.0146 Loss fft:  0.8111\n",
            "Time:  0.1330 Epoch: 284 Iter: 2600/3510 LR: 0.0000017122 Loss content:  0.0140 Loss fft:  0.8427\n",
            "Time:  0.1324 Epoch: 284 Iter: 2700/3510 LR: 0.0000017122 Loss content:  0.0144 Loss fft:  0.8529\n",
            "Time:  0.1334 Epoch: 284 Iter: 2800/3510 LR: 0.0000017122 Loss content:  0.0141 Loss fft:  0.8215\n",
            "Time:  0.1322 Epoch: 284 Iter: 2900/3510 LR: 0.0000017122 Loss content:  0.0140 Loss fft:  0.8245\n",
            "Time:  0.1394 Epoch: 284 Iter: 3000/3510 LR: 0.0000017122 Loss content:  0.0138 Loss fft:  0.8272\n",
            "Time:  0.1294 Epoch: 284 Iter: 3100/3510 LR: 0.0000017122 Loss content:  0.0140 Loss fft:  0.8303\n",
            "Time:  0.1310 Epoch: 284 Iter: 3200/3510 LR: 0.0000017122 Loss content:  0.0139 Loss fft:  0.8260\n",
            "Time:  0.1304 Epoch: 284 Iter: 3300/3510 LR: 0.0000017122 Loss content:  0.0144 Loss fft:  0.8468\n",
            "Time:  0.1287 Epoch: 284 Iter: 3400/3510 LR: 0.0000017122 Loss content:  0.0137 Loss fft:  0.8302\n",
            "Time:  0.1322 Epoch: 284 Iter: 3500/3510 LR: 0.0000017122 Loss content:  0.0147 Loss fft:  0.8455\n",
            "EPOCH: 284\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0141 Epoch FFT Loss:  0.8334\n",
            "Time:  0.1407 Epoch: 285 Iter:  100/3510 LR: 0.0000016267 Loss content:  0.0142 Loss fft:  0.8383\n",
            "Time:  0.1330 Epoch: 285 Iter:  200/3510 LR: 0.0000016267 Loss content:  0.0139 Loss fft:  0.8366\n",
            "Time:  0.1307 Epoch: 285 Iter:  300/3510 LR: 0.0000016267 Loss content:  0.0140 Loss fft:  0.8443\n",
            "Time:  0.1303 Epoch: 285 Iter:  400/3510 LR: 0.0000016267 Loss content:  0.0139 Loss fft:  0.8425\n",
            "Time:  0.1316 Epoch: 285 Iter:  500/3510 LR: 0.0000016267 Loss content:  0.0139 Loss fft:  0.8306\n",
            "Time:  0.1320 Epoch: 285 Iter:  600/3510 LR: 0.0000016267 Loss content:  0.0138 Loss fft:  0.8234\n",
            "Time:  0.1304 Epoch: 285 Iter:  700/3510 LR: 0.0000016267 Loss content:  0.0139 Loss fft:  0.8181\n",
            "Time:  0.1309 Epoch: 285 Iter:  800/3510 LR: 0.0000016267 Loss content:  0.0143 Loss fft:  0.8538\n",
            "Time:  0.1336 Epoch: 285 Iter:  900/3510 LR: 0.0000016267 Loss content:  0.0141 Loss fft:  0.8440\n",
            "Time:  0.1309 Epoch: 285 Iter: 1000/3510 LR: 0.0000016267 Loss content:  0.0141 Loss fft:  0.8379\n",
            "Time:  0.1338 Epoch: 285 Iter: 1100/3510 LR: 0.0000016267 Loss content:  0.0145 Loss fft:  0.8534\n",
            "Time:  0.1314 Epoch: 285 Iter: 1200/3510 LR: 0.0000016267 Loss content:  0.0143 Loss fft:  0.8503\n",
            "Time:  0.1302 Epoch: 285 Iter: 1300/3510 LR: 0.0000016267 Loss content:  0.0145 Loss fft:  0.8349\n",
            "Time:  0.1318 Epoch: 285 Iter: 1400/3510 LR: 0.0000016267 Loss content:  0.0141 Loss fft:  0.8322\n",
            "Time:  0.1322 Epoch: 285 Iter: 1500/3510 LR: 0.0000016267 Loss content:  0.0137 Loss fft:  0.8157\n",
            "Time:  0.1338 Epoch: 285 Iter: 1600/3510 LR: 0.0000016267 Loss content:  0.0142 Loss fft:  0.8263\n",
            "Time:  0.1316 Epoch: 285 Iter: 1700/3510 LR: 0.0000016267 Loss content:  0.0136 Loss fft:  0.8200\n",
            "Time:  0.1373 Epoch: 285 Iter: 1800/3510 LR: 0.0000016267 Loss content:  0.0139 Loss fft:  0.8204\n",
            "Time:  0.1320 Epoch: 285 Iter: 1900/3510 LR: 0.0000016267 Loss content:  0.0141 Loss fft:  0.8289\n",
            "Time:  0.1338 Epoch: 285 Iter: 2000/3510 LR: 0.0000016267 Loss content:  0.0141 Loss fft:  0.8430\n",
            "Time:  0.1338 Epoch: 285 Iter: 2100/3510 LR: 0.0000016267 Loss content:  0.0141 Loss fft:  0.8287\n",
            "Time:  0.1292 Epoch: 285 Iter: 2200/3510 LR: 0.0000016267 Loss content:  0.0136 Loss fft:  0.8275\n",
            "Time:  0.1301 Epoch: 285 Iter: 2300/3510 LR: 0.0000016267 Loss content:  0.0145 Loss fft:  0.8570\n",
            "Time:  0.1328 Epoch: 285 Iter: 2400/3510 LR: 0.0000016267 Loss content:  0.0142 Loss fft:  0.8416\n",
            "Time:  0.1299 Epoch: 285 Iter: 2500/3510 LR: 0.0000016267 Loss content:  0.0140 Loss fft:  0.8328\n",
            "Time:  0.1289 Epoch: 285 Iter: 2600/3510 LR: 0.0000016267 Loss content:  0.0140 Loss fft:  0.8313\n",
            "Time:  0.1294 Epoch: 285 Iter: 2700/3510 LR: 0.0000016267 Loss content:  0.0141 Loss fft:  0.8380\n",
            "Time:  0.1288 Epoch: 285 Iter: 2800/3510 LR: 0.0000016267 Loss content:  0.0143 Loss fft:  0.8261\n",
            "Time:  0.1322 Epoch: 285 Iter: 2900/3510 LR: 0.0000016267 Loss content:  0.0140 Loss fft:  0.8427\n",
            "Time:  0.1294 Epoch: 285 Iter: 3000/3510 LR: 0.0000016267 Loss content:  0.0141 Loss fft:  0.8243\n",
            "Time:  0.1285 Epoch: 285 Iter: 3100/3510 LR: 0.0000016267 Loss content:  0.0139 Loss fft:  0.8093\n",
            "Time:  0.1303 Epoch: 285 Iter: 3200/3510 LR: 0.0000016267 Loss content:  0.0137 Loss fft:  0.8313\n",
            "Time:  0.1348 Epoch: 285 Iter: 3300/3510 LR: 0.0000016267 Loss content:  0.0144 Loss fft:  0.8319\n",
            "Time:  0.1341 Epoch: 285 Iter: 3400/3510 LR: 0.0000016267 Loss content:  0.0141 Loss fft:  0.8336\n",
            "Time:  0.1294 Epoch: 285 Iter: 3500/3510 LR: 0.0000016267 Loss content:  0.0136 Loss fft:  0.8195\n",
            "EPOCH: 285\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0140 Epoch FFT Loss:  0.8335\n",
            "Time:  0.1416 Epoch: 286 Iter:  100/3510 LR: 0.0000015466 Loss content:  0.0141 Loss fft:  0.8538\n",
            "Time:  0.1299 Epoch: 286 Iter:  200/3510 LR: 0.0000015466 Loss content:  0.0139 Loss fft:  0.8173\n",
            "Time:  0.1316 Epoch: 286 Iter:  300/3510 LR: 0.0000015466 Loss content:  0.0138 Loss fft:  0.8183\n",
            "Time:  0.1304 Epoch: 286 Iter:  400/3510 LR: 0.0000015466 Loss content:  0.0137 Loss fft:  0.8208\n",
            "Time:  0.1337 Epoch: 286 Iter:  500/3510 LR: 0.0000015466 Loss content:  0.0142 Loss fft:  0.8385\n",
            "Time:  0.1356 Epoch: 286 Iter:  600/3510 LR: 0.0000015466 Loss content:  0.0141 Loss fft:  0.8384\n",
            "Time:  0.1313 Epoch: 286 Iter:  700/3510 LR: 0.0000015466 Loss content:  0.0142 Loss fft:  0.8405\n",
            "Time:  0.1325 Epoch: 286 Iter:  800/3510 LR: 0.0000015466 Loss content:  0.0136 Loss fft:  0.8348\n",
            "Time:  0.1317 Epoch: 286 Iter:  900/3510 LR: 0.0000015466 Loss content:  0.0145 Loss fft:  0.8203\n",
            "Time:  0.1337 Epoch: 286 Iter: 1000/3510 LR: 0.0000015466 Loss content:  0.0144 Loss fft:  0.8509\n",
            "Time:  0.1320 Epoch: 286 Iter: 1100/3510 LR: 0.0000015466 Loss content:  0.0143 Loss fft:  0.8408\n",
            "Time:  0.1314 Epoch: 286 Iter: 1200/3510 LR: 0.0000015466 Loss content:  0.0143 Loss fft:  0.8361\n",
            "Time:  0.1310 Epoch: 286 Iter: 1300/3510 LR: 0.0000015466 Loss content:  0.0147 Loss fft:  0.8379\n",
            "Time:  0.1306 Epoch: 286 Iter: 1400/3510 LR: 0.0000015466 Loss content:  0.0140 Loss fft:  0.8343\n",
            "Time:  0.1300 Epoch: 286 Iter: 1500/3510 LR: 0.0000015466 Loss content:  0.0140 Loss fft:  0.8378\n",
            "Time:  0.1334 Epoch: 286 Iter: 1600/3510 LR: 0.0000015466 Loss content:  0.0141 Loss fft:  0.8364\n",
            "Time:  0.1297 Epoch: 286 Iter: 1700/3510 LR: 0.0000015466 Loss content:  0.0144 Loss fft:  0.8417\n",
            "Time:  0.1288 Epoch: 286 Iter: 1800/3510 LR: 0.0000015466 Loss content:  0.0142 Loss fft:  0.8227\n",
            "Time:  0.1336 Epoch: 286 Iter: 1900/3510 LR: 0.0000015466 Loss content:  0.0141 Loss fft:  0.8196\n",
            "Time:  0.1316 Epoch: 286 Iter: 2000/3510 LR: 0.0000015466 Loss content:  0.0140 Loss fft:  0.8365\n",
            "Time:  0.1334 Epoch: 286 Iter: 2100/3510 LR: 0.0000015466 Loss content:  0.0139 Loss fft:  0.8337\n",
            "Time:  0.1307 Epoch: 286 Iter: 2200/3510 LR: 0.0000015466 Loss content:  0.0139 Loss fft:  0.8196\n",
            "Time:  0.1310 Epoch: 286 Iter: 2300/3510 LR: 0.0000015466 Loss content:  0.0143 Loss fft:  0.8314\n",
            "Time:  0.1312 Epoch: 286 Iter: 2400/3510 LR: 0.0000015466 Loss content:  0.0146 Loss fft:  0.8565\n",
            "Time:  0.1300 Epoch: 286 Iter: 2500/3510 LR: 0.0000015466 Loss content:  0.0134 Loss fft:  0.8263\n",
            "Time:  0.1297 Epoch: 286 Iter: 2600/3510 LR: 0.0000015466 Loss content:  0.0140 Loss fft:  0.8204\n",
            "Time:  0.1322 Epoch: 286 Iter: 2700/3510 LR: 0.0000015466 Loss content:  0.0141 Loss fft:  0.8537\n",
            "Time:  0.1297 Epoch: 286 Iter: 2800/3510 LR: 0.0000015466 Loss content:  0.0136 Loss fft:  0.8355\n",
            "Time:  0.1350 Epoch: 286 Iter: 2900/3510 LR: 0.0000015466 Loss content:  0.0136 Loss fft:  0.8200\n",
            "Time:  0.1292 Epoch: 286 Iter: 3000/3510 LR: 0.0000015466 Loss content:  0.0141 Loss fft:  0.8349\n",
            "Time:  0.1321 Epoch: 286 Iter: 3100/3510 LR: 0.0000015466 Loss content:  0.0136 Loss fft:  0.8046\n",
            "Time:  0.1323 Epoch: 286 Iter: 3200/3510 LR: 0.0000015466 Loss content:  0.0142 Loss fft:  0.8372\n",
            "Time:  0.1284 Epoch: 286 Iter: 3300/3510 LR: 0.0000015466 Loss content:  0.0135 Loss fft:  0.8223\n",
            "Time:  0.1282 Epoch: 286 Iter: 3400/3510 LR: 0.0000015466 Loss content:  0.0140 Loss fft:  0.8048\n",
            "Time:  0.1310 Epoch: 286 Iter: 3500/3510 LR: 0.0000015466 Loss content:  0.0141 Loss fft:  0.8531\n",
            "EPOCH: 286\n",
            "Elapsed time: 4.63 Epoch Pixel Loss:  0.0140 Epoch FFT Loss:  0.8323\n",
            "Time:  0.1434 Epoch: 287 Iter:  100/3510 LR: 0.0000014721 Loss content:  0.0140 Loss fft:  0.8264\n",
            "Time:  0.1360 Epoch: 287 Iter:  200/3510 LR: 0.0000014721 Loss content:  0.0141 Loss fft:  0.8619\n",
            "Time:  0.1309 Epoch: 287 Iter:  300/3510 LR: 0.0000014721 Loss content:  0.0141 Loss fft:  0.8297\n",
            "Time:  0.1306 Epoch: 287 Iter:  400/3510 LR: 0.0000014721 Loss content:  0.0142 Loss fft:  0.8395\n",
            "Time:  0.1321 Epoch: 287 Iter:  500/3510 LR: 0.0000014721 Loss content:  0.0144 Loss fft:  0.8324\n",
            "Time:  0.1332 Epoch: 287 Iter:  600/3510 LR: 0.0000014721 Loss content:  0.0136 Loss fft:  0.8284\n",
            "Time:  0.1303 Epoch: 287 Iter:  700/3510 LR: 0.0000014721 Loss content:  0.0138 Loss fft:  0.8230\n",
            "Time:  0.1329 Epoch: 287 Iter:  800/3510 LR: 0.0000014721 Loss content:  0.0136 Loss fft:  0.8059\n",
            "Time:  0.1287 Epoch: 287 Iter:  900/3510 LR: 0.0000014721 Loss content:  0.0140 Loss fft:  0.8363\n",
            "Time:  0.1311 Epoch: 287 Iter: 1000/3510 LR: 0.0000014721 Loss content:  0.0137 Loss fft:  0.8336\n",
            "Time:  0.1311 Epoch: 287 Iter: 1100/3510 LR: 0.0000014721 Loss content:  0.0136 Loss fft:  0.8052\n",
            "Time:  0.1287 Epoch: 287 Iter: 1200/3510 LR: 0.0000014721 Loss content:  0.0139 Loss fft:  0.8136\n",
            "Time:  0.1281 Epoch: 287 Iter: 1300/3510 LR: 0.0000014721 Loss content:  0.0138 Loss fft:  0.8164\n",
            "Time:  0.1314 Epoch: 287 Iter: 1400/3510 LR: 0.0000014721 Loss content:  0.0146 Loss fft:  0.8445\n",
            "Time:  0.1324 Epoch: 287 Iter: 1500/3510 LR: 0.0000014721 Loss content:  0.0137 Loss fft:  0.8114\n",
            "Time:  0.1325 Epoch: 287 Iter: 1600/3510 LR: 0.0000014721 Loss content:  0.0140 Loss fft:  0.8210\n",
            "Time:  0.1358 Epoch: 287 Iter: 1700/3510 LR: 0.0000014721 Loss content:  0.0142 Loss fft:  0.8384\n",
            "Time:  0.1326 Epoch: 287 Iter: 1800/3510 LR: 0.0000014721 Loss content:  0.0137 Loss fft:  0.8276\n",
            "Time:  0.1307 Epoch: 287 Iter: 1900/3510 LR: 0.0000014721 Loss content:  0.0140 Loss fft:  0.8332\n",
            "Time:  0.1298 Epoch: 287 Iter: 2000/3510 LR: 0.0000014721 Loss content:  0.0138 Loss fft:  0.8193\n",
            "Time:  0.1323 Epoch: 287 Iter: 2100/3510 LR: 0.0000014721 Loss content:  0.0144 Loss fft:  0.8524\n",
            "Time:  0.1288 Epoch: 287 Iter: 2200/3510 LR: 0.0000014721 Loss content:  0.0145 Loss fft:  0.8377\n",
            "Time:  0.1320 Epoch: 287 Iter: 2300/3510 LR: 0.0000014721 Loss content:  0.0138 Loss fft:  0.8398\n",
            "Time:  0.1319 Epoch: 287 Iter: 2400/3510 LR: 0.0000014721 Loss content:  0.0142 Loss fft:  0.8352\n",
            "Time:  0.1298 Epoch: 287 Iter: 2500/3510 LR: 0.0000014721 Loss content:  0.0142 Loss fft:  0.8313\n",
            "Time:  0.1299 Epoch: 287 Iter: 2600/3510 LR: 0.0000014721 Loss content:  0.0137 Loss fft:  0.8226\n",
            "Time:  0.1318 Epoch: 287 Iter: 2700/3510 LR: 0.0000014721 Loss content:  0.0142 Loss fft:  0.8407\n",
            "Time:  0.1307 Epoch: 287 Iter: 2800/3510 LR: 0.0000014721 Loss content:  0.0140 Loss fft:  0.8369\n",
            "Time:  0.1305 Epoch: 287 Iter: 2900/3510 LR: 0.0000014721 Loss content:  0.0143 Loss fft:  0.8306\n",
            "Time:  0.1287 Epoch: 287 Iter: 3000/3510 LR: 0.0000014721 Loss content:  0.0141 Loss fft:  0.8537\n",
            "Time:  0.1328 Epoch: 287 Iter: 3100/3510 LR: 0.0000014721 Loss content:  0.0139 Loss fft:  0.8196\n",
            "Time:  0.1315 Epoch: 287 Iter: 3200/3510 LR: 0.0000014721 Loss content:  0.0142 Loss fft:  0.8404\n",
            "Time:  0.1304 Epoch: 287 Iter: 3300/3510 LR: 0.0000014721 Loss content:  0.0145 Loss fft:  0.8535\n",
            "Time:  0.1306 Epoch: 287 Iter: 3400/3510 LR: 0.0000014721 Loss content:  0.0137 Loss fft:  0.8197\n",
            "Time:  0.1309 Epoch: 287 Iter: 3500/3510 LR: 0.0000014721 Loss content:  0.0142 Loss fft:  0.8200\n",
            "EPOCH: 287\n",
            "Elapsed time: 4.62 Epoch Pixel Loss:  0.0140 Epoch FFT Loss:  0.8309\n",
            "Time:  0.1439 Epoch: 288 Iter:  100/3510 LR: 0.0000014030 Loss content:  0.0139 Loss fft:  0.8191\n",
            "Time:  0.1317 Epoch: 288 Iter:  200/3510 LR: 0.0000014030 Loss content:  0.0141 Loss fft:  0.8523\n",
            "Time:  0.1308 Epoch: 288 Iter:  300/3510 LR: 0.0000014030 Loss content:  0.0135 Loss fft:  0.8340\n",
            "Time:  0.1333 Epoch: 288 Iter:  400/3510 LR: 0.0000014030 Loss content:  0.0139 Loss fft:  0.8080\n",
            "Time:  0.1377 Epoch: 288 Iter:  500/3510 LR: 0.0000014030 Loss content:  0.0138 Loss fft:  0.8181\n",
            "Time:  0.1299 Epoch: 288 Iter:  600/3510 LR: 0.0000014030 Loss content:  0.0148 Loss fft:  0.8466\n",
            "Time:  0.1301 Epoch: 288 Iter:  700/3510 LR: 0.0000014030 Loss content:  0.0144 Loss fft:  0.8272\n",
            "Time:  0.1340 Epoch: 288 Iter:  800/3510 LR: 0.0000014030 Loss content:  0.0142 Loss fft:  0.8186\n",
            "Time:  0.1328 Epoch: 288 Iter:  900/3510 LR: 0.0000014030 Loss content:  0.0142 Loss fft:  0.8473\n",
            "Time:  0.1307 Epoch: 288 Iter: 1000/3510 LR: 0.0000014030 Loss content:  0.0141 Loss fft:  0.8366\n",
            "Time:  0.1299 Epoch: 288 Iter: 1100/3510 LR: 0.0000014030 Loss content:  0.0137 Loss fft:  0.8191\n",
            "Time:  0.1294 Epoch: 288 Iter: 1200/3510 LR: 0.0000014030 Loss content:  0.0141 Loss fft:  0.8384\n",
            "Time:  0.1312 Epoch: 288 Iter: 1300/3510 LR: 0.0000014030 Loss content:  0.0135 Loss fft:  0.8027\n",
            "Time:  0.1308 Epoch: 288 Iter: 1400/3510 LR: 0.0000014030 Loss content:  0.0141 Loss fft:  0.8534\n",
            "Time:  0.1344 Epoch: 288 Iter: 1500/3510 LR: 0.0000014030 Loss content:  0.0139 Loss fft:  0.8521\n",
            "Time:  0.1284 Epoch: 288 Iter: 1600/3510 LR: 0.0000014030 Loss content:  0.0144 Loss fft:  0.8248\n",
            "Time:  0.1292 Epoch: 288 Iter: 1700/3510 LR: 0.0000014030 Loss content:  0.0141 Loss fft:  0.8331\n",
            "Time:  0.1304 Epoch: 288 Iter: 1800/3510 LR: 0.0000014030 Loss content:  0.0142 Loss fft:  0.8380\n",
            "Time:  0.1315 Epoch: 288 Iter: 1900/3510 LR: 0.0000014030 Loss content:  0.0143 Loss fft:  0.8401\n",
            "Time:  0.1295 Epoch: 288 Iter: 2000/3510 LR: 0.0000014030 Loss content:  0.0142 Loss fft:  0.8389\n",
            "Time:  0.1299 Epoch: 288 Iter: 2100/3510 LR: 0.0000014030 Loss content:  0.0141 Loss fft:  0.8349\n",
            "Time:  0.1315 Epoch: 288 Iter: 2200/3510 LR: 0.0000014030 Loss content:  0.0139 Loss fft:  0.8302\n",
            "Time:  0.1329 Epoch: 288 Iter: 2300/3510 LR: 0.0000014030 Loss content:  0.0139 Loss fft:  0.8279\n",
            "Time:  0.1307 Epoch: 288 Iter: 2400/3510 LR: 0.0000014030 Loss content:  0.0140 Loss fft:  0.8282\n",
            "Time:  0.1323 Epoch: 288 Iter: 2500/3510 LR: 0.0000014030 Loss content:  0.0141 Loss fft:  0.8483\n",
            "Time:  0.1332 Epoch: 288 Iter: 2600/3510 LR: 0.0000014030 Loss content:  0.0142 Loss fft:  0.8372\n",
            "Time:  0.1355 Epoch: 288 Iter: 2700/3510 LR: 0.0000014030 Loss content:  0.0141 Loss fft:  0.8283\n",
            "Time:  0.1300 Epoch: 288 Iter: 2800/3510 LR: 0.0000014030 Loss content:  0.0144 Loss fft:  0.8353\n",
            "Time:  0.1329 Epoch: 288 Iter: 2900/3510 LR: 0.0000014030 Loss content:  0.0137 Loss fft:  0.8261\n",
            "Time:  0.1339 Epoch: 288 Iter: 3000/3510 LR: 0.0000014030 Loss content:  0.0135 Loss fft:  0.8146\n",
            "Time:  0.1341 Epoch: 288 Iter: 3100/3510 LR: 0.0000014030 Loss content:  0.0148 Loss fft:  0.8666\n",
            "Time:  0.1304 Epoch: 288 Iter: 3200/3510 LR: 0.0000014030 Loss content:  0.0138 Loss fft:  0.8335\n",
            "Time:  0.1307 Epoch: 288 Iter: 3300/3510 LR: 0.0000014030 Loss content:  0.0136 Loss fft:  0.8078\n",
            "Time:  0.1343 Epoch: 288 Iter: 3400/3510 LR: 0.0000014030 Loss content:  0.0142 Loss fft:  0.8338\n",
            "Time:  0.1340 Epoch: 288 Iter: 3500/3510 LR: 0.0000014030 Loss content:  0.0138 Loss fft:  0.8147\n",
            "EPOCH: 288\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0140 Epoch FFT Loss:  0.8319\n",
            "Time:  0.1409 Epoch: 289 Iter:  100/3510 LR: 0.0000013394 Loss content:  0.0139 Loss fft:  0.8224\n",
            "Time:  0.1308 Epoch: 289 Iter:  200/3510 LR: 0.0000013394 Loss content:  0.0145 Loss fft:  0.8475\n",
            "Time:  0.1314 Epoch: 289 Iter:  300/3510 LR: 0.0000013394 Loss content:  0.0139 Loss fft:  0.8179\n",
            "Time:  0.1298 Epoch: 289 Iter:  400/3510 LR: 0.0000013394 Loss content:  0.0140 Loss fft:  0.8500\n",
            "Time:  0.1304 Epoch: 289 Iter:  500/3510 LR: 0.0000013394 Loss content:  0.0139 Loss fft:  0.8195\n",
            "Time:  0.1332 Epoch: 289 Iter:  600/3510 LR: 0.0000013394 Loss content:  0.0138 Loss fft:  0.8379\n",
            "Time:  0.1296 Epoch: 289 Iter:  700/3510 LR: 0.0000013394 Loss content:  0.0141 Loss fft:  0.8378\n",
            "Time:  0.1327 Epoch: 289 Iter:  800/3510 LR: 0.0000013394 Loss content:  0.0137 Loss fft:  0.8068\n",
            "Time:  0.1309 Epoch: 289 Iter:  900/3510 LR: 0.0000013394 Loss content:  0.0142 Loss fft:  0.8379\n",
            "Time:  0.1299 Epoch: 289 Iter: 1000/3510 LR: 0.0000013394 Loss content:  0.0142 Loss fft:  0.8295\n",
            "Time:  0.1318 Epoch: 289 Iter: 1100/3510 LR: 0.0000013394 Loss content:  0.0134 Loss fft:  0.8150\n",
            "Time:  0.1298 Epoch: 289 Iter: 1200/3510 LR: 0.0000013394 Loss content:  0.0140 Loss fft:  0.8403\n",
            "Time:  0.1323 Epoch: 289 Iter: 1300/3510 LR: 0.0000013394 Loss content:  0.0139 Loss fft:  0.8335\n",
            "Time:  0.1296 Epoch: 289 Iter: 1400/3510 LR: 0.0000013394 Loss content:  0.0142 Loss fft:  0.8321\n",
            "Time:  0.1334 Epoch: 289 Iter: 1500/3510 LR: 0.0000013394 Loss content:  0.0154 Loss fft:  0.8328\n",
            "Time:  0.1290 Epoch: 289 Iter: 1600/3510 LR: 0.0000013394 Loss content:  0.0140 Loss fft:  0.8382\n",
            "Time:  0.1338 Epoch: 289 Iter: 1700/3510 LR: 0.0000013394 Loss content:  0.0147 Loss fft:  0.8411\n",
            "Time:  0.1319 Epoch: 289 Iter: 1800/3510 LR: 0.0000013394 Loss content:  0.0135 Loss fft:  0.8174\n",
            "Time:  0.1309 Epoch: 289 Iter: 1900/3510 LR: 0.0000013394 Loss content:  0.0140 Loss fft:  0.8291\n",
            "Time:  0.1307 Epoch: 289 Iter: 2000/3510 LR: 0.0000013394 Loss content:  0.0140 Loss fft:  0.8451\n",
            "Time:  0.1277 Epoch: 289 Iter: 2100/3510 LR: 0.0000013394 Loss content:  0.0139 Loss fft:  0.8194\n",
            "Time:  0.1300 Epoch: 289 Iter: 2200/3510 LR: 0.0000013394 Loss content:  0.0141 Loss fft:  0.8282\n",
            "Time:  0.1292 Epoch: 289 Iter: 2300/3510 LR: 0.0000013394 Loss content:  0.0140 Loss fft:  0.8301\n",
            "Time:  0.1282 Epoch: 289 Iter: 2400/3510 LR: 0.0000013394 Loss content:  0.0135 Loss fft:  0.8211\n",
            "Time:  0.1288 Epoch: 289 Iter: 2500/3510 LR: 0.0000013394 Loss content:  0.0139 Loss fft:  0.8365\n",
            "Time:  0.1295 Epoch: 289 Iter: 2600/3510 LR: 0.0000013394 Loss content:  0.0138 Loss fft:  0.8284\n",
            "Time:  0.1289 Epoch: 289 Iter: 2700/3510 LR: 0.0000013394 Loss content:  0.0142 Loss fft:  0.8484\n",
            "Time:  0.1300 Epoch: 289 Iter: 2800/3510 LR: 0.0000013394 Loss content:  0.0137 Loss fft:  0.8179\n",
            "Time:  0.1304 Epoch: 289 Iter: 2900/3510 LR: 0.0000013394 Loss content:  0.0140 Loss fft:  0.8201\n",
            "Time:  0.1304 Epoch: 289 Iter: 3000/3510 LR: 0.0000013394 Loss content:  0.0142 Loss fft:  0.8515\n",
            "Time:  0.1324 Epoch: 289 Iter: 3100/3510 LR: 0.0000013394 Loss content:  0.0148 Loss fft:  0.8522\n",
            "Time:  0.1271 Epoch: 289 Iter: 3200/3510 LR: 0.0000013394 Loss content:  0.0138 Loss fft:  0.8244\n",
            "Time:  0.1300 Epoch: 289 Iter: 3300/3510 LR: 0.0000013394 Loss content:  0.0142 Loss fft:  0.8420\n",
            "Time:  0.1296 Epoch: 289 Iter: 3400/3510 LR: 0.0000013394 Loss content:  0.0142 Loss fft:  0.8409\n",
            "Time:  0.1303 Epoch: 289 Iter: 3500/3510 LR: 0.0000013394 Loss content:  0.0144 Loss fft:  0.8461\n",
            "EPOCH: 289\n",
            "Elapsed time: 4.59 Epoch Pixel Loss:  0.0140 Epoch FFT Loss:  0.8323\n",
            "Time:  0.1405 Epoch: 290 Iter:  100/3510 LR: 0.0000012813 Loss content:  0.0140 Loss fft:  0.8504\n",
            "Time:  0.1315 Epoch: 290 Iter:  200/3510 LR: 0.0000012813 Loss content:  0.0144 Loss fft:  0.8402\n",
            "Time:  0.1330 Epoch: 290 Iter:  300/3510 LR: 0.0000012813 Loss content:  0.0137 Loss fft:  0.8220\n",
            "Time:  0.1322 Epoch: 290 Iter:  400/3510 LR: 0.0000012813 Loss content:  0.0143 Loss fft:  0.8456\n",
            "Time:  0.1364 Epoch: 290 Iter:  500/3510 LR: 0.0000012813 Loss content:  0.0139 Loss fft:  0.8296\n",
            "Time:  0.1322 Epoch: 290 Iter:  600/3510 LR: 0.0000012813 Loss content:  0.0140 Loss fft:  0.8246\n",
            "Time:  0.1321 Epoch: 290 Iter:  700/3510 LR: 0.0000012813 Loss content:  0.0142 Loss fft:  0.8276\n",
            "Time:  0.1303 Epoch: 290 Iter:  800/3510 LR: 0.0000012813 Loss content:  0.0135 Loss fft:  0.8220\n",
            "Time:  0.1303 Epoch: 290 Iter:  900/3510 LR: 0.0000012813 Loss content:  0.0142 Loss fft:  0.8426\n",
            "Time:  0.1307 Epoch: 290 Iter: 1000/3510 LR: 0.0000012813 Loss content:  0.0137 Loss fft:  0.8282\n",
            "Time:  0.1323 Epoch: 290 Iter: 1100/3510 LR: 0.0000012813 Loss content:  0.0140 Loss fft:  0.8346\n",
            "Time:  0.1282 Epoch: 290 Iter: 1200/3510 LR: 0.0000012813 Loss content:  0.0143 Loss fft:  0.8394\n",
            "Time:  0.1304 Epoch: 290 Iter: 1300/3510 LR: 0.0000012813 Loss content:  0.0139 Loss fft:  0.8405\n",
            "Time:  0.1308 Epoch: 290 Iter: 1400/3510 LR: 0.0000012813 Loss content:  0.0140 Loss fft:  0.8336\n",
            "Time:  0.1320 Epoch: 290 Iter: 1500/3510 LR: 0.0000012813 Loss content:  0.0141 Loss fft:  0.8174\n",
            "Time:  0.1319 Epoch: 290 Iter: 1600/3510 LR: 0.0000012813 Loss content:  0.0143 Loss fft:  0.8319\n",
            "Time:  0.1321 Epoch: 290 Iter: 1700/3510 LR: 0.0000012813 Loss content:  0.0139 Loss fft:  0.8228\n",
            "Time:  0.1311 Epoch: 290 Iter: 1800/3510 LR: 0.0000012813 Loss content:  0.0135 Loss fft:  0.8099\n",
            "Time:  0.1302 Epoch: 290 Iter: 1900/3510 LR: 0.0000012813 Loss content:  0.0137 Loss fft:  0.8222\n",
            "Time:  0.1309 Epoch: 290 Iter: 2000/3510 LR: 0.0000012813 Loss content:  0.0141 Loss fft:  0.8535\n",
            "Time:  0.1277 Epoch: 290 Iter: 2100/3510 LR: 0.0000012813 Loss content:  0.0139 Loss fft:  0.8120\n",
            "Time:  0.1319 Epoch: 290 Iter: 2200/3510 LR: 0.0000012813 Loss content:  0.0141 Loss fft:  0.8525\n",
            "Time:  0.1299 Epoch: 290 Iter: 2300/3510 LR: 0.0000012813 Loss content:  0.0137 Loss fft:  0.8175\n",
            "Time:  0.1322 Epoch: 290 Iter: 2400/3510 LR: 0.0000012813 Loss content:  0.0142 Loss fft:  0.8310\n",
            "Time:  0.1302 Epoch: 290 Iter: 2500/3510 LR: 0.0000012813 Loss content:  0.0135 Loss fft:  0.8129\n",
            "Time:  0.1303 Epoch: 290 Iter: 2600/3510 LR: 0.0000012813 Loss content:  0.0141 Loss fft:  0.8248\n",
            "Time:  0.1316 Epoch: 290 Iter: 2700/3510 LR: 0.0000012813 Loss content:  0.0137 Loss fft:  0.8209\n",
            "Time:  0.1274 Epoch: 290 Iter: 2800/3510 LR: 0.0000012813 Loss content:  0.0138 Loss fft:  0.8327\n",
            "Time:  0.1319 Epoch: 290 Iter: 2900/3510 LR: 0.0000012813 Loss content:  0.0140 Loss fft:  0.8280\n",
            "Time:  0.1293 Epoch: 290 Iter: 3000/3510 LR: 0.0000012813 Loss content:  0.0136 Loss fft:  0.8314\n",
            "Time:  0.1313 Epoch: 290 Iter: 3100/3510 LR: 0.0000012813 Loss content:  0.0140 Loss fft:  0.8141\n",
            "Time:  0.1282 Epoch: 290 Iter: 3200/3510 LR: 0.0000012813 Loss content:  0.0138 Loss fft:  0.8130\n",
            "Time:  0.1326 Epoch: 290 Iter: 3300/3510 LR: 0.0000012813 Loss content:  0.0144 Loss fft:  0.8513\n",
            "Time:  0.1307 Epoch: 290 Iter: 3400/3510 LR: 0.0000012813 Loss content:  0.0138 Loss fft:  0.8202\n",
            "Time:  0.1311 Epoch: 290 Iter: 3500/3510 LR: 0.0000012813 Loss content:  0.0139 Loss fft:  0.8286\n",
            "EPOCH: 290\n",
            "Elapsed time: 4.62 Epoch Pixel Loss:  0.0139 Epoch FFT Loss:  0.8295\n",
            "Start Evaluation\n",
            "499 \n",
            "\n",
            "290 epoch \n",
            " Average PSNR 41.02 dB\n",
            "Time:  0.1419 Epoch: 291 Iter:  100/3510 LR: 0.0000012287 Loss content:  0.0139 Loss fft:  0.8230\n",
            "Time:  0.1287 Epoch: 291 Iter:  200/3510 LR: 0.0000012287 Loss content:  0.0147 Loss fft:  0.8570\n",
            "Time:  0.1287 Epoch: 291 Iter:  300/3510 LR: 0.0000012287 Loss content:  0.0142 Loss fft:  0.8365\n",
            "Time:  0.1294 Epoch: 291 Iter:  400/3510 LR: 0.0000012287 Loss content:  0.0137 Loss fft:  0.8235\n",
            "Time:  0.1310 Epoch: 291 Iter:  500/3510 LR: 0.0000012287 Loss content:  0.0136 Loss fft:  0.8205\n",
            "Time:  0.1332 Epoch: 291 Iter:  600/3510 LR: 0.0000012287 Loss content:  0.0142 Loss fft:  0.8399\n",
            "Time:  0.1305 Epoch: 291 Iter:  700/3510 LR: 0.0000012287 Loss content:  0.0138 Loss fft:  0.8255\n",
            "Time:  0.1315 Epoch: 291 Iter:  800/3510 LR: 0.0000012287 Loss content:  0.0136 Loss fft:  0.8299\n",
            "Time:  0.1319 Epoch: 291 Iter:  900/3510 LR: 0.0000012287 Loss content:  0.0140 Loss fft:  0.8269\n",
            "Time:  0.1309 Epoch: 291 Iter: 1000/3510 LR: 0.0000012287 Loss content:  0.0139 Loss fft:  0.8302\n",
            "Time:  0.1291 Epoch: 291 Iter: 1100/3510 LR: 0.0000012287 Loss content:  0.0140 Loss fft:  0.8232\n",
            "Time:  0.1292 Epoch: 291 Iter: 1200/3510 LR: 0.0000012287 Loss content:  0.0137 Loss fft:  0.8188\n",
            "Time:  0.1281 Epoch: 291 Iter: 1300/3510 LR: 0.0000012287 Loss content:  0.0139 Loss fft:  0.8326\n",
            "Time:  0.1289 Epoch: 291 Iter: 1400/3510 LR: 0.0000012287 Loss content:  0.0140 Loss fft:  0.8300\n",
            "Time:  0.1274 Epoch: 291 Iter: 1500/3510 LR: 0.0000012287 Loss content:  0.0131 Loss fft:  0.8130\n",
            "Time:  0.1273 Epoch: 291 Iter: 1600/3510 LR: 0.0000012287 Loss content:  0.0143 Loss fft:  0.8434\n",
            "Time:  0.1327 Epoch: 291 Iter: 1700/3510 LR: 0.0000012287 Loss content:  0.0141 Loss fft:  0.8337\n",
            "Time:  0.1307 Epoch: 291 Iter: 1800/3510 LR: 0.0000012287 Loss content:  0.0139 Loss fft:  0.8397\n",
            "Time:  0.1293 Epoch: 291 Iter: 1900/3510 LR: 0.0000012287 Loss content:  0.0143 Loss fft:  0.8462\n",
            "Time:  0.1278 Epoch: 291 Iter: 2000/3510 LR: 0.0000012287 Loss content:  0.0140 Loss fft:  0.8389\n",
            "Time:  0.1275 Epoch: 291 Iter: 2100/3510 LR: 0.0000012287 Loss content:  0.0142 Loss fft:  0.8039\n",
            "Time:  0.1319 Epoch: 291 Iter: 2200/3510 LR: 0.0000012287 Loss content:  0.0140 Loss fft:  0.8200\n",
            "Time:  0.1293 Epoch: 291 Iter: 2300/3510 LR: 0.0000012287 Loss content:  0.0142 Loss fft:  0.8242\n",
            "Time:  0.1287 Epoch: 291 Iter: 2400/3510 LR: 0.0000012287 Loss content:  0.0141 Loss fft:  0.8539\n",
            "Time:  0.1295 Epoch: 291 Iter: 2500/3510 LR: 0.0000012287 Loss content:  0.0141 Loss fft:  0.8285\n",
            "Time:  0.1288 Epoch: 291 Iter: 2600/3510 LR: 0.0000012287 Loss content:  0.0137 Loss fft:  0.8119\n",
            "Time:  0.1288 Epoch: 291 Iter: 2700/3510 LR: 0.0000012287 Loss content:  0.0142 Loss fft:  0.8520\n",
            "Time:  0.1278 Epoch: 291 Iter: 2800/3510 LR: 0.0000012287 Loss content:  0.0143 Loss fft:  0.8261\n",
            "Time:  0.1301 Epoch: 291 Iter: 2900/3510 LR: 0.0000012287 Loss content:  0.0140 Loss fft:  0.8355\n",
            "Time:  0.1291 Epoch: 291 Iter: 3000/3510 LR: 0.0000012287 Loss content:  0.0137 Loss fft:  0.8053\n",
            "Time:  0.1311 Epoch: 291 Iter: 3100/3510 LR: 0.0000012287 Loss content:  0.0134 Loss fft:  0.8233\n",
            "Time:  0.1294 Epoch: 291 Iter: 3200/3510 LR: 0.0000012287 Loss content:  0.0141 Loss fft:  0.8443\n",
            "Time:  0.1308 Epoch: 291 Iter: 3300/3510 LR: 0.0000012287 Loss content:  0.0139 Loss fft:  0.8284\n",
            "Time:  0.1304 Epoch: 291 Iter: 3400/3510 LR: 0.0000012287 Loss content:  0.0136 Loss fft:  0.8230\n",
            "Time:  0.1286 Epoch: 291 Iter: 3500/3510 LR: 0.0000012287 Loss content:  0.0141 Loss fft:  0.8325\n",
            "EPOCH: 291\n",
            "Elapsed time: 4.57 Epoch Pixel Loss:  0.0140 Epoch FFT Loss:  0.8298\n",
            "Time:  0.1410 Epoch: 292 Iter:  100/3510 LR: 0.0000011816 Loss content:  0.0135 Loss fft:  0.8204\n",
            "Time:  0.1297 Epoch: 292 Iter:  200/3510 LR: 0.0000011816 Loss content:  0.0136 Loss fft:  0.8143\n",
            "Time:  0.1294 Epoch: 292 Iter:  300/3510 LR: 0.0000011816 Loss content:  0.0137 Loss fft:  0.8171\n",
            "Time:  0.1332 Epoch: 292 Iter:  400/3510 LR: 0.0000011816 Loss content:  0.0140 Loss fft:  0.8277\n",
            "Time:  0.1284 Epoch: 292 Iter:  500/3510 LR: 0.0000011816 Loss content:  0.0139 Loss fft:  0.8424\n",
            "Time:  0.1275 Epoch: 292 Iter:  600/3510 LR: 0.0000011816 Loss content:  0.0141 Loss fft:  0.8455\n",
            "Time:  0.1306 Epoch: 292 Iter:  700/3510 LR: 0.0000011816 Loss content:  0.0141 Loss fft:  0.8279\n",
            "Time:  0.1308 Epoch: 292 Iter:  800/3510 LR: 0.0000011816 Loss content:  0.0141 Loss fft:  0.8251\n",
            "Time:  0.1306 Epoch: 292 Iter:  900/3510 LR: 0.0000011816 Loss content:  0.0144 Loss fft:  0.8252\n",
            "Time:  0.1302 Epoch: 292 Iter: 1000/3510 LR: 0.0000011816 Loss content:  0.0137 Loss fft:  0.8205\n",
            "Time:  0.1294 Epoch: 292 Iter: 1100/3510 LR: 0.0000011816 Loss content:  0.0140 Loss fft:  0.8098\n",
            "Time:  0.1309 Epoch: 292 Iter: 1200/3510 LR: 0.0000011816 Loss content:  0.0141 Loss fft:  0.8451\n",
            "Time:  0.1305 Epoch: 292 Iter: 1300/3510 LR: 0.0000011816 Loss content:  0.0139 Loss fft:  0.8248\n",
            "Time:  0.1298 Epoch: 292 Iter: 1400/3510 LR: 0.0000011816 Loss content:  0.0139 Loss fft:  0.8265\n",
            "Time:  0.1272 Epoch: 292 Iter: 1500/3510 LR: 0.0000011816 Loss content:  0.0141 Loss fft:  0.8347\n",
            "Time:  0.1305 Epoch: 292 Iter: 1600/3510 LR: 0.0000011816 Loss content:  0.0137 Loss fft:  0.8350\n",
            "Time:  0.1311 Epoch: 292 Iter: 1700/3510 LR: 0.0000011816 Loss content:  0.0143 Loss fft:  0.8395\n",
            "Time:  0.1298 Epoch: 292 Iter: 1800/3510 LR: 0.0000011816 Loss content:  0.0142 Loss fft:  0.8339\n",
            "Time:  0.1279 Epoch: 292 Iter: 1900/3510 LR: 0.0000011816 Loss content:  0.0142 Loss fft:  0.8244\n",
            "Time:  0.1300 Epoch: 292 Iter: 2000/3510 LR: 0.0000011816 Loss content:  0.0141 Loss fft:  0.8522\n",
            "Time:  0.1298 Epoch: 292 Iter: 2100/3510 LR: 0.0000011816 Loss content:  0.0140 Loss fft:  0.8288\n",
            "Time:  0.1285 Epoch: 292 Iter: 2200/3510 LR: 0.0000011816 Loss content:  0.0144 Loss fft:  0.8441\n",
            "Time:  0.1273 Epoch: 292 Iter: 2300/3510 LR: 0.0000011816 Loss content:  0.0138 Loss fft:  0.8537\n",
            "Time:  0.1293 Epoch: 292 Iter: 2400/3510 LR: 0.0000011816 Loss content:  0.0143 Loss fft:  0.8370\n",
            "Time:  0.1286 Epoch: 292 Iter: 2500/3510 LR: 0.0000011816 Loss content:  0.0134 Loss fft:  0.8139\n",
            "Time:  0.1296 Epoch: 292 Iter: 2600/3510 LR: 0.0000011816 Loss content:  0.0142 Loss fft:  0.8461\n",
            "Time:  0.1282 Epoch: 292 Iter: 2700/3510 LR: 0.0000011816 Loss content:  0.0143 Loss fft:  0.8526\n",
            "Time:  0.1332 Epoch: 292 Iter: 2800/3510 LR: 0.0000011816 Loss content:  0.0139 Loss fft:  0.8132\n",
            "Time:  0.1281 Epoch: 292 Iter: 2900/3510 LR: 0.0000011816 Loss content:  0.0138 Loss fft:  0.8241\n",
            "Time:  0.1272 Epoch: 292 Iter: 3000/3510 LR: 0.0000011816 Loss content:  0.0134 Loss fft:  0.8246\n",
            "Time:  0.1307 Epoch: 292 Iter: 3100/3510 LR: 0.0000011816 Loss content:  0.0139 Loss fft:  0.8401\n",
            "Time:  0.1268 Epoch: 292 Iter: 3200/3510 LR: 0.0000011816 Loss content:  0.0140 Loss fft:  0.8227\n",
            "Time:  0.1303 Epoch: 292 Iter: 3300/3510 LR: 0.0000011816 Loss content:  0.0142 Loss fft:  0.8254\n",
            "Time:  0.1323 Epoch: 292 Iter: 3400/3510 LR: 0.0000011816 Loss content:  0.0143 Loss fft:  0.8357\n",
            "Time:  0.1303 Epoch: 292 Iter: 3500/3510 LR: 0.0000011816 Loss content:  0.0144 Loss fft:  0.8242\n",
            "EPOCH: 292\n",
            "Elapsed time: 4.57 Epoch Pixel Loss:  0.0140 Epoch FFT Loss:  0.8308\n",
            "Time:  0.1385 Epoch: 293 Iter:  100/3510 LR: 0.0000011400 Loss content:  0.0132 Loss fft:  0.8007\n",
            "Time:  0.1291 Epoch: 293 Iter:  200/3510 LR: 0.0000011400 Loss content:  0.0139 Loss fft:  0.8152\n",
            "Time:  0.1290 Epoch: 293 Iter:  300/3510 LR: 0.0000011400 Loss content:  0.0136 Loss fft:  0.8184\n",
            "Time:  0.1286 Epoch: 293 Iter:  400/3510 LR: 0.0000011400 Loss content:  0.0143 Loss fft:  0.8499\n",
            "Time:  0.1285 Epoch: 293 Iter:  500/3510 LR: 0.0000011400 Loss content:  0.0137 Loss fft:  0.7931\n",
            "Time:  0.1284 Epoch: 293 Iter:  600/3510 LR: 0.0000011400 Loss content:  0.0139 Loss fft:  0.8214\n",
            "Time:  0.1285 Epoch: 293 Iter:  700/3510 LR: 0.0000011400 Loss content:  0.0139 Loss fft:  0.8427\n",
            "Time:  0.1270 Epoch: 293 Iter:  800/3510 LR: 0.0000011400 Loss content:  0.0143 Loss fft:  0.8284\n",
            "Time:  0.1298 Epoch: 293 Iter:  900/3510 LR: 0.0000011400 Loss content:  0.0141 Loss fft:  0.8414\n",
            "Time:  0.1314 Epoch: 293 Iter: 1000/3510 LR: 0.0000011400 Loss content:  0.0135 Loss fft:  0.8172\n",
            "Time:  0.1289 Epoch: 293 Iter: 1100/3510 LR: 0.0000011400 Loss content:  0.0138 Loss fft:  0.8325\n",
            "Time:  0.1270 Epoch: 293 Iter: 1200/3510 LR: 0.0000011400 Loss content:  0.0142 Loss fft:  0.8383\n",
            "Time:  0.1302 Epoch: 293 Iter: 1300/3510 LR: 0.0000011400 Loss content:  0.0139 Loss fft:  0.8269\n",
            "Time:  0.1277 Epoch: 293 Iter: 1400/3510 LR: 0.0000011400 Loss content:  0.0145 Loss fft:  0.8444\n",
            "Time:  0.1288 Epoch: 293 Iter: 1500/3510 LR: 0.0000011400 Loss content:  0.0137 Loss fft:  0.8181\n",
            "Time:  0.1363 Epoch: 293 Iter: 1600/3510 LR: 0.0000011400 Loss content:  0.0139 Loss fft:  0.8433\n",
            "Time:  0.1291 Epoch: 293 Iter: 1700/3510 LR: 0.0000011400 Loss content:  0.0137 Loss fft:  0.8312\n",
            "Time:  0.1319 Epoch: 293 Iter: 1800/3510 LR: 0.0000011400 Loss content:  0.0142 Loss fft:  0.8490\n",
            "Time:  0.1361 Epoch: 293 Iter: 1900/3510 LR: 0.0000011400 Loss content:  0.0137 Loss fft:  0.8194\n",
            "Time:  0.1343 Epoch: 293 Iter: 2000/3510 LR: 0.0000011400 Loss content:  0.0139 Loss fft:  0.8456\n",
            "Time:  0.1339 Epoch: 293 Iter: 2100/3510 LR: 0.0000011400 Loss content:  0.0139 Loss fft:  0.8366\n",
            "Time:  0.1346 Epoch: 293 Iter: 2200/3510 LR: 0.0000011400 Loss content:  0.0138 Loss fft:  0.8238\n",
            "Time:  0.1312 Epoch: 293 Iter: 2300/3510 LR: 0.0000011400 Loss content:  0.0137 Loss fft:  0.8273\n",
            "Time:  0.1328 Epoch: 293 Iter: 2400/3510 LR: 0.0000011400 Loss content:  0.0140 Loss fft:  0.8394\n",
            "Time:  0.1323 Epoch: 293 Iter: 2500/3510 LR: 0.0000011400 Loss content:  0.0140 Loss fft:  0.8293\n",
            "Time:  0.1334 Epoch: 293 Iter: 2600/3510 LR: 0.0000011400 Loss content:  0.0141 Loss fft:  0.8448\n",
            "Time:  0.1356 Epoch: 293 Iter: 2700/3510 LR: 0.0000011400 Loss content:  0.0141 Loss fft:  0.8487\n",
            "Time:  0.1319 Epoch: 293 Iter: 2800/3510 LR: 0.0000011400 Loss content:  0.0139 Loss fft:  0.8254\n",
            "Time:  0.1359 Epoch: 293 Iter: 2900/3510 LR: 0.0000011400 Loss content:  0.0140 Loss fft:  0.8435\n",
            "Time:  0.1340 Epoch: 293 Iter: 3000/3510 LR: 0.0000011400 Loss content:  0.0141 Loss fft:  0.8272\n",
            "Time:  0.1312 Epoch: 293 Iter: 3100/3510 LR: 0.0000011400 Loss content:  0.0141 Loss fft:  0.8303\n",
            "Time:  0.1316 Epoch: 293 Iter: 3200/3510 LR: 0.0000011400 Loss content:  0.0141 Loss fft:  0.8406\n",
            "Time:  0.1324 Epoch: 293 Iter: 3300/3510 LR: 0.0000011400 Loss content:  0.0141 Loss fft:  0.8433\n",
            "Time:  0.1294 Epoch: 293 Iter: 3400/3510 LR: 0.0000011400 Loss content:  0.0140 Loss fft:  0.8297\n",
            "Time:  0.1280 Epoch: 293 Iter: 3500/3510 LR: 0.0000011400 Loss content:  0.0135 Loss fft:  0.8243\n",
            "EPOCH: 293\n",
            "Elapsed time: 4.62 Epoch Pixel Loss:  0.0139 Epoch FFT Loss:  0.8311\n",
            "Time:  0.1413 Epoch: 294 Iter:  100/3510 LR: 0.0000011039 Loss content:  0.0141 Loss fft:  0.8317\n",
            "Time:  0.1307 Epoch: 294 Iter:  200/3510 LR: 0.0000011039 Loss content:  0.0144 Loss fft:  0.8429\n",
            "Time:  0.1303 Epoch: 294 Iter:  300/3510 LR: 0.0000011039 Loss content:  0.0142 Loss fft:  0.8426\n",
            "Time:  0.1334 Epoch: 294 Iter:  400/3510 LR: 0.0000011039 Loss content:  0.0139 Loss fft:  0.8372\n",
            "Time:  0.1295 Epoch: 294 Iter:  500/3510 LR: 0.0000011039 Loss content:  0.0137 Loss fft:  0.8282\n",
            "Time:  0.1322 Epoch: 294 Iter:  600/3510 LR: 0.0000011039 Loss content:  0.0137 Loss fft:  0.8310\n",
            "Time:  0.1288 Epoch: 294 Iter:  700/3510 LR: 0.0000011039 Loss content:  0.0141 Loss fft:  0.8238\n",
            "Time:  0.1303 Epoch: 294 Iter:  800/3510 LR: 0.0000011039 Loss content:  0.0137 Loss fft:  0.8250\n",
            "Time:  0.1297 Epoch: 294 Iter:  900/3510 LR: 0.0000011039 Loss content:  0.0142 Loss fft:  0.8344\n",
            "Time:  0.1298 Epoch: 294 Iter: 1000/3510 LR: 0.0000011039 Loss content:  0.0137 Loss fft:  0.8246\n",
            "Time:  0.1327 Epoch: 294 Iter: 1100/3510 LR: 0.0000011039 Loss content:  0.0140 Loss fft:  0.8408\n",
            "Time:  0.1335 Epoch: 294 Iter: 1200/3510 LR: 0.0000011039 Loss content:  0.0143 Loss fft:  0.8333\n",
            "Time:  0.1301 Epoch: 294 Iter: 1300/3510 LR: 0.0000011039 Loss content:  0.0143 Loss fft:  0.8419\n",
            "Time:  0.1336 Epoch: 294 Iter: 1400/3510 LR: 0.0000011039 Loss content:  0.0134 Loss fft:  0.8045\n",
            "Time:  0.1292 Epoch: 294 Iter: 1500/3510 LR: 0.0000011039 Loss content:  0.0140 Loss fft:  0.8359\n",
            "Time:  0.1348 Epoch: 294 Iter: 1600/3510 LR: 0.0000011039 Loss content:  0.0138 Loss fft:  0.8265\n",
            "Time:  0.1301 Epoch: 294 Iter: 1700/3510 LR: 0.0000011039 Loss content:  0.0139 Loss fft:  0.8252\n",
            "Time:  0.1335 Epoch: 294 Iter: 1800/3510 LR: 0.0000011039 Loss content:  0.0140 Loss fft:  0.8216\n",
            "Time:  0.1297 Epoch: 294 Iter: 1900/3510 LR: 0.0000011039 Loss content:  0.0138 Loss fft:  0.8418\n",
            "Time:  0.1296 Epoch: 294 Iter: 2000/3510 LR: 0.0000011039 Loss content:  0.0141 Loss fft:  0.8371\n",
            "Time:  0.1298 Epoch: 294 Iter: 2100/3510 LR: 0.0000011039 Loss content:  0.0145 Loss fft:  0.8320\n",
            "Time:  0.1337 Epoch: 294 Iter: 2200/3510 LR: 0.0000011039 Loss content:  0.0141 Loss fft:  0.8368\n",
            "Time:  0.1332 Epoch: 294 Iter: 2300/3510 LR: 0.0000011039 Loss content:  0.0146 Loss fft:  0.8439\n",
            "Time:  0.1328 Epoch: 294 Iter: 2400/3510 LR: 0.0000011039 Loss content:  0.0137 Loss fft:  0.8260\n",
            "Time:  0.1330 Epoch: 294 Iter: 2500/3510 LR: 0.0000011039 Loss content:  0.0138 Loss fft:  0.8258\n",
            "Time:  0.1303 Epoch: 294 Iter: 2600/3510 LR: 0.0000011039 Loss content:  0.0139 Loss fft:  0.8370\n",
            "Time:  0.1309 Epoch: 294 Iter: 2700/3510 LR: 0.0000011039 Loss content:  0.0137 Loss fft:  0.8278\n",
            "Time:  0.1355 Epoch: 294 Iter: 2800/3510 LR: 0.0000011039 Loss content:  0.0141 Loss fft:  0.8262\n",
            "Time:  0.1322 Epoch: 294 Iter: 2900/3510 LR: 0.0000011039 Loss content:  0.0137 Loss fft:  0.8287\n",
            "Time:  0.1310 Epoch: 294 Iter: 3000/3510 LR: 0.0000011039 Loss content:  0.0140 Loss fft:  0.8268\n",
            "Time:  0.1333 Epoch: 294 Iter: 3100/3510 LR: 0.0000011039 Loss content:  0.0138 Loss fft:  0.8300\n",
            "Time:  0.1327 Epoch: 294 Iter: 3200/3510 LR: 0.0000011039 Loss content:  0.0138 Loss fft:  0.8287\n",
            "Time:  0.1336 Epoch: 294 Iter: 3300/3510 LR: 0.0000011039 Loss content:  0.0138 Loss fft:  0.8136\n",
            "Time:  0.1339 Epoch: 294 Iter: 3400/3510 LR: 0.0000011039 Loss content:  0.0136 Loss fft:  0.8153\n",
            "Time:  0.1295 Epoch: 294 Iter: 3500/3510 LR: 0.0000011039 Loss content:  0.0138 Loss fft:  0.8445\n",
            "EPOCH: 294\n",
            "Elapsed time: 4.64 Epoch Pixel Loss:  0.0140 Epoch FFT Loss:  0.8309\n",
            "Time:  0.1426 Epoch: 295 Iter:  100/3510 LR: 0.0000010732 Loss content:  0.0138 Loss fft:  0.8335\n",
            "Time:  0.1298 Epoch: 295 Iter:  200/3510 LR: 0.0000010732 Loss content:  0.0140 Loss fft:  0.8285\n",
            "Time:  0.1328 Epoch: 295 Iter:  300/3510 LR: 0.0000010732 Loss content:  0.0135 Loss fft:  0.8259\n",
            "Time:  0.1327 Epoch: 295 Iter:  400/3510 LR: 0.0000010732 Loss content:  0.0140 Loss fft:  0.8288\n",
            "Time:  0.1311 Epoch: 295 Iter:  500/3510 LR: 0.0000010732 Loss content:  0.0142 Loss fft:  0.8433\n",
            "Time:  0.1324 Epoch: 295 Iter:  600/3510 LR: 0.0000010732 Loss content:  0.0142 Loss fft:  0.8262\n",
            "Time:  0.1340 Epoch: 295 Iter:  700/3510 LR: 0.0000010732 Loss content:  0.0142 Loss fft:  0.8207\n",
            "Time:  0.1319 Epoch: 295 Iter:  800/3510 LR: 0.0000010732 Loss content:  0.0137 Loss fft:  0.8235\n",
            "Time:  0.1341 Epoch: 295 Iter:  900/3510 LR: 0.0000010732 Loss content:  0.0144 Loss fft:  0.8482\n",
            "Time:  0.1336 Epoch: 295 Iter: 1000/3510 LR: 0.0000010732 Loss content:  0.0141 Loss fft:  0.8486\n",
            "Time:  0.1315 Epoch: 295 Iter: 1100/3510 LR: 0.0000010732 Loss content:  0.0140 Loss fft:  0.8561\n",
            "Time:  0.1360 Epoch: 295 Iter: 1200/3510 LR: 0.0000010732 Loss content:  0.0141 Loss fft:  0.8274\n",
            "Time:  0.1307 Epoch: 295 Iter: 1300/3510 LR: 0.0000010732 Loss content:  0.0136 Loss fft:  0.8117\n",
            "Time:  0.1297 Epoch: 295 Iter: 1400/3510 LR: 0.0000010732 Loss content:  0.0135 Loss fft:  0.8198\n",
            "Time:  0.1383 Epoch: 295 Iter: 1500/3510 LR: 0.0000010732 Loss content:  0.0139 Loss fft:  0.8236\n",
            "Time:  0.1328 Epoch: 295 Iter: 1600/3510 LR: 0.0000010732 Loss content:  0.0138 Loss fft:  0.8365\n",
            "Time:  0.1344 Epoch: 295 Iter: 1700/3510 LR: 0.0000010732 Loss content:  0.0138 Loss fft:  0.8253\n",
            "Time:  0.1315 Epoch: 295 Iter: 1800/3510 LR: 0.0000010732 Loss content:  0.0139 Loss fft:  0.8399\n",
            "Time:  0.1345 Epoch: 295 Iter: 1900/3510 LR: 0.0000010732 Loss content:  0.0141 Loss fft:  0.8330\n",
            "Time:  0.1325 Epoch: 295 Iter: 2000/3510 LR: 0.0000010732 Loss content:  0.0141 Loss fft:  0.8299\n",
            "Time:  0.1311 Epoch: 295 Iter: 2100/3510 LR: 0.0000010732 Loss content:  0.0142 Loss fft:  0.8382\n",
            "Time:  0.1295 Epoch: 295 Iter: 2200/3510 LR: 0.0000010732 Loss content:  0.0136 Loss fft:  0.8254\n",
            "Time:  0.1338 Epoch: 295 Iter: 2300/3510 LR: 0.0000010732 Loss content:  0.0141 Loss fft:  0.8216\n",
            "Time:  0.1331 Epoch: 295 Iter: 2400/3510 LR: 0.0000010732 Loss content:  0.0136 Loss fft:  0.8212\n",
            "Time:  0.1329 Epoch: 295 Iter: 2500/3510 LR: 0.0000010732 Loss content:  0.0137 Loss fft:  0.8443\n",
            "Time:  0.1289 Epoch: 295 Iter: 2600/3510 LR: 0.0000010732 Loss content:  0.0139 Loss fft:  0.8340\n",
            "Time:  0.1296 Epoch: 295 Iter: 2700/3510 LR: 0.0000010732 Loss content:  0.0139 Loss fft:  0.8119\n",
            "Time:  0.1296 Epoch: 295 Iter: 2800/3510 LR: 0.0000010732 Loss content:  0.0138 Loss fft:  0.8189\n",
            "Time:  0.1314 Epoch: 295 Iter: 2900/3510 LR: 0.0000010732 Loss content:  0.0142 Loss fft:  0.8464\n",
            "Time:  0.1309 Epoch: 295 Iter: 3000/3510 LR: 0.0000010732 Loss content:  0.0138 Loss fft:  0.8191\n",
            "Time:  0.1322 Epoch: 295 Iter: 3100/3510 LR: 0.0000010732 Loss content:  0.0135 Loss fft:  0.8160\n",
            "Time:  0.1314 Epoch: 295 Iter: 3200/3510 LR: 0.0000010732 Loss content:  0.0135 Loss fft:  0.8186\n",
            "Time:  0.1324 Epoch: 295 Iter: 3300/3510 LR: 0.0000010732 Loss content:  0.0137 Loss fft:  0.8028\n",
            "Time:  0.1294 Epoch: 295 Iter: 3400/3510 LR: 0.0000010732 Loss content:  0.0138 Loss fft:  0.8208\n",
            "Time:  0.1299 Epoch: 295 Iter: 3500/3510 LR: 0.0000010732 Loss content:  0.0133 Loss fft:  0.8310\n",
            "EPOCH: 295\n",
            "Elapsed time: 4.65 Epoch Pixel Loss:  0.0139 Epoch FFT Loss:  0.8285\n",
            "Time:  0.1398 Epoch: 296 Iter:  100/3510 LR: 0.0000010481 Loss content:  0.0143 Loss fft:  0.8466\n",
            "Time:  0.1294 Epoch: 296 Iter:  200/3510 LR: 0.0000010481 Loss content:  0.0137 Loss fft:  0.8198\n",
            "Time:  0.1310 Epoch: 296 Iter:  300/3510 LR: 0.0000010481 Loss content:  0.0140 Loss fft:  0.8291\n",
            "Time:  0.1349 Epoch: 296 Iter:  400/3510 LR: 0.0000010481 Loss content:  0.0133 Loss fft:  0.8240\n",
            "Time:  0.1294 Epoch: 296 Iter:  500/3510 LR: 0.0000010481 Loss content:  0.0143 Loss fft:  0.8287\n",
            "Time:  0.1300 Epoch: 296 Iter:  600/3510 LR: 0.0000010481 Loss content:  0.0137 Loss fft:  0.8192\n",
            "Time:  0.1296 Epoch: 296 Iter:  700/3510 LR: 0.0000010481 Loss content:  0.0138 Loss fft:  0.8193\n",
            "Time:  0.1320 Epoch: 296 Iter:  800/3510 LR: 0.0000010481 Loss content:  0.0136 Loss fft:  0.8184\n",
            "Time:  0.1314 Epoch: 296 Iter:  900/3510 LR: 0.0000010481 Loss content:  0.0138 Loss fft:  0.8190\n",
            "Time:  0.1300 Epoch: 296 Iter: 1000/3510 LR: 0.0000010481 Loss content:  0.0136 Loss fft:  0.8221\n",
            "Time:  0.1315 Epoch: 296 Iter: 1100/3510 LR: 0.0000010481 Loss content:  0.0141 Loss fft:  0.8293\n",
            "Time:  0.1282 Epoch: 296 Iter: 1200/3510 LR: 0.0000010481 Loss content:  0.0142 Loss fft:  0.8440\n",
            "Time:  0.1282 Epoch: 296 Iter: 1300/3510 LR: 0.0000010481 Loss content:  0.0139 Loss fft:  0.8265\n",
            "Time:  0.1283 Epoch: 296 Iter: 1400/3510 LR: 0.0000010481 Loss content:  0.0141 Loss fft:  0.8338\n",
            "Time:  0.1271 Epoch: 296 Iter: 1500/3510 LR: 0.0000010481 Loss content:  0.0136 Loss fft:  0.8197\n",
            "Time:  0.1273 Epoch: 296 Iter: 1600/3510 LR: 0.0000010481 Loss content:  0.0141 Loss fft:  0.8231\n",
            "Time:  0.1312 Epoch: 296 Iter: 1700/3510 LR: 0.0000010481 Loss content:  0.0145 Loss fft:  0.8480\n",
            "Time:  0.1295 Epoch: 296 Iter: 1800/3510 LR: 0.0000010481 Loss content:  0.0138 Loss fft:  0.8192\n",
            "Time:  0.1326 Epoch: 296 Iter: 1900/3510 LR: 0.0000010481 Loss content:  0.0145 Loss fft:  0.8344\n",
            "Time:  0.1310 Epoch: 296 Iter: 2000/3510 LR: 0.0000010481 Loss content:  0.0140 Loss fft:  0.8254\n",
            "Time:  0.1271 Epoch: 296 Iter: 2100/3510 LR: 0.0000010481 Loss content:  0.0134 Loss fft:  0.8212\n",
            "Time:  0.1282 Epoch: 296 Iter: 2200/3510 LR: 0.0000010481 Loss content:  0.0140 Loss fft:  0.8400\n",
            "Time:  0.1336 Epoch: 296 Iter: 2300/3510 LR: 0.0000010481 Loss content:  0.0138 Loss fft:  0.8371\n",
            "Time:  0.1317 Epoch: 296 Iter: 2400/3510 LR: 0.0000010481 Loss content:  0.0142 Loss fft:  0.8613\n",
            "Time:  0.1275 Epoch: 296 Iter: 2500/3510 LR: 0.0000010481 Loss content:  0.0138 Loss fft:  0.8209\n",
            "Time:  0.1278 Epoch: 296 Iter: 2600/3510 LR: 0.0000010481 Loss content:  0.0134 Loss fft:  0.8187\n",
            "Time:  0.1273 Epoch: 296 Iter: 2700/3510 LR: 0.0000010481 Loss content:  0.0145 Loss fft:  0.8471\n",
            "Time:  0.1348 Epoch: 296 Iter: 2800/3510 LR: 0.0000010481 Loss content:  0.0143 Loss fft:  0.8249\n",
            "Time:  0.1279 Epoch: 296 Iter: 2900/3510 LR: 0.0000010481 Loss content:  0.0137 Loss fft:  0.8144\n",
            "Time:  0.1280 Epoch: 296 Iter: 3000/3510 LR: 0.0000010481 Loss content:  0.0143 Loss fft:  0.8467\n",
            "Time:  0.1284 Epoch: 296 Iter: 3100/3510 LR: 0.0000010481 Loss content:  0.0139 Loss fft:  0.8105\n",
            "Time:  0.1331 Epoch: 296 Iter: 3200/3510 LR: 0.0000010481 Loss content:  0.0137 Loss fft:  0.8302\n",
            "Time:  0.1300 Epoch: 296 Iter: 3300/3510 LR: 0.0000010481 Loss content:  0.0140 Loss fft:  0.8614\n",
            "Time:  0.1298 Epoch: 296 Iter: 3400/3510 LR: 0.0000010481 Loss content:  0.0140 Loss fft:  0.8358\n",
            "Time:  0.1291 Epoch: 296 Iter: 3500/3510 LR: 0.0000010481 Loss content:  0.0137 Loss fft:  0.8270\n",
            "EPOCH: 296\n",
            "Elapsed time: 4.58 Epoch Pixel Loss:  0.0139 Epoch FFT Loss:  0.8298\n",
            "Time:  0.1371 Epoch: 297 Iter:  100/3510 LR: 0.0000010284 Loss content:  0.0136 Loss fft:  0.8177\n",
            "Time:  0.1275 Epoch: 297 Iter:  200/3510 LR: 0.0000010284 Loss content:  0.0137 Loss fft:  0.8372\n",
            "Time:  0.1269 Epoch: 297 Iter:  300/3510 LR: 0.0000010284 Loss content:  0.0141 Loss fft:  0.8340\n",
            "Time:  0.1311 Epoch: 297 Iter:  400/3510 LR: 0.0000010284 Loss content:  0.0143 Loss fft:  0.8439\n",
            "Time:  0.1307 Epoch: 297 Iter:  500/3510 LR: 0.0000010284 Loss content:  0.0138 Loss fft:  0.8087\n",
            "Time:  0.1317 Epoch: 297 Iter:  600/3510 LR: 0.0000010284 Loss content:  0.0140 Loss fft:  0.8244\n",
            "Time:  0.1331 Epoch: 297 Iter:  700/3510 LR: 0.0000010284 Loss content:  0.0140 Loss fft:  0.8205\n",
            "Time:  0.1338 Epoch: 297 Iter:  800/3510 LR: 0.0000010284 Loss content:  0.0140 Loss fft:  0.8396\n",
            "Time:  0.1340 Epoch: 297 Iter:  900/3510 LR: 0.0000010284 Loss content:  0.0137 Loss fft:  0.8125\n",
            "Time:  0.1317 Epoch: 297 Iter: 1000/3510 LR: 0.0000010284 Loss content:  0.0139 Loss fft:  0.8357\n",
            "Time:  0.1328 Epoch: 297 Iter: 1100/3510 LR: 0.0000010284 Loss content:  0.0135 Loss fft:  0.8093\n",
            "Time:  0.1344 Epoch: 297 Iter: 1200/3510 LR: 0.0000010284 Loss content:  0.0138 Loss fft:  0.8319\n",
            "Time:  0.1343 Epoch: 297 Iter: 1300/3510 LR: 0.0000010284 Loss content:  0.0142 Loss fft:  0.8554\n",
            "Time:  0.1284 Epoch: 297 Iter: 1400/3510 LR: 0.0000010284 Loss content:  0.0138 Loss fft:  0.8206\n",
            "Time:  0.1394 Epoch: 297 Iter: 1500/3510 LR: 0.0000010284 Loss content:  0.0136 Loss fft:  0.8360\n",
            "Time:  0.1309 Epoch: 297 Iter: 1600/3510 LR: 0.0000010284 Loss content:  0.0135 Loss fft:  0.8169\n",
            "Time:  0.1308 Epoch: 297 Iter: 1700/3510 LR: 0.0000010284 Loss content:  0.0141 Loss fft:  0.8269\n",
            "Time:  0.1363 Epoch: 297 Iter: 1800/3510 LR: 0.0000010284 Loss content:  0.0141 Loss fft:  0.8275\n",
            "Time:  0.1312 Epoch: 297 Iter: 1900/3510 LR: 0.0000010284 Loss content:  0.0142 Loss fft:  0.8566\n",
            "Time:  0.1325 Epoch: 297 Iter: 2000/3510 LR: 0.0000010284 Loss content:  0.0140 Loss fft:  0.8348\n",
            "Time:  0.1297 Epoch: 297 Iter: 2100/3510 LR: 0.0000010284 Loss content:  0.0140 Loss fft:  0.8341\n",
            "Time:  0.1302 Epoch: 297 Iter: 2200/3510 LR: 0.0000010284 Loss content:  0.0133 Loss fft:  0.8087\n",
            "Time:  0.1288 Epoch: 297 Iter: 2300/3510 LR: 0.0000010284 Loss content:  0.0140 Loss fft:  0.8250\n",
            "Time:  0.1306 Epoch: 297 Iter: 2400/3510 LR: 0.0000010284 Loss content:  0.0138 Loss fft:  0.8342\n",
            "Time:  0.1287 Epoch: 297 Iter: 2500/3510 LR: 0.0000010284 Loss content:  0.0139 Loss fft:  0.8254\n",
            "Time:  0.1312 Epoch: 297 Iter: 2600/3510 LR: 0.0000010284 Loss content:  0.0140 Loss fft:  0.8331\n",
            "Time:  0.1288 Epoch: 297 Iter: 2700/3510 LR: 0.0000010284 Loss content:  0.0132 Loss fft:  0.8045\n",
            "Time:  0.1291 Epoch: 297 Iter: 2800/3510 LR: 0.0000010284 Loss content:  0.0141 Loss fft:  0.8337\n",
            "Time:  0.1293 Epoch: 297 Iter: 2900/3510 LR: 0.0000010284 Loss content:  0.0136 Loss fft:  0.8107\n",
            "Time:  0.1302 Epoch: 297 Iter: 3000/3510 LR: 0.0000010284 Loss content:  0.0136 Loss fft:  0.8211\n",
            "Time:  0.1306 Epoch: 297 Iter: 3100/3510 LR: 0.0000010284 Loss content:  0.0136 Loss fft:  0.8261\n",
            "Time:  0.1285 Epoch: 297 Iter: 3200/3510 LR: 0.0000010284 Loss content:  0.0137 Loss fft:  0.8265\n",
            "Time:  0.1334 Epoch: 297 Iter: 3300/3510 LR: 0.0000010284 Loss content:  0.0139 Loss fft:  0.8429\n",
            "Time:  0.1301 Epoch: 297 Iter: 3400/3510 LR: 0.0000010284 Loss content:  0.0140 Loss fft:  0.8364\n",
            "Time:  0.1325 Epoch: 297 Iter: 3500/3510 LR: 0.0000010284 Loss content:  0.0138 Loss fft:  0.8333\n",
            "EPOCH: 297\n",
            "Elapsed time: 4.62 Epoch Pixel Loss:  0.0138 Epoch FFT Loss:  0.8281\n",
            "Time:  0.1380 Epoch: 298 Iter:  100/3510 LR: 0.0000010140 Loss content:  0.0138 Loss fft:  0.8237\n",
            "Time:  0.1302 Epoch: 298 Iter:  200/3510 LR: 0.0000010140 Loss content:  0.0139 Loss fft:  0.8123\n",
            "Time:  0.1374 Epoch: 298 Iter:  300/3510 LR: 0.0000010140 Loss content:  0.0140 Loss fft:  0.8280\n",
            "Time:  0.1287 Epoch: 298 Iter:  400/3510 LR: 0.0000010140 Loss content:  0.0138 Loss fft:  0.8298\n",
            "Time:  0.1303 Epoch: 298 Iter:  500/3510 LR: 0.0000010140 Loss content:  0.0141 Loss fft:  0.8295\n",
            "Time:  0.1303 Epoch: 298 Iter:  600/3510 LR: 0.0000010140 Loss content:  0.0139 Loss fft:  0.8284\n",
            "Time:  0.1299 Epoch: 298 Iter:  700/3510 LR: 0.0000010140 Loss content:  0.0141 Loss fft:  0.8494\n",
            "Time:  0.1340 Epoch: 298 Iter:  800/3510 LR: 0.0000010140 Loss content:  0.0139 Loss fft:  0.8376\n",
            "Time:  0.1297 Epoch: 298 Iter:  900/3510 LR: 0.0000010140 Loss content:  0.0134 Loss fft:  0.8213\n",
            "Time:  0.1285 Epoch: 298 Iter: 1000/3510 LR: 0.0000010140 Loss content:  0.0138 Loss fft:  0.8316\n",
            "Time:  0.1328 Epoch: 298 Iter: 1100/3510 LR: 0.0000010140 Loss content:  0.0139 Loss fft:  0.8298\n",
            "Time:  0.1331 Epoch: 298 Iter: 1200/3510 LR: 0.0000010140 Loss content:  0.0139 Loss fft:  0.8353\n",
            "Time:  0.1290 Epoch: 298 Iter: 1300/3510 LR: 0.0000010140 Loss content:  0.0138 Loss fft:  0.8342\n",
            "Time:  0.1271 Epoch: 298 Iter: 1400/3510 LR: 0.0000010140 Loss content:  0.0141 Loss fft:  0.8487\n",
            "Time:  0.1323 Epoch: 298 Iter: 1500/3510 LR: 0.0000010140 Loss content:  0.0140 Loss fft:  0.8290\n",
            "Time:  0.1334 Epoch: 298 Iter: 1600/3510 LR: 0.0000010140 Loss content:  0.0136 Loss fft:  0.8081\n",
            "Time:  0.1291 Epoch: 298 Iter: 1700/3510 LR: 0.0000010140 Loss content:  0.0139 Loss fft:  0.8355\n",
            "Time:  0.1300 Epoch: 298 Iter: 1800/3510 LR: 0.0000010140 Loss content:  0.0138 Loss fft:  0.8176\n",
            "Time:  0.1301 Epoch: 298 Iter: 1900/3510 LR: 0.0000010140 Loss content:  0.0138 Loss fft:  0.8361\n",
            "Time:  0.1313 Epoch: 298 Iter: 2000/3510 LR: 0.0000010140 Loss content:  0.0139 Loss fft:  0.8310\n",
            "Time:  0.1300 Epoch: 298 Iter: 2100/3510 LR: 0.0000010140 Loss content:  0.0138 Loss fft:  0.8396\n",
            "Time:  0.1315 Epoch: 298 Iter: 2200/3510 LR: 0.0000010140 Loss content:  0.0136 Loss fft:  0.8296\n",
            "Time:  0.1283 Epoch: 298 Iter: 2300/3510 LR: 0.0000010140 Loss content:  0.0136 Loss fft:  0.8109\n",
            "Time:  0.1310 Epoch: 298 Iter: 2400/3510 LR: 0.0000010140 Loss content:  0.0136 Loss fft:  0.8138\n",
            "Time:  0.1278 Epoch: 298 Iter: 2500/3510 LR: 0.0000010140 Loss content:  0.0139 Loss fft:  0.8160\n",
            "Time:  0.1302 Epoch: 298 Iter: 2600/3510 LR: 0.0000010140 Loss content:  0.0139 Loss fft:  0.8171\n",
            "Time:  0.1329 Epoch: 298 Iter: 2700/3510 LR: 0.0000010140 Loss content:  0.0137 Loss fft:  0.8311\n",
            "Time:  0.1290 Epoch: 298 Iter: 2800/3510 LR: 0.0000010140 Loss content:  0.0142 Loss fft:  0.8560\n",
            "Time:  0.1308 Epoch: 298 Iter: 2900/3510 LR: 0.0000010140 Loss content:  0.0137 Loss fft:  0.8013\n",
            "Time:  0.1298 Epoch: 298 Iter: 3000/3510 LR: 0.0000010140 Loss content:  0.0140 Loss fft:  0.8391\n",
            "Time:  0.1295 Epoch: 298 Iter: 3100/3510 LR: 0.0000010140 Loss content:  0.0138 Loss fft:  0.8447\n",
            "Time:  0.1294 Epoch: 298 Iter: 3200/3510 LR: 0.0000010140 Loss content:  0.0146 Loss fft:  0.8731\n",
            "Time:  0.1301 Epoch: 298 Iter: 3300/3510 LR: 0.0000010140 Loss content:  0.0139 Loss fft:  0.8097\n",
            "Time:  0.1271 Epoch: 298 Iter: 3400/3510 LR: 0.0000010140 Loss content:  0.0144 Loss fft:  0.8416\n",
            "Time:  0.1273 Epoch: 298 Iter: 3500/3510 LR: 0.0000010140 Loss content:  0.0136 Loss fft:  0.8052\n",
            "EPOCH: 298\n",
            "Elapsed time: 4.59 Epoch Pixel Loss:  0.0139 Epoch FFT Loss:  0.8293\n",
            "Time:  0.1363 Epoch: 299 Iter:  100/3510 LR: 0.0000010049 Loss content:  0.0136 Loss fft:  0.8298\n",
            "Time:  0.1296 Epoch: 299 Iter:  200/3510 LR: 0.0000010049 Loss content:  0.0138 Loss fft:  0.8342\n",
            "Time:  0.1291 Epoch: 299 Iter:  300/3510 LR: 0.0000010049 Loss content:  0.0137 Loss fft:  0.8282\n",
            "Time:  0.1279 Epoch: 299 Iter:  400/3510 LR: 0.0000010049 Loss content:  0.0144 Loss fft:  0.8491\n",
            "Time:  0.1302 Epoch: 299 Iter:  500/3510 LR: 0.0000010049 Loss content:  0.0138 Loss fft:  0.8195\n",
            "Time:  0.1314 Epoch: 299 Iter:  600/3510 LR: 0.0000010049 Loss content:  0.0141 Loss fft:  0.8308\n",
            "Time:  0.1287 Epoch: 299 Iter:  700/3510 LR: 0.0000010049 Loss content:  0.0140 Loss fft:  0.8468\n",
            "Time:  0.1291 Epoch: 299 Iter:  800/3510 LR: 0.0000010049 Loss content:  0.0138 Loss fft:  0.8201\n",
            "Time:  0.1289 Epoch: 299 Iter:  900/3510 LR: 0.0000010049 Loss content:  0.0136 Loss fft:  0.8234\n",
            "Time:  0.1295 Epoch: 299 Iter: 1000/3510 LR: 0.0000010049 Loss content:  0.0141 Loss fft:  0.8258\n",
            "Time:  0.1300 Epoch: 299 Iter: 1100/3510 LR: 0.0000010049 Loss content:  0.0137 Loss fft:  0.8375\n",
            "Time:  0.1289 Epoch: 299 Iter: 1200/3510 LR: 0.0000010049 Loss content:  0.0134 Loss fft:  0.8107\n",
            "Time:  0.1307 Epoch: 299 Iter: 1300/3510 LR: 0.0000010049 Loss content:  0.0141 Loss fft:  0.8347\n",
            "Time:  0.1302 Epoch: 299 Iter: 1400/3510 LR: 0.0000010049 Loss content:  0.0137 Loss fft:  0.8447\n",
            "Time:  0.1374 Epoch: 299 Iter: 1500/3510 LR: 0.0000010049 Loss content:  0.0143 Loss fft:  0.8396\n",
            "Time:  0.1309 Epoch: 299 Iter: 1600/3510 LR: 0.0000010049 Loss content:  0.0141 Loss fft:  0.8446\n",
            "Time:  0.1303 Epoch: 299 Iter: 1700/3510 LR: 0.0000010049 Loss content:  0.0137 Loss fft:  0.8256\n",
            "Time:  0.1291 Epoch: 299 Iter: 1800/3510 LR: 0.0000010049 Loss content:  0.0135 Loss fft:  0.8176\n",
            "Time:  0.1315 Epoch: 299 Iter: 1900/3510 LR: 0.0000010049 Loss content:  0.0138 Loss fft:  0.8217\n",
            "Time:  0.1312 Epoch: 299 Iter: 2000/3510 LR: 0.0000010049 Loss content:  0.0136 Loss fft:  0.8216\n",
            "Time:  0.1339 Epoch: 299 Iter: 2100/3510 LR: 0.0000010049 Loss content:  0.0139 Loss fft:  0.8158\n",
            "Time:  0.1336 Epoch: 299 Iter: 2200/3510 LR: 0.0000010049 Loss content:  0.0141 Loss fft:  0.8456\n",
            "Time:  0.1301 Epoch: 299 Iter: 2300/3510 LR: 0.0000010049 Loss content:  0.0140 Loss fft:  0.8460\n",
            "Time:  0.1326 Epoch: 299 Iter: 2400/3510 LR: 0.0000010049 Loss content:  0.0138 Loss fft:  0.8269\n",
            "Time:  0.1307 Epoch: 299 Iter: 2500/3510 LR: 0.0000010049 Loss content:  0.0139 Loss fft:  0.8121\n",
            "Time:  0.1327 Epoch: 299 Iter: 2600/3510 LR: 0.0000010049 Loss content:  0.0140 Loss fft:  0.8309\n",
            "Time:  0.1337 Epoch: 299 Iter: 2700/3510 LR: 0.0000010049 Loss content:  0.0137 Loss fft:  0.8393\n",
            "Time:  0.1295 Epoch: 299 Iter: 2800/3510 LR: 0.0000010049 Loss content:  0.0146 Loss fft:  0.8531\n",
            "Time:  0.1300 Epoch: 299 Iter: 2900/3510 LR: 0.0000010049 Loss content:  0.0137 Loss fft:  0.8298\n",
            "Time:  0.1313 Epoch: 299 Iter: 3000/3510 LR: 0.0000010049 Loss content:  0.0144 Loss fft:  0.8437\n",
            "Time:  0.1309 Epoch: 299 Iter: 3100/3510 LR: 0.0000010049 Loss content:  0.0144 Loss fft:  0.8413\n",
            "Time:  0.1332 Epoch: 299 Iter: 3200/3510 LR: 0.0000010049 Loss content:  0.0143 Loss fft:  0.8270\n",
            "Time:  0.1309 Epoch: 299 Iter: 3300/3510 LR: 0.0000010049 Loss content:  0.0137 Loss fft:  0.8265\n",
            "Time:  0.1314 Epoch: 299 Iter: 3400/3510 LR: 0.0000010049 Loss content:  0.0138 Loss fft:  0.8223\n",
            "Time:  0.1282 Epoch: 299 Iter: 3500/3510 LR: 0.0000010049 Loss content:  0.0143 Loss fft:  0.8358\n",
            "EPOCH: 299\n",
            "Elapsed time: 4.60 Epoch Pixel Loss:  0.0139 Epoch FFT Loss:  0.8314\n",
            "Time:  0.1419 Epoch: 300 Iter:  100/3510 LR: 0.0000010007 Loss content:  0.0137 Loss fft:  0.8134\n",
            "Time:  0.1317 Epoch: 300 Iter:  200/3510 LR: 0.0000010007 Loss content:  0.0139 Loss fft:  0.8430\n",
            "Time:  0.1368 Epoch: 300 Iter:  300/3510 LR: 0.0000010007 Loss content:  0.0135 Loss fft:  0.8300\n",
            "Time:  0.1315 Epoch: 300 Iter:  400/3510 LR: 0.0000010007 Loss content:  0.0136 Loss fft:  0.8194\n",
            "Time:  0.1302 Epoch: 300 Iter:  500/3510 LR: 0.0000010007 Loss content:  0.0137 Loss fft:  0.8290\n",
            "Time:  0.1311 Epoch: 300 Iter:  600/3510 LR: 0.0000010007 Loss content:  0.0137 Loss fft:  0.8403\n",
            "Time:  0.1328 Epoch: 300 Iter:  700/3510 LR: 0.0000010007 Loss content:  0.0138 Loss fft:  0.8319\n",
            "Time:  0.1292 Epoch: 300 Iter:  800/3510 LR: 0.0000010007 Loss content:  0.0140 Loss fft:  0.8083\n",
            "Time:  0.1330 Epoch: 300 Iter:  900/3510 LR: 0.0000010007 Loss content:  0.0140 Loss fft:  0.8399\n",
            "Time:  0.1332 Epoch: 300 Iter: 1000/3510 LR: 0.0000010007 Loss content:  0.0134 Loss fft:  0.8245\n",
            "Time:  0.1299 Epoch: 300 Iter: 1100/3510 LR: 0.0000010007 Loss content:  0.0136 Loss fft:  0.8128\n",
            "Time:  0.1290 Epoch: 300 Iter: 1200/3510 LR: 0.0000010007 Loss content:  0.0141 Loss fft:  0.8375\n",
            "Time:  0.1282 Epoch: 300 Iter: 1300/3510 LR: 0.0000010007 Loss content:  0.0137 Loss fft:  0.8342\n",
            "Time:  0.1297 Epoch: 300 Iter: 1400/3510 LR: 0.0000010007 Loss content:  0.0142 Loss fft:  0.8368\n",
            "Time:  0.1278 Epoch: 300 Iter: 1500/3510 LR: 0.0000010007 Loss content:  0.0141 Loss fft:  0.8384\n",
            "Time:  0.1324 Epoch: 300 Iter: 1600/3510 LR: 0.0000010007 Loss content:  0.0135 Loss fft:  0.8148\n",
            "Time:  0.1311 Epoch: 300 Iter: 1700/3510 LR: 0.0000010007 Loss content:  0.0135 Loss fft:  0.8172\n",
            "Time:  0.1309 Epoch: 300 Iter: 1800/3510 LR: 0.0000010007 Loss content:  0.0138 Loss fft:  0.8249\n",
            "Time:  0.1297 Epoch: 300 Iter: 1900/3510 LR: 0.0000010007 Loss content:  0.0143 Loss fft:  0.8384\n",
            "Time:  0.1309 Epoch: 300 Iter: 2000/3510 LR: 0.0000010007 Loss content:  0.0140 Loss fft:  0.8405\n",
            "Time:  0.1287 Epoch: 300 Iter: 2100/3510 LR: 0.0000010007 Loss content:  0.0142 Loss fft:  0.8412\n",
            "Time:  0.1319 Epoch: 300 Iter: 2200/3510 LR: 0.0000010007 Loss content:  0.0138 Loss fft:  0.8489\n",
            "Time:  0.1284 Epoch: 300 Iter: 2300/3510 LR: 0.0000010007 Loss content:  0.0140 Loss fft:  0.8274\n",
            "Time:  0.1279 Epoch: 300 Iter: 2400/3510 LR: 0.0000010007 Loss content:  0.0137 Loss fft:  0.8394\n",
            "Time:  0.1298 Epoch: 300 Iter: 2500/3510 LR: 0.0000010007 Loss content:  0.0138 Loss fft:  0.8107\n",
            "Time:  0.1314 Epoch: 300 Iter: 2600/3510 LR: 0.0000010007 Loss content:  0.0136 Loss fft:  0.8160\n",
            "Time:  0.1331 Epoch: 300 Iter: 2700/3510 LR: 0.0000010007 Loss content:  0.0144 Loss fft:  0.8637\n",
            "Time:  0.1282 Epoch: 300 Iter: 2800/3510 LR: 0.0000010007 Loss content:  0.0140 Loss fft:  0.8323\n",
            "Time:  0.1313 Epoch: 300 Iter: 2900/3510 LR: 0.0000010007 Loss content:  0.0143 Loss fft:  0.8601\n",
            "Time:  0.1311 Epoch: 300 Iter: 3000/3510 LR: 0.0000010007 Loss content:  0.0143 Loss fft:  0.8417\n",
            "Time:  0.1296 Epoch: 300 Iter: 3100/3510 LR: 0.0000010007 Loss content:  0.0139 Loss fft:  0.8245\n",
            "Time:  0.1300 Epoch: 300 Iter: 3200/3510 LR: 0.0000010007 Loss content:  0.0137 Loss fft:  0.8286\n",
            "Time:  0.1301 Epoch: 300 Iter: 3300/3510 LR: 0.0000010007 Loss content:  0.0137 Loss fft:  0.8056\n",
            "Time:  0.1290 Epoch: 300 Iter: 3400/3510 LR: 0.0000010007 Loss content:  0.0137 Loss fft:  0.8270\n",
            "Time:  0.1306 Epoch: 300 Iter: 3500/3510 LR: 0.0000010007 Loss content:  0.0139 Loss fft:  0.8509\n",
            "EPOCH: 300\n",
            "Elapsed time: 4.60 Epoch Pixel Loss:  0.0139 Epoch FFT Loss:  0.8314\n",
            "Start Evaluation\n",
            "499 \n",
            "\n",
            "300 epoch \n",
            " Average PSNR 41.04 dB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "# from torch.backends import cudnn # Uncomment if you need it\n",
        "\n",
        "class Args:\n",
        "    model_name = 'IRNeXt'\n",
        "    mode = 'train'\n",
        "    data_dir = path\n",
        "\n",
        "    # Train\n",
        "    batch_size = 4\n",
        "    learning_rate = 1e-4\n",
        "    weight_decay = 5e-4\n",
        "    num_epoch = 300\n",
        "    print_freq = 100\n",
        "    num_worker = 8\n",
        "    save_freq = 10\n",
        "    valid_freq = 10\n",
        "    resume = '/content/drive/MyDrive/reside-indoor/results/IRNeXt/ITS/model.pkl'\n",
        "\n",
        "    # Test\n",
        "    # test_model = ''\n",
        "    # save_image = False\n",
        "\n",
        "    # Directories (set these as per your requirement)\n",
        "    model_save_dir = os.path.join('/content/drive/MyDrive/reside-indoor/results/', 'IRNeXt', 'ITS/')\n",
        "    result_dir = os.path.join('/content/drive/MyDrive/reside-indoor/results/', model_name, 'test')\n",
        "\n",
        "def main(args):\n",
        "    # CUDNN\n",
        "    # cudnn.benchmark = True # Uncomment if you need it\n",
        "\n",
        "    if not os.path.exists('/content/drive/MyDrive/reside-indoor/results/'):\n",
        "        os.makedirs(args.model_save_dir)\n",
        "    if not os.path.exists('/content/drive/MyDrive/reside-indoor/results/' + args.model_name + '/'):\n",
        "        os.makedirs('/content/drive/MyDrive/reside-indoor/results/' + args.model_name + '/')\n",
        "    if not os.path.exists(args.model_save_dir):\n",
        "        os.makedirs(args.model_save_dir)\n",
        "    if not os.path.exists(args.result_dir):\n",
        "        os.makedirs(args.result_dir)\n",
        "\n",
        "    model = build_net()  # Make sure to define build_net or import it if it's defined elsewhere\n",
        "    print(model)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    if args.mode == 'train':\n",
        "        _train(model, args)  # Make sure to define _train or import it if it's defined elsewhere\n",
        "\n",
        "    elif args.mode == 'test':\n",
        "        _eval(model, args)   # Make sure to define _eval or import it if it's defined elsewhere\n",
        "\n",
        "# Replace parser.parse_args() with an instance of the Args class\n",
        "args = Args()\n",
        "if not os.path.exists(args.model_save_dir):\n",
        "    os.makedirs(args.model_save_dir)\n",
        "# Copying files (make sure these paths are correct)\n",
        "command = 'cp ' + 'models/layers.py ' + args.model_save_dir\n",
        "os.system(command)\n",
        "command = 'cp ' + 'models/IRNeXt.py ' + args.model_save_dir\n",
        "os.system(command)\n",
        "command = 'cp ' + 'train.py ' + args.model_save_dir\n",
        "os.system(command)\n",
        "command = 'cp ' + 'main.py ' + args.model_save_dir\n",
        "os.system(command)\n",
        "print(args)\n",
        "main(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbdgmURy0fj_"
      },
      "outputs": [],
      "source": [
        "state_last = torch.load('/content/drive/MyDrive/reside-indoor/results1/IRNeXt/ITS/model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  /content/drive/MyDrive/reside-indoor/SOTS.zip -d ./SOTS/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP-LKtKfCDrY",
        "outputId": "de6c91ac-fd2e-4577-85a8-fddb62f9e0d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/reside-indoor/SOTS.zip\n",
            "   creating: ./SOTS/SOTS/\n",
            "   creating: ./SOTS/SOTS/indoor/\n",
            "   creating: ./SOTS/SOTS/indoor/gt/\n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1401.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1400.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1402.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1403.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1404.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1405.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1406.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1407.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1408.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1409.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1410.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1411.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1412.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1413.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1414.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1415.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1416.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1417.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1418.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1419.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1420.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1421.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1422.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1423.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1424.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1425.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1426.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1427.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1428.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1429.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1430.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1431.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1432.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1433.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1434.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1435.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1436.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1437.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1438.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1439.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1440.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1441.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1442.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1443.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1444.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1445.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1446.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1447.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1448.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/gt/1449.png  \n",
            "   creating: ./SOTS/SOTS/indoor/hazy/\n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1400_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1400_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1400_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1400_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1400_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1400_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1400_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1400_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1400_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1400_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1401_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1401_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1401_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1401_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1401_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1401_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1401_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1401_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1401_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1401_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1402_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1402_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1402_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1402_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1402_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1402_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1402_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1402_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1402_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1402_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1403_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1403_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1403_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1403_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1403_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1403_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1403_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1403_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1403_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1403_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1404_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1404_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1404_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1404_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1404_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1404_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1404_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1404_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1404_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1404_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1405_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1405_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1405_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1405_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1405_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1405_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1405_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1405_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1405_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1405_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1406_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1406_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1406_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1406_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1406_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1406_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1406_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1406_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1406_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1406_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1407_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1407_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1407_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1407_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1407_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1407_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1407_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1407_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1407_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1407_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1408_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1408_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1408_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1408_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1408_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1408_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1408_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1408_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1408_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1408_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1409_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1409_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1409_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1409_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1409_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1409_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1409_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1409_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1409_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1409_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1410_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1410_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1410_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1410_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1410_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1410_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1410_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1410_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1410_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1410_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1411_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1411_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1411_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1411_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1411_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1411_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1411_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1411_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1411_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1411_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1412_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1412_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1412_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1412_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1412_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1412_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1412_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1412_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1412_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1412_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1413_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1413_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1413_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1413_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1413_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1413_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1413_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1413_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1413_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1413_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1414_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1414_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1414_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1414_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1414_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1414_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1414_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1414_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1414_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1414_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1415_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1415_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1415_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1415_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1415_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1415_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1415_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1415_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1415_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1415_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1416_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1416_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1416_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1416_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1416_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1416_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1416_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1416_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1416_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1416_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1417_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1417_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1417_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1417_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1417_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1417_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1417_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1417_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1417_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1417_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1418_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1418_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1418_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1418_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1418_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1418_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1418_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1418_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1418_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1418_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1419_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1419_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1419_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1419_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1419_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1419_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1419_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1419_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1419_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1419_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1420_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1420_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1420_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1420_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1420_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1420_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1420_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1420_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1420_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1420_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1421_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1421_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1421_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1421_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1421_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1421_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1421_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1421_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1421_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1421_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1422_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1422_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1422_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1422_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1422_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1422_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1422_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1422_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1422_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1422_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1423_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1423_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1423_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1423_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1423_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1423_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1423_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1423_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1423_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1423_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1424_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1424_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1424_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1424_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1424_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1424_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1424_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1424_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1424_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1424_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1425_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1425_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1425_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1425_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1425_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1425_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1425_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1425_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1425_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1425_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1426_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1426_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1426_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1426_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1426_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1426_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1426_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1426_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1426_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1426_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1427_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1427_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1427_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1427_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1427_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1427_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1427_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1427_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1427_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1427_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1428_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1428_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1428_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1428_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1428_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1428_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1428_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1428_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1428_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1428_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1429_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1429_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1429_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1429_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1429_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1429_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1429_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1429_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1429_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1429_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1430_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1430_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1430_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1430_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1430_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1430_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1430_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1430_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1430_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1430_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1431_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1431_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1431_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1431_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1431_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1431_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1431_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1431_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1431_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1431_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1432_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1432_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1432_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1432_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1432_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1432_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1432_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1432_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1432_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1432_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1433_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1433_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1433_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1433_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1433_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1433_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1433_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1433_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1433_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1433_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1434_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1434_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1434_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1434_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1434_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1434_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1434_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1434_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1434_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1434_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1435_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1435_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1435_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1435_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1435_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1435_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1435_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1435_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1435_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1435_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1436_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1436_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1436_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1436_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1436_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1436_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1436_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1436_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1436_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1436_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1437_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1437_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1437_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1437_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1437_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1437_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1437_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1437_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1437_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1437_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1438_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1438_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1438_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1438_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1438_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1438_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1438_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1438_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1438_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1438_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1439_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1439_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1439_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1439_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1439_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1439_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1439_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1439_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1439_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1439_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1440_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1440_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1440_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1440_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1440_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1440_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1440_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1440_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1440_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1440_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1441_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1441_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1441_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1441_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1441_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1441_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1441_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1441_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1441_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1441_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1442_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1442_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1442_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1442_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1442_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1442_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1442_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1442_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1442_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1442_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1443_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1443_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1443_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1443_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1443_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1443_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1443_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1443_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1443_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1443_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1444_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1444_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1444_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1444_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1444_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1444_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1444_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1444_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1444_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1444_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1445_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1445_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1445_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1445_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1445_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1445_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1445_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1445_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1445_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1445_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1446_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1446_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1446_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1446_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1446_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1446_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1446_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1446_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1446_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1446_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1447_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1447_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1447_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1447_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1447_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1447_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1447_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1447_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1447_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1447_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1448_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1448_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1448_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1448_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1448_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1448_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1448_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1448_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1448_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1448_9.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1449_1.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1449_10.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1449_2.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1449_3.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1449_4.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1449_5.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1449_6.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1449_7.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1449_8.png  \n",
            "  inflating: ./SOTS/SOTS/indoor/hazy/1449_9.png  \n",
            "   creating: ./SOTS/SOTS/outdoor/\n",
            "   creating: ./SOTS/SOTS/outdoor/gt/\n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0001.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0002.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0003.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0004.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0006.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0007.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0009.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0010.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0011.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0014.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0016.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0017.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0018.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0019.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0021.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0022.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0023.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0024.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0025.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0026.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0029.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0030.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0033.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0034.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0036.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0039.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0040.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0042.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0045.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0046.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0047.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0048.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0049.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0051.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0052.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0053.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0054.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0055.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0056.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0057.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0058.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0059.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0060.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0061.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0062.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0063.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0064.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0065.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0066.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0068.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0069.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0070.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0071.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0072.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0073.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0074.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0075.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0076.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0077.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0079.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0081.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0082.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0083.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0084.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0085.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0086.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0087.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0088.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0089.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0090.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0091.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0092.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0093.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0094.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0095.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0096.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0097.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0098.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0099.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0100.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0101.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0102.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0104.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0105.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0106.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0107.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0108.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0109.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0110.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0111.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0112.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0113.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0115.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0116.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0117.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0118.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0119.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0120.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0121.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0123.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0125.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0126.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0127.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0129.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0131.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0132.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0133.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0134.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0135.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0137.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0138.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0139.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0140.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0141.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0142.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0143.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0145.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0146.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0147.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0148.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0149.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0150.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0151.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0152.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0153.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0154.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0155.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0157.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0158.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0160.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0161.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0162.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0163.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0164.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0165.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0166.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0167.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0168.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0169.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0170.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0171.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0172.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0174.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0175.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0176.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0178.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0179.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0180.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0181.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0182.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0183.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0184.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0185.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0187.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0188.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0189.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0191.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0194.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0195.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0196.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0197.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0198.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0199.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0200.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0201.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0202.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0204.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0205.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0206.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0207.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0208.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0209.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0210.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0212.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0213.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0215.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0216.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0217.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0218.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0219.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0220.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0222.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0223.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0225.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0226.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0228.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0230.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0233.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0235.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0237.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0238.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0239.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0240.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0242.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0243.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0244.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0245.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0246.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0248.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0249.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0251.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0253.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0255.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0256.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0258.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0259.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0260.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0261.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0262.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0263.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0264.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0266.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0267.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0268.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0269.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0270.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0271.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0272.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0273.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0274.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0275.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0276.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0277.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0279.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0280.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0281.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0282.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0283.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0284.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0285.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0286.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0287.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0288.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0290.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0291.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0292.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0294.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0295.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0296.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0297.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0298.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0299.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0300.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0302.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0303.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0304.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0305.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0306.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0307.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0308.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0309.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0311.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0312.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0313.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0314.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0315.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0316.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0317.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0318.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0319.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0320.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0321.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0323.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0324.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0325.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0326.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0327.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0329.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0330.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0331.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0332.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0333.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0334.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0335.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0337.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0338.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0340.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0341.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0342.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0343.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0344.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0345.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0346.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0348.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0349.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0350.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0351.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0353.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0354.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0355.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0356.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0357.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0359.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0361.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0362.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0364.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0366.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0369.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0371.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0372.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0375.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0380.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0382.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0383.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0385.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0386.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0388.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0390.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0391.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0392.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0393.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0395.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0397.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0399.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0400.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0402.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0404.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0405.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0406.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0407.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0409.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0411.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/0413.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1001.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1002.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1005.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1006.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1007.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1008.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1009.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1010.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1011.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1012.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1015.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1016.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1018.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1020.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1022.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1027.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1030.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1034.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1037.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1038.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1040.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1042.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1044.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1046.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1048.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1050.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1051.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1053.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1055.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1057.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1059.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1060.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1063.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1709.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1712.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1713.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1714.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1716.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1718.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1722.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1724.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1726.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1728.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1730.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1731.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1732.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1734.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1736.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1738.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1741.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1742.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1743.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1744.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1747.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1749.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1753.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1756.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1757.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1759.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1760.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1765.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1771.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1774.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1778.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1781.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1784.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1790.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1800.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1805.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1812.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1815.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1818.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1821.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1822.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1824.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1826.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1828.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1831.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1832.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1834.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1837.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1839.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1840.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1843.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1845.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1846.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1848.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1849.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1851.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1852.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1853.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1855.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1857.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1858.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1859.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1861.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1862.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1863.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1865.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1867.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1868.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1869.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1871.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1872.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1873.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1874.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1875.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1876.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1877.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1878.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1879.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1880.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1881.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1882.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1883.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1887.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1889.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1891.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1893.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1896.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1898.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1899.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1900.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1903.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1909.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1913.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1915.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1917.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1919.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1920.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1921.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1923.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1924.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1926.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1927.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1928.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1930.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1931.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1932.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1933.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1934.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1936.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1938.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1940.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1942.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1944.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1945.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1947.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1949.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1950.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1953.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1954.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1956.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1958.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1960.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1962.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1964.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1966.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1968.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1970.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1971.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1973.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1975.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1977.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1981.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1982.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1984.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1986.png  \n",
            "  inflating: ./SOTS/SOTS/outdoor/gt/1988.png  \n",
            "   creating: ./SOTS/SOTS/outdoor/hazy/\n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0001_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0002_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0003_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0004_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0006_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0007_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0009_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0010_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0011_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0014_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0016_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0017_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0018_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0019_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0021_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0022_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0023_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0024_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0025_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0026_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0029_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0030_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0033_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0034_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0036_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0039_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0040_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0042_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0045_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0046_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0047_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0048_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0049_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0051_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0051_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0052_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0053_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0054_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0055_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0056_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0057_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0058_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0059_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0060_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0061_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0062_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0063_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0064_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0065_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0066_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0068_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0069_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0070_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0071_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0072_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0073_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0074_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0075_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0076_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0076_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0077_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0079_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0081_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0082_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0083_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0084_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0085_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0086_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0086_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0087_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0088_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0089_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0090_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0091_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0092_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0093_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0094_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0095_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0096_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0097_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0098_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0099_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0100_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0101_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0102_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0104_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0105_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0106_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0107_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0108_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0108_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0109_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0110_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0111_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0112_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0113_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0115_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0116_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0117_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0118_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0119_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0120_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0121_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0123_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0125_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0126_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0127_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0129_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0131_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0132_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0133_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0134_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0135_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0137_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0138_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0139_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0140_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0141_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0142_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0143_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0145_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0146_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0147_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0148_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0149_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0150_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0151_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0152_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0153_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0154_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0155_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0157_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0158_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0160_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0161_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0162_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0163_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0164_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0165_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0166_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0167_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0168_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0169_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0170_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0171_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0172_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0174_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0175_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0176_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0178_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0179_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0180_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0181_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0182_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0183_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0184_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0185_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0187_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0188_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0189_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0191_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0194_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0195_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0196_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0197_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0198_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0199_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0200_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0201_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0202_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0204_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0205_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0206_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0207_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0208_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0209_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0210_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0212_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0213_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0215_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0216_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0217_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0218_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0219_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0220_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0222_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0223_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0225_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0226_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0228_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0230_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0233_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0235_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0237_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0238_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0239_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0240_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0242_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0243_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0244_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0245_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0246_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0248_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0249_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0251_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0253_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0253_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0255_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0256_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0258_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0259_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0260_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0261_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0262_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0263_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0264_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0266_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0268_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0267_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0269_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0270_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0271_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0272_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0273_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0274_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0275_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0276_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0277_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0279_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0280_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0281_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0282_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0283_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0284_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0285_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0286_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0287_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0287_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0288_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0290_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0291_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0292_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0294_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0295_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0296_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0297_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0298_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0299_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0300_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0302_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0303_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0304_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0305_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0306_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0307_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0308_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0309_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0311_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0312_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0313_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0314_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0315_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0316_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0317_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0318_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0319_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0320_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0320_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0321_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0323_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0324_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0325_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0326_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0327_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0329_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0330_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0330_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0331_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0332_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0333_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0334_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0335_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0337_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0338_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0340_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0341_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0342_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0343_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0344_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0345_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0346_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0348_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0349_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0350_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0351_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0353_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0354_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0355_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0356_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0357_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0359_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0361_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0362_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0364_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0366_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0369_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0371_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0372_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0375_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0380_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0382_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0383_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0385_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0386_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0388_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0390_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0391_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0392_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0393_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0395_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0397_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0399_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0400_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0402_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0404_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0406_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0405_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0407_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0409_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0411_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/0413_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1001_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1002_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1005_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1006_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1007_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1008_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1009_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1010_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1011_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1012_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1015_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1016_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1018_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1020_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1022_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1027_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1030_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1034_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1037_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1038_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1040_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1042_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1044_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1046_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1048_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1050_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1051_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1053_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1055_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1057_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1059_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1060_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1063_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1709_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1712_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1713_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1714_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1716_0.95_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1718_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1722_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1724_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1726_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1728_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1730_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1731_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1732_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1734_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1736_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1738_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1741_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1742_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1743_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1744_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1747_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1749_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1753_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1756_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1757_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1759_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1760_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1765_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1771_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1774_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1778_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1781_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1784_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1790_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1800_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1805_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1812_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1815_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1818_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1821_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1822_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1824_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1826_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1828_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1831_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1832_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1834_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1837_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1839_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1840_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1843_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1845_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1846_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1848_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1849_1_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1851_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1852_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1853_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1855_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1857_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1858_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1859_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1861_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1862_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1863_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1865_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1867_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1868_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1869_1_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1871_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1872_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1873_0.85_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1874_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1875_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1876_1_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1877_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1878_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1879_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1880_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1881_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1882_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1883_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1887_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1889_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1891_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1893_0.9_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1896_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1898_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1899_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1900_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1903_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1909_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1913_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1915_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1917_0.95_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1919_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1920_0.95_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1921_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1923_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1924_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1926_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1927_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1928_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1930_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1931_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1932_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1933_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1934_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1936_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1938_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1940_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1942_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1944_0.9_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1945_0.9_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1947_0.8_0.16.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1949_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1950_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1953_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1954_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1956_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1958_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1960_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1962_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1964_0.85_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1966_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1968_0.8_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1970_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1971_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1973_0.95_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1975_0.85_0.12.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1977_0.8_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1981_0.8_0.2.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1982_1_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1984_0.85_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1986_0.9_0.08.jpg  \n",
            "  inflating: ./SOTS/SOTS/outdoor/hazy/1988_0.8_0.12.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inPOzALbGdWi"
      },
      "source": [
        "Main (test model)\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-GT-zvtFgE5",
        "outputId": "d50809a2-32e9-4ea5-dd7c-509bcc639959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.Args object at 0x7c4cc873a200>\n",
            "IRNeXt(\n",
            "  (Encoder): ModuleList(\n",
            "    (0): EBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): EBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(64, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): EBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(128, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (feat_extract): ModuleList(\n",
            "    (0): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (1): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (2): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (3): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (4): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (5): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (Decoder): ModuleList(\n",
            "    (0): DBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(128, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): DBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(64, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): DBlock(\n",
            "      (layers): Sequential(\n",
            "        (0): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): Identity()\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResBlock(\n",
            "          (main): Sequential(\n",
            "            (0): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "              )\n",
            "            )\n",
            "            (1): DeepPoolLayer(\n",
            "              (pools): ModuleList(\n",
            "                (0): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "                (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "                (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "              )\n",
            "              (convs): ModuleList(\n",
            "                (0-2): 3 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              )\n",
            "              (dynas): ModuleList(\n",
            "                (0-2): 3 x dynamic_filter(\n",
            "                  (conv): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (act): Tanh()\n",
            "                  (pad): ReflectionPad2d((1, 1, 1, 1))\n",
            "                  (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "                  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "                )\n",
            "              )\n",
            "              (relu): GELU(approximate='none')\n",
            "              (conv_sum): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            )\n",
            "            (2): BasicConv(\n",
            "              (main): Sequential(\n",
            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (Convs): ModuleList(\n",
            "    (0): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "    (1): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): GELU(approximate='none')\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ConvsOut): ModuleList(\n",
            "    (0): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (1): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (FAM1): FAM(\n",
            "    (merge): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (SCM1): SCM(\n",
            "    (main): Sequential(\n",
            "      (0): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (1): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (2): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (3): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "    )\n",
            "  )\n",
            "  (FAM2): FAM(\n",
            "    (merge): BasicConv(\n",
            "      (main): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (SCM2): SCM(\n",
            "    (main): Sequential(\n",
            "      (0): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (1): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (2): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (3): BasicConv(\n",
            "        (main): Sequential(\n",
            "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "1 iter PSNR_dehazing: 39.57 ssim: 0.997136\n",
            "1 iter PSNR: 39.57 time: 8.482759\n",
            "2 iter PSNR_dehazing: 38.86 ssim: 0.993755\n",
            "2 iter PSNR: 38.86 time: 0.027066\n",
            "3 iter PSNR_dehazing: 40.04 ssim: 0.997027\n",
            "3 iter PSNR: 40.04 time: 0.026206\n",
            "4 iter PSNR_dehazing: 39.77 ssim: 0.996765\n",
            "4 iter PSNR: 39.77 time: 0.026561\n",
            "5 iter PSNR_dehazing: 40.15 ssim: 0.996358\n",
            "5 iter PSNR: 40.15 time: 0.026334\n",
            "6 iter PSNR_dehazing: 39.89 ssim: 0.996000\n",
            "6 iter PSNR: 39.89 time: 0.029589\n",
            "7 iter PSNR_dehazing: 39.64 ssim: 0.995211\n",
            "7 iter PSNR: 39.64 time: 0.026451\n",
            "8 iter PSNR_dehazing: 39.50 ssim: 0.995097\n",
            "8 iter PSNR: 39.50 time: 0.029233\n",
            "9 iter PSNR_dehazing: 39.26 ssim: 0.994522\n",
            "9 iter PSNR: 39.26 time: 0.027902\n",
            "10 iter PSNR_dehazing: 39.29 ssim: 0.994044\n",
            "10 iter PSNR: 39.29 time: 0.025179\n",
            "11 iter PSNR_dehazing: 42.87 ssim: 0.997943\n",
            "11 iter PSNR: 42.87 time: 0.023793\n",
            "12 iter PSNR_dehazing: 39.60 ssim: 0.994689\n",
            "12 iter PSNR: 39.60 time: 0.025264\n",
            "13 iter PSNR_dehazing: 43.17 ssim: 0.997664\n",
            "13 iter PSNR: 43.17 time: 0.025644\n",
            "14 iter PSNR_dehazing: 42.79 ssim: 0.997443\n",
            "14 iter PSNR: 42.79 time: 0.024709\n",
            "15 iter PSNR_dehazing: 42.37 ssim: 0.996942\n",
            "15 iter PSNR: 42.37 time: 0.024782\n",
            "16 iter PSNR_dehazing: 42.06 ssim: 0.996823\n",
            "16 iter PSNR: 42.06 time: 0.025912\n",
            "17 iter PSNR_dehazing: 41.16 ssim: 0.996403\n",
            "17 iter PSNR: 41.16 time: 0.026173\n",
            "18 iter PSNR_dehazing: 41.05 ssim: 0.995915\n",
            "18 iter PSNR: 41.05 time: 0.037252\n",
            "19 iter PSNR_dehazing: 41.01 ssim: 0.995534\n",
            "19 iter PSNR: 41.01 time: 0.026712\n",
            "20 iter PSNR_dehazing: 40.26 ssim: 0.995094\n",
            "20 iter PSNR: 40.26 time: 0.027020\n",
            "21 iter PSNR_dehazing: 42.64 ssim: 0.997572\n",
            "21 iter PSNR: 42.64 time: 0.028407\n",
            "22 iter PSNR_dehazing: 38.97 ssim: 0.994277\n",
            "22 iter PSNR: 38.97 time: 0.029814\n",
            "23 iter PSNR_dehazing: 42.69 ssim: 0.997355\n",
            "23 iter PSNR: 42.69 time: 0.025537\n",
            "24 iter PSNR_dehazing: 41.56 ssim: 0.997012\n",
            "24 iter PSNR: 41.56 time: 0.027436\n",
            "25 iter PSNR_dehazing: 41.35 ssim: 0.996839\n",
            "25 iter PSNR: 41.35 time: 0.029564\n",
            "26 iter PSNR_dehazing: 40.80 ssim: 0.996407\n",
            "26 iter PSNR: 40.80 time: 0.025184\n",
            "27 iter PSNR_dehazing: 40.54 ssim: 0.995910\n",
            "27 iter PSNR: 40.54 time: 0.024315\n",
            "28 iter PSNR_dehazing: 39.91 ssim: 0.995464\n",
            "28 iter PSNR: 39.91 time: 0.019266\n",
            "29 iter PSNR_dehazing: 39.33 ssim: 0.995011\n",
            "29 iter PSNR: 39.33 time: 0.021164\n",
            "30 iter PSNR_dehazing: 39.24 ssim: 0.994595\n",
            "30 iter PSNR: 39.24 time: 0.028786\n",
            "31 iter PSNR_dehazing: 46.84 ssim: 0.998540\n",
            "31 iter PSNR: 46.84 time: 0.019572\n",
            "32 iter PSNR_dehazing: 41.13 ssim: 0.995307\n",
            "32 iter PSNR: 41.13 time: 0.018863\n",
            "33 iter PSNR_dehazing: 46.60 ssim: 0.997980\n",
            "33 iter PSNR: 46.60 time: 0.022832\n",
            "34 iter PSNR_dehazing: 45.32 ssim: 0.997926\n",
            "34 iter PSNR: 45.32 time: 0.019157\n",
            "35 iter PSNR_dehazing: 44.06 ssim: 0.997533\n",
            "35 iter PSNR: 44.06 time: 0.020243\n",
            "36 iter PSNR_dehazing: 43.88 ssim: 0.997197\n",
            "36 iter PSNR: 43.88 time: 0.022780\n",
            "37 iter PSNR_dehazing: 42.90 ssim: 0.996660\n",
            "37 iter PSNR: 42.90 time: 0.019673\n",
            "38 iter PSNR_dehazing: 43.26 ssim: 0.996586\n",
            "38 iter PSNR: 43.26 time: 0.019450\n",
            "39 iter PSNR_dehazing: 42.18 ssim: 0.996062\n",
            "39 iter PSNR: 42.18 time: 0.022974\n",
            "40 iter PSNR_dehazing: 41.37 ssim: 0.995705\n",
            "40 iter PSNR: 41.37 time: 0.019688\n",
            "41 iter PSNR_dehazing: 43.33 ssim: 0.998239\n",
            "41 iter PSNR: 43.33 time: 0.019583\n",
            "42 iter PSNR_dehazing: 39.80 ssim: 0.994620\n",
            "42 iter PSNR: 39.80 time: 0.018943\n",
            "43 iter PSNR_dehazing: 42.77 ssim: 0.997957\n",
            "43 iter PSNR: 42.77 time: 0.019656\n",
            "44 iter PSNR_dehazing: 42.50 ssim: 0.997620\n",
            "44 iter PSNR: 42.50 time: 0.028131\n",
            "45 iter PSNR_dehazing: 42.09 ssim: 0.997183\n",
            "45 iter PSNR: 42.09 time: 0.021381\n",
            "46 iter PSNR_dehazing: 41.48 ssim: 0.996873\n",
            "46 iter PSNR: 41.48 time: 0.022992\n",
            "47 iter PSNR_dehazing: 41.14 ssim: 0.996457\n",
            "47 iter PSNR: 41.14 time: 0.019269\n",
            "48 iter PSNR_dehazing: 40.68 ssim: 0.995912\n",
            "48 iter PSNR: 40.68 time: 0.020551\n",
            "49 iter PSNR_dehazing: 40.26 ssim: 0.995403\n",
            "49 iter PSNR: 40.26 time: 0.018525\n",
            "50 iter PSNR_dehazing: 40.00 ssim: 0.995004\n",
            "50 iter PSNR: 40.00 time: 0.019374\n",
            "51 iter PSNR_dehazing: 40.01 ssim: 0.997859\n",
            "51 iter PSNR: 40.01 time: 0.019313\n",
            "52 iter PSNR_dehazing: 36.14 ssim: 0.993781\n",
            "52 iter PSNR: 36.14 time: 0.018573\n",
            "53 iter PSNR_dehazing: 39.23 ssim: 0.997331\n",
            "53 iter PSNR: 39.23 time: 0.018255\n",
            "54 iter PSNR_dehazing: 38.38 ssim: 0.996838\n",
            "54 iter PSNR: 38.38 time: 0.018931\n",
            "55 iter PSNR_dehazing: 38.16 ssim: 0.996461\n",
            "55 iter PSNR: 38.16 time: 0.019700\n",
            "56 iter PSNR_dehazing: 37.86 ssim: 0.996108\n",
            "56 iter PSNR: 37.86 time: 0.018869\n",
            "57 iter PSNR_dehazing: 37.32 ssim: 0.995620\n",
            "57 iter PSNR: 37.32 time: 0.019308\n",
            "58 iter PSNR_dehazing: 37.09 ssim: 0.995185\n",
            "58 iter PSNR: 37.09 time: 0.020007\n",
            "59 iter PSNR_dehazing: 36.67 ssim: 0.994620\n",
            "59 iter PSNR: 36.67 time: 0.018979\n",
            "60 iter PSNR_dehazing: 36.70 ssim: 0.994391\n",
            "60 iter PSNR: 36.70 time: 0.019413\n",
            "61 iter PSNR_dehazing: 42.28 ssim: 0.997700\n",
            "61 iter PSNR: 42.28 time: 0.019632\n",
            "62 iter PSNR_dehazing: 37.35 ssim: 0.992857\n",
            "62 iter PSNR: 37.35 time: 0.019862\n",
            "63 iter PSNR_dehazing: 41.68 ssim: 0.997304\n",
            "63 iter PSNR: 41.68 time: 0.019278\n",
            "64 iter PSNR_dehazing: 41.33 ssim: 0.996826\n",
            "64 iter PSNR: 41.33 time: 0.018557\n",
            "65 iter PSNR_dehazing: 40.85 ssim: 0.996408\n",
            "65 iter PSNR: 40.85 time: 0.020258\n",
            "66 iter PSNR_dehazing: 40.41 ssim: 0.996024\n",
            "66 iter PSNR: 40.41 time: 0.019233\n",
            "67 iter PSNR_dehazing: 39.81 ssim: 0.995293\n",
            "67 iter PSNR: 39.81 time: 0.018867\n",
            "68 iter PSNR_dehazing: 39.11 ssim: 0.994769\n",
            "68 iter PSNR: 39.11 time: 0.019053\n",
            "69 iter PSNR_dehazing: 38.87 ssim: 0.994228\n",
            "69 iter PSNR: 38.87 time: 0.019485\n",
            "70 iter PSNR_dehazing: 38.11 ssim: 0.993590\n",
            "70 iter PSNR: 38.11 time: 0.021544\n",
            "71 iter PSNR_dehazing: 44.00 ssim: 0.998259\n",
            "71 iter PSNR: 44.00 time: 0.019413\n",
            "72 iter PSNR_dehazing: 39.25 ssim: 0.994442\n",
            "72 iter PSNR: 39.25 time: 0.019683\n",
            "73 iter PSNR_dehazing: 43.01 ssim: 0.997882\n",
            "73 iter PSNR: 43.01 time: 0.019911\n",
            "74 iter PSNR_dehazing: 42.25 ssim: 0.997480\n",
            "74 iter PSNR: 42.25 time: 0.018919\n",
            "75 iter PSNR_dehazing: 41.98 ssim: 0.997252\n",
            "75 iter PSNR: 41.98 time: 0.020137\n",
            "76 iter PSNR_dehazing: 41.45 ssim: 0.996648\n",
            "76 iter PSNR: 41.45 time: 0.019212\n",
            "77 iter PSNR_dehazing: 41.12 ssim: 0.996230\n",
            "77 iter PSNR: 41.12 time: 0.021369\n",
            "78 iter PSNR_dehazing: 40.64 ssim: 0.995739\n",
            "78 iter PSNR: 40.64 time: 0.019864\n",
            "79 iter PSNR_dehazing: 39.97 ssim: 0.995460\n",
            "79 iter PSNR: 39.97 time: 0.020730\n",
            "80 iter PSNR_dehazing: 39.59 ssim: 0.994693\n",
            "80 iter PSNR: 39.59 time: 0.019783\n",
            "81 iter PSNR_dehazing: 44.74 ssim: 0.998766\n",
            "81 iter PSNR: 44.74 time: 0.020272\n",
            "82 iter PSNR_dehazing: 40.02 ssim: 0.996666\n",
            "82 iter PSNR: 40.02 time: 0.018476\n",
            "83 iter PSNR_dehazing: 44.13 ssim: 0.998629\n",
            "83 iter PSNR: 44.13 time: 0.018976\n",
            "84 iter PSNR_dehazing: 43.48 ssim: 0.998403\n",
            "84 iter PSNR: 43.48 time: 0.021292\n",
            "85 iter PSNR_dehazing: 43.05 ssim: 0.998204\n",
            "85 iter PSNR: 43.05 time: 0.019847\n",
            "86 iter PSNR_dehazing: 42.30 ssim: 0.997971\n",
            "86 iter PSNR: 42.30 time: 0.018808\n",
            "87 iter PSNR_dehazing: 41.86 ssim: 0.997719\n",
            "87 iter PSNR: 41.86 time: 0.022187\n",
            "88 iter PSNR_dehazing: 41.18 ssim: 0.997482\n",
            "88 iter PSNR: 41.18 time: 0.019373\n",
            "89 iter PSNR_dehazing: 40.85 ssim: 0.997110\n",
            "89 iter PSNR: 40.85 time: 0.019048\n",
            "90 iter PSNR_dehazing: 40.55 ssim: 0.996979\n",
            "90 iter PSNR: 40.55 time: 0.021948\n",
            "91 iter PSNR_dehazing: 40.56 ssim: 0.998021\n",
            "91 iter PSNR: 40.56 time: 0.019584\n",
            "92 iter PSNR_dehazing: 36.91 ssim: 0.994134\n",
            "92 iter PSNR: 36.91 time: 0.019566\n",
            "93 iter PSNR_dehazing: 40.33 ssim: 0.997724\n",
            "93 iter PSNR: 40.33 time: 0.019170\n",
            "94 iter PSNR_dehazing: 39.83 ssim: 0.997351\n",
            "94 iter PSNR: 39.83 time: 0.019446\n",
            "95 iter PSNR_dehazing: 39.61 ssim: 0.996987\n",
            "95 iter PSNR: 39.61 time: 0.018796\n",
            "96 iter PSNR_dehazing: 38.90 ssim: 0.996479\n",
            "96 iter PSNR: 38.90 time: 0.019016\n",
            "97 iter PSNR_dehazing: 38.48 ssim: 0.996125\n",
            "97 iter PSNR: 38.48 time: 0.022918\n",
            "98 iter PSNR_dehazing: 37.61 ssim: 0.995542\n",
            "98 iter PSNR: 37.61 time: 0.019048\n",
            "99 iter PSNR_dehazing: 37.33 ssim: 0.995092\n",
            "99 iter PSNR: 37.33 time: 0.021902\n",
            "100 iter PSNR_dehazing: 37.44 ssim: 0.994636\n",
            "100 iter PSNR: 37.44 time: 0.024744\n",
            "101 iter PSNR_dehazing: 42.20 ssim: 0.997736\n",
            "101 iter PSNR: 42.20 time: 0.019544\n",
            "102 iter PSNR_dehazing: 37.85 ssim: 0.992350\n",
            "102 iter PSNR: 37.85 time: 0.019037\n",
            "103 iter PSNR_dehazing: 41.64 ssim: 0.997341\n",
            "103 iter PSNR: 41.64 time: 0.020867\n",
            "104 iter PSNR_dehazing: 40.87 ssim: 0.996883\n",
            "104 iter PSNR: 40.87 time: 0.018942\n",
            "105 iter PSNR_dehazing: 40.08 ssim: 0.996131\n",
            "105 iter PSNR: 40.08 time: 0.019732\n",
            "106 iter PSNR_dehazing: 40.09 ssim: 0.995950\n",
            "106 iter PSNR: 40.09 time: 0.019228\n",
            "107 iter PSNR_dehazing: 39.42 ssim: 0.995349\n",
            "107 iter PSNR: 39.42 time: 0.018785\n",
            "108 iter PSNR_dehazing: 38.74 ssim: 0.994589\n",
            "108 iter PSNR: 38.74 time: 0.018867\n",
            "109 iter PSNR_dehazing: 39.02 ssim: 0.994048\n",
            "109 iter PSNR: 39.02 time: 0.018686\n",
            "110 iter PSNR_dehazing: 38.52 ssim: 0.993381\n",
            "110 iter PSNR: 38.52 time: 0.018943\n",
            "111 iter PSNR_dehazing: 43.17 ssim: 0.997341\n",
            "111 iter PSNR: 43.17 time: 0.018958\n",
            "112 iter PSNR_dehazing: 38.47 ssim: 0.993811\n",
            "112 iter PSNR: 38.47 time: 0.019386\n",
            "113 iter PSNR_dehazing: 42.17 ssim: 0.996692\n",
            "113 iter PSNR: 42.17 time: 0.020704\n",
            "114 iter PSNR_dehazing: 42.22 ssim: 0.996423\n",
            "114 iter PSNR: 42.22 time: 0.019244\n",
            "115 iter PSNR_dehazing: 41.59 ssim: 0.995682\n",
            "115 iter PSNR: 41.59 time: 0.022255\n",
            "116 iter PSNR_dehazing: 41.23 ssim: 0.995511\n",
            "116 iter PSNR: 41.23 time: 0.022051\n",
            "117 iter PSNR_dehazing: 40.76 ssim: 0.995154\n",
            "117 iter PSNR: 40.76 time: 0.020772\n",
            "118 iter PSNR_dehazing: 39.88 ssim: 0.994472\n",
            "118 iter PSNR: 39.88 time: 0.018979\n",
            "119 iter PSNR_dehazing: 39.81 ssim: 0.994558\n",
            "119 iter PSNR: 39.81 time: 0.019808\n",
            "120 iter PSNR_dehazing: 39.36 ssim: 0.994160\n",
            "120 iter PSNR: 39.36 time: 0.019137\n",
            "121 iter PSNR_dehazing: 38.16 ssim: 0.995471\n",
            "121 iter PSNR: 38.16 time: 0.019132\n",
            "122 iter PSNR_dehazing: 33.02 ssim: 0.986449\n",
            "122 iter PSNR: 33.02 time: 0.019016\n",
            "123 iter PSNR_dehazing: 38.04 ssim: 0.994727\n",
            "123 iter PSNR: 38.04 time: 0.019513\n",
            "124 iter PSNR_dehazing: 37.03 ssim: 0.994013\n",
            "124 iter PSNR: 37.03 time: 0.018512\n",
            "125 iter PSNR_dehazing: 35.56 ssim: 0.992387\n",
            "125 iter PSNR: 35.56 time: 0.019037\n",
            "126 iter PSNR_dehazing: 35.93 ssim: 0.991868\n",
            "126 iter PSNR: 35.93 time: 0.019585\n",
            "127 iter PSNR_dehazing: 35.13 ssim: 0.990311\n",
            "127 iter PSNR: 35.13 time: 0.019603\n",
            "128 iter PSNR_dehazing: 33.77 ssim: 0.988090\n",
            "128 iter PSNR: 33.77 time: 0.020143\n",
            "129 iter PSNR_dehazing: 33.85 ssim: 0.988694\n",
            "129 iter PSNR: 33.85 time: 0.019843\n",
            "130 iter PSNR_dehazing: 33.13 ssim: 0.987379\n",
            "130 iter PSNR: 33.13 time: 0.020808\n",
            "131 iter PSNR_dehazing: 41.82 ssim: 0.996925\n",
            "131 iter PSNR: 41.82 time: 0.021541\n",
            "132 iter PSNR_dehazing: 36.71 ssim: 0.990138\n",
            "132 iter PSNR: 36.71 time: 0.025254\n",
            "133 iter PSNR_dehazing: 40.95 ssim: 0.996410\n",
            "133 iter PSNR: 40.95 time: 0.019914\n",
            "134 iter PSNR_dehazing: 40.51 ssim: 0.996066\n",
            "134 iter PSNR: 40.51 time: 0.020009\n",
            "135 iter PSNR_dehazing: 39.59 ssim: 0.994949\n",
            "135 iter PSNR: 39.59 time: 0.019466\n",
            "136 iter PSNR_dehazing: 39.18 ssim: 0.994561\n",
            "136 iter PSNR: 39.18 time: 0.019204\n",
            "137 iter PSNR_dehazing: 38.43 ssim: 0.993400\n",
            "137 iter PSNR: 38.43 time: 0.020783\n",
            "138 iter PSNR_dehazing: 38.22 ssim: 0.992935\n",
            "138 iter PSNR: 38.22 time: 0.018841\n",
            "139 iter PSNR_dehazing: 37.44 ssim: 0.992604\n",
            "139 iter PSNR: 37.44 time: 0.018747\n",
            "140 iter PSNR_dehazing: 37.47 ssim: 0.991230\n",
            "140 iter PSNR: 37.47 time: 0.021643\n",
            "141 iter PSNR_dehazing: 42.77 ssim: 0.997432\n",
            "141 iter PSNR: 42.77 time: 0.020021\n",
            "142 iter PSNR_dehazing: 39.00 ssim: 0.993747\n",
            "142 iter PSNR: 39.00 time: 0.019654\n",
            "143 iter PSNR_dehazing: 42.87 ssim: 0.997258\n",
            "143 iter PSNR: 42.87 time: 0.020904\n",
            "144 iter PSNR_dehazing: 42.23 ssim: 0.996785\n",
            "144 iter PSNR: 42.23 time: 0.019314\n",
            "145 iter PSNR_dehazing: 41.62 ssim: 0.996345\n",
            "145 iter PSNR: 41.62 time: 0.024587\n",
            "146 iter PSNR_dehazing: 40.67 ssim: 0.995558\n",
            "146 iter PSNR: 40.67 time: 0.018863\n",
            "147 iter PSNR_dehazing: 40.80 ssim: 0.995252\n",
            "147 iter PSNR: 40.80 time: 0.019424\n",
            "148 iter PSNR_dehazing: 39.95 ssim: 0.994828\n",
            "148 iter PSNR: 39.95 time: 0.019156\n",
            "149 iter PSNR_dehazing: 39.47 ssim: 0.994752\n",
            "149 iter PSNR: 39.47 time: 0.019453\n",
            "150 iter PSNR_dehazing: 39.28 ssim: 0.994377\n",
            "150 iter PSNR: 39.28 time: 0.019196\n",
            "151 iter PSNR_dehazing: 43.27 ssim: 0.997544\n",
            "151 iter PSNR: 43.27 time: 0.019542\n",
            "152 iter PSNR_dehazing: 37.80 ssim: 0.992656\n",
            "152 iter PSNR: 37.80 time: 0.018925\n",
            "153 iter PSNR_dehazing: 43.02 ssim: 0.997229\n",
            "153 iter PSNR: 43.02 time: 0.019243\n",
            "154 iter PSNR_dehazing: 42.46 ssim: 0.996711\n",
            "154 iter PSNR: 42.46 time: 0.019561\n",
            "155 iter PSNR_dehazing: 41.08 ssim: 0.996175\n",
            "155 iter PSNR: 41.08 time: 0.018753\n",
            "156 iter PSNR_dehazing: 40.68 ssim: 0.995725\n",
            "156 iter PSNR: 40.68 time: 0.019236\n",
            "157 iter PSNR_dehazing: 40.62 ssim: 0.995232\n",
            "157 iter PSNR: 40.62 time: 0.019698\n",
            "158 iter PSNR_dehazing: 39.65 ssim: 0.994645\n",
            "158 iter PSNR: 39.65 time: 0.023823\n",
            "159 iter PSNR_dehazing: 39.07 ssim: 0.994010\n",
            "159 iter PSNR: 39.07 time: 0.018719\n",
            "160 iter PSNR_dehazing: 38.76 ssim: 0.993539\n",
            "160 iter PSNR: 38.76 time: 0.019242\n",
            "161 iter PSNR_dehazing: 41.83 ssim: 0.998438\n",
            "161 iter PSNR: 41.83 time: 0.021394\n",
            "162 iter PSNR_dehazing: 38.85 ssim: 0.995464\n",
            "162 iter PSNR: 38.85 time: 0.019010\n",
            "163 iter PSNR_dehazing: 41.63 ssim: 0.997925\n",
            "163 iter PSNR: 41.63 time: 0.019979\n",
            "164 iter PSNR_dehazing: 40.63 ssim: 0.997756\n",
            "164 iter PSNR: 40.63 time: 0.019263\n",
            "165 iter PSNR_dehazing: 40.45 ssim: 0.997225\n",
            "165 iter PSNR: 40.45 time: 0.026362\n",
            "166 iter PSNR_dehazing: 40.04 ssim: 0.996822\n",
            "166 iter PSNR: 40.04 time: 0.029621\n",
            "167 iter PSNR_dehazing: 39.88 ssim: 0.996786\n",
            "167 iter PSNR: 39.88 time: 0.028200\n",
            "168 iter PSNR_dehazing: 39.48 ssim: 0.996556\n",
            "168 iter PSNR: 39.48 time: 0.025627\n",
            "169 iter PSNR_dehazing: 39.06 ssim: 0.996165\n",
            "169 iter PSNR: 39.06 time: 0.028233\n",
            "170 iter PSNR_dehazing: 38.89 ssim: 0.995861\n",
            "170 iter PSNR: 38.89 time: 0.028984\n",
            "171 iter PSNR_dehazing: 43.58 ssim: 0.998846\n",
            "171 iter PSNR: 43.58 time: 0.032069\n",
            "172 iter PSNR_dehazing: 39.05 ssim: 0.996348\n",
            "172 iter PSNR: 39.05 time: 0.029700\n",
            "173 iter PSNR_dehazing: 43.17 ssim: 0.998678\n",
            "173 iter PSNR: 43.17 time: 0.026426\n",
            "174 iter PSNR_dehazing: 42.85 ssim: 0.998378\n",
            "174 iter PSNR: 42.85 time: 0.026742\n",
            "175 iter PSNR_dehazing: 42.61 ssim: 0.998289\n",
            "175 iter PSNR: 42.61 time: 0.025834\n",
            "176 iter PSNR_dehazing: 41.79 ssim: 0.997937\n",
            "176 iter PSNR: 41.79 time: 0.025611\n",
            "177 iter PSNR_dehazing: 41.12 ssim: 0.997765\n",
            "177 iter PSNR: 41.12 time: 0.026636\n",
            "178 iter PSNR_dehazing: 40.50 ssim: 0.997391\n",
            "178 iter PSNR: 40.50 time: 0.024763\n",
            "179 iter PSNR_dehazing: 40.16 ssim: 0.997050\n",
            "179 iter PSNR: 40.16 time: 0.024652\n",
            "180 iter PSNR_dehazing: 39.60 ssim: 0.996722\n",
            "180 iter PSNR: 39.60 time: 0.024529\n",
            "181 iter PSNR_dehazing: 43.49 ssim: 0.998518\n",
            "181 iter PSNR: 43.49 time: 0.023928\n",
            "182 iter PSNR_dehazing: 39.69 ssim: 0.995592\n",
            "182 iter PSNR: 39.69 time: 0.027662\n",
            "183 iter PSNR_dehazing: 43.15 ssim: 0.998253\n",
            "183 iter PSNR: 43.15 time: 0.027643\n",
            "184 iter PSNR_dehazing: 42.24 ssim: 0.997930\n",
            "184 iter PSNR: 42.24 time: 0.025590\n",
            "185 iter PSNR_dehazing: 42.18 ssim: 0.997820\n",
            "185 iter PSNR: 42.18 time: 0.026174\n",
            "186 iter PSNR_dehazing: 41.77 ssim: 0.997494\n",
            "186 iter PSNR: 41.77 time: 0.027543\n",
            "187 iter PSNR_dehazing: 41.20 ssim: 0.997019\n",
            "187 iter PSNR: 41.20 time: 0.025603\n",
            "188 iter PSNR_dehazing: 41.03 ssim: 0.996865\n",
            "188 iter PSNR: 41.03 time: 0.027063\n",
            "189 iter PSNR_dehazing: 40.27 ssim: 0.996500\n",
            "189 iter PSNR: 40.27 time: 0.029867\n",
            "190 iter PSNR_dehazing: 40.14 ssim: 0.995978\n",
            "190 iter PSNR: 40.14 time: 0.025224\n",
            "191 iter PSNR_dehazing: 43.63 ssim: 0.998756\n",
            "191 iter PSNR: 43.63 time: 0.024640\n",
            "192 iter PSNR_dehazing: 38.67 ssim: 0.995738\n",
            "192 iter PSNR: 38.67 time: 0.025054\n",
            "193 iter PSNR_dehazing: 42.95 ssim: 0.998525\n",
            "193 iter PSNR: 42.95 time: 0.025064\n",
            "194 iter PSNR_dehazing: 42.25 ssim: 0.998246\n",
            "194 iter PSNR: 42.25 time: 0.029059\n",
            "195 iter PSNR_dehazing: 41.38 ssim: 0.997944\n",
            "195 iter PSNR: 41.38 time: 0.029138\n",
            "196 iter PSNR_dehazing: 40.93 ssim: 0.997566\n",
            "196 iter PSNR: 40.93 time: 0.027493\n",
            "197 iter PSNR_dehazing: 40.40 ssim: 0.997312\n",
            "197 iter PSNR: 40.40 time: 0.028013\n",
            "198 iter PSNR_dehazing: 39.45 ssim: 0.996847\n",
            "198 iter PSNR: 39.45 time: 0.026744\n",
            "199 iter PSNR_dehazing: 39.13 ssim: 0.996628\n",
            "199 iter PSNR: 39.13 time: 0.028186\n",
            "200 iter PSNR_dehazing: 38.37 ssim: 0.996106\n",
            "200 iter PSNR: 38.37 time: 0.027494\n",
            "201 iter PSNR_dehazing: 42.65 ssim: 0.998413\n",
            "201 iter PSNR: 42.65 time: 0.025060\n",
            "202 iter PSNR_dehazing: 38.04 ssim: 0.994221\n",
            "202 iter PSNR: 38.04 time: 0.026020\n",
            "203 iter PSNR_dehazing: 42.20 ssim: 0.998213\n",
            "203 iter PSNR: 42.20 time: 0.025216\n",
            "204 iter PSNR_dehazing: 41.59 ssim: 0.997785\n",
            "204 iter PSNR: 41.59 time: 0.030592\n",
            "205 iter PSNR_dehazing: 40.82 ssim: 0.997298\n",
            "205 iter PSNR: 40.82 time: 0.024849\n",
            "206 iter PSNR_dehazing: 40.79 ssim: 0.996830\n",
            "206 iter PSNR: 40.79 time: 0.028187\n",
            "207 iter PSNR_dehazing: 40.21 ssim: 0.996271\n",
            "207 iter PSNR: 40.21 time: 0.036728\n",
            "208 iter PSNR_dehazing: 39.68 ssim: 0.995906\n",
            "208 iter PSNR: 39.68 time: 0.026586\n",
            "209 iter PSNR_dehazing: 39.67 ssim: 0.995870\n",
            "209 iter PSNR: 39.67 time: 0.025217\n",
            "210 iter PSNR_dehazing: 38.72 ssim: 0.994964\n",
            "210 iter PSNR: 38.72 time: 0.024787\n",
            "211 iter PSNR_dehazing: 45.66 ssim: 0.998713\n",
            "211 iter PSNR: 45.66 time: 0.023963\n",
            "212 iter PSNR_dehazing: 40.38 ssim: 0.996079\n",
            "212 iter PSNR: 40.38 time: 0.024226\n",
            "213 iter PSNR_dehazing: 45.07 ssim: 0.998500\n",
            "213 iter PSNR: 45.07 time: 0.024464\n",
            "214 iter PSNR_dehazing: 43.72 ssim: 0.998270\n",
            "214 iter PSNR: 43.72 time: 0.025265\n",
            "215 iter PSNR_dehazing: 43.24 ssim: 0.997995\n",
            "215 iter PSNR: 43.24 time: 0.028855\n",
            "216 iter PSNR_dehazing: 42.50 ssim: 0.997621\n",
            "216 iter PSNR: 42.50 time: 0.026186\n",
            "217 iter PSNR_dehazing: 42.35 ssim: 0.997440\n",
            "217 iter PSNR: 42.35 time: 0.025362\n",
            "218 iter PSNR_dehazing: 41.73 ssim: 0.997030\n",
            "218 iter PSNR: 41.73 time: 0.033295\n",
            "219 iter PSNR_dehazing: 41.64 ssim: 0.996740\n",
            "219 iter PSNR: 41.64 time: 0.025320\n",
            "220 iter PSNR_dehazing: 41.10 ssim: 0.996328\n",
            "220 iter PSNR: 41.10 time: 0.025408\n",
            "221 iter PSNR_dehazing: 47.88 ssim: 0.997927\n",
            "221 iter PSNR: 47.88 time: 0.025641\n",
            "222 iter PSNR_dehazing: 41.43 ssim: 0.994936\n",
            "222 iter PSNR: 41.43 time: 0.025282\n",
            "223 iter PSNR_dehazing: 46.49 ssim: 0.997707\n",
            "223 iter PSNR: 46.49 time: 0.025677\n",
            "224 iter PSNR_dehazing: 45.71 ssim: 0.997499\n",
            "224 iter PSNR: 45.71 time: 0.027688\n",
            "225 iter PSNR_dehazing: 44.82 ssim: 0.997298\n",
            "225 iter PSNR: 44.82 time: 0.029707\n",
            "226 iter PSNR_dehazing: 44.62 ssim: 0.996766\n",
            "226 iter PSNR: 44.62 time: 0.028243\n",
            "227 iter PSNR_dehazing: 43.69 ssim: 0.996386\n",
            "227 iter PSNR: 43.69 time: 0.026634\n",
            "228 iter PSNR_dehazing: 42.79 ssim: 0.996132\n",
            "228 iter PSNR: 42.79 time: 0.026230\n",
            "229 iter PSNR_dehazing: 42.41 ssim: 0.995859\n",
            "229 iter PSNR: 42.41 time: 0.026333\n",
            "230 iter PSNR_dehazing: 42.44 ssim: 0.995611\n",
            "230 iter PSNR: 42.44 time: 0.027144\n",
            "231 iter PSNR_dehazing: 43.36 ssim: 0.997463\n",
            "231 iter PSNR: 43.36 time: 0.025069\n",
            "232 iter PSNR_dehazing: 40.74 ssim: 0.993390\n",
            "232 iter PSNR: 40.74 time: 0.025180\n",
            "233 iter PSNR_dehazing: 44.03 ssim: 0.997091\n",
            "233 iter PSNR: 44.03 time: 0.027463\n",
            "234 iter PSNR_dehazing: 43.26 ssim: 0.996745\n",
            "234 iter PSNR: 43.26 time: 0.027708\n",
            "235 iter PSNR_dehazing: 43.25 ssim: 0.996740\n",
            "235 iter PSNR: 43.25 time: 0.032062\n",
            "236 iter PSNR_dehazing: 42.54 ssim: 0.996057\n",
            "236 iter PSNR: 42.54 time: 0.024766\n",
            "237 iter PSNR_dehazing: 41.79 ssim: 0.995422\n",
            "237 iter PSNR: 41.79 time: 0.025705\n",
            "238 iter PSNR_dehazing: 41.18 ssim: 0.995086\n",
            "238 iter PSNR: 41.18 time: 0.030603\n",
            "239 iter PSNR_dehazing: 41.15 ssim: 0.994379\n",
            "239 iter PSNR: 41.15 time: 0.019430\n",
            "240 iter PSNR_dehazing: 41.61 ssim: 0.993894\n",
            "240 iter PSNR: 41.61 time: 0.021245\n",
            "241 iter PSNR_dehazing: 46.01 ssim: 0.998625\n",
            "241 iter PSNR: 46.01 time: 0.020149\n",
            "242 iter PSNR_dehazing: 40.95 ssim: 0.995859\n",
            "242 iter PSNR: 40.95 time: 0.019477\n",
            "243 iter PSNR_dehazing: 44.71 ssim: 0.998366\n",
            "243 iter PSNR: 44.71 time: 0.022755\n",
            "244 iter PSNR_dehazing: 44.47 ssim: 0.998141\n",
            "244 iter PSNR: 44.47 time: 0.018749\n",
            "245 iter PSNR_dehazing: 44.23 ssim: 0.997830\n",
            "245 iter PSNR: 44.23 time: 0.019416\n",
            "246 iter PSNR_dehazing: 43.81 ssim: 0.997654\n",
            "246 iter PSNR: 43.81 time: 0.021157\n",
            "247 iter PSNR_dehazing: 42.90 ssim: 0.997272\n",
            "247 iter PSNR: 42.90 time: 0.019648\n",
            "248 iter PSNR_dehazing: 42.63 ssim: 0.996924\n",
            "248 iter PSNR: 42.63 time: 0.019249\n",
            "249 iter PSNR_dehazing: 41.83 ssim: 0.996646\n",
            "249 iter PSNR: 41.83 time: 0.022747\n",
            "250 iter PSNR_dehazing: 41.15 ssim: 0.996043\n",
            "250 iter PSNR: 41.15 time: 0.019443\n",
            "251 iter PSNR_dehazing: 44.64 ssim: 0.997697\n",
            "251 iter PSNR: 44.64 time: 0.019834\n",
            "252 iter PSNR_dehazing: 39.31 ssim: 0.992832\n",
            "252 iter PSNR: 39.31 time: 0.022968\n",
            "253 iter PSNR_dehazing: 43.85 ssim: 0.997297\n",
            "253 iter PSNR: 43.85 time: 0.019771\n",
            "254 iter PSNR_dehazing: 43.33 ssim: 0.996754\n",
            "254 iter PSNR: 43.33 time: 0.018706\n",
            "255 iter PSNR_dehazing: 42.43 ssim: 0.996389\n",
            "255 iter PSNR: 42.43 time: 0.030423\n",
            "256 iter PSNR_dehazing: 42.43 ssim: 0.995974\n",
            "256 iter PSNR: 42.43 time: 0.020048\n",
            "257 iter PSNR_dehazing: 41.41 ssim: 0.995163\n",
            "257 iter PSNR: 41.41 time: 0.019649\n",
            "258 iter PSNR_dehazing: 40.96 ssim: 0.994840\n",
            "258 iter PSNR: 40.96 time: 0.020899\n",
            "259 iter PSNR_dehazing: 40.30 ssim: 0.994098\n",
            "259 iter PSNR: 40.30 time: 0.018704\n",
            "260 iter PSNR_dehazing: 40.66 ssim: 0.993845\n",
            "260 iter PSNR: 40.66 time: 0.018741\n",
            "261 iter PSNR_dehazing: 45.23 ssim: 0.997805\n",
            "261 iter PSNR: 45.23 time: 0.022134\n",
            "262 iter PSNR_dehazing: 40.26 ssim: 0.993918\n",
            "262 iter PSNR: 40.26 time: 0.019661\n",
            "263 iter PSNR_dehazing: 44.56 ssim: 0.997474\n",
            "263 iter PSNR: 44.56 time: 0.019475\n",
            "264 iter PSNR_dehazing: 43.58 ssim: 0.997214\n",
            "264 iter PSNR: 43.58 time: 0.023674\n",
            "265 iter PSNR_dehazing: 42.90 ssim: 0.996576\n",
            "265 iter PSNR: 42.90 time: 0.018039\n",
            "266 iter PSNR_dehazing: 42.05 ssim: 0.996261\n",
            "266 iter PSNR: 42.05 time: 0.019122\n",
            "267 iter PSNR_dehazing: 41.57 ssim: 0.995708\n",
            "267 iter PSNR: 41.57 time: 0.023778\n",
            "268 iter PSNR_dehazing: 41.38 ssim: 0.995422\n",
            "268 iter PSNR: 41.38 time: 0.018883\n",
            "269 iter PSNR_dehazing: 40.51 ssim: 0.994648\n",
            "269 iter PSNR: 40.51 time: 0.021216\n",
            "270 iter PSNR_dehazing: 40.43 ssim: 0.994292\n",
            "270 iter PSNR: 40.43 time: 0.025101\n",
            "271 iter PSNR_dehazing: 44.42 ssim: 0.998363\n",
            "271 iter PSNR: 44.42 time: 0.019375\n",
            "272 iter PSNR_dehazing: 41.84 ssim: 0.996188\n",
            "272 iter PSNR: 41.84 time: 0.019263\n",
            "273 iter PSNR_dehazing: 44.87 ssim: 0.998401\n",
            "273 iter PSNR: 44.87 time: 0.024128\n",
            "274 iter PSNR_dehazing: 43.16 ssim: 0.998265\n",
            "274 iter PSNR: 43.16 time: 0.019789\n",
            "275 iter PSNR_dehazing: 44.19 ssim: 0.998119\n",
            "275 iter PSNR: 44.19 time: 0.020199\n",
            "276 iter PSNR_dehazing: 43.86 ssim: 0.997859\n",
            "276 iter PSNR: 43.86 time: 0.022453\n",
            "277 iter PSNR_dehazing: 43.37 ssim: 0.997454\n",
            "277 iter PSNR: 43.37 time: 0.018375\n",
            "278 iter PSNR_dehazing: 43.97 ssim: 0.997028\n",
            "278 iter PSNR: 43.97 time: 0.019605\n",
            "279 iter PSNR_dehazing: 43.43 ssim: 0.996920\n",
            "279 iter PSNR: 43.43 time: 0.019111\n",
            "280 iter PSNR_dehazing: 42.68 ssim: 0.996466\n",
            "280 iter PSNR: 42.68 time: 0.018014\n",
            "281 iter PSNR_dehazing: 44.67 ssim: 0.997183\n",
            "281 iter PSNR: 44.67 time: 0.020746\n",
            "282 iter PSNR_dehazing: 40.28 ssim: 0.993270\n",
            "282 iter PSNR: 40.28 time: 0.018767\n",
            "283 iter PSNR_dehazing: 43.65 ssim: 0.996945\n",
            "283 iter PSNR: 43.65 time: 0.018788\n",
            "284 iter PSNR_dehazing: 43.18 ssim: 0.996454\n",
            "284 iter PSNR: 43.18 time: 0.018337\n",
            "285 iter PSNR_dehazing: 43.06 ssim: 0.996235\n",
            "285 iter PSNR: 43.06 time: 0.021381\n",
            "286 iter PSNR_dehazing: 42.31 ssim: 0.995703\n",
            "286 iter PSNR: 42.31 time: 0.019144\n",
            "287 iter PSNR_dehazing: 41.72 ssim: 0.995269\n",
            "287 iter PSNR: 41.72 time: 0.018546\n",
            "288 iter PSNR_dehazing: 41.29 ssim: 0.995016\n",
            "288 iter PSNR: 41.29 time: 0.021959\n",
            "289 iter PSNR_dehazing: 41.29 ssim: 0.994459\n",
            "289 iter PSNR: 41.29 time: 0.018215\n",
            "290 iter PSNR_dehazing: 40.42 ssim: 0.993946\n",
            "290 iter PSNR: 40.42 time: 0.018860\n",
            "291 iter PSNR_dehazing: 43.61 ssim: 0.997318\n",
            "291 iter PSNR: 43.61 time: 0.026185\n",
            "292 iter PSNR_dehazing: 38.31 ssim: 0.991443\n",
            "292 iter PSNR: 38.31 time: 0.019131\n",
            "293 iter PSNR_dehazing: 43.44 ssim: 0.996800\n",
            "293 iter PSNR: 43.44 time: 0.019055\n",
            "294 iter PSNR_dehazing: 42.80 ssim: 0.996457\n",
            "294 iter PSNR: 42.80 time: 0.024845\n",
            "295 iter PSNR_dehazing: 42.15 ssim: 0.995624\n",
            "295 iter PSNR: 42.15 time: 0.020057\n",
            "296 iter PSNR_dehazing: 41.72 ssim: 0.995402\n",
            "296 iter PSNR: 41.72 time: 0.019270\n",
            "297 iter PSNR_dehazing: 40.30 ssim: 0.994489\n",
            "297 iter PSNR: 40.30 time: 0.029519\n",
            "298 iter PSNR_dehazing: 39.82 ssim: 0.993816\n",
            "298 iter PSNR: 39.82 time: 0.018884\n",
            "299 iter PSNR_dehazing: 39.41 ssim: 0.992930\n",
            "299 iter PSNR: 39.41 time: 0.019409\n",
            "300 iter PSNR_dehazing: 39.01 ssim: 0.992339\n",
            "300 iter PSNR: 39.01 time: 0.022817\n",
            "301 iter PSNR_dehazing: 42.23 ssim: 0.996879\n",
            "301 iter PSNR: 42.23 time: 0.018487\n",
            "302 iter PSNR_dehazing: 36.36 ssim: 0.991069\n",
            "302 iter PSNR: 36.36 time: 0.018959\n",
            "303 iter PSNR_dehazing: 41.26 ssim: 0.996313\n",
            "303 iter PSNR: 41.26 time: 0.023240\n",
            "304 iter PSNR_dehazing: 40.73 ssim: 0.996132\n",
            "304 iter PSNR: 40.73 time: 0.018413\n",
            "305 iter PSNR_dehazing: 39.84 ssim: 0.995529\n",
            "305 iter PSNR: 39.84 time: 0.018896\n",
            "306 iter PSNR_dehazing: 39.29 ssim: 0.994886\n",
            "306 iter PSNR: 39.29 time: 0.019042\n",
            "307 iter PSNR_dehazing: 38.89 ssim: 0.994264\n",
            "307 iter PSNR: 38.89 time: 0.018726\n",
            "308 iter PSNR_dehazing: 37.87 ssim: 0.993360\n",
            "308 iter PSNR: 37.87 time: 0.019960\n",
            "309 iter PSNR_dehazing: 37.58 ssim: 0.992620\n",
            "309 iter PSNR: 37.58 time: 0.018133\n",
            "310 iter PSNR_dehazing: 37.00 ssim: 0.992031\n",
            "310 iter PSNR: 37.00 time: 0.019477\n",
            "311 iter PSNR_dehazing: 44.92 ssim: 0.997107\n",
            "311 iter PSNR: 44.92 time: 0.018269\n",
            "312 iter PSNR_dehazing: 40.53 ssim: 0.992074\n",
            "312 iter PSNR: 40.53 time: 0.018169\n",
            "313 iter PSNR_dehazing: 44.28 ssim: 0.996637\n",
            "313 iter PSNR: 44.28 time: 0.017942\n",
            "314 iter PSNR_dehazing: 43.48 ssim: 0.996197\n",
            "314 iter PSNR: 43.48 time: 0.018445\n",
            "315 iter PSNR_dehazing: 43.06 ssim: 0.995541\n",
            "315 iter PSNR: 43.06 time: 0.021183\n",
            "316 iter PSNR_dehazing: 42.26 ssim: 0.995162\n",
            "316 iter PSNR: 42.26 time: 0.019635\n",
            "317 iter PSNR_dehazing: 42.13 ssim: 0.994509\n",
            "317 iter PSNR: 42.13 time: 0.020088\n",
            "318 iter PSNR_dehazing: 41.75 ssim: 0.993638\n",
            "318 iter PSNR: 41.75 time: 0.022280\n",
            "319 iter PSNR_dehazing: 41.31 ssim: 0.993508\n",
            "319 iter PSNR: 41.31 time: 0.019237\n",
            "320 iter PSNR_dehazing: 40.86 ssim: 0.992567\n",
            "320 iter PSNR: 40.86 time: 0.019227\n",
            "321 iter PSNR_dehazing: 44.61 ssim: 0.996141\n",
            "321 iter PSNR: 44.61 time: 0.019147\n",
            "322 iter PSNR_dehazing: 40.19 ssim: 0.993024\n",
            "322 iter PSNR: 40.19 time: 0.025774\n",
            "323 iter PSNR_dehazing: 44.14 ssim: 0.996431\n",
            "323 iter PSNR: 44.14 time: 0.021003\n",
            "324 iter PSNR_dehazing: 43.37 ssim: 0.995976\n",
            "324 iter PSNR: 43.37 time: 0.018507\n",
            "325 iter PSNR_dehazing: 43.02 ssim: 0.995293\n",
            "325 iter PSNR: 43.02 time: 0.018566\n",
            "326 iter PSNR_dehazing: 42.21 ssim: 0.995410\n",
            "326 iter PSNR: 42.21 time: 0.019477\n",
            "327 iter PSNR_dehazing: 41.68 ssim: 0.994804\n",
            "327 iter PSNR: 41.68 time: 0.022381\n",
            "328 iter PSNR_dehazing: 41.43 ssim: 0.994076\n",
            "328 iter PSNR: 41.43 time: 0.018464\n",
            "329 iter PSNR_dehazing: 41.47 ssim: 0.993994\n",
            "329 iter PSNR: 41.47 time: 0.021514\n",
            "330 iter PSNR_dehazing: 40.46 ssim: 0.993455\n",
            "330 iter PSNR: 40.46 time: 0.018707\n",
            "331 iter PSNR_dehazing: 44.49 ssim: 0.997119\n",
            "331 iter PSNR: 44.49 time: 0.018479\n",
            "332 iter PSNR_dehazing: 40.38 ssim: 0.992570\n",
            "332 iter PSNR: 40.38 time: 0.021191\n",
            "333 iter PSNR_dehazing: 43.51 ssim: 0.996557\n",
            "333 iter PSNR: 43.51 time: 0.017598\n",
            "334 iter PSNR_dehazing: 42.82 ssim: 0.996237\n",
            "334 iter PSNR: 42.82 time: 0.018385\n",
            "335 iter PSNR_dehazing: 42.53 ssim: 0.995791\n",
            "335 iter PSNR: 42.53 time: 0.018172\n",
            "336 iter PSNR_dehazing: 42.29 ssim: 0.995323\n",
            "336 iter PSNR: 42.29 time: 0.020192\n",
            "337 iter PSNR_dehazing: 41.46 ssim: 0.994661\n",
            "337 iter PSNR: 41.46 time: 0.019157\n",
            "338 iter PSNR_dehazing: 41.14 ssim: 0.993932\n",
            "338 iter PSNR: 41.14 time: 0.019218\n",
            "339 iter PSNR_dehazing: 40.98 ssim: 0.993682\n",
            "339 iter PSNR: 40.98 time: 0.022854\n",
            "340 iter PSNR_dehazing: 40.40 ssim: 0.993130\n",
            "340 iter PSNR: 40.40 time: 0.019040\n",
            "341 iter PSNR_dehazing: 42.35 ssim: 0.998269\n",
            "341 iter PSNR: 42.35 time: 0.018351\n",
            "342 iter PSNR_dehazing: 37.86 ssim: 0.994695\n",
            "342 iter PSNR: 37.86 time: 0.019661\n",
            "343 iter PSNR_dehazing: 42.18 ssim: 0.998076\n",
            "343 iter PSNR: 42.18 time: 0.019642\n",
            "344 iter PSNR_dehazing: 40.74 ssim: 0.997665\n",
            "344 iter PSNR: 40.74 time: 0.019257\n",
            "345 iter PSNR_dehazing: 40.21 ssim: 0.997314\n",
            "345 iter PSNR: 40.21 time: 0.020508\n",
            "346 iter PSNR_dehazing: 39.66 ssim: 0.996889\n",
            "346 iter PSNR: 39.66 time: 0.018103\n",
            "347 iter PSNR_dehazing: 39.41 ssim: 0.996534\n",
            "347 iter PSNR: 39.41 time: 0.018514\n",
            "348 iter PSNR_dehazing: 39.16 ssim: 0.996118\n",
            "348 iter PSNR: 39.16 time: 0.018327\n",
            "349 iter PSNR_dehazing: 38.53 ssim: 0.995599\n",
            "349 iter PSNR: 38.53 time: 0.018696\n",
            "350 iter PSNR_dehazing: 38.03 ssim: 0.995053\n",
            "350 iter PSNR: 38.03 time: 0.019463\n",
            "351 iter PSNR_dehazing: 43.76 ssim: 0.998258\n",
            "351 iter PSNR: 43.76 time: 0.018607\n",
            "352 iter PSNR_dehazing: 39.74 ssim: 0.995486\n",
            "352 iter PSNR: 39.74 time: 0.018789\n",
            "353 iter PSNR_dehazing: 43.38 ssim: 0.998065\n",
            "353 iter PSNR: 43.38 time: 0.018821\n",
            "354 iter PSNR_dehazing: 42.85 ssim: 0.997739\n",
            "354 iter PSNR: 42.85 time: 0.018912\n",
            "355 iter PSNR_dehazing: 42.47 ssim: 0.997459\n",
            "355 iter PSNR: 42.47 time: 0.019443\n",
            "356 iter PSNR_dehazing: 42.08 ssim: 0.997135\n",
            "356 iter PSNR: 42.08 time: 0.020335\n",
            "357 iter PSNR_dehazing: 41.24 ssim: 0.996695\n",
            "357 iter PSNR: 41.24 time: 0.022323\n",
            "358 iter PSNR_dehazing: 40.98 ssim: 0.996209\n",
            "358 iter PSNR: 40.98 time: 0.018851\n",
            "359 iter PSNR_dehazing: 40.52 ssim: 0.996039\n",
            "359 iter PSNR: 40.52 time: 0.019120\n",
            "360 iter PSNR_dehazing: 39.99 ssim: 0.995734\n",
            "360 iter PSNR: 39.99 time: 0.018775\n",
            "361 iter PSNR_dehazing: 42.64 ssim: 0.998959\n",
            "361 iter PSNR: 42.64 time: 0.021830\n",
            "362 iter PSNR_dehazing: 37.87 ssim: 0.997018\n",
            "362 iter PSNR: 37.87 time: 0.019388\n",
            "363 iter PSNR_dehazing: 41.99 ssim: 0.998853\n",
            "363 iter PSNR: 41.99 time: 0.018239\n",
            "364 iter PSNR_dehazing: 41.12 ssim: 0.998675\n",
            "364 iter PSNR: 41.12 time: 0.019485\n",
            "365 iter PSNR_dehazing: 40.82 ssim: 0.998598\n",
            "365 iter PSNR: 40.82 time: 0.020271\n",
            "366 iter PSNR_dehazing: 40.65 ssim: 0.998406\n",
            "366 iter PSNR: 40.65 time: 0.021600\n",
            "367 iter PSNR_dehazing: 39.66 ssim: 0.998147\n",
            "367 iter PSNR: 39.66 time: 0.018718\n",
            "368 iter PSNR_dehazing: 39.38 ssim: 0.997992\n",
            "368 iter PSNR: 39.38 time: 0.018453\n",
            "369 iter PSNR_dehazing: 38.26 ssim: 0.997614\n",
            "369 iter PSNR: 38.26 time: 0.023071\n",
            "370 iter PSNR_dehazing: 38.52 ssim: 0.997446\n",
            "370 iter PSNR: 38.52 time: 0.019040\n",
            "371 iter PSNR_dehazing: 41.54 ssim: 0.997187\n",
            "371 iter PSNR: 41.54 time: 0.018579\n",
            "372 iter PSNR_dehazing: 36.34 ssim: 0.989877\n",
            "372 iter PSNR: 36.34 time: 0.018186\n",
            "373 iter PSNR_dehazing: 40.43 ssim: 0.996637\n",
            "373 iter PSNR: 40.43 time: 0.019500\n",
            "374 iter PSNR_dehazing: 39.99 ssim: 0.996072\n",
            "374 iter PSNR: 39.99 time: 0.018622\n",
            "375 iter PSNR_dehazing: 39.38 ssim: 0.995287\n",
            "375 iter PSNR: 39.38 time: 0.022545\n",
            "376 iter PSNR_dehazing: 38.48 ssim: 0.994305\n",
            "376 iter PSNR: 38.48 time: 0.030219\n",
            "377 iter PSNR_dehazing: 38.10 ssim: 0.993544\n",
            "377 iter PSNR: 38.10 time: 0.030046\n",
            "378 iter PSNR_dehazing: 37.49 ssim: 0.992707\n",
            "378 iter PSNR: 37.49 time: 0.026596\n",
            "379 iter PSNR_dehazing: 37.08 ssim: 0.991815\n",
            "379 iter PSNR: 37.08 time: 0.027755\n",
            "380 iter PSNR_dehazing: 36.13 ssim: 0.990573\n",
            "380 iter PSNR: 36.13 time: 0.032767\n",
            "381 iter PSNR_dehazing: 45.51 ssim: 0.994096\n",
            "381 iter PSNR: 45.51 time: 0.031020\n",
            "382 iter PSNR_dehazing: 40.43 ssim: 0.980893\n",
            "382 iter PSNR: 40.43 time: 0.025719\n",
            "383 iter PSNR_dehazing: 44.82 ssim: 0.992928\n",
            "383 iter PSNR: 44.82 time: 0.025711\n",
            "384 iter PSNR_dehazing: 44.50 ssim: 0.991926\n",
            "384 iter PSNR: 44.50 time: 0.029888\n",
            "385 iter PSNR_dehazing: 44.27 ssim: 0.991176\n",
            "385 iter PSNR: 44.27 time: 0.028960\n",
            "386 iter PSNR_dehazing: 43.62 ssim: 0.989780\n",
            "386 iter PSNR: 43.62 time: 0.025938\n",
            "387 iter PSNR_dehazing: 42.58 ssim: 0.988270\n",
            "387 iter PSNR: 42.58 time: 0.026750\n",
            "388 iter PSNR_dehazing: 42.61 ssim: 0.987692\n",
            "388 iter PSNR: 42.61 time: 0.025818\n",
            "389 iter PSNR_dehazing: 42.11 ssim: 0.986484\n",
            "389 iter PSNR: 42.11 time: 0.029697\n",
            "390 iter PSNR_dehazing: 41.66 ssim: 0.984483\n",
            "390 iter PSNR: 41.66 time: 0.032188\n",
            "391 iter PSNR_dehazing: 43.01 ssim: 0.998434\n",
            "391 iter PSNR: 43.01 time: 0.023667\n",
            "392 iter PSNR_dehazing: 39.06 ssim: 0.993848\n",
            "392 iter PSNR: 39.06 time: 0.024342\n",
            "393 iter PSNR_dehazing: 42.33 ssim: 0.998136\n",
            "393 iter PSNR: 42.33 time: 0.027931\n",
            "394 iter PSNR_dehazing: 41.65 ssim: 0.997712\n",
            "394 iter PSNR: 41.65 time: 0.025647\n",
            "395 iter PSNR_dehazing: 41.40 ssim: 0.997390\n",
            "395 iter PSNR: 41.40 time: 0.025853\n",
            "396 iter PSNR_dehazing: 40.58 ssim: 0.996510\n",
            "396 iter PSNR: 40.58 time: 0.029840\n",
            "397 iter PSNR_dehazing: 40.14 ssim: 0.995819\n",
            "397 iter PSNR: 40.14 time: 0.024554\n",
            "398 iter PSNR_dehazing: 39.52 ssim: 0.995964\n",
            "398 iter PSNR: 39.52 time: 0.025596\n",
            "399 iter PSNR_dehazing: 39.54 ssim: 0.995271\n",
            "399 iter PSNR: 39.54 time: 0.026883\n",
            "400 iter PSNR_dehazing: 39.13 ssim: 0.994705\n",
            "400 iter PSNR: 39.13 time: 0.026264\n",
            "401 iter PSNR_dehazing: 41.96 ssim: 0.996923\n",
            "401 iter PSNR: 41.96 time: 0.026399\n",
            "402 iter PSNR_dehazing: 33.45 ssim: 0.985932\n",
            "402 iter PSNR: 33.45 time: 0.025436\n",
            "403 iter PSNR_dehazing: 40.09 ssim: 0.995827\n",
            "403 iter PSNR: 40.09 time: 0.024296\n",
            "404 iter PSNR_dehazing: 39.10 ssim: 0.995295\n",
            "404 iter PSNR: 39.10 time: 0.023861\n",
            "405 iter PSNR_dehazing: 38.73 ssim: 0.994431\n",
            "405 iter PSNR: 38.73 time: 0.033591\n",
            "406 iter PSNR_dehazing: 37.57 ssim: 0.993566\n",
            "406 iter PSNR: 37.57 time: 0.025635\n",
            "407 iter PSNR_dehazing: 36.77 ssim: 0.992138\n",
            "407 iter PSNR: 36.77 time: 0.027654\n",
            "408 iter PSNR_dehazing: 36.37 ssim: 0.991565\n",
            "408 iter PSNR: 36.37 time: 0.032095\n",
            "409 iter PSNR_dehazing: 35.66 ssim: 0.990532\n",
            "409 iter PSNR: 35.66 time: 0.025152\n",
            "410 iter PSNR_dehazing: 34.73 ssim: 0.988498\n",
            "410 iter PSNR: 34.73 time: 0.027091\n",
            "411 iter PSNR_dehazing: 44.61 ssim: 0.998012\n",
            "411 iter PSNR: 44.61 time: 0.025448\n",
            "412 iter PSNR_dehazing: 41.10 ssim: 0.995304\n",
            "412 iter PSNR: 41.10 time: 0.024771\n",
            "413 iter PSNR_dehazing: 43.94 ssim: 0.997624\n",
            "413 iter PSNR: 43.94 time: 0.028569\n",
            "414 iter PSNR_dehazing: 43.76 ssim: 0.997570\n",
            "414 iter PSNR: 43.76 time: 0.025145\n",
            "415 iter PSNR_dehazing: 43.26 ssim: 0.997262\n",
            "415 iter PSNR: 43.26 time: 0.024750\n",
            "416 iter PSNR_dehazing: 42.99 ssim: 0.996986\n",
            "416 iter PSNR: 42.99 time: 0.024720\n",
            "417 iter PSNR_dehazing: 42.55 ssim: 0.996700\n",
            "417 iter PSNR: 42.55 time: 0.025704\n",
            "418 iter PSNR_dehazing: 42.10 ssim: 0.996303\n",
            "418 iter PSNR: 42.10 time: 0.030629\n",
            "419 iter PSNR_dehazing: 41.91 ssim: 0.996017\n",
            "419 iter PSNR: 41.91 time: 0.025761\n",
            "420 iter PSNR_dehazing: 41.34 ssim: 0.995679\n",
            "420 iter PSNR: 41.34 time: 0.027752\n",
            "421 iter PSNR_dehazing: 46.19 ssim: 0.997733\n",
            "421 iter PSNR: 46.19 time: 0.026918\n",
            "422 iter PSNR_dehazing: 40.26 ssim: 0.993585\n",
            "422 iter PSNR: 40.26 time: 0.024679\n",
            "423 iter PSNR_dehazing: 45.34 ssim: 0.997350\n",
            "423 iter PSNR: 45.34 time: 0.023705\n",
            "424 iter PSNR_dehazing: 45.01 ssim: 0.997058\n",
            "424 iter PSNR: 45.01 time: 0.024253\n",
            "425 iter PSNR_dehazing: 43.31 ssim: 0.996781\n",
            "425 iter PSNR: 43.31 time: 0.025600\n",
            "426 iter PSNR_dehazing: 43.14 ssim: 0.996374\n",
            "426 iter PSNR: 43.14 time: 0.028070\n",
            "427 iter PSNR_dehazing: 42.38 ssim: 0.995862\n",
            "427 iter PSNR: 42.38 time: 0.025824\n",
            "428 iter PSNR_dehazing: 41.78 ssim: 0.995372\n",
            "428 iter PSNR: 41.78 time: 0.025328\n",
            "429 iter PSNR_dehazing: 41.36 ssim: 0.994904\n",
            "429 iter PSNR: 41.36 time: 0.027013\n",
            "430 iter PSNR_dehazing: 41.47 ssim: 0.994395\n",
            "430 iter PSNR: 41.47 time: 0.027438\n",
            "431 iter PSNR_dehazing: 44.54 ssim: 0.997886\n",
            "431 iter PSNR: 44.54 time: 0.024650\n",
            "432 iter PSNR_dehazing: 39.71 ssim: 0.994779\n",
            "432 iter PSNR: 39.71 time: 0.025206\n",
            "433 iter PSNR_dehazing: 43.89 ssim: 0.997901\n",
            "433 iter PSNR: 43.89 time: 0.025126\n",
            "434 iter PSNR_dehazing: 43.37 ssim: 0.997489\n",
            "434 iter PSNR: 43.37 time: 0.028121\n",
            "435 iter PSNR_dehazing: 42.78 ssim: 0.997374\n",
            "435 iter PSNR: 42.78 time: 0.029090\n",
            "436 iter PSNR_dehazing: 42.07 ssim: 0.996807\n",
            "436 iter PSNR: 42.07 time: 0.023971\n",
            "437 iter PSNR_dehazing: 41.40 ssim: 0.996283\n",
            "437 iter PSNR: 41.40 time: 0.024855\n",
            "438 iter PSNR_dehazing: 41.28 ssim: 0.995823\n",
            "438 iter PSNR: 41.28 time: 0.023842\n",
            "439 iter PSNR_dehazing: 40.87 ssim: 0.995826\n",
            "439 iter PSNR: 40.87 time: 0.024087\n",
            "440 iter PSNR_dehazing: 40.71 ssim: 0.995369\n",
            "440 iter PSNR: 40.71 time: 0.024737\n",
            "441 iter PSNR_dehazing: 46.13 ssim: 0.997684\n",
            "441 iter PSNR: 46.13 time: 0.028033\n",
            "442 iter PSNR_dehazing: 40.92 ssim: 0.992330\n",
            "442 iter PSNR: 40.92 time: 0.026115\n",
            "443 iter PSNR_dehazing: 45.70 ssim: 0.997232\n",
            "443 iter PSNR: 45.70 time: 0.025157\n",
            "444 iter PSNR_dehazing: 44.71 ssim: 0.996912\n",
            "444 iter PSNR: 44.71 time: 0.023425\n",
            "445 iter PSNR_dehazing: 44.27 ssim: 0.996395\n",
            "445 iter PSNR: 44.27 time: 0.027999\n",
            "446 iter PSNR_dehazing: 43.32 ssim: 0.995868\n",
            "446 iter PSNR: 43.32 time: 0.024369\n",
            "447 iter PSNR_dehazing: 43.03 ssim: 0.995245\n",
            "447 iter PSNR: 43.03 time: 0.030274\n",
            "448 iter PSNR_dehazing: 42.45 ssim: 0.994609\n",
            "448 iter PSNR: 42.45 time: 0.027714\n",
            "449 iter PSNR_dehazing: 41.37 ssim: 0.993728\n",
            "449 iter PSNR: 41.37 time: 0.027478\n",
            "450 iter PSNR_dehazing: 41.23 ssim: 0.993158\n",
            "450 iter PSNR: 41.23 time: 0.027207\n",
            "451 iter PSNR_dehazing: 45.07 ssim: 0.998572\n",
            "451 iter PSNR: 45.07 time: 0.019394\n",
            "452 iter PSNR_dehazing: 39.18 ssim: 0.995500\n",
            "452 iter PSNR: 39.18 time: 0.018649\n",
            "453 iter PSNR_dehazing: 44.17 ssim: 0.998294\n",
            "453 iter PSNR: 44.17 time: 0.018603\n",
            "454 iter PSNR_dehazing: 43.29 ssim: 0.997989\n",
            "454 iter PSNR: 43.29 time: 0.023119\n",
            "455 iter PSNR_dehazing: 42.51 ssim: 0.997658\n",
            "455 iter PSNR: 42.51 time: 0.018611\n",
            "456 iter PSNR_dehazing: 41.83 ssim: 0.997341\n",
            "456 iter PSNR: 41.83 time: 0.018962\n",
            "457 iter PSNR_dehazing: 41.41 ssim: 0.997036\n",
            "457 iter PSNR: 41.41 time: 0.018716\n",
            "458 iter PSNR_dehazing: 40.81 ssim: 0.996803\n",
            "458 iter PSNR: 40.81 time: 0.021975\n",
            "459 iter PSNR_dehazing: 40.17 ssim: 0.996302\n",
            "459 iter PSNR: 40.17 time: 0.019227\n",
            "460 iter PSNR_dehazing: 39.69 ssim: 0.995894\n",
            "460 iter PSNR: 39.69 time: 0.019216\n",
            "461 iter PSNR_dehazing: 43.82 ssim: 0.998290\n",
            "461 iter PSNR: 43.82 time: 0.019389\n",
            "462 iter PSNR_dehazing: 38.81 ssim: 0.994684\n",
            "462 iter PSNR: 38.81 time: 0.021945\n",
            "463 iter PSNR_dehazing: 43.09 ssim: 0.997864\n",
            "463 iter PSNR: 43.09 time: 0.018934\n",
            "464 iter PSNR_dehazing: 42.53 ssim: 0.997808\n",
            "464 iter PSNR: 42.53 time: 0.019166\n",
            "465 iter PSNR_dehazing: 42.01 ssim: 0.997255\n",
            "465 iter PSNR: 42.01 time: 0.019152\n",
            "466 iter PSNR_dehazing: 41.85 ssim: 0.997109\n",
            "466 iter PSNR: 41.85 time: 0.019437\n",
            "467 iter PSNR_dehazing: 40.98 ssim: 0.996623\n",
            "467 iter PSNR: 40.98 time: 0.019152\n",
            "468 iter PSNR_dehazing: 40.46 ssim: 0.996192\n",
            "468 iter PSNR: 40.46 time: 0.029273\n",
            "469 iter PSNR_dehazing: 39.58 ssim: 0.995487\n",
            "469 iter PSNR: 39.58 time: 0.019807\n",
            "470 iter PSNR_dehazing: 39.41 ssim: 0.995322\n",
            "470 iter PSNR: 39.41 time: 0.018729\n",
            "471 iter PSNR_dehazing: 42.12 ssim: 0.997354\n",
            "471 iter PSNR: 42.12 time: 0.020595\n",
            "472 iter PSNR_dehazing: 37.26 ssim: 0.992166\n",
            "472 iter PSNR: 37.26 time: 0.018951\n",
            "473 iter PSNR_dehazing: 41.09 ssim: 0.996844\n",
            "473 iter PSNR: 41.09 time: 0.021858\n",
            "474 iter PSNR_dehazing: 40.48 ssim: 0.996343\n",
            "474 iter PSNR: 40.48 time: 0.023204\n",
            "475 iter PSNR_dehazing: 40.00 ssim: 0.995912\n",
            "475 iter PSNR: 40.00 time: 0.021124\n",
            "476 iter PSNR_dehazing: 39.66 ssim: 0.995289\n",
            "476 iter PSNR: 39.66 time: 0.019340\n",
            "477 iter PSNR_dehazing: 38.73 ssim: 0.994483\n",
            "477 iter PSNR: 38.73 time: 0.021106\n",
            "478 iter PSNR_dehazing: 38.49 ssim: 0.993816\n",
            "478 iter PSNR: 38.49 time: 0.019312\n",
            "479 iter PSNR_dehazing: 37.92 ssim: 0.993472\n",
            "479 iter PSNR: 37.92 time: 0.019140\n",
            "480 iter PSNR_dehazing: 37.75 ssim: 0.992645\n",
            "480 iter PSNR: 37.75 time: 0.018251\n",
            "481 iter PSNR_dehazing: 42.86 ssim: 0.997430\n",
            "481 iter PSNR: 42.86 time: 0.019562\n",
            "482 iter PSNR_dehazing: 38.01 ssim: 0.992611\n",
            "482 iter PSNR: 38.01 time: 0.028246\n",
            "483 iter PSNR_dehazing: 41.97 ssim: 0.996851\n",
            "483 iter PSNR: 41.97 time: 0.023755\n",
            "484 iter PSNR_dehazing: 41.68 ssim: 0.996376\n",
            "484 iter PSNR: 41.68 time: 0.018429\n",
            "485 iter PSNR_dehazing: 40.92 ssim: 0.995786\n",
            "485 iter PSNR: 40.92 time: 0.020430\n",
            "486 iter PSNR_dehazing: 40.51 ssim: 0.995188\n",
            "486 iter PSNR: 40.51 time: 0.018775\n",
            "487 iter PSNR_dehazing: 39.88 ssim: 0.994751\n",
            "487 iter PSNR: 39.88 time: 0.019790\n",
            "488 iter PSNR_dehazing: 39.62 ssim: 0.994263\n",
            "488 iter PSNR: 39.62 time: 0.018979\n",
            "489 iter PSNR_dehazing: 38.74 ssim: 0.993446\n",
            "489 iter PSNR: 38.74 time: 0.021933\n",
            "490 iter PSNR_dehazing: 38.65 ssim: 0.993138\n",
            "490 iter PSNR: 38.65 time: 0.018682\n",
            "491 iter PSNR_dehazing: 41.11 ssim: 0.998031\n",
            "491 iter PSNR: 41.11 time: 0.018696\n",
            "492 iter PSNR_dehazing: 38.16 ssim: 0.994482\n",
            "492 iter PSNR: 38.16 time: 0.018686\n",
            "493 iter PSNR_dehazing: 40.81 ssim: 0.997798\n",
            "493 iter PSNR: 40.81 time: 0.019449\n",
            "494 iter PSNR_dehazing: 40.13 ssim: 0.997398\n",
            "494 iter PSNR: 40.13 time: 0.018591\n",
            "495 iter PSNR_dehazing: 39.81 ssim: 0.996982\n",
            "495 iter PSNR: 39.81 time: 0.018340\n",
            "496 iter PSNR_dehazing: 39.80 ssim: 0.996742\n",
            "496 iter PSNR: 39.80 time: 0.025224\n",
            "497 iter PSNR_dehazing: 39.18 ssim: 0.996200\n",
            "497 iter PSNR: 39.18 time: 0.019527\n",
            "498 iter PSNR_dehazing: 38.63 ssim: 0.995791\n",
            "498 iter PSNR: 38.63 time: 0.022670\n",
            "499 iter PSNR_dehazing: 38.65 ssim: 0.995308\n",
            "499 iter PSNR: 38.65 time: 0.018342\n",
            "500 iter PSNR_dehazing: 38.21 ssim: 0.994930\n",
            "500 iter PSNR: 38.21 time: 0.019219\n",
            "==========================================================\n",
            "The average PSNR is 41.04 dB\n",
            "The average SSIM is 0.99576 dB\n",
            "Average time: 0.039372\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "# from torch.backends import cudnn # Uncomment if you need it\n",
        "\n",
        "class Args:\n",
        "    model_name = 'IRNeXt'\n",
        "    mode = 'test'\n",
        "    data_dir = './SOTS/SOTS/indoor'\n",
        "\n",
        "    # Train\n",
        "    batch_size = 4\n",
        "    learning_rate = 1e-4\n",
        "    weight_decay = 0\n",
        "    num_epoch = 5\n",
        "    print_freq = 100\n",
        "    num_worker = 8\n",
        "    save_freq = 10\n",
        "    valid_freq = 10\n",
        "    resume = ''\n",
        "\n",
        "    # Test\n",
        "    test_model = '/content/drive/MyDrive/reside-indoor/results/IRNeXt/ITS/Best.pkl'\n",
        "    save_image = False\n",
        "\n",
        "    # Directories (set these as per your requirement)\n",
        "    model_save_dir = os.path.join('/content/drive/MyDrive/reside-indoor/results/', 'IRNeXt', 'ITS/')\n",
        "    result_dir = os.path.join('/content/drive/MyDrive/reside-indoor/results/', model_name, 'test')\n",
        "\n",
        "def main(args):\n",
        "    # CUDNN\n",
        "    # cudnn.benchmark = True # Uncomment if you need it\n",
        "\n",
        "    if not os.path.exists('/content/drive/MyDrive/reside-indoor/results/'):\n",
        "        os.makedirs(args.model_save_dir)\n",
        "    if not os.path.exists('/content/drive/MyDrive/reside-indoor/results/' + args.model_name + '/'):\n",
        "        os.makedirs('/content/drive/MyDrive/reside-indoor/results/' + args.model_name + '/')\n",
        "    if not os.path.exists(args.model_save_dir):\n",
        "        os.makedirs(args.model_save_dir)\n",
        "    if not os.path.exists(args.result_dir):\n",
        "        os.makedirs(args.result_dir)\n",
        "\n",
        "    model = build_net()  # Make sure to define build_net or import it if it's defined elsewhere\n",
        "    print(model)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    if args.mode == 'train':\n",
        "        _train(model, args)  # Make sure to define _train or import it if it's defined elsewhere\n",
        "\n",
        "    elif args.mode == 'test':\n",
        "        _eval(model, args)   # Make sure to define _eval or import it if it's defined elsewhere\n",
        "\n",
        "# Replace parser.parse_args() with an instance of the Args class\n",
        "args = Args()\n",
        "if not os.path.exists(args.model_save_dir):\n",
        "    os.makedirs(args.model_save_dir)\n",
        "# Copying files (make sure these paths are correct)\n",
        "command = 'cp ' + 'models/layers.py ' + args.model_save_dir\n",
        "os.system(command)\n",
        "command = 'cp ' + 'models/IRNeXt.py ' + args.model_save_dir\n",
        "os.system(command)\n",
        "command = 'cp ' + 'train.py ' + args.model_save_dir\n",
        "os.system(command)\n",
        "command = 'cp ' + 'main.py ' + args.model_save_dir\n",
        "os.system(command)\n",
        "print(args)\n",
        "main(args)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}