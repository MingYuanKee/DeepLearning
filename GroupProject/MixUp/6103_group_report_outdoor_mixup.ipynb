{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLPM1G2oyK_V",
    "outputId": "7517dba6-7497-4045-d373-f1ccd9cbd7f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "#drive.flush_and_unmount()\n",
    "drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TShDSRqUnXHj"
   },
   "outputs": [],
   "source": [
    "#!cp ./drive/MyDrive/temp/outdoor_train.zip .\n",
    "\n",
    "!rm -rf reside-mix/\n",
    "!unzip  ./drive/MyDrive/temp/outdoor_train.zip -d ./reside-mix/ > log.txt\n",
    "!unzip  ./drive/MyDrive/temp/outdoor_test.zip -d ./reside-mix/ > testlog.txt\n",
    "\n",
    "!unzip  ./drive/MyDrive/temp/indoor_train.zip -d ./reside-mix/ > log.txt\n",
    "!unzip  ./drive/MyDrive/temp/indoor_test.zip -d ./reside-mix/ > testlog.txt\n",
    "\n",
    "\n",
    "#!cp -rf ./drive/MyDrive/reside-outdoor/ ./\n",
    "path = './reside-mix/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gG-ESQ4KHFaH"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "directory = r'/content/reside-mix/train/gt/'\n",
    "files = os.listdir(directory)\n",
    "# Then you rename the files\n",
    "for file_name in files:\n",
    "    # You give the full path of the file\n",
    "    old_name = os.path.join(directory, file_name)\n",
    "    # You CHANGE the extension\n",
    "    new_name = old_name.replace('.jpg', '.png')\n",
    "    os.rename(old_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XVwQ0ZIsRLEG",
    "outputId": "4820d0c5-41d3-4fcf-ed85-e234a052db4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_msssim\n",
      "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_msssim) (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_msssim) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_msssim) (1.3.0)\n",
      "Installing collected packages: pytorch_msssim\n",
      "Successfully installed pytorch_msssim-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Mrk7IMUeRzlk",
    "outputId": "9289f612-40a9-42e6-fca2-d4658bb9b79c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting warmup-scheduler\n",
      "  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: warmup-scheduler\n",
      "  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for warmup-scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2968 sha256=91c407fb75ed3725f2bdd72773e63da0647072d4a926eec3d4697deb103e143f\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/01/9e/d1820991c32916e9808c940f572b462f3e46427f3e76c4d852\n",
      "Successfully built warmup-scheduler\n",
      "Installing collected packages: warmup-scheduler\n",
      "Successfully installed warmup-scheduler-0.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install warmup-scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_h78ryOOBvc2"
   },
   "source": [
    "Data Augment\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z9B1WKSCD5O"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as FUNCTIONAL\n",
    "\n",
    "\n",
    "class PairRandomCrop(transforms.RandomCrop):\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "\n",
    "        if self.padding is not None:\n",
    "            image = FUNCTIONAL.pad(image, self.padding, self.fill, self.padding_mode)\n",
    "            label = FUNCTIONAL.pad(label, self.padding, self.fill, self.padding_mode)\n",
    "\n",
    "        # pad the width if needed\n",
    "        if self.pad_if_needed and image.size[0] < self.size[1]:\n",
    "            image = FUNCTIONAL.pad(image, (self.size[1] - image.size[0], 0), self.fill, self.padding_mode)\n",
    "            label = FUNCTIONAL.pad(label, (self.size[1] - label.size[0], 0), self.fill, self.padding_mode)\n",
    "        # pad the height if needed\n",
    "        if self.pad_if_needed and image.size[1] < self.size[0]:\n",
    "            image = FUNCTIONAL.pad(image, (0, self.size[0] - image.size[1]), self.fill, self.padding_mode)\n",
    "            label = FUNCTIONAL.pad(label, (0, self.size[0] - image.size[1]), self.fill, self.padding_mode)\n",
    "\n",
    "        i, j, h, w = self.get_params(image, self.size)\n",
    "\n",
    "        return FUNCTIONAL.crop(image, i, j, h, w), FUNCTIONAL.crop(label, i, j, h, w)\n",
    "\n",
    "\n",
    "class PairCompose(transforms.Compose):\n",
    "    def __call__(self, image, label):\n",
    "        for t in self.transforms:\n",
    "            image, label = t(image, label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class PairRandomHorizontalFilp(transforms.RandomHorizontalFlip):\n",
    "    def __call__(self, img, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be flipped.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:\n",
    "            return FUNCTIONAL.hflip(img), FUNCTIONAL.hflip(label)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "class PairToTensor(transforms.ToTensor):\n",
    "    def __call__(self, pic, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Converted image.\n",
    "        \"\"\"\n",
    "        return FUNCTIONAL.to_tensor(pic), FUNCTIONAL.to_tensor(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ik-THSPrBomo"
   },
   "source": [
    "Data Loader\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rFIJk2JBsbA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image as Image\n",
    "from torchvision.transforms import functional as Functional\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import to_tensor, resize\n",
    "\n",
    "def my_collate_fn(batch):\n",
    "    images, labels = zip(*batch)  # Unzipping images and labels\n",
    "    # Define the target size\n",
    "    target_height = 256  # Example height\n",
    "    target_width = 256   # Example width\n",
    "\n",
    "    # Resize and ensure all tensors have the same number of channels, in this case, 3\n",
    "    resized_images = [resize(img, (target_height, target_width))[:3, :, :] if img.shape[0] > 3 else resize(img, (target_height, target_width)) for img in images]\n",
    "    resized_labels = [resize(lbl, (target_height, target_width))[:3, :, :] if lbl.shape[0] > 3 else resize(lbl, (target_height, target_width)) for lbl in labels]\n",
    "\n",
    "    # Stack all images and labels\n",
    "    images = torch.stack(resized_images)\n",
    "    labels = torch.stack(resized_labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "def test_collate_fn(batch):\n",
    "    images, labels, name = zip(*batch)\n",
    "    # Define the target size\n",
    "    target_height = 256  # Example height\n",
    "    target_width = 256   # Example width\n",
    "\n",
    "    # Resize and ensure all tensors have the same number of channels, in this case, 3\n",
    "    resized_images = [resize(img, (target_height, target_width))[:3, :, :] if img.shape[0] > 3 else resize(img, (target_height, target_width)) for img in images]\n",
    "    resized_labels = [resize(lbl, (target_height, target_width))[:3, :, :] if lbl.shape[0] > 3 else resize(lbl, (target_height, target_width)) for lbl in labels]\n",
    "\n",
    "    # Stack all images and labels\n",
    "    images = torch.stack(resized_images)\n",
    "    labels = torch.stack(resized_labels)\n",
    "\n",
    "    return images, labels, name\n",
    "\n",
    "def train_dataloader(path, batch_size=8, num_workers=0, use_transform=True): # we change batch size = 1, but the original batch size = 64\n",
    "    image_dir = os.path.join(path, 'train')\n",
    "\n",
    "    transform = None\n",
    "    if use_transform:\n",
    "        transform = PairCompose(\n",
    "            [\n",
    "                PairRandomCrop(256),\n",
    "                PairRandomHorizontalFilp(),\n",
    "                PairToTensor()\n",
    "            ]\n",
    "        )\n",
    "    dataloader = DataLoader(\n",
    "        DeblurDataset(image_dir, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=my_collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def test_dataloader(path, batch_size=1, num_workers=0):\n",
    "    image_dir = os.path.join(path, 'test')\n",
    "    dataloader = DataLoader(\n",
    "        DeblurDataset(image_dir, is_test=True),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def valid_dataloader(path, batch_size=1, num_workers=0):\n",
    "    dataloader = DataLoader(\n",
    "        DeblurDataset(os.path.join(path, 'test', ), is_valid=True),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=my_collate_fn,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class DeblurDataset_ex(Dataset):\n",
    "    def __init__(self, image_dir, transform=None, is_test=False):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_list = os.listdir(os.path.join(image_dir, 'hazy/'))\n",
    "        self._check_image(self.image_list)\n",
    "        self.image_list.sort()\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.image_dir, 'hazy', self.image_list[idx]))\n",
    "        label = Image.open(os.path.join(self.image_dir, 'gt', self.image_list[idx].split('_')[0]+'.png'))\n",
    "\n",
    "        if self.transform:\n",
    "            image, label = self.transform(image, label)\n",
    "        else:\n",
    "            image = Functional.to_tensor(image)\n",
    "            label = Functional.to_tensor(label)\n",
    "        if self.is_test:\n",
    "            name = self.image_list[idx]\n",
    "            return image, label, name\n",
    "        return image, label\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_image(lst):\n",
    "        for x in lst:\n",
    "            splits = x.split('.')\n",
    "            if splits[-1] not in ['png', 'jpg', 'jpeg']:\n",
    "                raise ValueError\n",
    "\n",
    "import random\n",
    "class DeblurDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None, is_test=False, is_valid=False, ps=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_list = os.listdir(os.path.join(image_dir, 'hazy/'))\n",
    "        self._check_image(self.image_list)\n",
    "        self.image_list.sort()\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.is_valid = is_valid\n",
    "        self.ps = ps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.image_dir, 'hazy', self.image_list[idx])).convert('RGB')\n",
    "        if self.is_valid or self.is_test:\n",
    "            label = Image.open(os.path.join(self.image_dir, 'gt', self.image_list[idx].split('_')[0]+'.png')).convert('RGB')\n",
    "        else:\n",
    "            try:\n",
    "                label = Image.open(os.path.join(self.image_dir, 'gt', self.image_list[idx].split('_')[0]+'.jpg')).convert('RGB')\n",
    "            except:\n",
    "                label = Image.open(os.path.join(self.image_dir, 'gt', self.image_list[idx].split('_')[0]+'.png')).convert('RGB')\n",
    "        ps = self.ps\n",
    "\n",
    "        if self.ps is not None:\n",
    "            image = Functional.to_tensor(image)\n",
    "            label = Functional.to_tensor(label)\n",
    "\n",
    "            hh, ww = label.shape[1], label.shape[2]\n",
    "\n",
    "            rr = random.randint(0, hh-ps)\n",
    "            cc = random.randint(0, ww-ps)\n",
    "\n",
    "            image = image[:, rr:rr+ps, cc:cc+ps]\n",
    "            label = label[:, rr:rr+ps, cc:cc+ps]\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                image = image.flip(2)\n",
    "                label = label.flip(2)\n",
    "        else:\n",
    "            image = Functional.to_tensor(image)\n",
    "            label = Functional.to_tensor(label)\n",
    "\n",
    "        if self.is_test:\n",
    "            name = self.image_list[idx]\n",
    "            return image, label, name\n",
    "        return image, label\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_image(lst):\n",
    "        for x in lst:\n",
    "            splits = x.split('.')\n",
    "            if splits[-1] not in ['png', 'jpg', 'jpeg']:\n",
    "                raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V41ETfpGPTs8",
    "outputId": "46649e19-1d1b-4e41-e40e-fbb2ea90b9b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7b92ee524fa0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZHCSwIpNEIe"
   },
   "outputs": [],
   "source": [
    "print(len(train_dataloader(path)))\n",
    "print(len(test_dataloader(path)))\n",
    "print(len(valid_dataloader(path)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOmdMPEPBcqU"
   },
   "source": [
    "Utils\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3KXVt8fBgN_"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Adder(object):\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.num = float(0)\n",
    "\n",
    "    def reset(self):\n",
    "        self.count = 0\n",
    "        self.num = float(0)\n",
    "\n",
    "    def __call__(self, num):\n",
    "        self.count += 1\n",
    "        self.num += num\n",
    "\n",
    "    def average(self):\n",
    "        return self.num / self.count\n",
    "\n",
    "\n",
    "class Timer(object):\n",
    "    def __init__(self, option='s'):\n",
    "        self.tm = 0\n",
    "        self.option = option\n",
    "        if option == 's':\n",
    "            self.devider = 1\n",
    "        elif option == 'm':\n",
    "            self.devider = 60\n",
    "        else:\n",
    "            self.devider = 3600\n",
    "\n",
    "    def tic(self):\n",
    "        self.tm = time.time()\n",
    "\n",
    "    def toc(self):\n",
    "        return (time.time() - self.tm) / self.devider\n",
    "\n",
    "\n",
    "def check_lr(optimizer):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        lr = param_group['lr']\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuIwak2DBSmK"
   },
   "source": [
    "Eval\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQmJ-vK5BT4n"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "import time\n",
    "from pytorch_msssim import ssim\n",
    "import torch.nn.functional as f\n",
    "\n",
    "from skimage import img_as_ubyte\n",
    "import cv2\n",
    "\n",
    "def average(self):\n",
    "    return self.num / self.count if self.count != 0 else 0  # or return None\n",
    "\n",
    "def _eval(model, args):\n",
    "    state_dict = torch.load(args.test_model)\n",
    "    model.load_state_dict(state_dict['model'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dataloader = test_dataloader(args.data_dir, batch_size=1, num_workers=8)\n",
    "    torch.cuda.empty_cache()\n",
    "    adder = Adder()\n",
    "    model.eval()\n",
    "    factor = 32\n",
    "    with torch.no_grad():\n",
    "        psnr_adder = Adder()\n",
    "        ssim_adder = Adder()\n",
    "\n",
    "        for iter_idx, data in enumerate(dataloader):\n",
    "            input_img, label_img, name = data\n",
    "\n",
    "            input_img = input_img.to(device)\n",
    "\n",
    "            h, w = input_img.shape[2], input_img.shape[3]\n",
    "            H, W = ((h+factor)//factor)*factor, ((w+factor)//factor*factor)\n",
    "            padh = H-h if h%factor!=0 else 0\n",
    "            padw = W-w if w%factor!=0 else 0\n",
    "            input_img = f.pad(input_img, (0, padw, 0, padh), 'reflect')\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            tm = time.time()\n",
    "\n",
    "            pred = model(input_img)[2]\n",
    "            pred = pred[:,:,:h,:w]\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            elapsed = time.time() - tm\n",
    "            adder(elapsed)\n",
    "\n",
    "            pred_clip = torch.clamp(pred, 0, 1)\n",
    "\n",
    "            pred_numpy = pred_clip.squeeze(0).cpu().numpy()\n",
    "            label_numpy = label_img.squeeze(0).cpu().numpy()\n",
    "\n",
    "\n",
    "            label_img = (label_img).cuda()\n",
    "            psnr_val = 10 * torch.log10(1 / f.mse_loss(pred_clip, label_img))\n",
    "            down_ratio = max(1, round(min(H, W) / 256))\n",
    "            ssim_val = ssim(f.adaptive_avg_pool2d(pred_clip, (int(H / down_ratio), int(W / down_ratio))),\n",
    "                            f.adaptive_avg_pool2d(label_img, (int(H / down_ratio), int(W / down_ratio))),\n",
    "                            data_range=1, size_average=False)\n",
    "            #print('%d iter PSNR_dehazing: %.2f ssim: %f' % (iter_idx + 1, psnr_val, ssim_val))\n",
    "            print('%d iter PSNR_dehazing: %.2f ssim: %f' % (iter_idx + 1, psnr_val, ssim_val))\n",
    "            ssim_adder(ssim_val)\n",
    "            if args.save_image:\n",
    "                save_name = os.path.join(args.result_dir, name[0])\n",
    "                pred_clip += 0.5 / 255\n",
    "                pred = F.to_pil_image(pred_clip.squeeze(0).cpu(), 'RGB')\n",
    "                pred.save(save_name)\n",
    "\n",
    "            psnr_mimo = peak_signal_noise_ratio(pred_numpy, label_numpy, data_range=1)\n",
    "            psnr_adder(psnr_val)\n",
    "\n",
    "            print('%d iter PSNR: %.2f time: %f' % (iter_idx + 1, psnr_mimo, elapsed))\n",
    "\n",
    "        print('==========================================================')\n",
    "        print('The average PSNR is %.2f dB' % (psnr_adder.average()))\n",
    "        print('The average SSIM is %.5f dB' % (ssim_adder.average()))\n",
    "\n",
    "        print(\"Average time: %f\" % adder.average())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiBJcTJbCOcj"
   },
   "source": [
    "Layers\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qOrc8BLCPaH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fl\n",
    "import math\n",
    "\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, bias=True, norm=False, relu=True, transpose=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        if bias and norm:\n",
    "            bias = False\n",
    "\n",
    "        padding = kernel_size // 2\n",
    "        layers = list()\n",
    "        if transpose:\n",
    "            padding = kernel_size // 2 -1\n",
    "            layers.append(nn.ConvTranspose2d(in_channel, out_channel, kernel_size, padding=padding, stride=stride, bias=bias))\n",
    "        else:\n",
    "            layers.append(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size, padding=padding, stride=stride, bias=bias))\n",
    "        if norm:\n",
    "            layers.append(nn.BatchNorm2d(out_channel))\n",
    "        if relu:\n",
    "            layers.append(nn.GELU())\n",
    "        self.main = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, filter=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            BasicConv(in_channel, out_channel, kernel_size=3, stride=1, relu=True),\n",
    "            DeepPoolLayer(in_channel, out_channel) if filter else nn.Identity(),\n",
    "            BasicConv(out_channel, out_channel, kernel_size=3, stride=1, relu=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x) + x\n",
    "\n",
    "\n",
    "class DeepPoolLayer(nn.Module):\n",
    "    def __init__(self, k, k_out):\n",
    "        super(DeepPoolLayer, self).__init__()\n",
    "        self.pools_sizes = [8,4,2]\n",
    "        pools, convs, dynas = [],[],[]\n",
    "        for i in self.pools_sizes:\n",
    "            pools.append(nn.AvgPool2d(kernel_size=i, stride=i))\n",
    "            convs.append(nn.Conv2d(k, k, 3, 1, 1, bias=False))\n",
    "            dynas.append(dynamic_filter(inchannels=k, kernel_size=3))\n",
    "        self.pools = nn.ModuleList(pools)\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.dynas = nn.ModuleList(dynas)\n",
    "        self.relu = nn.GELU()\n",
    "        self.conv_sum = nn.Conv2d(k, k_out, 3, 1, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        resl = x\n",
    "        for i in range(len(self.pools_sizes)):\n",
    "            if i == 0:\n",
    "                y = self.dynas[i](self.convs[i](self.pools[i](x)))\n",
    "            else:\n",
    "                y = self.dynas[i](self.convs[i](self.pools[i](x)+y_up))\n",
    "            resl = torch.add(resl, fl.interpolate(y, x_size[2:], mode='bilinear', align_corners=True))\n",
    "            if i != len(self.pools_sizes)-1:\n",
    "                y_up = fl.interpolate(y, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        resl = self.relu(resl)\n",
    "        resl = self.conv_sum(resl)\n",
    "\n",
    "        return resl\n",
    "\n",
    "class dynamic_filter(nn.Module):\n",
    "    def __init__(self, inchannels, kernel_size=3, stride=1, group=8):\n",
    "        super(dynamic_filter, self).__init__()\n",
    "\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.group = group\n",
    "\n",
    "        self.conv = nn.Conv2d(inchannels, group*kernel_size**2, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(group*kernel_size**2)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "        nn.init.kaiming_normal_(self.conv.weight, mode='fan_out', nonlinearity='relu')\n",
    "        self.lamb_l = nn.Parameter(torch.zeros(inchannels), requires_grad=True)\n",
    "        self.lamb_h = nn.Parameter(torch.zeros(inchannels), requires_grad=True)\n",
    "        self.pad = nn.ReflectionPad2d(kernel_size//2)\n",
    "\n",
    "        self.ap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.inside_all = nn.Parameter(torch.zeros(inchannels,1,1), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity_input = x\n",
    "        # the Conv_{3x3} layer in eq.3 is included in DeepPoolLayer.convs\n",
    "        low_filter = self.ap(x)\n",
    "        low_filter = self.conv(low_filter)\n",
    "        low_filter = self.bn(low_filter)\n",
    "\n",
    "        n, c, h, w = x.shape\n",
    "        x = fl.unfold(self.pad(x), kernel_size=self.kernel_size).reshape(n, self.group, c//self.group, self.kernel_size**2, h*w)\n",
    "\n",
    "        n,c1,p,q = low_filter.shape\n",
    "        low_filter = low_filter.reshape(n, c1//self.kernel_size**2, self.kernel_size**2, p*q).unsqueeze(2)\n",
    "        low_filter = self.act(low_filter)\n",
    "        low_part = torch.sum(x * low_filter, dim=3).reshape(n, c, h, w)\n",
    "\n",
    "        # the variables here are slightly different from the paper: (code) --> (paper)\n",
    "        # low_filter --> A (eq.3)\n",
    "        # In Eq.7, X*A'= X*(A_{l} + WA_{h})\n",
    "        #              = X*A_{l} + WX*(A - A_{l})\n",
    "        #              = X*A_{l} + WX*A - WX*A_{l}\n",
    "        #              = WX*A - X*A_{l}(W-1)\n",
    "        # we substitute gap for A_{l} for simplicity, which is a coarser low-frequency filter\n",
    "        out_low = low_part * (self.inside_all + 1.) - self.inside_all * self.gap(identity_input)\n",
    "\n",
    "        out_low = out_low * self.lamb_l[None,:,None,None]\n",
    "        out_high = (identity_input) * (self.lamb_h[None,:,None,None] + 1.)\n",
    "\n",
    "        return out_low + out_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muFr7px4CKua"
   },
   "source": [
    "IRNeXt\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNdQN8JdCMEh"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as ff\n",
    "\n",
    "class EBlock(nn.Module):\n",
    "    def __init__(self, out_channel, num_res=8):\n",
    "        super(EBlock, self).__init__()\n",
    "\n",
    "        layers = [ResBlock(out_channel, out_channel) for _ in range(num_res-1)]\n",
    "        layers.append(ResBlock(out_channel, out_channel, filter=True))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class DBlock(nn.Module):\n",
    "    def __init__(self, channel, num_res=8):\n",
    "        super(DBlock, self).__init__()\n",
    "\n",
    "        layers = [ResBlock(channel, channel) for _ in range(num_res-1)]\n",
    "        layers.append(ResBlock(channel, channel, filter=True))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class SCM(nn.Module):\n",
    "    def __init__(self, out_plane):\n",
    "        super(SCM, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            BasicConv(3, out_plane//4, kernel_size=3, stride=1, relu=True),\n",
    "            BasicConv(out_plane // 4, out_plane // 2, kernel_size=1, stride=1, relu=True),\n",
    "            BasicConv(out_plane // 2, out_plane // 2, kernel_size=3, stride=1, relu=True),\n",
    "            BasicConv(out_plane // 2, out_plane, kernel_size=1, stride=1, relu=False),\n",
    "            nn.InstanceNorm2d(out_plane, affine=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "class FAM(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(FAM, self).__init__()\n",
    "\n",
    "        self.merge = BasicConv(channel*2, channel, kernel_size=3, stride=1, relu=False)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        return self.merge(torch.cat([x1, x2], dim=1))\n",
    "\n",
    "class IRNeXt(nn.Module):\n",
    "    def __init__(self, num_res=4):\n",
    "        super(IRNeXt, self).__init__()\n",
    "\n",
    "        base_channel = 32\n",
    "        self.Encoder = nn.ModuleList([\n",
    "            EBlock(base_channel, num_res),\n",
    "            EBlock(base_channel*2, num_res),\n",
    "            EBlock(base_channel*4, num_res),\n",
    "        ])\n",
    "\n",
    "        self.feat_extract = nn.ModuleList([\n",
    "            BasicConv(3, base_channel, kernel_size=3, relu=True, stride=1),\n",
    "            BasicConv(base_channel, base_channel*2, kernel_size=3, relu=True, stride=2),\n",
    "            BasicConv(base_channel*2, base_channel*4, kernel_size=3, relu=True, stride=2),\n",
    "            BasicConv(base_channel*4, base_channel*2, kernel_size=4, relu=True, stride=2, transpose=True),\n",
    "            BasicConv(base_channel*2, base_channel, kernel_size=4, relu=True, stride=2, transpose=True),\n",
    "            BasicConv(base_channel, 3, kernel_size=3, relu=False, stride=1)\n",
    "        ])\n",
    "\n",
    "        self.Decoder = nn.ModuleList([\n",
    "            DBlock(base_channel * 4, num_res),\n",
    "            DBlock(base_channel * 2, num_res),\n",
    "            DBlock(base_channel, num_res)\n",
    "        ])\n",
    "\n",
    "        self.Convs = nn.ModuleList([\n",
    "            BasicConv(base_channel * 4, base_channel * 2, kernel_size=1, relu=True, stride=1),\n",
    "            BasicConv(base_channel * 2, base_channel, kernel_size=1, relu=True, stride=1),\n",
    "        ])\n",
    "\n",
    "        self.ConvsOut = nn.ModuleList(\n",
    "            [\n",
    "                BasicConv(base_channel * 4, 3, kernel_size=3, relu=False, stride=1),\n",
    "                BasicConv(base_channel * 2, 3, kernel_size=3, relu=False, stride=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.FAM1 = FAM(base_channel * 4)\n",
    "        self.SCM1 = SCM(base_channel * 4)\n",
    "        self.FAM2 = FAM(base_channel * 2)\n",
    "        self.SCM2 = SCM(base_channel * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_2 = ff.interpolate(x, scale_factor=0.5)\n",
    "        x_4 = ff.interpolate(x_2, scale_factor=0.5)\n",
    "        z2 = self.SCM2(x_2)\n",
    "        z4 = self.SCM1(x_4)\n",
    "\n",
    "        outputs = list()\n",
    "        # 256\n",
    "        x_ = self.feat_extract[0](x)\n",
    "        res1 = self.Encoder[0](x_)\n",
    "        # 128\n",
    "        z = self.feat_extract[1](res1)\n",
    "        z = self.FAM2(z, z2)\n",
    "        res2 = self.Encoder[1](z)\n",
    "        # 64\n",
    "        z = self.feat_extract[2](res2)\n",
    "        z = self.FAM1(z, z4)\n",
    "        z = self.Encoder[2](z)\n",
    "\n",
    "        z = self.Decoder[0](z)\n",
    "        z_ = self.ConvsOut[0](z)\n",
    "        # 128\n",
    "        z = self.feat_extract[3](z)\n",
    "        outputs.append(z_+x_4)\n",
    "\n",
    "        z = torch.cat([z, res2], dim=1)\n",
    "        z = self.Convs[0](z)\n",
    "        z = self.Decoder[1](z)\n",
    "        z_ = self.ConvsOut[1](z)\n",
    "        # 256\n",
    "        z = self.feat_extract[4](z)\n",
    "        outputs.append(z_+x_2)\n",
    "\n",
    "        z = torch.cat([z, res1], dim=1)\n",
    "        z = self.Convs[1](z)\n",
    "        z = self.Decoder[2](z)\n",
    "        z = self.feat_extract[5](z)\n",
    "        outputs.append(z+x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def build_net():\n",
    "    return IRNeXt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ_iPV8xBg0K"
   },
   "source": [
    "Valid\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfAK2d13Bjq9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "import os\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "import torch.nn.functional as fv\n",
    "\n",
    "\n",
    "def _valid(model, args, ep):\n",
    "    print('Load test data')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    its = valid_dataloader(args.data_dir, batch_size=1, num_workers=0)\n",
    "    model.eval()\n",
    "    psnr_adder = Adder()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print('Start Evaluation')\n",
    "        factor = 32\n",
    "        for idx, data in enumerate(its):\n",
    "            input_img, label_img = data\n",
    "            input_img = input_img.to(device)\n",
    "\n",
    "            h, w = input_img.shape[2], input_img.shape[3]\n",
    "            H, W = ((h+factor)//factor)*factor, ((w+factor)//factor*factor)\n",
    "            padh = H-h if h%factor!=0 else 0\n",
    "            padw = W-w if w%factor!=0 else 0\n",
    "            input_img = fv.pad(input_img, (0, padw, 0, padh), 'reflect')\n",
    "\n",
    "            if not os.path.exists(os.path.join(args.result_dir, '%d' % (ep))):\n",
    "                os.mkdir(os.path.join(args.result_dir, '%d' % (ep)))\n",
    "\n",
    "            pred = model(input_img)[2]\n",
    "            pred = pred[:,:,:h,:w]\n",
    "\n",
    "            pred_clip = torch.clamp(pred, 0, 1)\n",
    "            p_numpy = pred_clip.squeeze(0).cpu().numpy()\n",
    "            label_numpy = label_img.squeeze(0).cpu().numpy()\n",
    "\n",
    "            psnr = peak_signal_noise_ratio(p_numpy, label_numpy, data_range=1)\n",
    "\n",
    "            psnr_adder(psnr)\n",
    "            print('\\r%03d'%idx, end=' ')\n",
    "\n",
    "    print('\\n')\n",
    "    model.train()\n",
    "    return psnr_adder.average()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1n87ZbXeBapS"
   },
   "source": [
    "TRAIN\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jt9V7QBGBcGV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as ft\n",
    "import torch.nn as nn\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "save_dir = '/content/drive/MyDrive/results'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def _train(model, args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    criterion = torch.nn.L1Loss().to(device)\n",
    "    print(\"training LR:\", args.learning_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, betas=(0.9, 0.999), eps=1e-8)\n",
    "    dataloader = train_dataloader(args.data_dir, args.batch_size, args.num_worker)\n",
    "    max_iter = len(dataloader)\n",
    "    warmup_epochs=3\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.num_epoch-warmup_epochs, eta_min=1e-6)\n",
    "    scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=warmup_epochs, after_scheduler=scheduler_cosine)\n",
    "    scheduler.step()\n",
    "    epoch = 1\n",
    "    if args.resume:\n",
    "        state = torch.load(args.resume)\n",
    "        epoch = state['epoch']\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        model.load_state_dict(state['model'])\n",
    "        print('Resume from %d'%epoch)\n",
    "        epoch += 1\n",
    "        for i in range(epoch-1):\n",
    "          scheduler.step()\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "    epoch_pixel_adder = Adder()\n",
    "    epoch_fft_adder = Adder()\n",
    "    iter_pixel_adder = Adder()\n",
    "    iter_fft_adder = Adder()\n",
    "    epoch_timer = Timer('m')\n",
    "    iter_timer = Timer('m')\n",
    "    best_psnr=-1\n",
    "    epoch_floss = []\n",
    "    epoch_ploss = []\n",
    "    epoch_psnr = []\n",
    "\n",
    "    for epoch_idx in range(epoch, args.num_epoch + 1):\n",
    "\n",
    "        epoch_timer.tic()\n",
    "        iter_timer.tic()\n",
    "        for iter_idx, batch_data in enumerate(dataloader):\n",
    "            input_img, label_img = batch_data\n",
    "            input_img = input_img.to(device)\n",
    "            label_img = label_img.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_img = model(input_img)\n",
    "            label_img2 = ft.interpolate(label_img, scale_factor=0.5, mode='bilinear')\n",
    "            label_img4 = ft.interpolate(label_img, scale_factor=0.25, mode='bilinear')\n",
    "            l1 = criterion(pred_img[0], label_img4)\n",
    "            l2 = criterion(pred_img[1], label_img2)\n",
    "            l3 = criterion(pred_img[2], label_img)\n",
    "            loss_content = l1+l2+l3\n",
    "\n",
    "            label_fft1 = torch.fft.fft2(label_img4, dim=(-2,-1))\n",
    "            label_fft1 = torch.stack((label_fft1.real, label_fft1.imag), -1)\n",
    "\n",
    "            pred_fft1 = torch.fft.fft2(pred_img[0], dim=(-2,-1))\n",
    "            pred_fft1 = torch.stack((pred_fft1.real, pred_fft1.imag), -1)\n",
    "\n",
    "            label_fft2 = torch.fft.fft2(label_img2, dim=(-2,-1))\n",
    "            label_fft2 = torch.stack((label_fft2.real, label_fft2.imag), -1)\n",
    "\n",
    "            pred_fft2 = torch.fft.fft2(pred_img[1], dim=(-2,-1))\n",
    "            pred_fft2 = torch.stack((pred_fft2.real, pred_fft2.imag), -1)\n",
    "\n",
    "            label_fft3 = torch.fft.fft2(label_img, dim=(-2,-1))\n",
    "            label_fft3 = torch.stack((label_fft3.real, label_fft3.imag), -1)\n",
    "\n",
    "            pred_fft3 = torch.fft.fft2(pred_img[2], dim=(-2,-1))\n",
    "            pred_fft3 = torch.stack((pred_fft3.real, pred_fft3.imag), -1)\n",
    "\n",
    "            f1 = criterion(pred_fft1, label_fft1)\n",
    "            f2 = criterion(pred_fft2, label_fft2)\n",
    "            f3 = criterion(pred_fft3, label_fft3)\n",
    "            loss_fft = f1+f2+f3\n",
    "\n",
    "            loss = loss_content + 0.1 * loss_fft\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.001)\n",
    "            optimizer.step()\n",
    "\n",
    "            iter_pixel_adder(loss_content.item())\n",
    "            iter_fft_adder(loss_fft.item())\n",
    "\n",
    "            epoch_pixel_adder(loss_content.item())\n",
    "            epoch_fft_adder(loss_fft.item())\n",
    "\n",
    "            if (iter_idx + 1) % args.print_freq == 0:\n",
    "                print(\"Time: %7.4f Epoch: %03d Iter: %4d/%4d LR: %.10f Loss content: %7.4f Loss fft: %7.4f\" % (\n",
    "                    iter_timer.toc(), epoch_idx, iter_idx + 1, max_iter, scheduler.get_lr()[0], iter_pixel_adder.average(),\n",
    "                    iter_fft_adder.average()))\n",
    "                writer.add_scalar('Pixel Loss', iter_pixel_adder.average(), iter_idx + (epoch_idx-1)* max_iter)\n",
    "                writer.add_scalar('FFT Loss', iter_fft_adder.average(), iter_idx + (epoch_idx - 1) * max_iter)\n",
    "\n",
    "                iter_timer.tic()\n",
    "                iter_pixel_adder.reset()\n",
    "                iter_fft_adder.reset()\n",
    "        overwrite_name = os.path.join(args.model_save_dir, 'model.pkl')\n",
    "        torch.save({'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epoch': epoch_idx}, overwrite_name)\n",
    "\n",
    "        if epoch_idx % args.save_freq == 0:\n",
    "            save_name = os.path.join(args.model_save_dir, 'model_%d.pkl' % epoch_idx)\n",
    "            torch.save({'model': model.state_dict()}, save_name)\n",
    "        print(\"EPOCH: %02d\\nElapsed time: %4.2f Epoch Pixel Loss: %7.4f Epoch FFT Loss: %7.4f\" % (\n",
    "            epoch_idx, epoch_timer.toc(), epoch_pixel_adder.average(), epoch_fft_adder.average()))\n",
    "        epoch_floss.append(epoch_fft_adder.average())\n",
    "        epoch_ploss.append(epoch_pixel_adder.average())\n",
    "        epoch_fft_adder.reset()\n",
    "        epoch_pixel_adder.reset()\n",
    "        scheduler.step()\n",
    "        if epoch_idx % args.valid_freq == 0:\n",
    "            val = _valid(model, args, epoch_idx)\n",
    "            print('%03d epoch \\n Average PSNR %.2f dB' % (epoch_idx, val))\n",
    "            epoch_psnr.append(val)\n",
    "            writer.add_scalar('PSNR', val, epoch_idx)\n",
    "            if val >= best_psnr:\n",
    "                torch.save({'model': model.state_dict()}, os.path.join(args.model_save_dir, 'Best.pkl'))\n",
    "        if epoch_idx % 10 == 0:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(epoch_ploss, label='Pixel Loss')\n",
    "            plt.plot(epoch_floss, label='FFT Loss')\n",
    "            #plt.plot(epoch_psnr, label='PSNR')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Metrics')\n",
    "            plt.title('Training Metrics Over Epochs')\n",
    "            plt.legend()\n",
    "            file_path = os.path.join(save_dir, args.figname)\n",
    "            plt.savefig(file_path)\n",
    "    save_name = os.path.join(args.model_save_dir, 'Final.pkl')\n",
    "    torch.save({'model': model.state_dict()}, save_name)\n",
    "    print(\"PSNR = \", epoch_psnr)\n",
    "    print(\"Pixel Loss =\", epoch_ploss)\n",
    "    print(\"FFT Loss =\", epoch_floss)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkZX62DbuysV"
   },
   "source": [
    "##  Mix Up Train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3mf_d2suxgK"
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Applies MixUp augmentation $####\n",
    "## Input parameters:\n",
    "## 1) x: Input data (features)\n",
    "## 2) y: Target data (labels)\n",
    "## 3) alpha: hyperparameter to control the mixup rate\n",
    "##\n",
    "## Output parameters\n",
    "## output data after mixed\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    '''Compute the mixup loss'''\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as ft\n",
    "import torch.nn as nn\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "save_dir = '/content/drive/MyDrive/results'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def _train(model, args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    criterion = torch.nn.L1Loss().to(device)\n",
    "    print(\"training LR:\", args.learning_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, betas=(0.9, 0.999), eps=1e-8)\n",
    "    dataloader = train_dataloader(args.data_dir, args.batch_size, args.num_worker)\n",
    "    max_iter = len(dataloader)\n",
    "    warmup_epochs=3\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.num_epoch-warmup_epochs, eta_min=1e-6)\n",
    "    scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=warmup_epochs, after_scheduler=scheduler_cosine)\n",
    "    scheduler.step()\n",
    "    epoch = 1\n",
    "    if args.resume:\n",
    "        state = torch.load(args.resume)\n",
    "        epoch = state['epoch']\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        model.load_state_dict(state['model'])\n",
    "        print('Resume from %d'%epoch)\n",
    "        epoch += 1\n",
    "        for i in range(epoch-1):\n",
    "          scheduler.step()\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "    epoch_pixel_adder = Adder()\n",
    "    epoch_fft_adder = Adder()\n",
    "    iter_pixel_adder = Adder()\n",
    "    iter_fft_adder = Adder()\n",
    "    epoch_timer = Timer('m')\n",
    "    iter_timer = Timer('m')\n",
    "    best_psnr=-1\n",
    "    epoch_floss = []\n",
    "    epoch_ploss = []\n",
    "    epoch_psnr = []\n",
    "\n",
    "    for epoch_idx in range(epoch, args.num_epoch + 1):\n",
    "\n",
    "        epoch_timer.tic()\n",
    "        iter_timer.tic()\n",
    "        for iter_idx, batch_data in enumerate(dataloader):\n",
    "            input_img, label_img = batch_data\n",
    "            input_img, label_img = input_img.to(device), label_img.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Apply Mixup Data Augmentation\n",
    "            mixed_input, mixed_label_a, mixed_label_b, lam = mixup_data(input_img, label_img, alpha=0.2)\n",
    "\n",
    "\n",
    "            # Forward pass with mixed inputs\n",
    "            pred_img = model(mixed_input)\n",
    "\n",
    "            label_img2_a = ft.interpolate(mixed_label_a, scale_factor=0.5, mode='bilinear')\n",
    "            label_img2_b = ft.interpolate(mixed_label_b, scale_factor=0.5, mode='bilinear')\n",
    "            label_img4_a = ft.interpolate(mixed_label_a, scale_factor=0.25, mode='bilinear')\n",
    "            label_img4_b = ft.interpolate(mixed_label_b, scale_factor=0.25, mode='bilinear')\n",
    "            #l1 = criterion(pred_img[0], label_img4)\n",
    "            #l2 = criterion(pred_img[1], label_img2)\n",
    "            #l3 = criterion(pred_img[2], label_img)\n",
    "\n",
    "            l1 = mixup_criterion(criterion, pred_img[0], label_img4_a, label_img4_b, lam)\n",
    "            l2 = mixup_criterion(criterion, pred_img[1], label_img2_a, label_img2_b, lam)\n",
    "            l3 = mixup_criterion(criterion, pred_img[2], mixed_label_a, mixed_label_b, lam)\n",
    "            loss_content = l1+l2+l3\n",
    "\n",
    "            label_fft1_a = torch.fft.fft2(label_img4_a, dim=(-2,-1))\n",
    "            label_fft1_a = torch.stack((label_fft1_a.real, label_fft1_a.imag), -1)\n",
    "            label_fft1_b = torch.fft.fft2(label_img4_b, dim=(-2,-1))\n",
    "            label_fft1_b = torch.stack((label_fft1_b.real, label_fft1_b.imag), -1)\n",
    "\n",
    "            pred_fft1 = torch.fft.fft2(pred_img[0], dim=(-2,-1))\n",
    "            pred_fft1 = torch.stack((pred_fft1.real, pred_fft1.imag), -1)\n",
    "\n",
    "            label_fft2_a = torch.fft.fft2(label_img2_a, dim=(-2,-1))\n",
    "            label_fft2_a = torch.stack((label_fft2_a.real, label_fft2_a.imag), -1)\n",
    "            label_fft2_b = torch.fft.fft2(label_img2_b, dim=(-2,-1))\n",
    "            label_fft2_b = torch.stack((label_fft2_b.real, label_fft2_b.imag), -1)\n",
    "\n",
    "            pred_fft2 = torch.fft.fft2(pred_img[1], dim=(-2,-1))\n",
    "            pred_fft2 = torch.stack((pred_fft2.real, pred_fft2.imag), -1)\n",
    "\n",
    "            label_fft3_a = torch.fft.fft2(mixed_label_a, dim=(-2,-1))\n",
    "            label_fft3_a = torch.stack((label_fft3_a.real, label_fft3_a.imag), -1)\n",
    "            label_fft3_b = torch.fft.fft2(mixed_label_b, dim=(-2,-1))\n",
    "            label_fft3_b = torch.stack((label_fft3_b.real, label_fft3_b.imag), -1)\n",
    "\n",
    "            pred_fft3 = torch.fft.fft2(pred_img[2], dim=(-2,-1))\n",
    "            pred_fft3 = torch.stack((pred_fft3.real, pred_fft3.imag), -1)\n",
    "\n",
    "            #f1 = criterion(pred_fft1, label_fft1)\n",
    "            #f2 = criterion(pred_fft2, label_fft2)\n",
    "            #f3 = criterion(pred_fft3, label_fft3)\n",
    "            f1 = mixup_criterion(criterion, pred_fft1, label_fft1_a, label_fft1_b, lam)\n",
    "            f2 = mixup_criterion(criterion, pred_fft2, label_fft2_a, label_fft2_b, lam)\n",
    "            f3 = mixup_criterion(criterion, pred_fft3, label_fft3_a, label_fft3_b, lam)\n",
    "            loss_fft = f1+f2+f3\n",
    "\n",
    "            loss = loss_content + 0.1 * loss_fft\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.001)\n",
    "            optimizer.step()\n",
    "\n",
    "            iter_pixel_adder(loss_content.item())\n",
    "            iter_fft_adder(loss_fft.item())\n",
    "\n",
    "            epoch_pixel_adder(loss_content.item())\n",
    "            epoch_fft_adder(loss_fft.item())\n",
    "\n",
    "            if (iter_idx + 1) % args.print_freq == 0:\n",
    "                print(\"Time: %7.4f Epoch: %03d Iter: %4d/%4d LR: %.10f Loss content: %7.4f Loss fft: %7.4f\" % (\n",
    "                    iter_timer.toc(), epoch_idx, iter_idx + 1, max_iter, scheduler.get_lr()[0], iter_pixel_adder.average(),\n",
    "                    iter_fft_adder.average()))\n",
    "                writer.add_scalar('Pixel Loss', iter_pixel_adder.average(), iter_idx + (epoch_idx-1)* max_iter)\n",
    "                writer.add_scalar('FFT Loss', iter_fft_adder.average(), iter_idx + (epoch_idx - 1) * max_iter)\n",
    "\n",
    "                iter_timer.tic()\n",
    "                iter_pixel_adder.reset()\n",
    "                iter_fft_adder.reset()\n",
    "        overwrite_name = os.path.join(args.model_save_dir, 'model.pkl')\n",
    "        torch.save({'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epoch': epoch_idx}, overwrite_name)\n",
    "\n",
    "        if epoch_idx % args.save_freq == 0:\n",
    "            save_name = os.path.join(args.model_save_dir, 'model_%d.pkl' % epoch_idx)\n",
    "            torch.save({'model': model.state_dict()}, save_name)\n",
    "        print(\"EPOCH: %02d\\nElapsed time: %4.2f Epoch Pixel Loss: %7.4f Epoch FFT Loss: %7.4f\" % (\n",
    "            epoch_idx, epoch_timer.toc(), epoch_pixel_adder.average(), epoch_fft_adder.average()))\n",
    "        epoch_floss.append(epoch_fft_adder.average())\n",
    "        epoch_ploss.append(epoch_pixel_adder.average())\n",
    "        epoch_fft_adder.reset()\n",
    "        epoch_pixel_adder.reset()\n",
    "        scheduler.step()\n",
    "        if epoch_idx % args.valid_freq == 0:\n",
    "            val = _valid(model, args, epoch_idx)\n",
    "            print('%03d epoch \\n Average PSNR %.2f dB' % (epoch_idx, val))\n",
    "            epoch_psnr.append(val)\n",
    "            writer.add_scalar('PSNR', val, epoch_idx)\n",
    "            if val >= best_psnr:\n",
    "                torch.save({'model': model.state_dict()}, os.path.join(args.model_save_dir, 'Best.pkl'))\n",
    "        if epoch_idx % 10 == 0:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(epoch_ploss, label='Pixel Loss')\n",
    "            plt.plot(epoch_floss, label='FFT Loss')\n",
    "            #plt.plot(epoch_psnr, label='PSNR')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Metrics')\n",
    "            plt.title('Training Metrics Over Epochs')\n",
    "            plt.legend()\n",
    "            file_path = os.path.join(save_dir, args.figname)\n",
    "            plt.savefig(file_path)\n",
    "    save_name = os.path.join(args.model_save_dir, 'Final.pkl')\n",
    "    torch.save({'model': model.state_dict()}, save_name)\n",
    "    print(\"PSNR = \", epoch_psnr)\n",
    "    print(\"Pixel Loss =\", epoch_ploss)\n",
    "    print(\"FFT Loss =\", epoch_floss)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoDUXGBNBWr7"
   },
   "source": [
    "Main\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "kcF3qG8RSAcd",
    "outputId": "0fa2907f-dac6-49ae-c4fb-4993acfb8401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x7a0810f01f60>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c2f1a6215e68>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-c2f1a6215e68>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Make sure to define _train or import it if it's defined elsewhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "# from torch.backends import cudnn # Uncomment if you need it\n",
    "\n",
    "class Args:\n",
    "    model_name = 'IRNeXt'\n",
    "    mode = 'train'\n",
    "    data_dir = './reside-outdoor/'\n",
    "\n",
    "    # Train\n",
    "    batch_size = 8\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 0\n",
    "    num_epoch = 30\n",
    "    print_freq = 500\n",
    "    num_worker = 8\n",
    "    save_freq = 10\n",
    "    valid_freq = 10\n",
    "    figname = 'outdoor_30epoch.jpg'\n",
    "    resume = '/content/drive/MyDrive/results/IRNeXt/OTS/model.pkl'\n",
    "\n",
    "    # Test\n",
    "    test_model = '/content/drive/MyDrive/results/IRNeXt/OTS/Final.pkl'\n",
    "    # save_image = False\n",
    "\n",
    "    # Directories (set these as per your requirement)\n",
    "    model_save_dir = os.path.join('/content/drive/MyDrive/results/', 'IRNeXt', 'OTS/')\n",
    "    result_dir = os.path.join('/content/drive/MyDrive/results/', model_name, 'test')\n",
    "\n",
    "def main(args):\n",
    "    # CUDNN\n",
    "    # cudnn.benchmark = True # Uncomment if you need it\n",
    "\n",
    "    if not os.path.exists('/content/drive/MyDrive/results/'):\n",
    "        os.makedirs(args.model_save_dir)\n",
    "    if not os.path.exists('/content/drive/MyDrive/results/' + args.model_name + '/'):\n",
    "        os.makedirs('/content/drive/MyDrive/results/' + args.model_name + '/')\n",
    "    if not os.path.exists(args.model_save_dir):\n",
    "        os.makedirs(args.model_save_dir)\n",
    "    if not os.path.exists(args.result_dir):\n",
    "        os.makedirs(args.result_dir)\n",
    "\n",
    "    model = build_net()  # Make sure to define build_net or import it if it's defined elsewhere\n",
    "    #print(model)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    if args.mode == 'train':\n",
    "        _train(model, args)  # Make sure to define _train or import it if it's defined elsewhere\n",
    "\n",
    "    elif args.mode == 'test':\n",
    "        _eval(model, args)   # Make sure to define _eval or import it if it's defined elsewhere\n",
    "\n",
    "# Replace parser.parse_args() with an instance of the Args class\n",
    "args = Args()\n",
    "if not os.path.exists(args.model_save_dir):\n",
    "    os.makedirs(args.model_save_dir)\n",
    "# Copying files (make sure these paths are correct)\n",
    "command = 'cp ' + 'models/layers.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "command = 'cp ' + 'models/IRNeXt.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "command = 'cp ' + 'train.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "command = 'cp ' + 'main.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "print(args)\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5aGTHRISo4o",
    "outputId": "32c1757c-c967-41fa-d1cf-e6307eae6052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x78631f418430>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iter PSNR_dehazing: 34.00 ssim: 0.989454\n",
      "1 iter PSNR: 34.00 time: 0.057719\n",
      "2 iter PSNR_dehazing: 29.70 ssim: 0.988927\n",
      "2 iter PSNR: 29.70 time: 0.033097\n",
      "3 iter PSNR_dehazing: 34.98 ssim: 0.992817\n",
      "3 iter PSNR: 34.98 time: 0.021873\n",
      "4 iter PSNR_dehazing: 35.84 ssim: 0.995107\n",
      "4 iter PSNR: 35.84 time: 0.021759\n",
      "5 iter PSNR_dehazing: 32.37 ssim: 0.985748\n",
      "5 iter PSNR: 32.37 time: 0.021308\n",
      "6 iter PSNR_dehazing: 32.71 ssim: 0.981001\n",
      "6 iter PSNR: 32.71 time: 0.021047\n",
      "7 iter PSNR_dehazing: 30.27 ssim: 0.968758\n",
      "7 iter PSNR: 30.27 time: 0.021554\n",
      "8 iter PSNR_dehazing: 31.64 ssim: 0.974349\n",
      "8 iter PSNR: 31.64 time: 0.021356\n",
      "9 iter PSNR_dehazing: 30.13 ssim: 0.940247\n",
      "9 iter PSNR: 30.13 time: 0.022548\n",
      "10 iter PSNR_dehazing: 34.55 ssim: 0.994172\n",
      "10 iter PSNR: 34.55 time: 0.021042\n",
      "11 iter PSNR_dehazing: 30.01 ssim: 0.986667\n",
      "11 iter PSNR: 30.01 time: 0.032099\n",
      "12 iter PSNR_dehazing: 37.75 ssim: 0.994114\n",
      "12 iter PSNR: 37.75 time: 0.020892\n",
      "13 iter PSNR_dehazing: 30.63 ssim: 0.987885\n",
      "13 iter PSNR: 30.63 time: 0.020946\n",
      "14 iter PSNR_dehazing: 31.72 ssim: 0.988895\n",
      "14 iter PSNR: 31.72 time: 0.023419\n",
      "15 iter PSNR_dehazing: 31.56 ssim: 0.992890\n",
      "15 iter PSNR: 31.56 time: 0.021117\n",
      "16 iter PSNR_dehazing: 41.73 ssim: 0.994401\n",
      "16 iter PSNR: 41.73 time: 0.023154\n",
      "17 iter PSNR_dehazing: 38.81 ssim: 0.991426\n",
      "17 iter PSNR: 38.81 time: 0.025014\n",
      "18 iter PSNR_dehazing: 42.53 ssim: 0.991798\n",
      "18 iter PSNR: 42.53 time: 0.022682\n",
      "19 iter PSNR_dehazing: 34.07 ssim: 0.988426\n",
      "19 iter PSNR: 34.07 time: 0.022491\n",
      "20 iter PSNR_dehazing: 34.55 ssim: 0.981434\n",
      "20 iter PSNR: 34.55 time: 0.021781\n",
      "21 iter PSNR_dehazing: 32.27 ssim: 0.985463\n",
      "21 iter PSNR: 32.27 time: 0.022197\n",
      "22 iter PSNR_dehazing: 34.68 ssim: 0.988953\n",
      "22 iter PSNR: 34.68 time: 0.020901\n",
      "23 iter PSNR_dehazing: 31.56 ssim: 0.986336\n",
      "23 iter PSNR: 31.56 time: 0.022038\n",
      "24 iter PSNR_dehazing: 34.97 ssim: 0.992397\n",
      "24 iter PSNR: 34.97 time: 0.021624\n",
      "25 iter PSNR_dehazing: 38.46 ssim: 0.996575\n",
      "25 iter PSNR: 38.46 time: 0.022654\n",
      "26 iter PSNR_dehazing: 32.24 ssim: 0.982105\n",
      "26 iter PSNR: 32.24 time: 0.023466\n",
      "27 iter PSNR_dehazing: 31.96 ssim: 0.987459\n",
      "27 iter PSNR: 31.96 time: 0.023009\n",
      "28 iter PSNR_dehazing: 32.51 ssim: 0.989743\n",
      "28 iter PSNR: 32.51 time: 0.021495\n",
      "29 iter PSNR_dehazing: 34.11 ssim: 0.992833\n",
      "29 iter PSNR: 34.11 time: 0.021297\n",
      "30 iter PSNR_dehazing: 33.14 ssim: 0.981317\n",
      "30 iter PSNR: 33.14 time: 0.022798\n",
      "31 iter PSNR_dehazing: 36.10 ssim: 0.993169\n",
      "31 iter PSNR: 36.10 time: 0.021210\n",
      "32 iter PSNR_dehazing: 31.31 ssim: 0.987355\n",
      "32 iter PSNR: 31.31 time: 0.021315\n",
      "33 iter PSNR_dehazing: 31.46 ssim: 0.991018\n",
      "33 iter PSNR: 31.46 time: 0.027147\n",
      "34 iter PSNR_dehazing: 35.21 ssim: 0.988476\n",
      "34 iter PSNR: 35.21 time: 0.024249\n",
      "35 iter PSNR_dehazing: 34.01 ssim: 0.992658\n",
      "35 iter PSNR: 34.01 time: 0.031651\n",
      "36 iter PSNR_dehazing: 26.54 ssim: 0.960371\n",
      "36 iter PSNR: 26.54 time: 0.032650\n",
      "37 iter PSNR_dehazing: 33.84 ssim: 0.988345\n",
      "37 iter PSNR: 33.84 time: 0.023744\n",
      "38 iter PSNR_dehazing: 34.16 ssim: 0.991634\n",
      "38 iter PSNR: 34.16 time: 0.024168\n",
      "39 iter PSNR_dehazing: 39.75 ssim: 0.995268\n",
      "39 iter PSNR: 39.75 time: 0.023108\n",
      "40 iter PSNR_dehazing: 36.66 ssim: 0.992252\n",
      "40 iter PSNR: 36.66 time: 0.025081\n",
      "41 iter PSNR_dehazing: 23.15 ssim: 0.985159\n",
      "41 iter PSNR: 23.15 time: 0.021905\n",
      "42 iter PSNR_dehazing: 32.65 ssim: 0.986253\n",
      "42 iter PSNR: 32.65 time: 0.022223\n",
      "43 iter PSNR_dehazing: 32.71 ssim: 0.990299\n",
      "43 iter PSNR: 32.71 time: 0.023099\n",
      "44 iter PSNR_dehazing: 23.30 ssim: 0.935598\n",
      "44 iter PSNR: 23.30 time: 0.024445\n",
      "45 iter PSNR_dehazing: 29.82 ssim: 0.986958\n",
      "45 iter PSNR: 29.82 time: 0.022780\n",
      "46 iter PSNR_dehazing: 30.52 ssim: 0.978148\n",
      "46 iter PSNR: 30.52 time: 0.023019\n",
      "47 iter PSNR_dehazing: 30.20 ssim: 0.981475\n",
      "47 iter PSNR: 30.20 time: 0.022310\n",
      "48 iter PSNR_dehazing: 33.73 ssim: 0.982452\n",
      "48 iter PSNR: 33.73 time: 0.032873\n",
      "49 iter PSNR_dehazing: 36.82 ssim: 0.993803\n",
      "49 iter PSNR: 36.82 time: 0.021825\n",
      "50 iter PSNR_dehazing: 35.00 ssim: 0.990931\n",
      "50 iter PSNR: 35.00 time: 0.023347\n",
      "51 iter PSNR_dehazing: 25.49 ssim: 0.971682\n",
      "51 iter PSNR: 25.49 time: 0.021627\n",
      "52 iter PSNR_dehazing: 33.44 ssim: 0.989678\n",
      "52 iter PSNR: 33.44 time: 0.025210\n",
      "53 iter PSNR_dehazing: 33.24 ssim: 0.990158\n",
      "53 iter PSNR: 33.24 time: 0.021712\n",
      "54 iter PSNR_dehazing: 29.44 ssim: 0.972552\n",
      "54 iter PSNR: 29.44 time: 0.023510\n",
      "55 iter PSNR_dehazing: 25.94 ssim: 0.978881\n",
      "55 iter PSNR: 25.94 time: 0.023085\n",
      "56 iter PSNR_dehazing: 36.86 ssim: 0.986067\n",
      "56 iter PSNR: 36.86 time: 0.024053\n",
      "57 iter PSNR_dehazing: 28.81 ssim: 0.967145\n",
      "57 iter PSNR: 28.81 time: 0.025066\n",
      "58 iter PSNR_dehazing: 30.20 ssim: 0.982542\n",
      "58 iter PSNR: 30.20 time: 0.023127\n",
      "59 iter PSNR_dehazing: 30.45 ssim: 0.985409\n",
      "59 iter PSNR: 30.45 time: 0.026306\n",
      "60 iter PSNR_dehazing: 28.82 ssim: 0.982961\n",
      "60 iter PSNR: 28.82 time: 0.032540\n",
      "61 iter PSNR_dehazing: 28.82 ssim: 0.962110\n",
      "61 iter PSNR: 28.82 time: 0.021975\n",
      "62 iter PSNR_dehazing: 37.06 ssim: 0.992717\n",
      "62 iter PSNR: 37.06 time: 0.022408\n",
      "63 iter PSNR_dehazing: 28.11 ssim: 0.990372\n",
      "63 iter PSNR: 28.11 time: 0.022241\n",
      "64 iter PSNR_dehazing: 31.85 ssim: 0.991026\n",
      "64 iter PSNR: 31.85 time: 0.024434\n",
      "65 iter PSNR_dehazing: 27.00 ssim: 0.986639\n",
      "65 iter PSNR: 27.00 time: 0.022391\n",
      "66 iter PSNR_dehazing: 31.43 ssim: 0.960167\n",
      "66 iter PSNR: 31.43 time: 0.023483\n",
      "67 iter PSNR_dehazing: 33.29 ssim: 0.987933\n",
      "67 iter PSNR: 33.29 time: 0.023237\n",
      "68 iter PSNR_dehazing: 34.02 ssim: 0.984738\n",
      "68 iter PSNR: 34.02 time: 0.023376\n",
      "69 iter PSNR_dehazing: 33.09 ssim: 0.985207\n",
      "69 iter PSNR: 33.09 time: 0.023009\n",
      "70 iter PSNR_dehazing: 32.79 ssim: 0.984083\n",
      "70 iter PSNR: 32.79 time: 0.022080\n",
      "71 iter PSNR_dehazing: 38.74 ssim: 0.993794\n",
      "71 iter PSNR: 38.74 time: 0.034200\n",
      "72 iter PSNR_dehazing: 25.68 ssim: 0.965500\n",
      "72 iter PSNR: 25.68 time: 0.025357\n",
      "73 iter PSNR_dehazing: 29.92 ssim: 0.990395\n",
      "73 iter PSNR: 29.92 time: 0.022673\n",
      "74 iter PSNR_dehazing: 29.95 ssim: 0.984288\n",
      "74 iter PSNR: 29.95 time: 0.021872\n",
      "75 iter PSNR_dehazing: 29.56 ssim: 0.986838\n",
      "75 iter PSNR: 29.56 time: 0.025992\n",
      "76 iter PSNR_dehazing: 26.05 ssim: 0.988563\n",
      "76 iter PSNR: 26.05 time: 0.023794\n",
      "77 iter PSNR_dehazing: 28.17 ssim: 0.986230\n",
      "77 iter PSNR: 28.17 time: 0.023337\n",
      "78 iter PSNR_dehazing: 32.91 ssim: 0.991575\n",
      "78 iter PSNR: 32.91 time: 0.023409\n",
      "79 iter PSNR_dehazing: 30.79 ssim: 0.979712\n",
      "79 iter PSNR: 30.79 time: 0.024899\n",
      "80 iter PSNR_dehazing: 38.08 ssim: 0.995930\n",
      "80 iter PSNR: 38.08 time: 0.024741\n",
      "81 iter PSNR_dehazing: 25.79 ssim: 0.964933\n",
      "81 iter PSNR: 25.79 time: 0.022062\n",
      "82 iter PSNR_dehazing: 30.22 ssim: 0.979830\n",
      "82 iter PSNR: 30.22 time: 0.023585\n",
      "83 iter PSNR_dehazing: 32.29 ssim: 0.991361\n",
      "83 iter PSNR: 32.29 time: 0.030840\n",
      "84 iter PSNR_dehazing: 37.04 ssim: 0.992044\n",
      "84 iter PSNR: 37.04 time: 0.023377\n",
      "85 iter PSNR_dehazing: 32.18 ssim: 0.986784\n",
      "85 iter PSNR: 32.18 time: 0.023653\n",
      "86 iter PSNR_dehazing: 33.09 ssim: 0.985054\n",
      "86 iter PSNR: 33.09 time: 0.025265\n",
      "87 iter PSNR_dehazing: 25.91 ssim: 0.977393\n",
      "87 iter PSNR: 25.91 time: 0.023794\n",
      "88 iter PSNR_dehazing: 28.32 ssim: 0.992853\n",
      "88 iter PSNR: 28.32 time: 0.022011\n",
      "89 iter PSNR_dehazing: 35.00 ssim: 0.995185\n",
      "89 iter PSNR: 35.00 time: 0.024384\n",
      "90 iter PSNR_dehazing: 28.62 ssim: 0.946331\n",
      "90 iter PSNR: 28.62 time: 0.023655\n",
      "91 iter PSNR_dehazing: 22.95 ssim: 0.913359\n",
      "91 iter PSNR: 22.95 time: 0.023358\n",
      "92 iter PSNR_dehazing: 31.34 ssim: 0.989553\n",
      "92 iter PSNR: 31.34 time: 0.021974\n",
      "93 iter PSNR_dehazing: 38.01 ssim: 0.993429\n",
      "93 iter PSNR: 38.01 time: 0.022838\n",
      "94 iter PSNR_dehazing: 30.13 ssim: 0.954208\n",
      "94 iter PSNR: 30.13 time: 0.025376\n",
      "95 iter PSNR_dehazing: 24.50 ssim: 0.983951\n",
      "95 iter PSNR: 24.50 time: 0.022119\n",
      "96 iter PSNR_dehazing: 40.08 ssim: 0.987049\n",
      "96 iter PSNR: 40.08 time: 0.023219\n",
      "97 iter PSNR_dehazing: 36.00 ssim: 0.986437\n",
      "97 iter PSNR: 36.00 time: 0.021689\n",
      "98 iter PSNR_dehazing: 28.17 ssim: 0.969711\n",
      "98 iter PSNR: 28.17 time: 0.021778\n",
      "99 iter PSNR_dehazing: 29.34 ssim: 0.990459\n",
      "99 iter PSNR: 29.34 time: 0.022429\n",
      "100 iter PSNR_dehazing: 28.91 ssim: 0.978060\n",
      "100 iter PSNR: 28.91 time: 0.022081\n",
      "101 iter PSNR_dehazing: 31.47 ssim: 0.990935\n",
      "101 iter PSNR: 31.47 time: 0.022360\n",
      "102 iter PSNR_dehazing: 32.81 ssim: 0.984126\n",
      "102 iter PSNR: 32.81 time: 0.025613\n",
      "103 iter PSNR_dehazing: 28.47 ssim: 0.990328\n",
      "103 iter PSNR: 28.47 time: 0.022251\n",
      "104 iter PSNR_dehazing: 32.10 ssim: 0.978626\n",
      "104 iter PSNR: 32.10 time: 0.021530\n",
      "105 iter PSNR_dehazing: 32.11 ssim: 0.986098\n",
      "105 iter PSNR: 32.11 time: 0.021636\n",
      "106 iter PSNR_dehazing: 35.23 ssim: 0.990238\n",
      "106 iter PSNR: 35.23 time: 0.021659\n",
      "107 iter PSNR_dehazing: 22.46 ssim: 0.981081\n",
      "107 iter PSNR: 22.46 time: 0.021561\n",
      "108 iter PSNR_dehazing: 32.71 ssim: 0.987739\n",
      "108 iter PSNR: 32.71 time: 0.024544\n",
      "109 iter PSNR_dehazing: 35.41 ssim: 0.985319\n",
      "109 iter PSNR: 35.41 time: 0.022256\n",
      "110 iter PSNR_dehazing: 34.41 ssim: 0.990562\n",
      "110 iter PSNR: 34.41 time: 0.024675\n",
      "111 iter PSNR_dehazing: 24.89 ssim: 0.973422\n",
      "111 iter PSNR: 24.89 time: 0.022894\n",
      "112 iter PSNR_dehazing: 31.69 ssim: 0.973629\n",
      "112 iter PSNR: 31.69 time: 0.022261\n",
      "113 iter PSNR_dehazing: 33.39 ssim: 0.986390\n",
      "113 iter PSNR: 33.39 time: 0.021604\n",
      "114 iter PSNR_dehazing: 32.91 ssim: 0.988135\n",
      "114 iter PSNR: 32.91 time: 0.021580\n",
      "115 iter PSNR_dehazing: 31.86 ssim: 0.975601\n",
      "115 iter PSNR: 31.86 time: 0.021933\n",
      "116 iter PSNR_dehazing: 30.20 ssim: 0.982148\n",
      "116 iter PSNR: 30.20 time: 0.021854\n",
      "117 iter PSNR_dehazing: 31.96 ssim: 0.985807\n",
      "117 iter PSNR: 31.96 time: 0.021466\n",
      "118 iter PSNR_dehazing: 31.09 ssim: 0.982095\n",
      "118 iter PSNR: 31.09 time: 0.024048\n",
      "119 iter PSNR_dehazing: 36.31 ssim: 0.992554\n",
      "119 iter PSNR: 36.31 time: 0.022281\n",
      "120 iter PSNR_dehazing: 28.57 ssim: 0.968336\n",
      "120 iter PSNR: 28.57 time: 0.035189\n",
      "121 iter PSNR_dehazing: 22.19 ssim: 0.933661\n",
      "121 iter PSNR: 22.19 time: 0.021970\n",
      "122 iter PSNR_dehazing: 27.61 ssim: 0.957588\n",
      "122 iter PSNR: 27.61 time: 0.022501\n",
      "123 iter PSNR_dehazing: 33.93 ssim: 0.984885\n",
      "123 iter PSNR: 33.93 time: 0.022956\n",
      "124 iter PSNR_dehazing: 33.44 ssim: 0.963362\n",
      "124 iter PSNR: 33.44 time: 0.022577\n",
      "125 iter PSNR_dehazing: 30.78 ssim: 0.952380\n",
      "125 iter PSNR: 30.78 time: 0.024294\n",
      "126 iter PSNR_dehazing: 37.12 ssim: 0.992386\n",
      "126 iter PSNR: 37.12 time: 0.022202\n",
      "127 iter PSNR_dehazing: 31.93 ssim: 0.992511\n",
      "127 iter PSNR: 31.93 time: 0.022571\n",
      "128 iter PSNR_dehazing: 23.68 ssim: 0.984152\n",
      "128 iter PSNR: 23.68 time: 0.022901\n",
      "129 iter PSNR_dehazing: 40.61 ssim: 0.995503\n",
      "129 iter PSNR: 40.61 time: 0.022487\n",
      "130 iter PSNR_dehazing: 31.77 ssim: 0.982400\n",
      "130 iter PSNR: 31.77 time: 0.022745\n",
      "131 iter PSNR_dehazing: 34.15 ssim: 0.991346\n",
      "131 iter PSNR: 34.15 time: 0.022309\n",
      "132 iter PSNR_dehazing: 38.01 ssim: 0.994103\n",
      "132 iter PSNR: 38.01 time: 0.023158\n",
      "133 iter PSNR_dehazing: 31.42 ssim: 0.978275\n",
      "133 iter PSNR: 31.42 time: 0.023204\n",
      "134 iter PSNR_dehazing: 35.69 ssim: 0.994606\n",
      "134 iter PSNR: 35.69 time: 0.021625\n",
      "135 iter PSNR_dehazing: 33.37 ssim: 0.996134\n",
      "135 iter PSNR: 33.37 time: 0.021877\n",
      "136 iter PSNR_dehazing: 36.05 ssim: 0.995528\n",
      "136 iter PSNR: 36.05 time: 0.022922\n",
      "137 iter PSNR_dehazing: 36.07 ssim: 0.994167\n",
      "137 iter PSNR: 36.07 time: 0.022104\n",
      "138 iter PSNR_dehazing: 30.65 ssim: 0.979568\n",
      "138 iter PSNR: 30.65 time: 0.022385\n",
      "139 iter PSNR_dehazing: 33.09 ssim: 0.980993\n",
      "139 iter PSNR: 33.09 time: 0.022978\n",
      "140 iter PSNR_dehazing: 33.59 ssim: 0.990744\n",
      "140 iter PSNR: 33.59 time: 0.023261\n",
      "141 iter PSNR_dehazing: 38.59 ssim: 0.994264\n",
      "141 iter PSNR: 38.59 time: 0.024056\n",
      "142 iter PSNR_dehazing: 32.26 ssim: 0.980773\n",
      "142 iter PSNR: 32.26 time: 0.022234\n",
      "143 iter PSNR_dehazing: 37.37 ssim: 0.992638\n",
      "143 iter PSNR: 37.37 time: 0.022310\n",
      "144 iter PSNR_dehazing: 29.69 ssim: 0.976004\n",
      "144 iter PSNR: 29.69 time: 0.023917\n",
      "145 iter PSNR_dehazing: 33.02 ssim: 0.976160\n",
      "145 iter PSNR: 33.02 time: 0.023256\n",
      "146 iter PSNR_dehazing: 37.09 ssim: 0.994014\n",
      "146 iter PSNR: 37.09 time: 0.023182\n",
      "147 iter PSNR_dehazing: 36.76 ssim: 0.992450\n",
      "147 iter PSNR: 36.76 time: 0.022678\n",
      "148 iter PSNR_dehazing: 34.75 ssim: 0.976765\n",
      "148 iter PSNR: 34.75 time: 0.022873\n",
      "149 iter PSNR_dehazing: 35.59 ssim: 0.987353\n",
      "149 iter PSNR: 35.59 time: 0.023377\n",
      "150 iter PSNR_dehazing: 32.53 ssim: 0.987192\n",
      "150 iter PSNR: 32.53 time: 0.022470\n",
      "151 iter PSNR_dehazing: 32.70 ssim: 0.981921\n",
      "151 iter PSNR: 32.70 time: 0.022183\n",
      "152 iter PSNR_dehazing: 32.05 ssim: 0.990580\n",
      "152 iter PSNR: 32.05 time: 0.024574\n",
      "153 iter PSNR_dehazing: 34.44 ssim: 0.989704\n",
      "153 iter PSNR: 34.44 time: 0.024523\n",
      "154 iter PSNR_dehazing: 29.94 ssim: 0.975281\n",
      "154 iter PSNR: 29.94 time: 0.022136\n",
      "155 iter PSNR_dehazing: 35.00 ssim: 0.983669\n",
      "155 iter PSNR: 35.00 time: 0.022221\n",
      "156 iter PSNR_dehazing: 28.23 ssim: 0.984230\n",
      "156 iter PSNR: 28.23 time: 0.024627\n",
      "157 iter PSNR_dehazing: 32.27 ssim: 0.985826\n",
      "157 iter PSNR: 32.27 time: 0.024973\n",
      "158 iter PSNR_dehazing: 33.46 ssim: 0.988189\n",
      "158 iter PSNR: 33.46 time: 0.026022\n",
      "159 iter PSNR_dehazing: 33.62 ssim: 0.990688\n",
      "159 iter PSNR: 33.62 time: 0.023442\n",
      "160 iter PSNR_dehazing: 33.10 ssim: 0.976182\n",
      "160 iter PSNR: 33.10 time: 0.024155\n",
      "161 iter PSNR_dehazing: 36.17 ssim: 0.990136\n",
      "161 iter PSNR: 36.17 time: 0.021678\n",
      "162 iter PSNR_dehazing: 29.23 ssim: 0.893181\n",
      "162 iter PSNR: 29.23 time: 0.021816\n",
      "163 iter PSNR_dehazing: 33.31 ssim: 0.988492\n",
      "163 iter PSNR: 33.31 time: 0.021180\n",
      "164 iter PSNR_dehazing: 30.57 ssim: 0.969201\n",
      "164 iter PSNR: 30.57 time: 0.021970\n",
      "165 iter PSNR_dehazing: 34.11 ssim: 0.985666\n",
      "165 iter PSNR: 34.11 time: 0.025054\n",
      "166 iter PSNR_dehazing: 29.88 ssim: 0.977589\n",
      "166 iter PSNR: 29.88 time: 0.022253\n",
      "167 iter PSNR_dehazing: 34.74 ssim: 0.984138\n",
      "167 iter PSNR: 34.74 time: 0.021761\n",
      "168 iter PSNR_dehazing: 33.45 ssim: 0.978781\n",
      "168 iter PSNR: 33.45 time: 0.022035\n",
      "169 iter PSNR_dehazing: 33.04 ssim: 0.958081\n",
      "169 iter PSNR: 33.04 time: 0.023756\n",
      "170 iter PSNR_dehazing: 30.55 ssim: 0.964098\n",
      "170 iter PSNR: 30.55 time: 0.024306\n",
      "171 iter PSNR_dehazing: 29.57 ssim: 0.989104\n",
      "171 iter PSNR: 29.57 time: 0.024312\n",
      "172 iter PSNR_dehazing: 29.85 ssim: 0.961623\n",
      "172 iter PSNR: 29.85 time: 0.022087\n",
      "173 iter PSNR_dehazing: 33.80 ssim: 0.992248\n",
      "173 iter PSNR: 33.80 time: 0.025570\n",
      "174 iter PSNR_dehazing: 34.11 ssim: 0.989448\n",
      "174 iter PSNR: 34.11 time: 0.024404\n",
      "175 iter PSNR_dehazing: 33.83 ssim: 0.992660\n",
      "175 iter PSNR: 33.83 time: 0.024658\n",
      "176 iter PSNR_dehazing: 33.86 ssim: 0.987036\n",
      "176 iter PSNR: 33.86 time: 0.022988\n",
      "177 iter PSNR_dehazing: 32.33 ssim: 0.984160\n",
      "177 iter PSNR: 32.33 time: 0.021837\n",
      "178 iter PSNR_dehazing: 32.27 ssim: 0.991205\n",
      "178 iter PSNR: 32.27 time: 0.021967\n",
      "179 iter PSNR_dehazing: 33.69 ssim: 0.987212\n",
      "179 iter PSNR: 33.69 time: 0.022631\n",
      "180 iter PSNR_dehazing: 36.94 ssim: 0.991926\n",
      "180 iter PSNR: 36.94 time: 0.023144\n",
      "181 iter PSNR_dehazing: 32.48 ssim: 0.989488\n",
      "181 iter PSNR: 32.48 time: 0.024908\n",
      "182 iter PSNR_dehazing: 33.36 ssim: 0.983769\n",
      "182 iter PSNR: 33.36 time: 0.021966\n",
      "183 iter PSNR_dehazing: 34.42 ssim: 0.990960\n",
      "183 iter PSNR: 34.42 time: 0.025931\n",
      "184 iter PSNR_dehazing: 40.10 ssim: 0.996009\n",
      "184 iter PSNR: 40.10 time: 0.021868\n",
      "185 iter PSNR_dehazing: 30.30 ssim: 0.975162\n",
      "185 iter PSNR: 30.30 time: 0.021857\n",
      "186 iter PSNR_dehazing: 27.49 ssim: 0.981378\n",
      "186 iter PSNR: 27.49 time: 0.022901\n",
      "187 iter PSNR_dehazing: 31.52 ssim: 0.989704\n",
      "187 iter PSNR: 31.52 time: 0.022142\n",
      "188 iter PSNR_dehazing: 35.23 ssim: 0.971363\n",
      "188 iter PSNR: 35.23 time: 0.022191\n",
      "189 iter PSNR_dehazing: 35.26 ssim: 0.993804\n",
      "189 iter PSNR: 35.26 time: 0.024045\n",
      "190 iter PSNR_dehazing: 28.23 ssim: 0.956117\n",
      "190 iter PSNR: 28.23 time: 0.022040\n",
      "191 iter PSNR_dehazing: 36.58 ssim: 0.995087\n",
      "191 iter PSNR: 36.58 time: 0.021677\n",
      "192 iter PSNR_dehazing: 37.62 ssim: 0.994990\n",
      "192 iter PSNR: 37.62 time: 0.022048\n",
      "193 iter PSNR_dehazing: 35.04 ssim: 0.984927\n",
      "193 iter PSNR: 35.04 time: 0.021528\n",
      "194 iter PSNR_dehazing: 28.91 ssim: 0.982465\n",
      "194 iter PSNR: 28.91 time: 0.022522\n",
      "195 iter PSNR_dehazing: 35.18 ssim: 0.992408\n",
      "195 iter PSNR: 35.18 time: 0.026325\n",
      "196 iter PSNR_dehazing: 31.00 ssim: 0.991487\n",
      "196 iter PSNR: 31.00 time: 0.022074\n",
      "197 iter PSNR_dehazing: 31.43 ssim: 0.979497\n",
      "197 iter PSNR: 31.43 time: 0.025894\n",
      "198 iter PSNR_dehazing: 33.47 ssim: 0.989535\n",
      "198 iter PSNR: 33.47 time: 0.022984\n",
      "199 iter PSNR_dehazing: 30.01 ssim: 0.984472\n",
      "199 iter PSNR: 30.01 time: 0.021619\n",
      "200 iter PSNR_dehazing: 34.12 ssim: 0.984273\n",
      "200 iter PSNR: 34.12 time: 0.025009\n",
      "201 iter PSNR_dehazing: 33.04 ssim: 0.985291\n",
      "201 iter PSNR: 33.04 time: 0.022789\n",
      "202 iter PSNR_dehazing: 33.58 ssim: 0.945607\n",
      "202 iter PSNR: 33.58 time: 0.023825\n",
      "203 iter PSNR_dehazing: 31.84 ssim: 0.956288\n",
      "203 iter PSNR: 31.84 time: 0.021761\n",
      "204 iter PSNR_dehazing: 31.44 ssim: 0.953323\n",
      "204 iter PSNR: 31.44 time: 0.021859\n",
      "205 iter PSNR_dehazing: 33.48 ssim: 0.978891\n",
      "205 iter PSNR: 33.48 time: 0.025121\n",
      "206 iter PSNR_dehazing: 24.51 ssim: 0.978592\n",
      "206 iter PSNR: 24.51 time: 0.022941\n",
      "207 iter PSNR_dehazing: 31.51 ssim: 0.986816\n",
      "207 iter PSNR: 31.51 time: 0.022247\n",
      "208 iter PSNR_dehazing: 33.91 ssim: 0.977403\n",
      "208 iter PSNR: 33.91 time: 0.021761\n",
      "209 iter PSNR_dehazing: 26.09 ssim: 0.922063\n",
      "209 iter PSNR: 26.09 time: 0.021626\n",
      "210 iter PSNR_dehazing: 30.45 ssim: 0.935339\n",
      "210 iter PSNR: 30.45 time: 0.022250\n",
      "211 iter PSNR_dehazing: 38.24 ssim: 0.988502\n",
      "211 iter PSNR: 38.24 time: 0.021939\n",
      "212 iter PSNR_dehazing: 34.47 ssim: 0.989408\n",
      "212 iter PSNR: 34.47 time: 0.022485\n",
      "213 iter PSNR_dehazing: 34.96 ssim: 0.979140\n",
      "213 iter PSNR: 34.96 time: 0.024773\n",
      "214 iter PSNR_dehazing: 30.37 ssim: 0.933094\n",
      "214 iter PSNR: 30.37 time: 0.022686\n",
      "215 iter PSNR_dehazing: 31.26 ssim: 0.982044\n",
      "215 iter PSNR: 31.26 time: 0.022588\n",
      "216 iter PSNR_dehazing: 25.50 ssim: 0.974734\n",
      "216 iter PSNR: 25.50 time: 0.022546\n",
      "217 iter PSNR_dehazing: 22.79 ssim: 0.955634\n",
      "217 iter PSNR: 22.79 time: 0.021906\n",
      "218 iter PSNR_dehazing: 25.56 ssim: 0.984089\n",
      "218 iter PSNR: 25.56 time: 0.022048\n",
      "219 iter PSNR_dehazing: 31.13 ssim: 0.982298\n",
      "219 iter PSNR: 31.13 time: 0.023942\n",
      "220 iter PSNR_dehazing: 31.39 ssim: 0.990056\n",
      "220 iter PSNR: 31.39 time: 0.022222\n",
      "221 iter PSNR_dehazing: 35.53 ssim: 0.989845\n",
      "221 iter PSNR: 35.53 time: 0.024788\n",
      "222 iter PSNR_dehazing: 36.85 ssim: 0.987856\n",
      "222 iter PSNR: 36.85 time: 0.022009\n",
      "223 iter PSNR_dehazing: 36.79 ssim: 0.992314\n",
      "223 iter PSNR: 36.79 time: 0.021579\n",
      "224 iter PSNR_dehazing: 33.97 ssim: 0.993660\n",
      "224 iter PSNR: 33.97 time: 0.022514\n",
      "225 iter PSNR_dehazing: 34.21 ssim: 0.994318\n",
      "225 iter PSNR: 34.21 time: 0.022000\n",
      "226 iter PSNR_dehazing: 33.34 ssim: 0.979173\n",
      "226 iter PSNR: 33.34 time: 0.022721\n",
      "227 iter PSNR_dehazing: 30.90 ssim: 0.962256\n",
      "227 iter PSNR: 30.90 time: 0.022363\n",
      "228 iter PSNR_dehazing: 40.78 ssim: 0.996195\n",
      "228 iter PSNR: 40.78 time: 0.022689\n",
      "229 iter PSNR_dehazing: 34.55 ssim: 0.993100\n",
      "229 iter PSNR: 34.55 time: 0.027203\n",
      "230 iter PSNR_dehazing: 31.39 ssim: 0.992240\n",
      "230 iter PSNR: 31.39 time: 0.022792\n",
      "231 iter PSNR_dehazing: 36.23 ssim: 0.994472\n",
      "231 iter PSNR: 36.23 time: 0.024377\n",
      "232 iter PSNR_dehazing: 34.06 ssim: 0.992053\n",
      "232 iter PSNR: 34.06 time: 0.022678\n",
      "233 iter PSNR_dehazing: 31.52 ssim: 0.990431\n",
      "233 iter PSNR: 31.52 time: 0.023789\n",
      "234 iter PSNR_dehazing: 30.60 ssim: 0.980903\n",
      "234 iter PSNR: 30.60 time: 0.023352\n",
      "235 iter PSNR_dehazing: 34.12 ssim: 0.984376\n",
      "235 iter PSNR: 34.12 time: 0.022380\n",
      "236 iter PSNR_dehazing: 36.85 ssim: 0.992572\n",
      "236 iter PSNR: 36.85 time: 0.022231\n",
      "237 iter PSNR_dehazing: 35.34 ssim: 0.986375\n",
      "237 iter PSNR: 35.34 time: 0.025083\n",
      "238 iter PSNR_dehazing: 39.91 ssim: 0.993575\n",
      "238 iter PSNR: 39.91 time: 0.024663\n",
      "239 iter PSNR_dehazing: 31.11 ssim: 0.974736\n",
      "239 iter PSNR: 31.11 time: 0.024544\n",
      "240 iter PSNR_dehazing: 34.03 ssim: 0.992974\n",
      "240 iter PSNR: 34.03 time: 0.022346\n",
      "241 iter PSNR_dehazing: 32.50 ssim: 0.992449\n",
      "241 iter PSNR: 32.50 time: 0.024365\n",
      "242 iter PSNR_dehazing: 30.41 ssim: 0.981017\n",
      "242 iter PSNR: 30.41 time: 0.022645\n",
      "243 iter PSNR_dehazing: 31.33 ssim: 0.983042\n",
      "243 iter PSNR: 31.33 time: 0.021992\n",
      "244 iter PSNR_dehazing: 31.06 ssim: 0.982745\n",
      "244 iter PSNR: 31.06 time: 0.022565\n",
      "245 iter PSNR_dehazing: 31.55 ssim: 0.987956\n",
      "245 iter PSNR: 31.55 time: 0.024654\n",
      "246 iter PSNR_dehazing: 31.15 ssim: 0.980092\n",
      "246 iter PSNR: 31.15 time: 0.023010\n",
      "247 iter PSNR_dehazing: 35.91 ssim: 0.993508\n",
      "247 iter PSNR: 35.91 time: 0.023916\n",
      "248 iter PSNR_dehazing: 37.90 ssim: 0.996367\n",
      "248 iter PSNR: 37.90 time: 0.022063\n",
      "249 iter PSNR_dehazing: 33.02 ssim: 0.992136\n",
      "249 iter PSNR: 33.02 time: 0.024070\n",
      "250 iter PSNR_dehazing: 32.19 ssim: 0.985319\n",
      "250 iter PSNR: 32.19 time: 0.022184\n",
      "251 iter PSNR_dehazing: 34.17 ssim: 0.991835\n",
      "251 iter PSNR: 34.17 time: 0.022249\n",
      "252 iter PSNR_dehazing: 28.42 ssim: 0.963266\n",
      "252 iter PSNR: 28.42 time: 0.023435\n",
      "253 iter PSNR_dehazing: 33.72 ssim: 0.987129\n",
      "253 iter PSNR: 33.72 time: 0.023553\n",
      "254 iter PSNR_dehazing: 28.79 ssim: 0.986134\n",
      "254 iter PSNR: 28.79 time: 0.022060\n",
      "255 iter PSNR_dehazing: 31.33 ssim: 0.993865\n",
      "255 iter PSNR: 31.33 time: 0.023403\n",
      "256 iter PSNR_dehazing: 30.98 ssim: 0.989981\n",
      "256 iter PSNR: 30.98 time: 0.021830\n",
      "257 iter PSNR_dehazing: 31.47 ssim: 0.991586\n",
      "257 iter PSNR: 31.47 time: 0.022205\n",
      "258 iter PSNR_dehazing: 32.28 ssim: 0.978783\n",
      "258 iter PSNR: 32.28 time: 0.022036\n",
      "259 iter PSNR_dehazing: 35.02 ssim: 0.992107\n",
      "259 iter PSNR: 35.02 time: 0.021908\n",
      "260 iter PSNR_dehazing: 36.89 ssim: 0.993714\n",
      "260 iter PSNR: 36.89 time: 0.021753\n",
      "261 iter PSNR_dehazing: 32.02 ssim: 0.976851\n",
      "261 iter PSNR: 32.02 time: 0.026486\n",
      "262 iter PSNR_dehazing: 33.38 ssim: 0.988049\n",
      "262 iter PSNR: 33.38 time: 0.021591\n",
      "263 iter PSNR_dehazing: 35.59 ssim: 0.990894\n",
      "263 iter PSNR: 35.59 time: 0.023911\n",
      "264 iter PSNR_dehazing: 34.11 ssim: 0.977952\n",
      "264 iter PSNR: 34.11 time: 0.021882\n",
      "265 iter PSNR_dehazing: 34.11 ssim: 0.982821\n",
      "265 iter PSNR: 34.11 time: 0.021973\n",
      "266 iter PSNR_dehazing: 31.08 ssim: 0.982937\n",
      "266 iter PSNR: 31.08 time: 0.021683\n",
      "267 iter PSNR_dehazing: 39.30 ssim: 0.990372\n",
      "267 iter PSNR: 39.30 time: 0.022865\n",
      "268 iter PSNR_dehazing: 34.36 ssim: 0.982782\n",
      "268 iter PSNR: 34.36 time: 0.022708\n",
      "269 iter PSNR_dehazing: 34.38 ssim: 0.975903\n",
      "269 iter PSNR: 34.38 time: 0.027213\n",
      "270 iter PSNR_dehazing: 32.72 ssim: 0.987114\n",
      "270 iter PSNR: 32.72 time: 0.028934\n",
      "271 iter PSNR_dehazing: 34.44 ssim: 0.991070\n",
      "271 iter PSNR: 34.44 time: 0.023394\n",
      "272 iter PSNR_dehazing: 34.14 ssim: 0.992771\n",
      "272 iter PSNR: 34.14 time: 0.021528\n",
      "273 iter PSNR_dehazing: 35.00 ssim: 0.991873\n",
      "273 iter PSNR: 35.00 time: 0.021488\n",
      "274 iter PSNR_dehazing: 36.65 ssim: 0.994672\n",
      "274 iter PSNR: 36.65 time: 0.023768\n",
      "275 iter PSNR_dehazing: 31.86 ssim: 0.988088\n",
      "275 iter PSNR: 31.86 time: 0.021249\n",
      "276 iter PSNR_dehazing: 37.18 ssim: 0.992781\n",
      "276 iter PSNR: 37.18 time: 0.022135\n",
      "277 iter PSNR_dehazing: 35.57 ssim: 0.992690\n",
      "277 iter PSNR: 35.57 time: 0.022063\n",
      "278 iter PSNR_dehazing: 30.33 ssim: 0.985929\n",
      "278 iter PSNR: 30.33 time: 0.022119\n",
      "279 iter PSNR_dehazing: 36.97 ssim: 0.993875\n",
      "279 iter PSNR: 36.97 time: 0.022179\n",
      "280 iter PSNR_dehazing: 29.90 ssim: 0.985537\n",
      "280 iter PSNR: 29.90 time: 0.022563\n",
      "281 iter PSNR_dehazing: 32.63 ssim: 0.983909\n",
      "281 iter PSNR: 32.63 time: 0.022662\n",
      "282 iter PSNR_dehazing: 34.81 ssim: 0.992131\n",
      "282 iter PSNR: 34.81 time: 0.031335\n",
      "283 iter PSNR_dehazing: 35.05 ssim: 0.996198\n",
      "283 iter PSNR: 35.05 time: 0.021556\n",
      "284 iter PSNR_dehazing: 36.13 ssim: 0.994972\n",
      "284 iter PSNR: 36.13 time: 0.021479\n",
      "285 iter PSNR_dehazing: 31.62 ssim: 0.991872\n",
      "285 iter PSNR: 31.62 time: 0.023395\n",
      "286 iter PSNR_dehazing: 24.99 ssim: 0.963018\n",
      "286 iter PSNR: 24.99 time: 0.021469\n",
      "287 iter PSNR_dehazing: 36.23 ssim: 0.987756\n",
      "287 iter PSNR: 36.23 time: 0.023626\n",
      "288 iter PSNR_dehazing: 36.51 ssim: 0.992958\n",
      "288 iter PSNR: 36.51 time: 0.021799\n",
      "289 iter PSNR_dehazing: 31.66 ssim: 0.986693\n",
      "289 iter PSNR: 31.66 time: 0.023479\n",
      "290 iter PSNR_dehazing: 35.76 ssim: 0.984491\n",
      "290 iter PSNR: 35.76 time: 0.025063\n",
      "291 iter PSNR_dehazing: 34.25 ssim: 0.986484\n",
      "291 iter PSNR: 34.25 time: 0.021236\n",
      "292 iter PSNR_dehazing: 37.84 ssim: 0.972906\n",
      "292 iter PSNR: 37.84 time: 0.022800\n",
      "293 iter PSNR_dehazing: 33.56 ssim: 0.985337\n",
      "293 iter PSNR: 33.56 time: 0.022415\n",
      "294 iter PSNR_dehazing: 28.26 ssim: 0.958866\n",
      "294 iter PSNR: 28.26 time: 0.023728\n",
      "295 iter PSNR_dehazing: 30.67 ssim: 0.987511\n",
      "295 iter PSNR: 30.67 time: 0.023556\n",
      "296 iter PSNR_dehazing: 37.26 ssim: 0.988387\n",
      "296 iter PSNR: 37.26 time: 0.023540\n",
      "297 iter PSNR_dehazing: 35.68 ssim: 0.990869\n",
      "297 iter PSNR: 35.68 time: 0.021420\n",
      "298 iter PSNR_dehazing: 35.47 ssim: 0.992545\n",
      "298 iter PSNR: 35.47 time: 0.021987\n",
      "299 iter PSNR_dehazing: 36.24 ssim: 0.988426\n",
      "299 iter PSNR: 36.24 time: 0.021478\n",
      "300 iter PSNR_dehazing: 32.38 ssim: 0.980505\n",
      "300 iter PSNR: 32.38 time: 0.022717\n",
      "301 iter PSNR_dehazing: 33.55 ssim: 0.980978\n",
      "301 iter PSNR: 33.55 time: 0.023333\n",
      "302 iter PSNR_dehazing: 31.51 ssim: 0.978621\n",
      "302 iter PSNR: 31.51 time: 0.021417\n",
      "303 iter PSNR_dehazing: 35.30 ssim: 0.991742\n",
      "303 iter PSNR: 35.30 time: 0.023610\n",
      "304 iter PSNR_dehazing: 28.89 ssim: 0.982937\n",
      "304 iter PSNR: 28.89 time: 0.023880\n",
      "305 iter PSNR_dehazing: 30.01 ssim: 0.984190\n",
      "305 iter PSNR: 30.01 time: 0.027587\n",
      "306 iter PSNR_dehazing: 34.36 ssim: 0.985573\n",
      "306 iter PSNR: 34.36 time: 0.023686\n",
      "307 iter PSNR_dehazing: 32.39 ssim: 0.982496\n",
      "307 iter PSNR: 32.39 time: 0.024750\n",
      "308 iter PSNR_dehazing: 35.54 ssim: 0.988901\n",
      "308 iter PSNR: 35.54 time: 0.021544\n",
      "309 iter PSNR_dehazing: 32.15 ssim: 0.982950\n",
      "309 iter PSNR: 32.15 time: 0.023767\n",
      "310 iter PSNR_dehazing: 31.71 ssim: 0.980533\n",
      "310 iter PSNR: 31.71 time: 0.022593\n",
      "311 iter PSNR_dehazing: 37.48 ssim: 0.995052\n",
      "311 iter PSNR: 37.48 time: 0.021964\n",
      "312 iter PSNR_dehazing: 26.91 ssim: 0.984566\n",
      "312 iter PSNR: 26.91 time: 0.022059\n",
      "313 iter PSNR_dehazing: 37.25 ssim: 0.986178\n",
      "313 iter PSNR: 37.25 time: 0.023567\n",
      "314 iter PSNR_dehazing: 33.31 ssim: 0.979353\n",
      "314 iter PSNR: 33.31 time: 0.022028\n",
      "315 iter PSNR_dehazing: 36.03 ssim: 0.975517\n",
      "315 iter PSNR: 36.03 time: 0.022378\n",
      "316 iter PSNR_dehazing: 31.80 ssim: 0.980050\n",
      "316 iter PSNR: 31.80 time: 0.022182\n",
      "317 iter PSNR_dehazing: 30.64 ssim: 0.985479\n",
      "317 iter PSNR: 30.64 time: 0.024655\n",
      "318 iter PSNR_dehazing: 29.52 ssim: 0.982873\n",
      "318 iter PSNR: 29.52 time: 0.021811\n",
      "319 iter PSNR_dehazing: 29.04 ssim: 0.989015\n",
      "319 iter PSNR: 29.04 time: 0.023248\n",
      "320 iter PSNR_dehazing: 39.46 ssim: 0.996130\n",
      "320 iter PSNR: 39.46 time: 0.022710\n",
      "321 iter PSNR_dehazing: 30.05 ssim: 0.992830\n",
      "321 iter PSNR: 30.05 time: 0.021481\n",
      "322 iter PSNR_dehazing: 33.86 ssim: 0.989340\n",
      "322 iter PSNR: 33.86 time: 0.021981\n",
      "323 iter PSNR_dehazing: 36.02 ssim: 0.993200\n",
      "323 iter PSNR: 36.02 time: 0.021460\n",
      "324 iter PSNR_dehazing: 30.57 ssim: 0.978201\n",
      "324 iter PSNR: 30.57 time: 0.022640\n",
      "325 iter PSNR_dehazing: 36.94 ssim: 0.992614\n",
      "325 iter PSNR: 36.94 time: 0.023413\n",
      "326 iter PSNR_dehazing: 37.38 ssim: 0.995627\n",
      "326 iter PSNR: 37.38 time: 0.021064\n",
      "327 iter PSNR_dehazing: 23.65 ssim: 0.982297\n",
      "327 iter PSNR: 23.65 time: 0.024023\n",
      "328 iter PSNR_dehazing: 33.92 ssim: 0.991216\n",
      "328 iter PSNR: 33.92 time: 0.021394\n",
      "329 iter PSNR_dehazing: 31.05 ssim: 0.985939\n",
      "329 iter PSNR: 31.05 time: 0.021543\n",
      "330 iter PSNR_dehazing: 32.23 ssim: 0.990397\n",
      "330 iter PSNR: 32.23 time: 0.021399\n",
      "331 iter PSNR_dehazing: 31.18 ssim: 0.987622\n",
      "331 iter PSNR: 31.18 time: 0.021628\n",
      "332 iter PSNR_dehazing: 36.04 ssim: 0.989752\n",
      "332 iter PSNR: 36.04 time: 0.021874\n",
      "333 iter PSNR_dehazing: 36.74 ssim: 0.993532\n",
      "333 iter PSNR: 36.74 time: 0.024539\n",
      "334 iter PSNR_dehazing: 28.23 ssim: 0.984350\n",
      "334 iter PSNR: 28.23 time: 0.021113\n",
      "335 iter PSNR_dehazing: 29.36 ssim: 0.987370\n",
      "335 iter PSNR: 29.36 time: 0.022492\n",
      "336 iter PSNR_dehazing: 42.58 ssim: 0.995292\n",
      "336 iter PSNR: 42.58 time: 0.025383\n",
      "337 iter PSNR_dehazing: 35.39 ssim: 0.975914\n",
      "337 iter PSNR: 35.39 time: 0.021044\n",
      "338 iter PSNR_dehazing: 36.66 ssim: 0.994047\n",
      "338 iter PSNR: 36.66 time: 0.021794\n",
      "339 iter PSNR_dehazing: 31.60 ssim: 0.987437\n",
      "339 iter PSNR: 31.60 time: 0.022140\n",
      "340 iter PSNR_dehazing: 33.73 ssim: 0.988349\n",
      "340 iter PSNR: 33.73 time: 0.021165\n",
      "341 iter PSNR_dehazing: 35.26 ssim: 0.991981\n",
      "341 iter PSNR: 35.26 time: 0.024503\n",
      "342 iter PSNR_dehazing: 30.12 ssim: 0.991502\n",
      "342 iter PSNR: 30.12 time: 0.021039\n",
      "343 iter PSNR_dehazing: 35.22 ssim: 0.988019\n",
      "343 iter PSNR: 35.22 time: 0.023661\n",
      "344 iter PSNR_dehazing: 34.97 ssim: 0.992852\n",
      "344 iter PSNR: 34.97 time: 0.023968\n",
      "345 iter PSNR_dehazing: 30.96 ssim: 0.993200\n",
      "345 iter PSNR: 30.96 time: 0.023816\n",
      "346 iter PSNR_dehazing: 32.12 ssim: 0.988883\n",
      "346 iter PSNR: 32.12 time: 0.022312\n",
      "347 iter PSNR_dehazing: 35.17 ssim: 0.986778\n",
      "347 iter PSNR: 35.17 time: 0.021409\n",
      "348 iter PSNR_dehazing: 28.33 ssim: 0.976024\n",
      "348 iter PSNR: 28.33 time: 0.024037\n",
      "349 iter PSNR_dehazing: 28.55 ssim: 0.978135\n",
      "349 iter PSNR: 28.55 time: 0.023005\n",
      "350 iter PSNR_dehazing: 33.79 ssim: 0.994038\n",
      "350 iter PSNR: 33.79 time: 0.023070\n",
      "351 iter PSNR_dehazing: 28.51 ssim: 0.987123\n",
      "351 iter PSNR: 28.51 time: 0.023300\n",
      "352 iter PSNR_dehazing: 34.93 ssim: 0.991199\n",
      "352 iter PSNR: 34.93 time: 0.023042\n",
      "353 iter PSNR_dehazing: 32.88 ssim: 0.987971\n",
      "353 iter PSNR: 32.88 time: 0.021486\n",
      "354 iter PSNR_dehazing: 39.07 ssim: 0.991370\n",
      "354 iter PSNR: 39.07 time: 0.023545\n",
      "355 iter PSNR_dehazing: 35.39 ssim: 0.987052\n",
      "355 iter PSNR: 35.39 time: 0.021433\n",
      "356 iter PSNR_dehazing: 32.79 ssim: 0.984322\n",
      "356 iter PSNR: 32.79 time: 0.024673\n",
      "357 iter PSNR_dehazing: 34.42 ssim: 0.982248\n",
      "357 iter PSNR: 34.42 time: 0.024596\n",
      "358 iter PSNR_dehazing: 37.49 ssim: 0.993146\n",
      "358 iter PSNR: 37.49 time: 0.022402\n",
      "359 iter PSNR_dehazing: 29.33 ssim: 0.982171\n",
      "359 iter PSNR: 29.33 time: 0.024382\n",
      "360 iter PSNR_dehazing: 29.15 ssim: 0.983127\n",
      "360 iter PSNR: 29.15 time: 0.023449\n",
      "361 iter PSNR_dehazing: 35.43 ssim: 0.990507\n",
      "361 iter PSNR: 35.43 time: 0.022043\n",
      "362 iter PSNR_dehazing: 26.25 ssim: 0.971975\n",
      "362 iter PSNR: 26.25 time: 0.024196\n",
      "363 iter PSNR_dehazing: 34.66 ssim: 0.992250\n",
      "363 iter PSNR: 34.66 time: 0.021942\n",
      "364 iter PSNR_dehazing: 30.84 ssim: 0.984919\n",
      "364 iter PSNR: 30.84 time: 0.023455\n",
      "365 iter PSNR_dehazing: 31.71 ssim: 0.980969\n",
      "365 iter PSNR: 31.71 time: 0.024270\n",
      "366 iter PSNR_dehazing: 29.46 ssim: 0.985121\n",
      "366 iter PSNR: 29.46 time: 0.023546\n",
      "367 iter PSNR_dehazing: 34.79 ssim: 0.992957\n",
      "367 iter PSNR: 34.79 time: 0.023283\n",
      "368 iter PSNR_dehazing: 25.09 ssim: 0.935165\n",
      "368 iter PSNR: 25.09 time: 0.025845\n",
      "369 iter PSNR_dehazing: 34.39 ssim: 0.986189\n",
      "369 iter PSNR: 34.39 time: 0.022799\n",
      "370 iter PSNR_dehazing: 25.43 ssim: 0.961661\n",
      "370 iter PSNR: 25.43 time: 0.021569\n",
      "371 iter PSNR_dehazing: 31.79 ssim: 0.980591\n",
      "371 iter PSNR: 31.79 time: 0.024051\n",
      "372 iter PSNR_dehazing: 27.62 ssim: 0.968775\n",
      "372 iter PSNR: 27.62 time: 0.023685\n",
      "373 iter PSNR_dehazing: 30.86 ssim: 0.984687\n",
      "373 iter PSNR: 30.86 time: 0.023623\n",
      "374 iter PSNR_dehazing: 33.46 ssim: 0.987971\n",
      "374 iter PSNR: 33.46 time: 0.021921\n",
      "375 iter PSNR_dehazing: 34.53 ssim: 0.989782\n",
      "375 iter PSNR: 34.53 time: 0.023148\n",
      "376 iter PSNR_dehazing: 34.30 ssim: 0.987201\n",
      "376 iter PSNR: 34.30 time: 0.024015\n",
      "377 iter PSNR_dehazing: 23.72 ssim: 0.928880\n",
      "377 iter PSNR: 23.72 time: 0.024642\n",
      "378 iter PSNR_dehazing: 36.41 ssim: 0.993119\n",
      "378 iter PSNR: 36.41 time: 0.021764\n",
      "379 iter PSNR_dehazing: 34.03 ssim: 0.987772\n",
      "379 iter PSNR: 34.03 time: 0.023588\n",
      "380 iter PSNR_dehazing: 25.34 ssim: 0.963972\n",
      "380 iter PSNR: 25.34 time: 0.021748\n",
      "381 iter PSNR_dehazing: 25.68 ssim: 0.955254\n",
      "381 iter PSNR: 25.68 time: 0.023611\n",
      "382 iter PSNR_dehazing: 32.74 ssim: 0.987137\n",
      "382 iter PSNR: 32.74 time: 0.021626\n",
      "383 iter PSNR_dehazing: 36.31 ssim: 0.993032\n",
      "383 iter PSNR: 36.31 time: 0.022817\n",
      "384 iter PSNR_dehazing: 38.93 ssim: 0.989762\n",
      "384 iter PSNR: 38.93 time: 0.023048\n",
      "385 iter PSNR_dehazing: 28.58 ssim: 0.978260\n",
      "385 iter PSNR: 28.58 time: 0.022840\n",
      "386 iter PSNR_dehazing: 30.50 ssim: 0.977350\n",
      "386 iter PSNR: 30.50 time: 0.022462\n",
      "387 iter PSNR_dehazing: 35.91 ssim: 0.994754\n",
      "387 iter PSNR: 35.91 time: 0.021493\n",
      "388 iter PSNR_dehazing: 36.25 ssim: 0.991751\n",
      "388 iter PSNR: 36.25 time: 0.022416\n",
      "389 iter PSNR_dehazing: 31.80 ssim: 0.980571\n",
      "389 iter PSNR: 31.80 time: 0.022801\n",
      "390 iter PSNR_dehazing: 26.85 ssim: 0.951579\n",
      "390 iter PSNR: 26.85 time: 0.021422\n",
      "391 iter PSNR_dehazing: 33.10 ssim: 0.988944\n",
      "391 iter PSNR: 33.10 time: 0.021806\n",
      "392 iter PSNR_dehazing: 34.33 ssim: 0.988134\n",
      "392 iter PSNR: 34.33 time: 0.021846\n",
      "393 iter PSNR_dehazing: 30.25 ssim: 0.985631\n",
      "393 iter PSNR: 30.25 time: 0.021349\n",
      "394 iter PSNR_dehazing: 28.55 ssim: 0.971848\n",
      "394 iter PSNR: 28.55 time: 0.022780\n",
      "395 iter PSNR_dehazing: 35.27 ssim: 0.991518\n",
      "395 iter PSNR: 35.27 time: 0.021443\n",
      "396 iter PSNR_dehazing: 35.15 ssim: 0.991775\n",
      "396 iter PSNR: 35.15 time: 0.023196\n",
      "397 iter PSNR_dehazing: 37.58 ssim: 0.994324\n",
      "397 iter PSNR: 37.58 time: 0.022454\n",
      "398 iter PSNR_dehazing: 36.25 ssim: 0.966983\n",
      "398 iter PSNR: 36.25 time: 0.021988\n",
      "399 iter PSNR_dehazing: 28.99 ssim: 0.979834\n",
      "399 iter PSNR: 28.99 time: 0.023169\n",
      "400 iter PSNR_dehazing: 31.27 ssim: 0.987167\n",
      "400 iter PSNR: 31.27 time: 0.022074\n",
      "401 iter PSNR_dehazing: 30.63 ssim: 0.970956\n",
      "401 iter PSNR: 30.63 time: 0.022459\n",
      "402 iter PSNR_dehazing: 34.73 ssim: 0.980777\n",
      "402 iter PSNR: 34.73 time: 0.021520\n",
      "403 iter PSNR_dehazing: 34.52 ssim: 0.988119\n",
      "403 iter PSNR: 34.52 time: 0.022485\n",
      "404 iter PSNR_dehazing: 40.60 ssim: 0.994056\n",
      "404 iter PSNR: 40.60 time: 0.021801\n",
      "405 iter PSNR_dehazing: 35.34 ssim: 0.993259\n",
      "405 iter PSNR: 35.34 time: 0.022819\n",
      "406 iter PSNR_dehazing: 40.31 ssim: 0.992319\n",
      "406 iter PSNR: 40.31 time: 0.021995\n",
      "407 iter PSNR_dehazing: 35.39 ssim: 0.988055\n",
      "407 iter PSNR: 35.39 time: 0.023676\n",
      "408 iter PSNR_dehazing: 40.52 ssim: 0.996652\n",
      "408 iter PSNR: 40.52 time: 0.024060\n",
      "409 iter PSNR_dehazing: 40.74 ssim: 0.993025\n",
      "409 iter PSNR: 40.74 time: 0.021484\n",
      "410 iter PSNR_dehazing: 40.54 ssim: 0.991753\n",
      "410 iter PSNR: 40.54 time: 0.022817\n",
      "411 iter PSNR_dehazing: 27.81 ssim: 0.979311\n",
      "411 iter PSNR: 27.81 time: 0.022476\n",
      "412 iter PSNR_dehazing: 39.62 ssim: 0.993014\n",
      "412 iter PSNR: 39.62 time: 0.022441\n",
      "413 iter PSNR_dehazing: 35.28 ssim: 0.989859\n",
      "413 iter PSNR: 35.28 time: 0.025750\n",
      "414 iter PSNR_dehazing: 33.93 ssim: 0.994713\n",
      "414 iter PSNR: 33.93 time: 0.024074\n",
      "415 iter PSNR_dehazing: 33.55 ssim: 0.976750\n",
      "415 iter PSNR: 33.55 time: 0.021209\n",
      "416 iter PSNR_dehazing: 32.32 ssim: 0.985071\n",
      "416 iter PSNR: 32.32 time: 0.024157\n",
      "417 iter PSNR_dehazing: 36.01 ssim: 0.983429\n",
      "417 iter PSNR: 36.01 time: 0.023165\n",
      "418 iter PSNR_dehazing: 33.45 ssim: 0.991045\n",
      "418 iter PSNR: 33.45 time: 0.021426\n",
      "419 iter PSNR_dehazing: 30.39 ssim: 0.988798\n",
      "419 iter PSNR: 30.39 time: 0.021700\n",
      "420 iter PSNR_dehazing: 34.77 ssim: 0.978678\n",
      "420 iter PSNR: 34.77 time: 0.021554\n",
      "421 iter PSNR_dehazing: 38.42 ssim: 0.989891\n",
      "421 iter PSNR: 38.42 time: 0.024641\n",
      "422 iter PSNR_dehazing: 37.76 ssim: 0.996343\n",
      "422 iter PSNR: 37.76 time: 0.021776\n",
      "423 iter PSNR_dehazing: 36.35 ssim: 0.996477\n",
      "423 iter PSNR: 36.35 time: 0.021980\n",
      "424 iter PSNR_dehazing: 35.41 ssim: 0.988743\n",
      "424 iter PSNR: 35.41 time: 0.023174\n",
      "425 iter PSNR_dehazing: 33.21 ssim: 0.986128\n",
      "425 iter PSNR: 33.21 time: 0.022759\n",
      "426 iter PSNR_dehazing: 26.83 ssim: 0.990913\n",
      "426 iter PSNR: 26.83 time: 0.021534\n",
      "427 iter PSNR_dehazing: 23.76 ssim: 0.960756\n",
      "427 iter PSNR: 23.76 time: 0.021710\n",
      "428 iter PSNR_dehazing: 30.94 ssim: 0.980031\n",
      "428 iter PSNR: 30.94 time: 0.021851\n",
      "429 iter PSNR_dehazing: 32.53 ssim: 0.984161\n",
      "429 iter PSNR: 32.53 time: 0.023657\n",
      "430 iter PSNR_dehazing: 29.15 ssim: 0.981266\n",
      "430 iter PSNR: 29.15 time: 0.022041\n",
      "431 iter PSNR_dehazing: 27.91 ssim: 0.981708\n",
      "431 iter PSNR: 27.91 time: 0.022469\n",
      "432 iter PSNR_dehazing: 37.78 ssim: 0.991498\n",
      "432 iter PSNR: 37.78 time: 0.023488\n",
      "433 iter PSNR_dehazing: 26.22 ssim: 0.986346\n",
      "433 iter PSNR: 26.22 time: 0.021456\n",
      "434 iter PSNR_dehazing: 35.73 ssim: 0.990026\n",
      "434 iter PSNR: 35.73 time: 0.023508\n",
      "435 iter PSNR_dehazing: 38.61 ssim: 0.993956\n",
      "435 iter PSNR: 38.61 time: 0.021706\n",
      "436 iter PSNR_dehazing: 34.34 ssim: 0.988648\n",
      "436 iter PSNR: 34.34 time: 0.022593\n",
      "437 iter PSNR_dehazing: 35.86 ssim: 0.986806\n",
      "437 iter PSNR: 35.86 time: 0.022404\n",
      "438 iter PSNR_dehazing: 39.74 ssim: 0.993982\n",
      "438 iter PSNR: 39.74 time: 0.021412\n",
      "439 iter PSNR_dehazing: 36.63 ssim: 0.987405\n",
      "439 iter PSNR: 36.63 time: 0.022998\n",
      "440 iter PSNR_dehazing: 36.40 ssim: 0.982123\n",
      "440 iter PSNR: 36.40 time: 0.022006\n",
      "441 iter PSNR_dehazing: 34.11 ssim: 0.993615\n",
      "441 iter PSNR: 34.11 time: 0.023713\n",
      "442 iter PSNR_dehazing: 36.28 ssim: 0.991903\n",
      "442 iter PSNR: 36.28 time: 0.021641\n",
      "443 iter PSNR_dehazing: 40.07 ssim: 0.993636\n",
      "443 iter PSNR: 40.07 time: 0.023264\n",
      "444 iter PSNR_dehazing: 30.72 ssim: 0.977161\n",
      "444 iter PSNR: 30.72 time: 0.022602\n",
      "445 iter PSNR_dehazing: 32.41 ssim: 0.989244\n",
      "445 iter PSNR: 32.41 time: 0.023738\n",
      "446 iter PSNR_dehazing: 33.33 ssim: 0.989899\n",
      "446 iter PSNR: 33.33 time: 0.022665\n",
      "447 iter PSNR_dehazing: 38.72 ssim: 0.989680\n",
      "447 iter PSNR: 38.72 time: 0.022748\n",
      "448 iter PSNR_dehazing: 42.02 ssim: 0.994168\n",
      "448 iter PSNR: 42.02 time: 0.023365\n",
      "449 iter PSNR_dehazing: 31.07 ssim: 0.981065\n",
      "449 iter PSNR: 31.07 time: 0.023468\n",
      "450 iter PSNR_dehazing: 34.33 ssim: 0.981527\n",
      "450 iter PSNR: 34.33 time: 0.022280\n",
      "451 iter PSNR_dehazing: 35.04 ssim: 0.987944\n",
      "451 iter PSNR: 35.04 time: 0.022142\n",
      "452 iter PSNR_dehazing: 30.31 ssim: 0.991235\n",
      "452 iter PSNR: 30.31 time: 0.024191\n",
      "453 iter PSNR_dehazing: 35.48 ssim: 0.985641\n",
      "453 iter PSNR: 35.48 time: 0.023422\n",
      "454 iter PSNR_dehazing: 35.67 ssim: 0.985955\n",
      "454 iter PSNR: 35.67 time: 0.024230\n",
      "455 iter PSNR_dehazing: 35.34 ssim: 0.991699\n",
      "455 iter PSNR: 35.34 time: 0.022568\n",
      "456 iter PSNR_dehazing: 30.40 ssim: 0.980373\n",
      "456 iter PSNR: 30.40 time: 0.023649\n",
      "457 iter PSNR_dehazing: 30.62 ssim: 0.981416\n",
      "457 iter PSNR: 30.62 time: 0.021601\n",
      "458 iter PSNR_dehazing: 31.45 ssim: 0.987449\n",
      "458 iter PSNR: 31.45 time: 0.021818\n",
      "459 iter PSNR_dehazing: 30.21 ssim: 0.965857\n",
      "459 iter PSNR: 30.21 time: 0.023626\n",
      "460 iter PSNR_dehazing: 34.69 ssim: 0.987407\n",
      "460 iter PSNR: 34.69 time: 0.022712\n",
      "461 iter PSNR_dehazing: 28.07 ssim: 0.982836\n",
      "461 iter PSNR: 28.07 time: 0.024147\n",
      "462 iter PSNR_dehazing: 30.34 ssim: 0.981287\n",
      "462 iter PSNR: 30.34 time: 0.023902\n",
      "463 iter PSNR_dehazing: 35.44 ssim: 0.991271\n",
      "463 iter PSNR: 35.44 time: 0.023115\n",
      "464 iter PSNR_dehazing: 29.36 ssim: 0.976895\n",
      "464 iter PSNR: 29.36 time: 0.022075\n",
      "465 iter PSNR_dehazing: 34.43 ssim: 0.991309\n",
      "465 iter PSNR: 34.43 time: 0.022428\n",
      "466 iter PSNR_dehazing: 33.20 ssim: 0.991076\n",
      "466 iter PSNR: 33.20 time: 0.022524\n",
      "467 iter PSNR_dehazing: 26.36 ssim: 0.978063\n",
      "467 iter PSNR: 26.36 time: 0.022539\n",
      "468 iter PSNR_dehazing: 28.90 ssim: 0.986394\n",
      "468 iter PSNR: 28.90 time: 0.022600\n",
      "469 iter PSNR_dehazing: 28.28 ssim: 0.987681\n",
      "469 iter PSNR: 28.28 time: 0.023857\n",
      "470 iter PSNR_dehazing: 31.91 ssim: 0.982579\n",
      "470 iter PSNR: 31.91 time: 0.023698\n",
      "471 iter PSNR_dehazing: 29.02 ssim: 0.986074\n",
      "471 iter PSNR: 29.02 time: 0.022330\n",
      "472 iter PSNR_dehazing: 34.89 ssim: 0.991859\n",
      "472 iter PSNR: 34.89 time: 0.022171\n",
      "473 iter PSNR_dehazing: 37.73 ssim: 0.995590\n",
      "473 iter PSNR: 37.73 time: 0.027664\n",
      "474 iter PSNR_dehazing: 37.43 ssim: 0.997040\n",
      "474 iter PSNR: 37.43 time: 0.022384\n",
      "475 iter PSNR_dehazing: 24.74 ssim: 0.987181\n",
      "475 iter PSNR: 24.74 time: 0.022344\n",
      "476 iter PSNR_dehazing: 30.71 ssim: 0.992588\n",
      "476 iter PSNR: 30.71 time: 0.023030\n",
      "477 iter PSNR_dehazing: 27.37 ssim: 0.985111\n",
      "477 iter PSNR: 27.37 time: 0.023443\n",
      "478 iter PSNR_dehazing: 28.31 ssim: 0.984627\n",
      "478 iter PSNR: 28.31 time: 0.023659\n",
      "479 iter PSNR_dehazing: 25.04 ssim: 0.986052\n",
      "479 iter PSNR: 25.04 time: 0.022393\n",
      "480 iter PSNR_dehazing: 34.00 ssim: 0.991837\n",
      "480 iter PSNR: 34.00 time: 0.022376\n",
      "481 iter PSNR_dehazing: 33.87 ssim: 0.989448\n",
      "481 iter PSNR: 33.87 time: 0.023773\n",
      "482 iter PSNR_dehazing: 31.06 ssim: 0.985711\n",
      "482 iter PSNR: 31.06 time: 0.023623\n",
      "483 iter PSNR_dehazing: 33.09 ssim: 0.986495\n",
      "483 iter PSNR: 33.09 time: 0.022105\n",
      "484 iter PSNR_dehazing: 34.30 ssim: 0.989554\n",
      "484 iter PSNR: 34.30 time: 0.022057\n",
      "485 iter PSNR_dehazing: 34.53 ssim: 0.990356\n",
      "485 iter PSNR: 34.53 time: 0.023135\n",
      "486 iter PSNR_dehazing: 36.62 ssim: 0.992478\n",
      "486 iter PSNR: 36.62 time: 0.021190\n",
      "487 iter PSNR_dehazing: 39.29 ssim: 0.993892\n",
      "487 iter PSNR: 39.29 time: 0.021091\n",
      "488 iter PSNR_dehazing: 30.90 ssim: 0.988745\n",
      "488 iter PSNR: 30.90 time: 0.021418\n",
      "489 iter PSNR_dehazing: 37.72 ssim: 0.993272\n",
      "489 iter PSNR: 37.72 time: 0.021334\n",
      "490 iter PSNR_dehazing: 36.43 ssim: 0.994868\n",
      "490 iter PSNR: 36.43 time: 0.023605\n",
      "491 iter PSNR_dehazing: 33.62 ssim: 0.979420\n",
      "491 iter PSNR: 33.62 time: 0.021621\n",
      "492 iter PSNR_dehazing: 32.80 ssim: 0.981286\n",
      "492 iter PSNR: 32.80 time: 0.020563\n",
      "493 iter PSNR_dehazing: 34.88 ssim: 0.991830\n",
      "493 iter PSNR: 34.88 time: 0.020571\n",
      "494 iter PSNR_dehazing: 37.99 ssim: 0.980184\n",
      "494 iter PSNR: 37.99 time: 0.021421\n",
      "495 iter PSNR_dehazing: 35.57 ssim: 0.986877\n",
      "495 iter PSNR: 35.57 time: 0.020708\n",
      "496 iter PSNR_dehazing: 39.81 ssim: 0.994209\n",
      "496 iter PSNR: 39.81 time: 0.020524\n",
      "497 iter PSNR_dehazing: 37.08 ssim: 0.994071\n",
      "497 iter PSNR: 37.08 time: 0.020406\n",
      "498 iter PSNR_dehazing: 39.22 ssim: 0.995227\n",
      "498 iter PSNR: 39.22 time: 0.021774\n",
      "499 iter PSNR_dehazing: 41.38 ssim: 0.995046\n",
      "499 iter PSNR: 41.38 time: 0.020725\n",
      "500 iter PSNR_dehazing: 34.68 ssim: 0.990777\n",
      "500 iter PSNR: 34.68 time: 0.020521\n",
      "==========================================================\n",
      "The average PSNR is 32.91 dB\n",
      "The average SSIM is 0.98424 dB\n",
      "Average time: 0.023094\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "# from torch.backends import cudnn # Uncomment if you need it\n",
    "\n",
    "class Args:\n",
    "    model_name = 'IRNeXt'\n",
    "    mode = 'test'\n",
    "    data_dir = './reside-outdoor/'\n",
    "\n",
    "    # Train\n",
    "    batch_size = 4\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 0\n",
    "    num_epoch = 30\n",
    "    print_freq = 500\n",
    "    num_worker = 8\n",
    "    save_freq = 10\n",
    "    valid_freq = 10\n",
    "    figname = 'outdoor_30epoch.jpg'\n",
    "    resume = '/content/drive/MyDrive/results/IRNeXt/OTS/model.pkl'\n",
    "\n",
    "    # Test\n",
    "    test_model = '/content/drive/MyDrive/results/IRNeXt/OTS/Final.pkl'\n",
    "    save_image = False\n",
    "\n",
    "    # Directories (set these as per your requirement)\n",
    "    model_save_dir = os.path.join('/content/drive/MyDrive/results/', 'IRNeXt', 'OTS/')\n",
    "    result_dir = os.path.join('/content/drive/MyDrive/results/', model_name, 'test')\n",
    "\n",
    "def main(args):\n",
    "    # CUDNN\n",
    "    # cudnn.benchmark = True # Uncomment if you need it\n",
    "\n",
    "    if not os.path.exists('/content/drive/MyDrive/results/'):\n",
    "        os.makedirs(args.model_save_dir)\n",
    "    if not os.path.exists('/content/drive/MyDrive/results/' + args.model_name + '/'):\n",
    "        os.makedirs('/content/drive/MyDrive/results/' + args.model_name + '/')\n",
    "    if not os.path.exists(args.model_save_dir):\n",
    "        os.makedirs(args.model_save_dir)\n",
    "    if not os.path.exists(args.result_dir):\n",
    "        os.makedirs(args.result_dir)\n",
    "\n",
    "    model = build_net()  # Make sure to define build_net or import it if it's defined elsewhere\n",
    "    #print(model)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    if args.mode == 'train':\n",
    "        _train(model, args)  # Make sure to define _train or import it if it's defined elsewhere\n",
    "\n",
    "    elif args.mode == 'test':\n",
    "        _eval(model, args)   # Make sure to define _eval or import it if it's defined elsewhere\n",
    "\n",
    "# Replace parser.parse_args() with an instance of the Args class\n",
    "args = Args()\n",
    "if not os.path.exists(args.model_save_dir):\n",
    "    os.makedirs(args.model_save_dir)\n",
    "# Copying files (make sure these paths are correct)\n",
    "command = 'cp ' + 'models/layers.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "command = 'cp ' + 'models/IRNeXt.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "command = 'cp ' + 'train.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "command = 'cp ' + 'main.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "print(args)\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvTwi00y3xG0"
   },
   "source": [
    "### Main (Mixup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywmyq21qr0Pb",
    "outputId": "6909ae99-e0b4-469e-9188-0c606f010a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x7c6c5a37da20>\n",
      "training LR: 0.0001\n",
      "Resume from 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:809: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0796 Epoch: 015 Iter:  500/40967 LR: 0.0000597110 Loss content:  0.0993 Loss fft:  3.9035\n",
      "Time:  1.0608 Epoch: 015 Iter: 1000/40967 LR: 0.0000597110 Loss content:  0.1061 Loss fft:  4.1417\n",
      "Time:  1.0615 Epoch: 015 Iter: 1500/40967 LR: 0.0000597110 Loss content:  0.1019 Loss fft:  4.0236\n",
      "Time:  1.0604 Epoch: 015 Iter: 2000/40967 LR: 0.0000597110 Loss content:  0.1152 Loss fft:  4.4105\n",
      "Time:  1.0643 Epoch: 015 Iter: 2500/40967 LR: 0.0000597110 Loss content:  0.1091 Loss fft:  4.2940\n",
      "Time:  1.0606 Epoch: 015 Iter: 3000/40967 LR: 0.0000597110 Loss content:  0.1068 Loss fft:  4.1822\n",
      "Time:  1.0606 Epoch: 015 Iter: 3500/40967 LR: 0.0000597110 Loss content:  0.1007 Loss fft:  3.9539\n",
      "Time:  1.0602 Epoch: 015 Iter: 4000/40967 LR: 0.0000597110 Loss content:  0.0998 Loss fft:  3.9031\n",
      "Time:  1.0647 Epoch: 015 Iter: 4500/40967 LR: 0.0000597110 Loss content:  0.1068 Loss fft:  4.1782\n",
      "Time:  1.0610 Epoch: 015 Iter: 5000/40967 LR: 0.0000597110 Loss content:  0.0994 Loss fft:  3.9079\n",
      "Time:  1.0607 Epoch: 015 Iter: 5500/40967 LR: 0.0000597110 Loss content:  0.1064 Loss fft:  4.1542\n",
      "Time:  1.0610 Epoch: 015 Iter: 6000/40967 LR: 0.0000597110 Loss content:  0.1002 Loss fft:  3.9676\n",
      "Time:  1.0611 Epoch: 015 Iter: 6500/40967 LR: 0.0000597110 Loss content:  0.1018 Loss fft:  3.9930\n",
      "Time:  1.0645 Epoch: 015 Iter: 7000/40967 LR: 0.0000597110 Loss content:  0.1021 Loss fft:  4.0233\n",
      "Time:  1.0609 Epoch: 015 Iter: 7500/40967 LR: 0.0000597110 Loss content:  0.1026 Loss fft:  4.0094\n",
      "Time:  1.0610 Epoch: 015 Iter: 8000/40967 LR: 0.0000597110 Loss content:  0.1116 Loss fft:  4.3789\n",
      "Time:  1.0605 Epoch: 015 Iter: 8500/40967 LR: 0.0000597110 Loss content:  0.1120 Loss fft:  4.3288\n",
      "Time:  1.0653 Epoch: 015 Iter: 9000/40967 LR: 0.0000597110 Loss content:  0.0994 Loss fft:  3.8879\n",
      "Time:  1.0610 Epoch: 015 Iter: 9500/40967 LR: 0.0000597110 Loss content:  0.1025 Loss fft:  3.9833\n",
      "Time:  1.0606 Epoch: 015 Iter: 10000/40967 LR: 0.0000597110 Loss content:  0.1094 Loss fft:  4.2237\n",
      "Time:  1.0619 Epoch: 015 Iter: 10500/40967 LR: 0.0000597110 Loss content:  0.1055 Loss fft:  4.1871\n",
      "Time:  1.0600 Epoch: 015 Iter: 11000/40967 LR: 0.0000597110 Loss content:  0.1076 Loss fft:  4.2189\n",
      "Time:  1.0650 Epoch: 015 Iter: 11500/40967 LR: 0.0000597110 Loss content:  0.1062 Loss fft:  4.1139\n",
      "Time:  1.0603 Epoch: 015 Iter: 12000/40967 LR: 0.0000597110 Loss content:  0.0937 Loss fft:  3.7152\n",
      "Time:  1.0610 Epoch: 015 Iter: 12500/40967 LR: 0.0000597110 Loss content:  0.1059 Loss fft:  4.1334\n",
      "Time:  1.0609 Epoch: 015 Iter: 13000/40967 LR: 0.0000597110 Loss content:  0.0950 Loss fft:  3.7669\n",
      "Time:  1.0638 Epoch: 015 Iter: 13500/40967 LR: 0.0000597110 Loss content:  0.1050 Loss fft:  4.1453\n",
      "Time:  1.0614 Epoch: 015 Iter: 14000/40967 LR: 0.0000597110 Loss content:  0.0965 Loss fft:  3.7771\n",
      "Time:  1.0596 Epoch: 015 Iter: 14500/40967 LR: 0.0000597110 Loss content:  0.1070 Loss fft:  4.1825\n",
      "Time:  1.0610 Epoch: 015 Iter: 15000/40967 LR: 0.0000597110 Loss content:  0.1058 Loss fft:  4.1269\n",
      "Time:  1.0611 Epoch: 015 Iter: 15500/40967 LR: 0.0000597110 Loss content:  0.1141 Loss fft:  4.4498\n",
      "Time:  1.0646 Epoch: 015 Iter: 16000/40967 LR: 0.0000597110 Loss content:  0.1095 Loss fft:  4.2860\n",
      "Time:  1.0610 Epoch: 015 Iter: 16500/40967 LR: 0.0000597110 Loss content:  0.0963 Loss fft:  3.8557\n",
      "Time:  1.0610 Epoch: 015 Iter: 17000/40967 LR: 0.0000597110 Loss content:  0.1010 Loss fft:  3.9894\n",
      "Time:  1.0609 Epoch: 015 Iter: 17500/40967 LR: 0.0000597110 Loss content:  0.1035 Loss fft:  4.0304\n",
      "Time:  1.0598 Epoch: 015 Iter: 18000/40967 LR: 0.0000597110 Loss content:  0.1028 Loss fft:  4.0059\n",
      "Time:  1.0643 Epoch: 015 Iter: 18500/40967 LR: 0.0000597110 Loss content:  0.1073 Loss fft:  4.2003\n",
      "Time:  1.0612 Epoch: 015 Iter: 19000/40967 LR: 0.0000597110 Loss content:  0.1068 Loss fft:  4.2061\n",
      "Time:  1.0599 Epoch: 015 Iter: 19500/40967 LR: 0.0000597110 Loss content:  0.1089 Loss fft:  4.2343\n",
      "Time:  1.0605 Epoch: 015 Iter: 20000/40967 LR: 0.0000597110 Loss content:  0.1066 Loss fft:  4.2082\n",
      "Time:  1.0647 Epoch: 015 Iter: 20500/40967 LR: 0.0000597110 Loss content:  0.1054 Loss fft:  4.1179\n",
      "Time:  1.0600 Epoch: 015 Iter: 21000/40967 LR: 0.0000597110 Loss content:  0.1095 Loss fft:  4.2914\n",
      "Time:  1.0599 Epoch: 015 Iter: 21500/40967 LR: 0.0000597110 Loss content:  0.1094 Loss fft:  4.2538\n",
      "Time:  1.0606 Epoch: 015 Iter: 22000/40967 LR: 0.0000597110 Loss content:  0.1027 Loss fft:  4.0307\n",
      "Time:  1.0608 Epoch: 015 Iter: 22500/40967 LR: 0.0000597110 Loss content:  0.1059 Loss fft:  4.1055\n",
      "Time:  1.0645 Epoch: 015 Iter: 23000/40967 LR: 0.0000597110 Loss content:  0.1016 Loss fft:  4.0336\n",
      "Time:  1.0632 Epoch: 015 Iter: 23500/40967 LR: 0.0000597110 Loss content:  0.1101 Loss fft:  4.2944\n",
      "Time:  1.0611 Epoch: 015 Iter: 24000/40967 LR: 0.0000597110 Loss content:  0.1043 Loss fft:  4.1037\n",
      "Time:  1.0605 Epoch: 015 Iter: 24500/40967 LR: 0.0000597110 Loss content:  0.1048 Loss fft:  4.1282\n",
      "Time:  1.0641 Epoch: 015 Iter: 25000/40967 LR: 0.0000597110 Loss content:  0.0977 Loss fft:  3.8464\n",
      "Time:  1.0609 Epoch: 015 Iter: 25500/40967 LR: 0.0000597110 Loss content:  0.1044 Loss fft:  4.1315\n",
      "Time:  1.0614 Epoch: 015 Iter: 26000/40967 LR: 0.0000597110 Loss content:  0.0987 Loss fft:  3.8760\n",
      "Time:  1.0599 Epoch: 015 Iter: 26500/40967 LR: 0.0000597110 Loss content:  0.1007 Loss fft:  3.9467\n",
      "Time:  1.0606 Epoch: 015 Iter: 27000/40967 LR: 0.0000597110 Loss content:  0.1011 Loss fft:  3.9263\n",
      "Time:  1.0649 Epoch: 015 Iter: 27500/40967 LR: 0.0000597110 Loss content:  0.1066 Loss fft:  4.1895\n",
      "Time:  1.0607 Epoch: 015 Iter: 28000/40967 LR: 0.0000597110 Loss content:  0.0984 Loss fft:  3.9046\n",
      "Time:  1.0604 Epoch: 015 Iter: 28500/40967 LR: 0.0000597110 Loss content:  0.1022 Loss fft:  4.0462\n",
      "Time:  1.0610 Epoch: 015 Iter: 29000/40967 LR: 0.0000597110 Loss content:  0.1014 Loss fft:  4.0196\n",
      "Time:  1.0644 Epoch: 015 Iter: 29500/40967 LR: 0.0000597110 Loss content:  0.1050 Loss fft:  4.1163\n",
      "Time:  1.0605 Epoch: 015 Iter: 30000/40967 LR: 0.0000597110 Loss content:  0.1007 Loss fft:  4.0022\n",
      "Time:  1.0607 Epoch: 015 Iter: 30500/40967 LR: 0.0000597110 Loss content:  0.1087 Loss fft:  4.2356\n",
      "Time:  1.0606 Epoch: 015 Iter: 31000/40967 LR: 0.0000597110 Loss content:  0.1108 Loss fft:  4.3367\n",
      "Time:  1.0605 Epoch: 015 Iter: 31500/40967 LR: 0.0000597110 Loss content:  0.1055 Loss fft:  4.1795\n",
      "Time:  1.0637 Epoch: 015 Iter: 32000/40967 LR: 0.0000597110 Loss content:  0.1019 Loss fft:  4.0158\n",
      "Time:  1.0617 Epoch: 015 Iter: 32500/40967 LR: 0.0000597110 Loss content:  0.1007 Loss fft:  3.9337\n",
      "Time:  1.0606 Epoch: 015 Iter: 33000/40967 LR: 0.0000597110 Loss content:  0.1017 Loss fft:  4.0590\n",
      "Time:  1.0603 Epoch: 015 Iter: 33500/40967 LR: 0.0000597110 Loss content:  0.0959 Loss fft:  3.7986\n",
      "Time:  1.0641 Epoch: 015 Iter: 34000/40967 LR: 0.0000597110 Loss content:  0.1066 Loss fft:  4.2113\n",
      "Time:  1.0606 Epoch: 015 Iter: 34500/40967 LR: 0.0000597110 Loss content:  0.1114 Loss fft:  4.3813\n",
      "Time:  1.0608 Epoch: 015 Iter: 35000/40967 LR: 0.0000597110 Loss content:  0.0942 Loss fft:  3.7115\n",
      "Time:  1.0609 Epoch: 015 Iter: 35500/40967 LR: 0.0000597110 Loss content:  0.0995 Loss fft:  3.9467\n",
      "Time:  1.0602 Epoch: 015 Iter: 36000/40967 LR: 0.0000597110 Loss content:  0.1019 Loss fft:  4.0318\n",
      "Time:  1.0644 Epoch: 015 Iter: 36500/40967 LR: 0.0000597110 Loss content:  0.0975 Loss fft:  3.8513\n",
      "Time:  1.0611 Epoch: 015 Iter: 37000/40967 LR: 0.0000597110 Loss content:  0.1029 Loss fft:  4.0831\n",
      "Time:  1.0607 Epoch: 015 Iter: 37500/40967 LR: 0.0000597110 Loss content:  0.1029 Loss fft:  4.0611\n",
      "Time:  1.0612 Epoch: 015 Iter: 38000/40967 LR: 0.0000597110 Loss content:  0.1118 Loss fft:  4.3529\n",
      "Time:  1.0611 Epoch: 015 Iter: 38500/40967 LR: 0.0000597110 Loss content:  0.0984 Loss fft:  3.9468\n",
      "Time:  1.0648 Epoch: 015 Iter: 39000/40967 LR: 0.0000597110 Loss content:  0.1208 Loss fft:  4.6401\n",
      "Time:  1.0605 Epoch: 015 Iter: 39500/40967 LR: 0.0000597110 Loss content:  0.1030 Loss fft:  4.0631\n",
      "Time:  1.0614 Epoch: 015 Iter: 40000/40967 LR: 0.0000597110 Loss content:  0.1047 Loss fft:  4.1159\n",
      "Time:  1.0607 Epoch: 015 Iter: 40500/40967 LR: 0.0000597110 Loss content:  0.0957 Loss fft:  3.8088\n",
      "EPOCH: 15\n",
      "Elapsed time: 87.01 Epoch Pixel Loss:  0.1040 Epoch FFT Loss:  4.0839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0763 Epoch: 016 Iter:  500/40967 LR: 0.0000539869 Loss content:  0.1039 Loss fft:  4.0991\n",
      "Time:  1.0617 Epoch: 016 Iter: 1000/40967 LR: 0.0000539869 Loss content:  0.1050 Loss fft:  4.1384\n",
      "Time:  1.0614 Epoch: 016 Iter: 1500/40967 LR: 0.0000539869 Loss content:  0.1030 Loss fft:  4.0795\n",
      "Time:  1.0626 Epoch: 016 Iter: 2000/40967 LR: 0.0000539869 Loss content:  0.1024 Loss fft:  4.0229\n",
      "Time:  1.0668 Epoch: 016 Iter: 2500/40967 LR: 0.0000539869 Loss content:  0.1025 Loss fft:  4.0695\n",
      "Time:  1.0615 Epoch: 016 Iter: 3000/40967 LR: 0.0000539869 Loss content:  0.1019 Loss fft:  4.0353\n",
      "Time:  1.0616 Epoch: 016 Iter: 3500/40967 LR: 0.0000539869 Loss content:  0.0992 Loss fft:  3.9717\n",
      "Time:  1.0619 Epoch: 016 Iter: 4000/40967 LR: 0.0000539869 Loss content:  0.1138 Loss fft:  4.3946\n",
      "Time:  1.0657 Epoch: 016 Iter: 4500/40967 LR: 0.0000539869 Loss content:  0.1073 Loss fft:  4.2321\n",
      "Time:  1.0624 Epoch: 016 Iter: 5000/40967 LR: 0.0000539869 Loss content:  0.0979 Loss fft:  3.8697\n",
      "Time:  1.0630 Epoch: 016 Iter: 5500/40967 LR: 0.0000539869 Loss content:  0.1062 Loss fft:  4.1851\n",
      "Time:  1.0615 Epoch: 016 Iter: 6000/40967 LR: 0.0000539869 Loss content:  0.0968 Loss fft:  3.8686\n",
      "Time:  1.0621 Epoch: 016 Iter: 6500/40967 LR: 0.0000539869 Loss content:  0.1039 Loss fft:  4.0567\n",
      "Time:  1.0656 Epoch: 016 Iter: 7000/40967 LR: 0.0000539869 Loss content:  0.1027 Loss fft:  4.0484\n",
      "Time:  1.0624 Epoch: 016 Iter: 7500/40967 LR: 0.0000539869 Loss content:  0.0957 Loss fft:  3.8197\n",
      "Time:  1.0615 Epoch: 016 Iter: 8000/40967 LR: 0.0000539869 Loss content:  0.1017 Loss fft:  4.0576\n",
      "Time:  1.0627 Epoch: 016 Iter: 8500/40967 LR: 0.0000539869 Loss content:  0.1009 Loss fft:  3.9666\n",
      "Time:  1.0655 Epoch: 016 Iter: 9000/40967 LR: 0.0000539869 Loss content:  0.1073 Loss fft:  4.2304\n",
      "Time:  1.0618 Epoch: 016 Iter: 9500/40967 LR: 0.0000539869 Loss content:  0.1011 Loss fft:  4.0350\n",
      "Time:  1.0631 Epoch: 016 Iter: 10000/40967 LR: 0.0000539869 Loss content:  0.0976 Loss fft:  3.8663\n",
      "Time:  1.0618 Epoch: 016 Iter: 10500/40967 LR: 0.0000539869 Loss content:  0.1042 Loss fft:  4.0931\n",
      "Time:  1.0623 Epoch: 016 Iter: 11000/40967 LR: 0.0000539869 Loss content:  0.0969 Loss fft:  3.8545\n",
      "Time:  1.0650 Epoch: 016 Iter: 11500/40967 LR: 0.0000539869 Loss content:  0.1084 Loss fft:  4.2982\n",
      "Time:  1.0617 Epoch: 016 Iter: 12000/40967 LR: 0.0000539869 Loss content:  0.1007 Loss fft:  3.9689\n",
      "Time:  1.0622 Epoch: 016 Iter: 12500/40967 LR: 0.0000539869 Loss content:  0.1008 Loss fft:  4.0117\n",
      "Time:  1.0609 Epoch: 016 Iter: 13000/40967 LR: 0.0000539869 Loss content:  0.1001 Loss fft:  3.9494\n",
      "Time:  1.0654 Epoch: 016 Iter: 13500/40967 LR: 0.0000539869 Loss content:  0.0992 Loss fft:  3.8614\n",
      "Time:  1.0616 Epoch: 016 Iter: 14000/40967 LR: 0.0000539869 Loss content:  0.1031 Loss fft:  4.0750\n",
      "Time:  1.0625 Epoch: 016 Iter: 14500/40967 LR: 0.0000539869 Loss content:  0.0998 Loss fft:  3.9466\n",
      "Time:  1.0611 Epoch: 016 Iter: 15000/40967 LR: 0.0000539869 Loss content:  0.1075 Loss fft:  4.2288\n",
      "Time:  1.0624 Epoch: 016 Iter: 15500/40967 LR: 0.0000539869 Loss content:  0.1026 Loss fft:  4.0788\n",
      "Time:  1.0660 Epoch: 016 Iter: 16000/40967 LR: 0.0000539869 Loss content:  0.1090 Loss fft:  4.2931\n",
      "Time:  1.0617 Epoch: 016 Iter: 16500/40967 LR: 0.0000539869 Loss content:  0.1030 Loss fft:  4.1170\n",
      "Time:  1.0620 Epoch: 016 Iter: 17000/40967 LR: 0.0000539869 Loss content:  0.1026 Loss fft:  4.1059\n",
      "Time:  1.0616 Epoch: 016 Iter: 17500/40967 LR: 0.0000539869 Loss content:  0.1022 Loss fft:  4.0378\n",
      "Time:  1.0621 Epoch: 016 Iter: 18000/40967 LR: 0.0000539869 Loss content:  0.1035 Loss fft:  4.0933\n",
      "Time:  1.0654 Epoch: 016 Iter: 18500/40967 LR: 0.0000539869 Loss content:  0.1049 Loss fft:  4.1352\n",
      "Time:  1.0615 Epoch: 016 Iter: 19000/40967 LR: 0.0000539869 Loss content:  0.1096 Loss fft:  4.3277\n",
      "Time:  1.0621 Epoch: 016 Iter: 19500/40967 LR: 0.0000539869 Loss content:  0.0983 Loss fft:  3.8845\n",
      "Time:  1.0609 Epoch: 016 Iter: 20000/40967 LR: 0.0000539869 Loss content:  0.1032 Loss fft:  4.1015\n",
      "Time:  1.0652 Epoch: 016 Iter: 20500/40967 LR: 0.0000539869 Loss content:  0.1021 Loss fft:  4.0437\n",
      "Time:  1.0611 Epoch: 016 Iter: 21000/40967 LR: 0.0000539869 Loss content:  0.1049 Loss fft:  4.1216\n",
      "Time:  1.0631 Epoch: 016 Iter: 21500/40967 LR: 0.0000539869 Loss content:  0.0970 Loss fft:  3.8495\n",
      "Time:  1.0621 Epoch: 016 Iter: 22000/40967 LR: 0.0000539869 Loss content:  0.1031 Loss fft:  4.0743\n",
      "Time:  1.0623 Epoch: 016 Iter: 22500/40967 LR: 0.0000539869 Loss content:  0.0979 Loss fft:  3.8849\n",
      "Time:  1.0658 Epoch: 016 Iter: 23000/40967 LR: 0.0000539869 Loss content:  0.1043 Loss fft:  4.1042\n",
      "Time:  1.0614 Epoch: 016 Iter: 23500/40967 LR: 0.0000539869 Loss content:  0.1102 Loss fft:  4.2687\n",
      "Time:  1.0617 Epoch: 016 Iter: 24000/40967 LR: 0.0000539869 Loss content:  0.1070 Loss fft:  4.2180\n",
      "Time:  1.0622 Epoch: 016 Iter: 24500/40967 LR: 0.0000539869 Loss content:  0.0986 Loss fft:  3.9500\n",
      "Time:  1.0661 Epoch: 016 Iter: 25000/40967 LR: 0.0000539869 Loss content:  0.0910 Loss fft:  3.6077\n",
      "Time:  1.0617 Epoch: 016 Iter: 25500/40967 LR: 0.0000539869 Loss content:  0.0954 Loss fft:  3.8331\n",
      "Time:  1.0609 Epoch: 016 Iter: 26000/40967 LR: 0.0000539869 Loss content:  0.1056 Loss fft:  4.1427\n",
      "Time:  1.0625 Epoch: 016 Iter: 26500/40967 LR: 0.0000539869 Loss content:  0.1104 Loss fft:  4.3417\n",
      "Time:  1.0622 Epoch: 016 Iter: 27000/40967 LR: 0.0000539869 Loss content:  0.1070 Loss fft:  4.2102\n",
      "Time:  1.0649 Epoch: 016 Iter: 27500/40967 LR: 0.0000539869 Loss content:  0.0989 Loss fft:  3.9408\n",
      "Time:  1.0616 Epoch: 016 Iter: 28000/40967 LR: 0.0000539869 Loss content:  0.1050 Loss fft:  4.1327\n",
      "Time:  1.0612 Epoch: 016 Iter: 28500/40967 LR: 0.0000539869 Loss content:  0.1013 Loss fft:  3.9942\n",
      "Time:  1.0613 Epoch: 016 Iter: 29000/40967 LR: 0.0000539869 Loss content:  0.1085 Loss fft:  4.2561\n",
      "Time:  1.0649 Epoch: 016 Iter: 29500/40967 LR: 0.0000539869 Loss content:  0.1016 Loss fft:  4.0152\n",
      "Time:  1.0628 Epoch: 016 Iter: 30000/40967 LR: 0.0000539869 Loss content:  0.1029 Loss fft:  4.0774\n",
      "Time:  1.0610 Epoch: 016 Iter: 30500/40967 LR: 0.0000539869 Loss content:  0.1068 Loss fft:  4.1494\n",
      "Time:  1.0609 Epoch: 016 Iter: 31000/40967 LR: 0.0000539869 Loss content:  0.1031 Loss fft:  4.0955\n",
      "Time:  1.0623 Epoch: 016 Iter: 31500/40967 LR: 0.0000539869 Loss content:  0.1031 Loss fft:  4.0968\n",
      "Time:  1.0652 Epoch: 016 Iter: 32000/40967 LR: 0.0000539869 Loss content:  0.0941 Loss fft:  3.7788\n",
      "Time:  1.0614 Epoch: 016 Iter: 32500/40967 LR: 0.0000539869 Loss content:  0.1014 Loss fft:  4.0326\n",
      "Time:  1.0618 Epoch: 016 Iter: 33000/40967 LR: 0.0000539869 Loss content:  0.0954 Loss fft:  3.8439\n",
      "Time:  1.0610 Epoch: 016 Iter: 33500/40967 LR: 0.0000539869 Loss content:  0.1009 Loss fft:  3.9846\n",
      "Time:  1.0652 Epoch: 016 Iter: 34000/40967 LR: 0.0000539869 Loss content:  0.1082 Loss fft:  4.2740\n",
      "Time:  1.0621 Epoch: 016 Iter: 34500/40967 LR: 0.0000539869 Loss content:  0.1057 Loss fft:  4.1232\n",
      "Time:  1.0612 Epoch: 016 Iter: 35000/40967 LR: 0.0000539869 Loss content:  0.1051 Loss fft:  4.1299\n",
      "Time:  1.0620 Epoch: 016 Iter: 35500/40967 LR: 0.0000539869 Loss content:  0.0922 Loss fft:  3.6769\n",
      "Time:  1.0611 Epoch: 016 Iter: 36000/40967 LR: 0.0000539869 Loss content:  0.1031 Loss fft:  4.0821\n",
      "Time:  1.0654 Epoch: 016 Iter: 36500/40967 LR: 0.0000539869 Loss content:  0.1043 Loss fft:  4.1615\n",
      "Time:  1.0614 Epoch: 016 Iter: 37000/40967 LR: 0.0000539869 Loss content:  0.1031 Loss fft:  4.0962\n",
      "Time:  1.0608 Epoch: 016 Iter: 37500/40967 LR: 0.0000539869 Loss content:  0.0980 Loss fft:  3.9065\n",
      "Time:  1.0612 Epoch: 016 Iter: 38000/40967 LR: 0.0000539869 Loss content:  0.0995 Loss fft:  3.9734\n",
      "Time:  1.0613 Epoch: 016 Iter: 38500/40967 LR: 0.0000539869 Loss content:  0.1056 Loss fft:  4.1144\n",
      "Time:  1.0662 Epoch: 016 Iter: 39000/40967 LR: 0.0000539869 Loss content:  0.1018 Loss fft:  3.9776\n",
      "Time:  1.0620 Epoch: 016 Iter: 39500/40967 LR: 0.0000539869 Loss content:  0.1098 Loss fft:  4.3635\n",
      "Time:  1.0620 Epoch: 016 Iter: 40000/40967 LR: 0.0000539869 Loss content:  0.1023 Loss fft:  4.0679\n",
      "Time:  1.0624 Epoch: 016 Iter: 40500/40967 LR: 0.0000539869 Loss content:  0.1002 Loss fft:  3.9600\n",
      "EPOCH: 16\n",
      "Elapsed time: 87.09 Epoch Pixel Loss:  0.1026 Epoch FFT Loss:  4.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0741 Epoch: 017 Iter:  500/40967 LR: 0.0000482234 Loss content:  0.1004 Loss fft:  3.9652\n",
      "Time:  1.0634 Epoch: 017 Iter: 1000/40967 LR: 0.0000482234 Loss content:  0.1044 Loss fft:  4.1033\n",
      "Time:  1.0623 Epoch: 017 Iter: 1500/40967 LR: 0.0000482234 Loss content:  0.1047 Loss fft:  4.1408\n",
      "Time:  1.0628 Epoch: 017 Iter: 2000/40967 LR: 0.0000482234 Loss content:  0.1093 Loss fft:  4.2936\n",
      "Time:  1.0675 Epoch: 017 Iter: 2500/40967 LR: 0.0000482234 Loss content:  0.0949 Loss fft:  3.8245\n",
      "Time:  1.0626 Epoch: 017 Iter: 3000/40967 LR: 0.0000482234 Loss content:  0.0983 Loss fft:  3.9278\n",
      "Time:  1.0618 Epoch: 017 Iter: 3500/40967 LR: 0.0000482234 Loss content:  0.1156 Loss fft:  4.5816\n",
      "Time:  1.0650 Epoch: 017 Iter: 4000/40967 LR: 0.0000482234 Loss content:  0.0984 Loss fft:  3.8742\n",
      "Time:  1.0662 Epoch: 017 Iter: 4500/40967 LR: 0.0000482234 Loss content:  0.0999 Loss fft:  3.9845\n",
      "Time:  1.0618 Epoch: 017 Iter: 5000/40967 LR: 0.0000482234 Loss content:  0.1016 Loss fft:  4.0440\n",
      "Time:  1.0616 Epoch: 017 Iter: 5500/40967 LR: 0.0000482234 Loss content:  0.1003 Loss fft:  3.9886\n",
      "Time:  1.0609 Epoch: 017 Iter: 6000/40967 LR: 0.0000482234 Loss content:  0.0955 Loss fft:  3.8547\n",
      "Time:  1.0616 Epoch: 017 Iter: 6500/40967 LR: 0.0000482234 Loss content:  0.1108 Loss fft:  4.3154\n",
      "Time:  1.0653 Epoch: 017 Iter: 7000/40967 LR: 0.0000482234 Loss content:  0.1109 Loss fft:  4.3803\n",
      "Time:  1.0622 Epoch: 017 Iter: 7500/40967 LR: 0.0000482234 Loss content:  0.0952 Loss fft:  3.7776\n",
      "Time:  1.0630 Epoch: 017 Iter: 8000/40967 LR: 0.0000482234 Loss content:  0.0997 Loss fft:  3.9877\n",
      "Time:  1.0620 Epoch: 017 Iter: 8500/40967 LR: 0.0000482234 Loss content:  0.0964 Loss fft:  3.8719\n",
      "Time:  1.0653 Epoch: 017 Iter: 9000/40967 LR: 0.0000482234 Loss content:  0.0954 Loss fft:  3.8199\n",
      "Time:  1.0625 Epoch: 017 Iter: 9500/40967 LR: 0.0000482234 Loss content:  0.1157 Loss fft:  4.5516\n",
      "Time:  1.0619 Epoch: 017 Iter: 10000/40967 LR: 0.0000482234 Loss content:  0.1015 Loss fft:  4.0614\n",
      "Time:  1.0621 Epoch: 017 Iter: 10500/40967 LR: 0.0000482234 Loss content:  0.1045 Loss fft:  4.1915\n",
      "Time:  1.0616 Epoch: 017 Iter: 11000/40967 LR: 0.0000482234 Loss content:  0.1032 Loss fft:  4.1101\n",
      "Time:  1.0649 Epoch: 017 Iter: 11500/40967 LR: 0.0000482234 Loss content:  0.1062 Loss fft:  4.1961\n",
      "Time:  1.0614 Epoch: 017 Iter: 12000/40967 LR: 0.0000482234 Loss content:  0.0960 Loss fft:  3.8269\n",
      "Time:  1.0623 Epoch: 017 Iter: 12500/40967 LR: 0.0000482234 Loss content:  0.0995 Loss fft:  3.9357\n",
      "Time:  1.0618 Epoch: 017 Iter: 13000/40967 LR: 0.0000482234 Loss content:  0.0962 Loss fft:  3.9107\n",
      "Time:  1.0618 Epoch: 017 Iter: 13500/40967 LR: 0.0000482234 Loss content:  0.0977 Loss fft:  3.9079\n",
      "Time:  1.0656 Epoch: 017 Iter: 14000/40967 LR: 0.0000482234 Loss content:  0.1065 Loss fft:  4.2026\n",
      "Time:  1.0613 Epoch: 017 Iter: 14500/40967 LR: 0.0000482234 Loss content:  0.1082 Loss fft:  4.2719\n",
      "Time:  1.0617 Epoch: 017 Iter: 15000/40967 LR: 0.0000482234 Loss content:  0.1029 Loss fft:  4.1037\n",
      "Time:  1.0623 Epoch: 017 Iter: 15500/40967 LR: 0.0000482234 Loss content:  0.1109 Loss fft:  4.4016\n",
      "Time:  1.0654 Epoch: 017 Iter: 16000/40967 LR: 0.0000482234 Loss content:  0.0972 Loss fft:  3.8992\n",
      "Time:  1.0614 Epoch: 017 Iter: 16500/40967 LR: 0.0000482234 Loss content:  0.1001 Loss fft:  4.0047\n",
      "Time:  1.0612 Epoch: 017 Iter: 17000/40967 LR: 0.0000482234 Loss content:  0.1001 Loss fft:  4.0094\n",
      "Time:  1.0627 Epoch: 017 Iter: 17500/40967 LR: 0.0000482234 Loss content:  0.0971 Loss fft:  3.8596\n",
      "Time:  1.0616 Epoch: 017 Iter: 18000/40967 LR: 0.0000482234 Loss content:  0.1035 Loss fft:  4.0833\n",
      "Time:  1.0655 Epoch: 017 Iter: 18500/40967 LR: 0.0000482234 Loss content:  0.1109 Loss fft:  4.3523\n",
      "Time:  1.0615 Epoch: 017 Iter: 19000/40967 LR: 0.0000482234 Loss content:  0.1017 Loss fft:  4.0381\n",
      "Time:  1.0616 Epoch: 017 Iter: 19500/40967 LR: 0.0000482234 Loss content:  0.1033 Loss fft:  4.0965\n",
      "Time:  1.0623 Epoch: 017 Iter: 20000/40967 LR: 0.0000482234 Loss content:  0.1037 Loss fft:  4.1260\n",
      "Time:  1.0656 Epoch: 017 Iter: 20500/40967 LR: 0.0000482234 Loss content:  0.0947 Loss fft:  3.7883\n",
      "Time:  1.0626 Epoch: 017 Iter: 21000/40967 LR: 0.0000482234 Loss content:  0.1002 Loss fft:  4.0176\n",
      "Time:  1.0605 Epoch: 017 Iter: 21500/40967 LR: 0.0000482234 Loss content:  0.1084 Loss fft:  4.3004\n",
      "Time:  1.0620 Epoch: 017 Iter: 22000/40967 LR: 0.0000482234 Loss content:  0.0997 Loss fft:  3.9663\n",
      "Time:  1.0616 Epoch: 017 Iter: 22500/40967 LR: 0.0000482234 Loss content:  0.1046 Loss fft:  4.1577\n",
      "Time:  1.0653 Epoch: 017 Iter: 23000/40967 LR: 0.0000482234 Loss content:  0.0912 Loss fft:  3.6679\n",
      "Time:  1.0611 Epoch: 017 Iter: 23500/40967 LR: 0.0000482234 Loss content:  0.1009 Loss fft:  4.0787\n",
      "Time:  1.0618 Epoch: 017 Iter: 24000/40967 LR: 0.0000482234 Loss content:  0.1030 Loss fft:  4.0942\n",
      "Time:  1.0634 Epoch: 017 Iter: 24500/40967 LR: 0.0000482234 Loss content:  0.1059 Loss fft:  4.1802\n",
      "Time:  1.0650 Epoch: 017 Iter: 25000/40967 LR: 0.0000482234 Loss content:  0.0981 Loss fft:  3.9220\n",
      "Time:  1.0612 Epoch: 017 Iter: 25500/40967 LR: 0.0000482234 Loss content:  0.1090 Loss fft:  4.3465\n",
      "Time:  1.0623 Epoch: 017 Iter: 26000/40967 LR: 0.0000482234 Loss content:  0.1019 Loss fft:  4.0905\n",
      "Time:  1.0624 Epoch: 017 Iter: 26500/40967 LR: 0.0000482234 Loss content:  0.1032 Loss fft:  4.1083\n",
      "Time:  1.0614 Epoch: 017 Iter: 27000/40967 LR: 0.0000482234 Loss content:  0.0957 Loss fft:  3.8061\n",
      "Time:  1.0653 Epoch: 017 Iter: 27500/40967 LR: 0.0000482234 Loss content:  0.1075 Loss fft:  4.2855\n",
      "Time:  1.0621 Epoch: 017 Iter: 28000/40967 LR: 0.0000482234 Loss content:  0.1043 Loss fft:  4.1470\n",
      "Time:  1.0615 Epoch: 017 Iter: 28500/40967 LR: 0.0000482234 Loss content:  0.0966 Loss fft:  3.8738\n",
      "Time:  1.0627 Epoch: 017 Iter: 29000/40967 LR: 0.0000482234 Loss content:  0.1049 Loss fft:  4.2312\n",
      "Time:  1.0615 Epoch: 017 Iter: 29500/40967 LR: 0.0000482234 Loss content:  0.0962 Loss fft:  3.8360\n",
      "Time:  1.0651 Epoch: 017 Iter: 30000/40967 LR: 0.0000482234 Loss content:  0.0999 Loss fft:  4.0193\n",
      "Time:  1.0615 Epoch: 017 Iter: 30500/40967 LR: 0.0000482234 Loss content:  0.1037 Loss fft:  4.1418\n",
      "Time:  1.0617 Epoch: 017 Iter: 31000/40967 LR: 0.0000482234 Loss content:  0.0994 Loss fft:  3.9398\n",
      "Time:  1.0611 Epoch: 017 Iter: 31500/40967 LR: 0.0000482234 Loss content:  0.1008 Loss fft:  4.0051\n",
      "Time:  1.0657 Epoch: 017 Iter: 32000/40967 LR: 0.0000482234 Loss content:  0.0926 Loss fft:  3.7373\n",
      "Time:  1.0624 Epoch: 017 Iter: 32500/40967 LR: 0.0000482234 Loss content:  0.1032 Loss fft:  4.1167\n",
      "Time:  1.0613 Epoch: 017 Iter: 33000/40967 LR: 0.0000482234 Loss content:  0.1038 Loss fft:  4.1436\n",
      "Time:  1.0617 Epoch: 017 Iter: 33500/40967 LR: 0.0000482234 Loss content:  0.1003 Loss fft:  4.0318\n",
      "Time:  1.0614 Epoch: 017 Iter: 34000/40967 LR: 0.0000482234 Loss content:  0.0992 Loss fft:  3.9496\n",
      "Time:  1.0655 Epoch: 017 Iter: 34500/40967 LR: 0.0000482234 Loss content:  0.0966 Loss fft:  3.8458\n",
      "Time:  1.0626 Epoch: 017 Iter: 35000/40967 LR: 0.0000482234 Loss content:  0.0964 Loss fft:  3.8023\n",
      "Time:  1.0618 Epoch: 017 Iter: 35500/40967 LR: 0.0000482234 Loss content:  0.1022 Loss fft:  4.0944\n",
      "Time:  1.0615 Epoch: 017 Iter: 36000/40967 LR: 0.0000482234 Loss content:  0.1097 Loss fft:  4.3254\n",
      "Time:  1.0654 Epoch: 017 Iter: 36500/40967 LR: 0.0000482234 Loss content:  0.0970 Loss fft:  3.8993\n",
      "Time:  1.0617 Epoch: 017 Iter: 37000/40967 LR: 0.0000482234 Loss content:  0.1012 Loss fft:  4.0555\n",
      "Time:  1.0615 Epoch: 017 Iter: 37500/40967 LR: 0.0000482234 Loss content:  0.1073 Loss fft:  4.2118\n",
      "Time:  1.0606 Epoch: 017 Iter: 38000/40967 LR: 0.0000482234 Loss content:  0.1013 Loss fft:  3.9963\n",
      "Time:  1.0620 Epoch: 017 Iter: 38500/40967 LR: 0.0000482234 Loss content:  0.0954 Loss fft:  3.8125\n",
      "Time:  1.0653 Epoch: 017 Iter: 39000/40967 LR: 0.0000482234 Loss content:  0.1018 Loss fft:  4.0322\n",
      "Time:  1.0619 Epoch: 017 Iter: 39500/40967 LR: 0.0000482234 Loss content:  0.0976 Loss fft:  3.9118\n",
      "Time:  1.0615 Epoch: 017 Iter: 40000/40967 LR: 0.0000482234 Loss content:  0.0946 Loss fft:  3.8274\n",
      "Time:  1.0614 Epoch: 017 Iter: 40500/40967 LR: 0.0000482234 Loss content:  0.0971 Loss fft:  3.9137\n",
      "EPOCH: 17\n",
      "Elapsed time: 87.09 Epoch Pixel Loss:  0.1015 Epoch FFT Loss:  4.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0756 Epoch: 018 Iter:  500/40967 LR: 0.0000424981 Loss content:  0.1011 Loss fft:  4.0629\n",
      "Time:  1.0623 Epoch: 018 Iter: 1000/40967 LR: 0.0000424981 Loss content:  0.1039 Loss fft:  4.1921\n",
      "Time:  1.0622 Epoch: 018 Iter: 1500/40967 LR: 0.0000424981 Loss content:  0.0927 Loss fft:  3.7393\n",
      "Time:  1.0620 Epoch: 018 Iter: 2000/40967 LR: 0.0000424981 Loss content:  0.0964 Loss fft:  3.8612\n",
      "Time:  1.0679 Epoch: 018 Iter: 2500/40967 LR: 0.0000424981 Loss content:  0.1011 Loss fft:  4.0770\n",
      "Time:  1.0612 Epoch: 018 Iter: 3000/40967 LR: 0.0000424981 Loss content:  0.0980 Loss fft:  3.9463\n",
      "Time:  1.0615 Epoch: 018 Iter: 3500/40967 LR: 0.0000424981 Loss content:  0.0989 Loss fft:  3.9888\n",
      "Time:  1.0622 Epoch: 018 Iter: 4000/40967 LR: 0.0000424981 Loss content:  0.0942 Loss fft:  3.8286\n",
      "Time:  1.0656 Epoch: 018 Iter: 4500/40967 LR: 0.0000424981 Loss content:  0.1035 Loss fft:  4.1394\n",
      "Time:  1.0620 Epoch: 018 Iter: 5000/40967 LR: 0.0000424981 Loss content:  0.1017 Loss fft:  4.1057\n",
      "Time:  1.0628 Epoch: 018 Iter: 5500/40967 LR: 0.0000424981 Loss content:  0.0957 Loss fft:  3.8458\n",
      "Time:  1.0619 Epoch: 018 Iter: 6000/40967 LR: 0.0000424981 Loss content:  0.0978 Loss fft:  3.9189\n",
      "Time:  1.0631 Epoch: 018 Iter: 6500/40967 LR: 0.0000424981 Loss content:  0.0993 Loss fft:  4.0173\n",
      "Time:  1.0667 Epoch: 018 Iter: 7000/40967 LR: 0.0000424981 Loss content:  0.0939 Loss fft:  3.7810\n",
      "Time:  1.0624 Epoch: 018 Iter: 7500/40967 LR: 0.0000424981 Loss content:  0.1051 Loss fft:  4.1601\n",
      "Time:  1.0623 Epoch: 018 Iter: 8000/40967 LR: 0.0000424981 Loss content:  0.1010 Loss fft:  4.0392\n",
      "Time:  1.0622 Epoch: 018 Iter: 8500/40967 LR: 0.0000424981 Loss content:  0.1013 Loss fft:  4.0940\n",
      "Time:  1.0621 Epoch: 018 Iter: 9000/40967 LR: 0.0000424981 Loss content:  0.1027 Loss fft:  4.1184\n",
      "Time:  1.0661 Epoch: 018 Iter: 9500/40967 LR: 0.0000424981 Loss content:  0.1046 Loss fft:  4.1975\n",
      "Time:  1.0632 Epoch: 018 Iter: 10000/40967 LR: 0.0000424981 Loss content:  0.1051 Loss fft:  4.2123\n",
      "Time:  1.0620 Epoch: 018 Iter: 10500/40967 LR: 0.0000424981 Loss content:  0.1020 Loss fft:  4.0796\n",
      "Time:  1.0625 Epoch: 018 Iter: 11000/40967 LR: 0.0000424981 Loss content:  0.0976 Loss fft:  3.9238\n",
      "Time:  1.0658 Epoch: 018 Iter: 11500/40967 LR: 0.0000424981 Loss content:  0.1024 Loss fft:  4.1282\n",
      "Time:  1.0624 Epoch: 018 Iter: 12000/40967 LR: 0.0000424981 Loss content:  0.0983 Loss fft:  3.9294\n",
      "Time:  1.0611 Epoch: 018 Iter: 12500/40967 LR: 0.0000424981 Loss content:  0.1002 Loss fft:  3.9359\n",
      "Time:  1.0608 Epoch: 018 Iter: 13000/40967 LR: 0.0000424981 Loss content:  0.1015 Loss fft:  4.1049\n",
      "Time:  1.0617 Epoch: 018 Iter: 13500/40967 LR: 0.0000424981 Loss content:  0.1028 Loss fft:  4.1163\n",
      "Time:  1.0659 Epoch: 018 Iter: 14000/40967 LR: 0.0000424981 Loss content:  0.1007 Loss fft:  4.0536\n",
      "Time:  1.0622 Epoch: 018 Iter: 14500/40967 LR: 0.0000424981 Loss content:  0.0944 Loss fft:  3.7969\n",
      "Time:  1.0627 Epoch: 018 Iter: 15000/40967 LR: 0.0000424981 Loss content:  0.1007 Loss fft:  4.0551\n",
      "Time:  1.0620 Epoch: 018 Iter: 15500/40967 LR: 0.0000424981 Loss content:  0.1067 Loss fft:  4.2375\n",
      "Time:  1.0666 Epoch: 018 Iter: 16000/40967 LR: 0.0000424981 Loss content:  0.0989 Loss fft:  3.9826\n",
      "Time:  1.0617 Epoch: 018 Iter: 16500/40967 LR: 0.0000424981 Loss content:  0.0951 Loss fft:  3.8112\n",
      "Time:  1.0623 Epoch: 018 Iter: 17000/40967 LR: 0.0000424981 Loss content:  0.0992 Loss fft:  3.9235\n",
      "Time:  1.0625 Epoch: 018 Iter: 17500/40967 LR: 0.0000424981 Loss content:  0.1004 Loss fft:  4.0230\n",
      "Time:  1.0614 Epoch: 018 Iter: 18000/40967 LR: 0.0000424981 Loss content:  0.0997 Loss fft:  4.0263\n",
      "Time:  1.0660 Epoch: 018 Iter: 18500/40967 LR: 0.0000424981 Loss content:  0.1003 Loss fft:  4.0217\n",
      "Time:  1.0620 Epoch: 018 Iter: 19000/40967 LR: 0.0000424981 Loss content:  0.0979 Loss fft:  3.9627\n",
      "Time:  1.0619 Epoch: 018 Iter: 19500/40967 LR: 0.0000424981 Loss content:  0.0996 Loss fft:  3.9771\n",
      "Time:  1.0615 Epoch: 018 Iter: 20000/40967 LR: 0.0000424981 Loss content:  0.1093 Loss fft:  4.3650\n",
      "Time:  1.0654 Epoch: 018 Iter: 20500/40967 LR: 0.0000424981 Loss content:  0.0987 Loss fft:  4.0118\n",
      "Time:  1.0623 Epoch: 018 Iter: 21000/40967 LR: 0.0000424981 Loss content:  0.1017 Loss fft:  4.0387\n",
      "Time:  1.0621 Epoch: 018 Iter: 21500/40967 LR: 0.0000424981 Loss content:  0.0982 Loss fft:  3.9689\n",
      "Time:  1.0620 Epoch: 018 Iter: 22000/40967 LR: 0.0000424981 Loss content:  0.1057 Loss fft:  4.2567\n",
      "Time:  1.0617 Epoch: 018 Iter: 22500/40967 LR: 0.0000424981 Loss content:  0.1022 Loss fft:  4.0940\n",
      "Time:  1.0664 Epoch: 018 Iter: 23000/40967 LR: 0.0000424981 Loss content:  0.1117 Loss fft:  4.4849\n",
      "Time:  1.0617 Epoch: 018 Iter: 23500/40967 LR: 0.0000424981 Loss content:  0.0953 Loss fft:  3.8538\n",
      "Time:  1.0622 Epoch: 018 Iter: 24000/40967 LR: 0.0000424981 Loss content:  0.0954 Loss fft:  3.8490\n",
      "Time:  1.0628 Epoch: 018 Iter: 24500/40967 LR: 0.0000424981 Loss content:  0.1028 Loss fft:  4.0379\n",
      "Time:  1.0633 Epoch: 018 Iter: 25000/40967 LR: 0.0000424981 Loss content:  0.0965 Loss fft:  3.9108\n",
      "Time:  1.0651 Epoch: 018 Iter: 25500/40967 LR: 0.0000424981 Loss content:  0.0971 Loss fft:  3.9457\n",
      "Time:  1.0628 Epoch: 018 Iter: 26000/40967 LR: 0.0000424981 Loss content:  0.0980 Loss fft:  3.9142\n",
      "Time:  1.0623 Epoch: 018 Iter: 26500/40967 LR: 0.0000424981 Loss content:  0.1038 Loss fft:  4.1498\n",
      "Time:  1.0613 Epoch: 018 Iter: 27000/40967 LR: 0.0000424981 Loss content:  0.0990 Loss fft:  3.9517\n",
      "Time:  1.0656 Epoch: 018 Iter: 27500/40967 LR: 0.0000424981 Loss content:  0.0963 Loss fft:  3.8902\n",
      "Time:  1.0610 Epoch: 018 Iter: 28000/40967 LR: 0.0000424981 Loss content:  0.1025 Loss fft:  4.0650\n",
      "Time:  1.0616 Epoch: 018 Iter: 28500/40967 LR: 0.0000424981 Loss content:  0.0974 Loss fft:  3.9330\n",
      "Time:  1.0613 Epoch: 018 Iter: 29000/40967 LR: 0.0000424981 Loss content:  0.0995 Loss fft:  4.0242\n",
      "Time:  1.0619 Epoch: 018 Iter: 29500/40967 LR: 0.0000424981 Loss content:  0.1034 Loss fft:  4.1607\n",
      "Time:  1.0660 Epoch: 018 Iter: 30000/40967 LR: 0.0000424981 Loss content:  0.1035 Loss fft:  4.1059\n",
      "Time:  1.0624 Epoch: 018 Iter: 30500/40967 LR: 0.0000424981 Loss content:  0.1008 Loss fft:  3.9857\n",
      "Time:  1.0616 Epoch: 018 Iter: 31000/40967 LR: 0.0000424981 Loss content:  0.1009 Loss fft:  4.0154\n",
      "Time:  1.0612 Epoch: 018 Iter: 31500/40967 LR: 0.0000424981 Loss content:  0.1042 Loss fft:  4.1409\n",
      "Time:  1.0656 Epoch: 018 Iter: 32000/40967 LR: 0.0000424981 Loss content:  0.0976 Loss fft:  3.9366\n",
      "Time:  1.0617 Epoch: 018 Iter: 32500/40967 LR: 0.0000424981 Loss content:  0.1041 Loss fft:  4.1654\n",
      "Time:  1.0625 Epoch: 018 Iter: 33000/40967 LR: 0.0000424981 Loss content:  0.0964 Loss fft:  3.9324\n",
      "Time:  1.0616 Epoch: 018 Iter: 33500/40967 LR: 0.0000424981 Loss content:  0.0996 Loss fft:  4.0113\n",
      "Time:  1.0621 Epoch: 018 Iter: 34000/40967 LR: 0.0000424981 Loss content:  0.1090 Loss fft:  4.3630\n",
      "Time:  1.0661 Epoch: 018 Iter: 34500/40967 LR: 0.0000424981 Loss content:  0.1008 Loss fft:  4.0695\n",
      "Time:  1.0625 Epoch: 018 Iter: 35000/40967 LR: 0.0000424981 Loss content:  0.0965 Loss fft:  3.8460\n",
      "Time:  1.0626 Epoch: 018 Iter: 35500/40967 LR: 0.0000424981 Loss content:  0.0990 Loss fft:  4.0458\n",
      "Time:  1.0618 Epoch: 018 Iter: 36000/40967 LR: 0.0000424981 Loss content:  0.0940 Loss fft:  3.7924\n",
      "Time:  1.0659 Epoch: 018 Iter: 36500/40967 LR: 0.0000424981 Loss content:  0.0887 Loss fft:  3.6345\n",
      "Time:  1.0621 Epoch: 018 Iter: 37000/40967 LR: 0.0000424981 Loss content:  0.1027 Loss fft:  4.1042\n",
      "Time:  1.0613 Epoch: 018 Iter: 37500/40967 LR: 0.0000424981 Loss content:  0.0911 Loss fft:  3.6825\n",
      "Time:  1.0616 Epoch: 018 Iter: 38000/40967 LR: 0.0000424981 Loss content:  0.1097 Loss fft:  4.3831\n",
      "Time:  1.0621 Epoch: 018 Iter: 38500/40967 LR: 0.0000424981 Loss content:  0.1045 Loss fft:  4.1951\n",
      "Time:  1.0657 Epoch: 018 Iter: 39000/40967 LR: 0.0000424981 Loss content:  0.1048 Loss fft:  4.1473\n",
      "Time:  1.0617 Epoch: 018 Iter: 39500/40967 LR: 0.0000424981 Loss content:  0.1042 Loss fft:  4.1939\n",
      "Time:  1.0618 Epoch: 018 Iter: 40000/40967 LR: 0.0000424981 Loss content:  0.0979 Loss fft:  3.9407\n",
      "Time:  1.0625 Epoch: 018 Iter: 40500/40967 LR: 0.0000424981 Loss content:  0.0925 Loss fft:  3.6821\n",
      "EPOCH: 18\n",
      "Elapsed time: 87.10 Epoch Pixel Loss:  0.1002 Epoch FFT Loss:  4.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0836 Epoch: 019 Iter:  500/40967 LR: 0.0000368881 Loss content:  0.1044 Loss fft:  4.1809\n",
      "Time:  1.0628 Epoch: 019 Iter: 1000/40967 LR: 0.0000368881 Loss content:  0.0965 Loss fft:  3.9025\n",
      "Time:  1.0625 Epoch: 019 Iter: 1500/40967 LR: 0.0000368881 Loss content:  0.0945 Loss fft:  3.8383\n",
      "Time:  1.0622 Epoch: 019 Iter: 2000/40967 LR: 0.0000368881 Loss content:  0.0983 Loss fft:  3.9402\n",
      "Time:  1.0659 Epoch: 019 Iter: 2500/40967 LR: 0.0000368881 Loss content:  0.1033 Loss fft:  4.1771\n",
      "Time:  1.0629 Epoch: 019 Iter: 3000/40967 LR: 0.0000368881 Loss content:  0.0973 Loss fft:  3.9662\n",
      "Time:  1.0630 Epoch: 019 Iter: 3500/40967 LR: 0.0000368881 Loss content:  0.1039 Loss fft:  4.1956\n",
      "Time:  1.0627 Epoch: 019 Iter: 4000/40967 LR: 0.0000368881 Loss content:  0.0929 Loss fft:  3.7956\n",
      "Time:  1.0631 Epoch: 019 Iter: 4500/40967 LR: 0.0000368881 Loss content:  0.0927 Loss fft:  3.7630\n",
      "Time:  1.0671 Epoch: 019 Iter: 5000/40967 LR: 0.0000368881 Loss content:  0.0978 Loss fft:  3.9746\n",
      "Time:  1.0618 Epoch: 019 Iter: 5500/40967 LR: 0.0000368881 Loss content:  0.0959 Loss fft:  3.8982\n",
      "Time:  1.0626 Epoch: 019 Iter: 6000/40967 LR: 0.0000368881 Loss content:  0.1022 Loss fft:  4.0992\n",
      "Time:  1.0627 Epoch: 019 Iter: 6500/40967 LR: 0.0000368881 Loss content:  0.0933 Loss fft:  3.8194\n",
      "Time:  1.0654 Epoch: 019 Iter: 7000/40967 LR: 0.0000368881 Loss content:  0.0987 Loss fft:  3.9918\n",
      "Time:  1.0616 Epoch: 019 Iter: 7500/40967 LR: 0.0000368881 Loss content:  0.1050 Loss fft:  4.1873\n",
      "Time:  1.0613 Epoch: 019 Iter: 8000/40967 LR: 0.0000368881 Loss content:  0.0960 Loss fft:  3.8882\n",
      "Time:  1.0607 Epoch: 019 Iter: 8500/40967 LR: 0.0000368881 Loss content:  0.1054 Loss fft:  4.1989\n",
      "Time:  1.0621 Epoch: 019 Iter: 9000/40967 LR: 0.0000368881 Loss content:  0.0951 Loss fft:  3.8207\n",
      "Time:  1.0675 Epoch: 019 Iter: 9500/40967 LR: 0.0000368881 Loss content:  0.0967 Loss fft:  3.9321\n",
      "Time:  1.0616 Epoch: 019 Iter: 10000/40967 LR: 0.0000368881 Loss content:  0.1044 Loss fft:  4.1951\n",
      "Time:  1.0625 Epoch: 019 Iter: 10500/40967 LR: 0.0000368881 Loss content:  0.1034 Loss fft:  4.1682\n",
      "Time:  1.0615 Epoch: 019 Iter: 11000/40967 LR: 0.0000368881 Loss content:  0.1051 Loss fft:  4.2189\n",
      "Time:  1.0665 Epoch: 019 Iter: 11500/40967 LR: 0.0000368881 Loss content:  0.0947 Loss fft:  3.8958\n",
      "Time:  1.0630 Epoch: 019 Iter: 12000/40967 LR: 0.0000368881 Loss content:  0.0990 Loss fft:  3.9910\n",
      "Time:  1.0622 Epoch: 019 Iter: 12500/40967 LR: 0.0000368881 Loss content:  0.0934 Loss fft:  3.7878\n",
      "Time:  1.0623 Epoch: 019 Iter: 13000/40967 LR: 0.0000368881 Loss content:  0.0949 Loss fft:  3.8990\n",
      "Time:  1.0616 Epoch: 019 Iter: 13500/40967 LR: 0.0000368881 Loss content:  0.0985 Loss fft:  3.9624\n",
      "Time:  1.0657 Epoch: 019 Iter: 14000/40967 LR: 0.0000368881 Loss content:  0.0992 Loss fft:  4.0039\n",
      "Time:  1.0615 Epoch: 019 Iter: 14500/40967 LR: 0.0000368881 Loss content:  0.0920 Loss fft:  3.7293\n",
      "Time:  1.0614 Epoch: 019 Iter: 15000/40967 LR: 0.0000368881 Loss content:  0.0998 Loss fft:  4.0368\n",
      "Time:  1.0632 Epoch: 019 Iter: 15500/40967 LR: 0.0000368881 Loss content:  0.1007 Loss fft:  4.0354\n",
      "Time:  1.0630 Epoch: 019 Iter: 16000/40967 LR: 0.0000368881 Loss content:  0.0892 Loss fft:  3.6300\n",
      "Time:  1.0660 Epoch: 019 Iter: 16500/40967 LR: 0.0000368881 Loss content:  0.1004 Loss fft:  4.0650\n",
      "Time:  1.0622 Epoch: 019 Iter: 17000/40967 LR: 0.0000368881 Loss content:  0.1065 Loss fft:  4.2600\n",
      "Time:  1.0612 Epoch: 019 Iter: 17500/40967 LR: 0.0000368881 Loss content:  0.0962 Loss fft:  3.8640\n",
      "Time:  1.0614 Epoch: 019 Iter: 18000/40967 LR: 0.0000368881 Loss content:  0.0933 Loss fft:  3.7974\n",
      "Time:  1.0646 Epoch: 019 Iter: 18500/40967 LR: 0.0000368881 Loss content:  0.0967 Loss fft:  3.9482\n",
      "Time:  1.0617 Epoch: 019 Iter: 19000/40967 LR: 0.0000368881 Loss content:  0.1068 Loss fft:  4.2923\n",
      "Time:  1.0613 Epoch: 019 Iter: 19500/40967 LR: 0.0000368881 Loss content:  0.0974 Loss fft:  3.9418\n",
      "Time:  1.0615 Epoch: 019 Iter: 20000/40967 LR: 0.0000368881 Loss content:  0.1033 Loss fft:  4.1859\n",
      "Time:  1.0617 Epoch: 019 Iter: 20500/40967 LR: 0.0000368881 Loss content:  0.1105 Loss fft:  4.4002\n",
      "Time:  1.0649 Epoch: 019 Iter: 21000/40967 LR: 0.0000368881 Loss content:  0.1086 Loss fft:  4.3969\n",
      "Time:  1.0623 Epoch: 019 Iter: 21500/40967 LR: 0.0000368881 Loss content:  0.1012 Loss fft:  4.0372\n",
      "Time:  1.0625 Epoch: 019 Iter: 22000/40967 LR: 0.0000368881 Loss content:  0.1026 Loss fft:  4.1432\n",
      "Time:  1.0612 Epoch: 019 Iter: 22500/40967 LR: 0.0000368881 Loss content:  0.1070 Loss fft:  4.2736\n",
      "Time:  1.0648 Epoch: 019 Iter: 23000/40967 LR: 0.0000368881 Loss content:  0.0987 Loss fft:  3.9957\n",
      "Time:  1.0614 Epoch: 019 Iter: 23500/40967 LR: 0.0000368881 Loss content:  0.1014 Loss fft:  4.0920\n",
      "Time:  1.0625 Epoch: 019 Iter: 24000/40967 LR: 0.0000368881 Loss content:  0.0913 Loss fft:  3.7718\n",
      "Time:  1.0624 Epoch: 019 Iter: 24500/40967 LR: 0.0000368881 Loss content:  0.1045 Loss fft:  4.1909\n",
      "Time:  1.0625 Epoch: 019 Iter: 25000/40967 LR: 0.0000368881 Loss content:  0.0990 Loss fft:  3.9726\n",
      "Time:  1.0654 Epoch: 019 Iter: 25500/40967 LR: 0.0000368881 Loss content:  0.1012 Loss fft:  4.1014\n",
      "Time:  1.0616 Epoch: 019 Iter: 26000/40967 LR: 0.0000368881 Loss content:  0.1052 Loss fft:  4.2101\n",
      "Time:  1.0620 Epoch: 019 Iter: 26500/40967 LR: 0.0000368881 Loss content:  0.0977 Loss fft:  3.9871\n",
      "Time:  1.0624 Epoch: 019 Iter: 27000/40967 LR: 0.0000368881 Loss content:  0.0897 Loss fft:  3.6640\n",
      "Time:  1.0661 Epoch: 019 Iter: 27500/40967 LR: 0.0000368881 Loss content:  0.0936 Loss fft:  3.8240\n",
      "Time:  1.0632 Epoch: 019 Iter: 28000/40967 LR: 0.0000368881 Loss content:  0.0916 Loss fft:  3.7585\n",
      "Time:  1.0616 Epoch: 019 Iter: 28500/40967 LR: 0.0000368881 Loss content:  0.1014 Loss fft:  4.0179\n",
      "Time:  1.0623 Epoch: 019 Iter: 29000/40967 LR: 0.0000368881 Loss content:  0.0978 Loss fft:  3.9326\n",
      "Time:  1.0628 Epoch: 019 Iter: 29500/40967 LR: 0.0000368881 Loss content:  0.0984 Loss fft:  3.9948\n",
      "Time:  1.0648 Epoch: 019 Iter: 30000/40967 LR: 0.0000368881 Loss content:  0.1011 Loss fft:  4.0612\n",
      "Time:  1.0611 Epoch: 019 Iter: 30500/40967 LR: 0.0000368881 Loss content:  0.1053 Loss fft:  4.2175\n",
      "Time:  1.0612 Epoch: 019 Iter: 31000/40967 LR: 0.0000368881 Loss content:  0.1020 Loss fft:  4.1277\n",
      "Time:  1.0617 Epoch: 019 Iter: 31500/40967 LR: 0.0000368881 Loss content:  0.1015 Loss fft:  4.0902\n",
      "Time:  1.0653 Epoch: 019 Iter: 32000/40967 LR: 0.0000368881 Loss content:  0.1020 Loss fft:  4.1189\n",
      "Time:  1.0620 Epoch: 019 Iter: 32500/40967 LR: 0.0000368881 Loss content:  0.1068 Loss fft:  4.3056\n",
      "Time:  1.0621 Epoch: 019 Iter: 33000/40967 LR: 0.0000368881 Loss content:  0.1035 Loss fft:  4.2491\n",
      "Time:  1.0613 Epoch: 019 Iter: 33500/40967 LR: 0.0000368881 Loss content:  0.0994 Loss fft:  4.0616\n",
      "Time:  1.0617 Epoch: 019 Iter: 34000/40967 LR: 0.0000368881 Loss content:  0.0988 Loss fft:  4.0284\n",
      "Time:  1.0652 Epoch: 019 Iter: 34500/40967 LR: 0.0000368881 Loss content:  0.1017 Loss fft:  4.0866\n",
      "Time:  1.0618 Epoch: 019 Iter: 35000/40967 LR: 0.0000368881 Loss content:  0.0974 Loss fft:  3.8750\n",
      "Time:  1.0616 Epoch: 019 Iter: 35500/40967 LR: 0.0000368881 Loss content:  0.1012 Loss fft:  4.1317\n",
      "Time:  1.0614 Epoch: 019 Iter: 36000/40967 LR: 0.0000368881 Loss content:  0.0989 Loss fft:  3.9808\n",
      "Time:  1.0620 Epoch: 019 Iter: 36500/40967 LR: 0.0000368881 Loss content:  0.0993 Loss fft:  4.0075\n",
      "Time:  1.0646 Epoch: 019 Iter: 37000/40967 LR: 0.0000368881 Loss content:  0.1057 Loss fft:  4.2582\n",
      "Time:  1.0609 Epoch: 019 Iter: 37500/40967 LR: 0.0000368881 Loss content:  0.1006 Loss fft:  4.0943\n",
      "Time:  1.0613 Epoch: 019 Iter: 38000/40967 LR: 0.0000368881 Loss content:  0.1040 Loss fft:  4.1471\n",
      "Time:  1.0620 Epoch: 019 Iter: 38500/40967 LR: 0.0000368881 Loss content:  0.0907 Loss fft:  3.6906\n",
      "Time:  1.0649 Epoch: 019 Iter: 39000/40967 LR: 0.0000368881 Loss content:  0.1015 Loss fft:  4.1107\n",
      "Time:  1.0610 Epoch: 019 Iter: 39500/40967 LR: 0.0000368881 Loss content:  0.0935 Loss fft:  3.7625\n",
      "Time:  1.0616 Epoch: 019 Iter: 40000/40967 LR: 0.0000368881 Loss content:  0.0940 Loss fft:  3.8358\n",
      "Time:  1.0627 Epoch: 019 Iter: 40500/40967 LR: 0.0000368881 Loss content:  0.1021 Loss fft:  4.1062\n",
      "EPOCH: 19\n",
      "Elapsed time: 87.10 Epoch Pixel Loss:  0.0996 Epoch FFT Loss:  4.0237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0803 Epoch: 020 Iter:  500/40967 LR: 0.0000314691 Loss content:  0.1037 Loss fft:  4.2059\n",
      "Time:  1.0622 Epoch: 020 Iter: 1000/40967 LR: 0.0000314691 Loss content:  0.1015 Loss fft:  4.0756\n",
      "Time:  1.0632 Epoch: 020 Iter: 1500/40967 LR: 0.0000314691 Loss content:  0.0952 Loss fft:  3.9078\n",
      "Time:  1.0626 Epoch: 020 Iter: 2000/40967 LR: 0.0000314691 Loss content:  0.1047 Loss fft:  4.2782\n",
      "Time:  1.0665 Epoch: 020 Iter: 2500/40967 LR: 0.0000314691 Loss content:  0.0997 Loss fft:  4.1419\n",
      "Time:  1.0627 Epoch: 020 Iter: 3000/40967 LR: 0.0000314691 Loss content:  0.1035 Loss fft:  4.1263\n",
      "Time:  1.0621 Epoch: 020 Iter: 3500/40967 LR: 0.0000314691 Loss content:  0.1056 Loss fft:  4.2385\n",
      "Time:  1.0619 Epoch: 020 Iter: 4000/40967 LR: 0.0000314691 Loss content:  0.1042 Loss fft:  4.2004\n",
      "Time:  1.0608 Epoch: 020 Iter: 4500/40967 LR: 0.0000314691 Loss content:  0.0953 Loss fft:  3.8665\n",
      "Time:  1.0667 Epoch: 020 Iter: 5000/40967 LR: 0.0000314691 Loss content:  0.1057 Loss fft:  4.2530\n",
      "Time:  1.0616 Epoch: 020 Iter: 5500/40967 LR: 0.0000314691 Loss content:  0.0909 Loss fft:  3.6864\n",
      "Time:  1.0613 Epoch: 020 Iter: 6000/40967 LR: 0.0000314691 Loss content:  0.1009 Loss fft:  4.0828\n",
      "Time:  1.0611 Epoch: 020 Iter: 6500/40967 LR: 0.0000314691 Loss content:  0.0932 Loss fft:  3.8399\n",
      "Time:  1.0646 Epoch: 020 Iter: 7000/40967 LR: 0.0000314691 Loss content:  0.0996 Loss fft:  4.0650\n",
      "Time:  1.0610 Epoch: 020 Iter: 7500/40967 LR: 0.0000314691 Loss content:  0.0975 Loss fft:  3.9827\n",
      "Time:  1.0618 Epoch: 020 Iter: 8000/40967 LR: 0.0000314691 Loss content:  0.0991 Loss fft:  4.0256\n",
      "Time:  1.0623 Epoch: 020 Iter: 8500/40967 LR: 0.0000314691 Loss content:  0.0949 Loss fft:  3.8987\n",
      "Time:  1.0631 Epoch: 020 Iter: 9000/40967 LR: 0.0000314691 Loss content:  0.0995 Loss fft:  4.0579\n",
      "Time:  1.0659 Epoch: 020 Iter: 9500/40967 LR: 0.0000314691 Loss content:  0.0967 Loss fft:  3.8784\n",
      "Time:  1.0618 Epoch: 020 Iter: 10000/40967 LR: 0.0000314691 Loss content:  0.1006 Loss fft:  4.0470\n",
      "Time:  1.0625 Epoch: 020 Iter: 10500/40967 LR: 0.0000314691 Loss content:  0.0911 Loss fft:  3.7507\n",
      "Time:  1.0614 Epoch: 020 Iter: 11000/40967 LR: 0.0000314691 Loss content:  0.0992 Loss fft:  4.0380\n",
      "Time:  1.0613 Epoch: 020 Iter: 11500/40967 LR: 0.0000314691 Loss content:  0.0993 Loss fft:  4.0519\n",
      "Time:  1.0647 Epoch: 020 Iter: 12000/40967 LR: 0.0000314691 Loss content:  0.0965 Loss fft:  3.9296\n",
      "Time:  1.0612 Epoch: 020 Iter: 12500/40967 LR: 0.0000314691 Loss content:  0.0977 Loss fft:  3.9399\n",
      "Time:  1.0614 Epoch: 020 Iter: 13000/40967 LR: 0.0000314691 Loss content:  0.0966 Loss fft:  3.9124\n",
      "Time:  1.0609 Epoch: 020 Iter: 13500/40967 LR: 0.0000314691 Loss content:  0.0947 Loss fft:  3.8965\n",
      "Time:  1.0676 Epoch: 020 Iter: 14000/40967 LR: 0.0000314691 Loss content:  0.0920 Loss fft:  3.7355\n",
      "Time:  1.0611 Epoch: 020 Iter: 14500/40967 LR: 0.0000314691 Loss content:  0.0991 Loss fft:  4.0167\n",
      "Time:  1.0612 Epoch: 020 Iter: 15000/40967 LR: 0.0000314691 Loss content:  0.0880 Loss fft:  3.6146\n",
      "Time:  1.0619 Epoch: 020 Iter: 15500/40967 LR: 0.0000314691 Loss content:  0.0984 Loss fft:  4.0011\n",
      "Time:  1.0622 Epoch: 020 Iter: 16000/40967 LR: 0.0000314691 Loss content:  0.0974 Loss fft:  3.9350\n",
      "Time:  1.0658 Epoch: 020 Iter: 16500/40967 LR: 0.0000314691 Loss content:  0.1015 Loss fft:  4.1402\n",
      "Time:  1.0623 Epoch: 020 Iter: 17000/40967 LR: 0.0000314691 Loss content:  0.0954 Loss fft:  3.8982\n",
      "Time:  1.0622 Epoch: 020 Iter: 17500/40967 LR: 0.0000314691 Loss content:  0.0920 Loss fft:  3.7533\n",
      "Time:  1.0625 Epoch: 020 Iter: 18000/40967 LR: 0.0000314691 Loss content:  0.0960 Loss fft:  3.9419\n",
      "Time:  1.0658 Epoch: 020 Iter: 18500/40967 LR: 0.0000314691 Loss content:  0.0974 Loss fft:  3.9795\n",
      "Time:  1.0624 Epoch: 020 Iter: 19000/40967 LR: 0.0000314691 Loss content:  0.0914 Loss fft:  3.7538\n",
      "Time:  1.0620 Epoch: 020 Iter: 19500/40967 LR: 0.0000314691 Loss content:  0.1027 Loss fft:  4.1860\n",
      "Time:  1.0622 Epoch: 020 Iter: 20000/40967 LR: 0.0000314691 Loss content:  0.1032 Loss fft:  4.1307\n",
      "Time:  1.0615 Epoch: 020 Iter: 20500/40967 LR: 0.0000314691 Loss content:  0.0989 Loss fft:  4.0202\n",
      "Time:  1.0657 Epoch: 020 Iter: 21000/40967 LR: 0.0000314691 Loss content:  0.0913 Loss fft:  3.7772\n",
      "Time:  1.0616 Epoch: 020 Iter: 21500/40967 LR: 0.0000314691 Loss content:  0.0997 Loss fft:  4.0378\n",
      "Time:  1.0629 Epoch: 020 Iter: 22000/40967 LR: 0.0000314691 Loss content:  0.0961 Loss fft:  3.9293\n",
      "Time:  1.0624 Epoch: 020 Iter: 22500/40967 LR: 0.0000314691 Loss content:  0.0900 Loss fft:  3.7462\n",
      "Time:  1.0661 Epoch: 020 Iter: 23000/40967 LR: 0.0000314691 Loss content:  0.0970 Loss fft:  3.9866\n",
      "Time:  1.0612 Epoch: 020 Iter: 23500/40967 LR: 0.0000314691 Loss content:  0.0975 Loss fft:  3.9460\n",
      "Time:  1.0619 Epoch: 020 Iter: 24000/40967 LR: 0.0000314691 Loss content:  0.1046 Loss fft:  4.1688\n",
      "Time:  1.0621 Epoch: 020 Iter: 24500/40967 LR: 0.0000314691 Loss content:  0.0991 Loss fft:  4.0426\n",
      "Time:  1.0629 Epoch: 020 Iter: 25000/40967 LR: 0.0000314691 Loss content:  0.0980 Loss fft:  3.9767\n",
      "Time:  1.0658 Epoch: 020 Iter: 25500/40967 LR: 0.0000314691 Loss content:  0.0926 Loss fft:  3.8013\n",
      "Time:  1.0619 Epoch: 020 Iter: 26000/40967 LR: 0.0000314691 Loss content:  0.1006 Loss fft:  4.0830\n",
      "Time:  1.0619 Epoch: 020 Iter: 26500/40967 LR: 0.0000314691 Loss content:  0.1043 Loss fft:  4.2730\n",
      "Time:  1.0625 Epoch: 020 Iter: 27000/40967 LR: 0.0000314691 Loss content:  0.1025 Loss fft:  4.1050\n",
      "Time:  1.0626 Epoch: 020 Iter: 27500/40967 LR: 0.0000314691 Loss content:  0.0992 Loss fft:  4.0148\n",
      "Time:  1.0650 Epoch: 020 Iter: 28000/40967 LR: 0.0000314691 Loss content:  0.0970 Loss fft:  3.9961\n",
      "Time:  1.0613 Epoch: 020 Iter: 28500/40967 LR: 0.0000314691 Loss content:  0.0914 Loss fft:  3.7144\n",
      "Time:  1.0622 Epoch: 020 Iter: 29000/40967 LR: 0.0000314691 Loss content:  0.1030 Loss fft:  4.1496\n",
      "Time:  1.0614 Epoch: 020 Iter: 29500/40967 LR: 0.0000314691 Loss content:  0.0960 Loss fft:  3.9233\n",
      "Time:  1.0653 Epoch: 020 Iter: 30000/40967 LR: 0.0000314691 Loss content:  0.0970 Loss fft:  3.9293\n",
      "Time:  1.0607 Epoch: 020 Iter: 30500/40967 LR: 0.0000314691 Loss content:  0.1024 Loss fft:  4.1743\n",
      "Time:  1.0618 Epoch: 020 Iter: 31000/40967 LR: 0.0000314691 Loss content:  0.0947 Loss fft:  3.9069\n",
      "Time:  1.0622 Epoch: 020 Iter: 31500/40967 LR: 0.0000314691 Loss content:  0.0936 Loss fft:  3.8327\n",
      "Time:  1.0624 Epoch: 020 Iter: 32000/40967 LR: 0.0000314691 Loss content:  0.0958 Loss fft:  3.9039\n",
      "Time:  1.0648 Epoch: 020 Iter: 32500/40967 LR: 0.0000314691 Loss content:  0.0964 Loss fft:  3.9452\n",
      "Time:  1.0619 Epoch: 020 Iter: 33000/40967 LR: 0.0000314691 Loss content:  0.1029 Loss fft:  4.1815\n",
      "Time:  1.0619 Epoch: 020 Iter: 33500/40967 LR: 0.0000314691 Loss content:  0.1031 Loss fft:  4.1222\n",
      "Time:  1.0626 Epoch: 020 Iter: 34000/40967 LR: 0.0000314691 Loss content:  0.0941 Loss fft:  3.8496\n",
      "Time:  1.0663 Epoch: 020 Iter: 34500/40967 LR: 0.0000314691 Loss content:  0.1022 Loss fft:  4.1555\n",
      "Time:  1.0616 Epoch: 020 Iter: 35000/40967 LR: 0.0000314691 Loss content:  0.0950 Loss fft:  3.8788\n",
      "Time:  1.0610 Epoch: 020 Iter: 35500/40967 LR: 0.0000314691 Loss content:  0.1070 Loss fft:  4.3081\n",
      "Time:  1.0621 Epoch: 020 Iter: 36000/40967 LR: 0.0000314691 Loss content:  0.1032 Loss fft:  4.1746\n",
      "Time:  1.0615 Epoch: 020 Iter: 36500/40967 LR: 0.0000314691 Loss content:  0.0916 Loss fft:  3.7837\n",
      "Time:  1.0655 Epoch: 020 Iter: 37000/40967 LR: 0.0000314691 Loss content:  0.1005 Loss fft:  4.0721\n",
      "Time:  1.0618 Epoch: 020 Iter: 37500/40967 LR: 0.0000314691 Loss content:  0.1009 Loss fft:  4.0811\n",
      "Time:  1.0624 Epoch: 020 Iter: 38000/40967 LR: 0.0000314691 Loss content:  0.1022 Loss fft:  4.1015\n",
      "Time:  1.0613 Epoch: 020 Iter: 38500/40967 LR: 0.0000314691 Loss content:  0.1040 Loss fft:  4.2094\n",
      "Time:  1.0653 Epoch: 020 Iter: 39000/40967 LR: 0.0000314691 Loss content:  0.1004 Loss fft:  4.1118\n",
      "Time:  1.0622 Epoch: 020 Iter: 39500/40967 LR: 0.0000314691 Loss content:  0.0917 Loss fft:  3.7733\n",
      "Time:  1.0616 Epoch: 020 Iter: 40000/40967 LR: 0.0000314691 Loss content:  0.1035 Loss fft:  4.2214\n",
      "Time:  1.0621 Epoch: 020 Iter: 40500/40967 LR: 0.0000314691 Loss content:  0.0912 Loss fft:  3.7662\n",
      "EPOCH: 20\n",
      "Elapsed time: 87.10 Epoch Pixel Loss:  0.0981 Epoch FFT Loss:  3.9941\n",
      "Load test data\n",
      "Start Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 \n",
      "\n",
      "020 epoch \n",
      " Average PSNR 33.94 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:809: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0826 Epoch: 021 Iter:  500/40967 LR: 0.0000263137 Loss content:  0.0976 Loss fft:  3.9896\n",
      "Time:  1.0654 Epoch: 021 Iter: 1000/40967 LR: 0.0000263137 Loss content:  0.0985 Loss fft:  4.0411\n",
      "Time:  1.0628 Epoch: 021 Iter: 1500/40967 LR: 0.0000263137 Loss content:  0.1026 Loss fft:  4.1880\n",
      "Time:  1.0634 Epoch: 021 Iter: 2000/40967 LR: 0.0000263137 Loss content:  0.0968 Loss fft:  3.9561\n",
      "Time:  1.0672 Epoch: 021 Iter: 2500/40967 LR: 0.0000263137 Loss content:  0.0879 Loss fft:  3.6626\n",
      "Time:  1.0630 Epoch: 021 Iter: 3000/40967 LR: 0.0000263137 Loss content:  0.0937 Loss fft:  3.8401\n",
      "Time:  1.0631 Epoch: 021 Iter: 3500/40967 LR: 0.0000263137 Loss content:  0.1000 Loss fft:  4.0825\n",
      "Time:  1.0630 Epoch: 021 Iter: 4000/40967 LR: 0.0000263137 Loss content:  0.1011 Loss fft:  4.1343\n",
      "Time:  1.0633 Epoch: 021 Iter: 4500/40967 LR: 0.0000263137 Loss content:  0.0992 Loss fft:  3.9826\n",
      "Time:  1.0657 Epoch: 021 Iter: 5000/40967 LR: 0.0000263137 Loss content:  0.0956 Loss fft:  3.9340\n",
      "Time:  1.0623 Epoch: 021 Iter: 5500/40967 LR: 0.0000263137 Loss content:  0.0918 Loss fft:  3.7727\n",
      "Time:  1.0635 Epoch: 021 Iter: 6000/40967 LR: 0.0000263137 Loss content:  0.0986 Loss fft:  4.0103\n",
      "Time:  1.0627 Epoch: 021 Iter: 6500/40967 LR: 0.0000263137 Loss content:  0.0960 Loss fft:  3.9147\n",
      "Time:  1.0627 Epoch: 021 Iter: 7000/40967 LR: 0.0000263137 Loss content:  0.0914 Loss fft:  3.7456\n",
      "Time:  1.0675 Epoch: 021 Iter: 7500/40967 LR: 0.0000263137 Loss content:  0.1044 Loss fft:  4.2604\n",
      "Time:  1.0623 Epoch: 021 Iter: 8000/40967 LR: 0.0000263137 Loss content:  0.1046 Loss fft:  4.2253\n",
      "Time:  1.0638 Epoch: 021 Iter: 8500/40967 LR: 0.0000263137 Loss content:  0.1003 Loss fft:  4.1035\n",
      "Time:  1.0625 Epoch: 021 Iter: 9000/40967 LR: 0.0000263137 Loss content:  0.0968 Loss fft:  3.9613\n",
      "Time:  1.0661 Epoch: 021 Iter: 9500/40967 LR: 0.0000263137 Loss content:  0.0973 Loss fft:  3.9853\n",
      "Time:  1.0613 Epoch: 021 Iter: 10000/40967 LR: 0.0000263137 Loss content:  0.1032 Loss fft:  4.2004\n",
      "Time:  1.0623 Epoch: 021 Iter: 10500/40967 LR: 0.0000263137 Loss content:  0.1021 Loss fft:  4.1608\n",
      "Time:  1.0636 Epoch: 021 Iter: 11000/40967 LR: 0.0000263137 Loss content:  0.0979 Loss fft:  4.0384\n",
      "Time:  1.0632 Epoch: 021 Iter: 11500/40967 LR: 0.0000263137 Loss content:  0.1000 Loss fft:  4.1336\n",
      "Time:  1.0668 Epoch: 021 Iter: 12000/40967 LR: 0.0000263137 Loss content:  0.1013 Loss fft:  4.0936\n",
      "Time:  1.0630 Epoch: 021 Iter: 12500/40967 LR: 0.0000263137 Loss content:  0.1061 Loss fft:  4.3409\n",
      "Time:  1.0618 Epoch: 021 Iter: 13000/40967 LR: 0.0000263137 Loss content:  0.0974 Loss fft:  3.9760\n",
      "Time:  1.0617 Epoch: 021 Iter: 13500/40967 LR: 0.0000263137 Loss content:  0.0948 Loss fft:  3.9178\n",
      "Time:  1.0659 Epoch: 021 Iter: 14000/40967 LR: 0.0000263137 Loss content:  0.1036 Loss fft:  4.2118\n",
      "Time:  1.0623 Epoch: 021 Iter: 14500/40967 LR: 0.0000263137 Loss content:  0.1009 Loss fft:  4.1181\n",
      "Time:  1.0622 Epoch: 021 Iter: 15000/40967 LR: 0.0000263137 Loss content:  0.1021 Loss fft:  4.1678\n",
      "Time:  1.0621 Epoch: 021 Iter: 15500/40967 LR: 0.0000263137 Loss content:  0.0982 Loss fft:  3.9657\n",
      "Time:  1.0622 Epoch: 021 Iter: 16000/40967 LR: 0.0000263137 Loss content:  0.0986 Loss fft:  4.0391\n",
      "Time:  1.0664 Epoch: 021 Iter: 16500/40967 LR: 0.0000263137 Loss content:  0.0841 Loss fft:  3.5191\n",
      "Time:  1.0623 Epoch: 021 Iter: 17000/40967 LR: 0.0000263137 Loss content:  0.0993 Loss fft:  4.0743\n",
      "Time:  1.0620 Epoch: 021 Iter: 17500/40967 LR: 0.0000263137 Loss content:  0.0891 Loss fft:  3.6887\n",
      "Time:  1.0618 Epoch: 021 Iter: 18000/40967 LR: 0.0000263137 Loss content:  0.0963 Loss fft:  3.9401\n",
      "Time:  1.0628 Epoch: 021 Iter: 18500/40967 LR: 0.0000263137 Loss content:  0.0969 Loss fft:  3.9585\n",
      "Time:  1.0661 Epoch: 021 Iter: 19000/40967 LR: 0.0000263137 Loss content:  0.0936 Loss fft:  3.8309\n",
      "Time:  1.0629 Epoch: 021 Iter: 19500/40967 LR: 0.0000263137 Loss content:  0.1018 Loss fft:  4.1666\n",
      "Time:  1.0626 Epoch: 021 Iter: 20000/40967 LR: 0.0000263137 Loss content:  0.0923 Loss fft:  3.7766\n",
      "Time:  1.0617 Epoch: 021 Iter: 20500/40967 LR: 0.0000263137 Loss content:  0.0982 Loss fft:  4.0931\n",
      "Time:  1.0656 Epoch: 021 Iter: 21000/40967 LR: 0.0000263137 Loss content:  0.1003 Loss fft:  4.0723\n",
      "Time:  1.0643 Epoch: 021 Iter: 21500/40967 LR: 0.0000263137 Loss content:  0.1017 Loss fft:  4.1927\n",
      "Time:  1.0629 Epoch: 021 Iter: 22000/40967 LR: 0.0000263137 Loss content:  0.1016 Loss fft:  4.1580\n",
      "Time:  1.0619 Epoch: 021 Iter: 22500/40967 LR: 0.0000263137 Loss content:  0.0937 Loss fft:  3.9045\n",
      "Time:  1.0623 Epoch: 021 Iter: 23000/40967 LR: 0.0000263137 Loss content:  0.1026 Loss fft:  4.1762\n",
      "Time:  1.0659 Epoch: 021 Iter: 23500/40967 LR: 0.0000263137 Loss content:  0.0982 Loss fft:  4.0017\n",
      "Time:  1.0621 Epoch: 021 Iter: 24000/40967 LR: 0.0000263137 Loss content:  0.1027 Loss fft:  4.1626\n",
      "Time:  1.0629 Epoch: 021 Iter: 24500/40967 LR: 0.0000263137 Loss content:  0.0918 Loss fft:  3.7941\n",
      "Time:  1.0625 Epoch: 021 Iter: 25000/40967 LR: 0.0000263137 Loss content:  0.0940 Loss fft:  3.8677\n",
      "Time:  1.0653 Epoch: 021 Iter: 25500/40967 LR: 0.0000263137 Loss content:  0.1023 Loss fft:  4.1558\n",
      "Time:  1.0629 Epoch: 021 Iter: 26000/40967 LR: 0.0000263137 Loss content:  0.0959 Loss fft:  3.8983\n",
      "Time:  1.0610 Epoch: 021 Iter: 26500/40967 LR: 0.0000263137 Loss content:  0.0987 Loss fft:  4.0423\n",
      "Time:  1.0617 Epoch: 021 Iter: 27000/40967 LR: 0.0000263137 Loss content:  0.0944 Loss fft:  3.8420\n",
      "Time:  1.0634 Epoch: 021 Iter: 27500/40967 LR: 0.0000263137 Loss content:  0.0971 Loss fft:  4.0196\n",
      "Time:  1.0671 Epoch: 021 Iter: 28000/40967 LR: 0.0000263137 Loss content:  0.0955 Loss fft:  3.9258\n",
      "Time:  1.0630 Epoch: 021 Iter: 28500/40967 LR: 0.0000263137 Loss content:  0.0981 Loss fft:  3.9756\n",
      "Time:  1.0623 Epoch: 021 Iter: 29000/40967 LR: 0.0000263137 Loss content:  0.0964 Loss fft:  3.9258\n",
      "Time:  1.0616 Epoch: 021 Iter: 29500/40967 LR: 0.0000263137 Loss content:  0.0980 Loss fft:  4.0065\n",
      "Time:  1.0624 Epoch: 021 Iter: 30000/40967 LR: 0.0000263137 Loss content:  0.0899 Loss fft:  3.7412\n",
      "Time:  1.0662 Epoch: 021 Iter: 30500/40967 LR: 0.0000263137 Loss content:  0.0918 Loss fft:  3.7635\n",
      "Time:  1.0633 Epoch: 021 Iter: 31000/40967 LR: 0.0000263137 Loss content:  0.1063 Loss fft:  4.3323\n",
      "Time:  1.0628 Epoch: 021 Iter: 31500/40967 LR: 0.0000263137 Loss content:  0.0959 Loss fft:  3.9876\n",
      "Time:  1.0626 Epoch: 021 Iter: 32000/40967 LR: 0.0000263137 Loss content:  0.0970 Loss fft:  3.9531\n",
      "Time:  1.0666 Epoch: 021 Iter: 32500/40967 LR: 0.0000263137 Loss content:  0.0942 Loss fft:  3.8705\n",
      "Time:  1.0619 Epoch: 021 Iter: 33000/40967 LR: 0.0000263137 Loss content:  0.1024 Loss fft:  4.1221\n",
      "Time:  1.0624 Epoch: 021 Iter: 33500/40967 LR: 0.0000263137 Loss content:  0.0939 Loss fft:  3.8393\n",
      "Time:  1.0622 Epoch: 021 Iter: 34000/40967 LR: 0.0000263137 Loss content:  0.1045 Loss fft:  4.2397\n",
      "Time:  1.0622 Epoch: 021 Iter: 34500/40967 LR: 0.0000263137 Loss content:  0.0975 Loss fft:  3.9652\n",
      "Time:  1.0664 Epoch: 021 Iter: 35000/40967 LR: 0.0000263137 Loss content:  0.1006 Loss fft:  4.1107\n",
      "Time:  1.0620 Epoch: 021 Iter: 35500/40967 LR: 0.0000263137 Loss content:  0.1036 Loss fft:  4.2110\n",
      "Time:  1.0642 Epoch: 021 Iter: 36000/40967 LR: 0.0000263137 Loss content:  0.1064 Loss fft:  4.3157\n",
      "Time:  1.0630 Epoch: 021 Iter: 36500/40967 LR: 0.0000263137 Loss content:  0.1012 Loss fft:  4.1191\n",
      "Time:  1.0660 Epoch: 021 Iter: 37000/40967 LR: 0.0000263137 Loss content:  0.0864 Loss fft:  3.6207\n",
      "Time:  1.0629 Epoch: 021 Iter: 37500/40967 LR: 0.0000263137 Loss content:  0.0915 Loss fft:  3.7649\n",
      "Time:  1.0619 Epoch: 021 Iter: 38000/40967 LR: 0.0000263137 Loss content:  0.0918 Loss fft:  3.8323\n",
      "Time:  1.0620 Epoch: 021 Iter: 38500/40967 LR: 0.0000263137 Loss content:  0.0966 Loss fft:  3.9928\n",
      "Time:  1.0621 Epoch: 021 Iter: 39000/40967 LR: 0.0000263137 Loss content:  0.0982 Loss fft:  4.0160\n",
      "Time:  1.0667 Epoch: 021 Iter: 39500/40967 LR: 0.0000263137 Loss content:  0.0974 Loss fft:  4.0057\n",
      "Time:  1.0628 Epoch: 021 Iter: 40000/40967 LR: 0.0000263137 Loss content:  0.0986 Loss fft:  4.0303\n",
      "Time:  1.0627 Epoch: 021 Iter: 40500/40967 LR: 0.0000263137 Loss content:  0.1010 Loss fft:  4.1232\n",
      "EPOCH: 21\n",
      "Elapsed time: 87.15 Epoch Pixel Loss:  0.0978 Epoch FFT Loss:  4.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0774 Epoch: 022 Iter:  500/40967 LR: 0.0000214911 Loss content:  0.1008 Loss fft:  4.1308\n",
      "Time:  1.0696 Epoch: 022 Iter: 1000/40967 LR: 0.0000214911 Loss content:  0.0985 Loss fft:  4.0319\n",
      "Time:  1.0649 Epoch: 022 Iter: 1500/40967 LR: 0.0000214911 Loss content:  0.0936 Loss fft:  3.8470\n",
      "Time:  1.0637 Epoch: 022 Iter: 2000/40967 LR: 0.0000214911 Loss content:  0.0989 Loss fft:  4.0462\n",
      "Time:  1.0626 Epoch: 022 Iter: 2500/40967 LR: 0.0000214911 Loss content:  0.0979 Loss fft:  4.0148\n",
      "Time:  1.0674 Epoch: 022 Iter: 3000/40967 LR: 0.0000214911 Loss content:  0.0942 Loss fft:  3.8923\n",
      "Time:  1.0641 Epoch: 022 Iter: 3500/40967 LR: 0.0000214911 Loss content:  0.0946 Loss fft:  3.9102\n",
      "Time:  1.0638 Epoch: 022 Iter: 4000/40967 LR: 0.0000214911 Loss content:  0.0984 Loss fft:  4.0316\n",
      "Time:  1.0630 Epoch: 022 Iter: 4500/40967 LR: 0.0000214911 Loss content:  0.0901 Loss fft:  3.7557\n",
      "Time:  1.0631 Epoch: 022 Iter: 5000/40967 LR: 0.0000214911 Loss content:  0.0840 Loss fft:  3.5182\n",
      "Time:  1.0664 Epoch: 022 Iter: 5500/40967 LR: 0.0000214911 Loss content:  0.0892 Loss fft:  3.7225\n",
      "Time:  1.0623 Epoch: 022 Iter: 6000/40967 LR: 0.0000214911 Loss content:  0.0992 Loss fft:  4.0893\n",
      "Time:  1.0634 Epoch: 022 Iter: 6500/40967 LR: 0.0000214911 Loss content:  0.0922 Loss fft:  3.7573\n",
      "Time:  1.0627 Epoch: 022 Iter: 7000/40967 LR: 0.0000214911 Loss content:  0.0953 Loss fft:  3.9654\n",
      "Time:  1.0661 Epoch: 022 Iter: 7500/40967 LR: 0.0000214911 Loss content:  0.0911 Loss fft:  3.7190\n",
      "Time:  1.0645 Epoch: 022 Iter: 8000/40967 LR: 0.0000214911 Loss content:  0.0888 Loss fft:  3.7394\n",
      "Time:  1.0637 Epoch: 022 Iter: 8500/40967 LR: 0.0000214911 Loss content:  0.0912 Loss fft:  3.7927\n",
      "Time:  1.0638 Epoch: 022 Iter: 9000/40967 LR: 0.0000214911 Loss content:  0.0923 Loss fft:  3.7967\n",
      "Time:  1.0634 Epoch: 022 Iter: 9500/40967 LR: 0.0000214911 Loss content:  0.0928 Loss fft:  3.8650\n",
      "Time:  1.0685 Epoch: 022 Iter: 10000/40967 LR: 0.0000214911 Loss content:  0.0961 Loss fft:  3.9539\n",
      "Time:  1.0627 Epoch: 022 Iter: 10500/40967 LR: 0.0000214911 Loss content:  0.0996 Loss fft:  4.0807\n",
      "Time:  1.0638 Epoch: 022 Iter: 11000/40967 LR: 0.0000214911 Loss content:  0.0997 Loss fft:  4.0653\n",
      "Time:  1.0622 Epoch: 022 Iter: 11500/40967 LR: 0.0000214911 Loss content:  0.0975 Loss fft:  4.0042\n",
      "Time:  1.0625 Epoch: 022 Iter: 12000/40967 LR: 0.0000214911 Loss content:  0.0956 Loss fft:  4.0343\n",
      "Time:  1.0673 Epoch: 022 Iter: 12500/40967 LR: 0.0000214911 Loss content:  0.0989 Loss fft:  4.0851\n",
      "Time:  1.0639 Epoch: 022 Iter: 13000/40967 LR: 0.0000214911 Loss content:  0.0874 Loss fft:  3.6746\n",
      "Time:  1.0642 Epoch: 022 Iter: 13500/40967 LR: 0.0000214911 Loss content:  0.0981 Loss fft:  4.0407\n",
      "Time:  1.0640 Epoch: 022 Iter: 14000/40967 LR: 0.0000214911 Loss content:  0.0910 Loss fft:  3.8053\n",
      "Time:  1.0675 Epoch: 022 Iter: 14500/40967 LR: 0.0000214911 Loss content:  0.0987 Loss fft:  4.0735\n",
      "Time:  1.0635 Epoch: 022 Iter: 15000/40967 LR: 0.0000214911 Loss content:  0.0963 Loss fft:  4.0325\n",
      "Time:  1.0628 Epoch: 022 Iter: 15500/40967 LR: 0.0000214911 Loss content:  0.0945 Loss fft:  3.8976\n",
      "Time:  1.0630 Epoch: 022 Iter: 16000/40967 LR: 0.0000214911 Loss content:  0.1021 Loss fft:  4.1717\n",
      "Time:  1.0622 Epoch: 022 Iter: 16500/40967 LR: 0.0000214911 Loss content:  0.0848 Loss fft:  3.5669\n",
      "Time:  1.0677 Epoch: 022 Iter: 17000/40967 LR: 0.0000214911 Loss content:  0.0999 Loss fft:  4.0666\n",
      "Time:  1.0633 Epoch: 022 Iter: 17500/40967 LR: 0.0000214911 Loss content:  0.0867 Loss fft:  3.5883\n",
      "Time:  1.0624 Epoch: 022 Iter: 18000/40967 LR: 0.0000214911 Loss content:  0.1006 Loss fft:  4.1088\n",
      "Time:  1.0627 Epoch: 022 Iter: 18500/40967 LR: 0.0000214911 Loss content:  0.1041 Loss fft:  4.2620\n",
      "Time:  1.0673 Epoch: 022 Iter: 19000/40967 LR: 0.0000214911 Loss content:  0.0914 Loss fft:  3.8212\n",
      "Time:  1.0641 Epoch: 022 Iter: 19500/40967 LR: 0.0000214911 Loss content:  0.0985 Loss fft:  4.1069\n",
      "Time:  1.0651 Epoch: 022 Iter: 20000/40967 LR: 0.0000214911 Loss content:  0.0944 Loss fft:  3.8221\n",
      "Time:  1.0629 Epoch: 022 Iter: 20500/40967 LR: 0.0000214911 Loss content:  0.0999 Loss fft:  4.1393\n",
      "Time:  1.0639 Epoch: 022 Iter: 21000/40967 LR: 0.0000214911 Loss content:  0.1020 Loss fft:  4.2249\n",
      "Time:  1.0684 Epoch: 022 Iter: 21500/40967 LR: 0.0000214911 Loss content:  0.0952 Loss fft:  3.9413\n",
      "Time:  1.0638 Epoch: 022 Iter: 22000/40967 LR: 0.0000214911 Loss content:  0.0931 Loss fft:  3.9273\n",
      "Time:  1.0628 Epoch: 022 Iter: 22500/40967 LR: 0.0000214911 Loss content:  0.0931 Loss fft:  3.8893\n",
      "Time:  1.0638 Epoch: 022 Iter: 23000/40967 LR: 0.0000214911 Loss content:  0.0910 Loss fft:  3.7884\n",
      "Time:  1.0650 Epoch: 022 Iter: 23500/40967 LR: 0.0000214911 Loss content:  0.0959 Loss fft:  4.0123\n",
      "Time:  1.0677 Epoch: 022 Iter: 24000/40967 LR: 0.0000214911 Loss content:  0.0932 Loss fft:  3.8607\n",
      "Time:  1.0629 Epoch: 022 Iter: 24500/40967 LR: 0.0000214911 Loss content:  0.0971 Loss fft:  3.9938\n",
      "Time:  1.0618 Epoch: 022 Iter: 25000/40967 LR: 0.0000214911 Loss content:  0.0925 Loss fft:  3.8474\n",
      "Time:  1.0618 Epoch: 022 Iter: 25500/40967 LR: 0.0000214911 Loss content:  0.0964 Loss fft:  3.9730\n",
      "Time:  1.0658 Epoch: 022 Iter: 26000/40967 LR: 0.0000214911 Loss content:  0.0933 Loss fft:  3.8492\n",
      "Time:  1.0638 Epoch: 022 Iter: 26500/40967 LR: 0.0000214911 Loss content:  0.0960 Loss fft:  3.9622\n",
      "Time:  1.0634 Epoch: 022 Iter: 27000/40967 LR: 0.0000214911 Loss content:  0.0950 Loss fft:  3.9151\n",
      "Time:  1.0636 Epoch: 022 Iter: 27500/40967 LR: 0.0000214911 Loss content:  0.0950 Loss fft:  3.9365\n",
      "Time:  1.0651 Epoch: 022 Iter: 28000/40967 LR: 0.0000214911 Loss content:  0.0947 Loss fft:  3.9337\n",
      "Time:  1.0676 Epoch: 022 Iter: 28500/40967 LR: 0.0000214911 Loss content:  0.0980 Loss fft:  4.0255\n",
      "Time:  1.0635 Epoch: 022 Iter: 29000/40967 LR: 0.0000214911 Loss content:  0.0979 Loss fft:  4.0070\n",
      "Time:  1.0631 Epoch: 022 Iter: 29500/40967 LR: 0.0000214911 Loss content:  0.0992 Loss fft:  4.1291\n",
      "Time:  1.0634 Epoch: 022 Iter: 30000/40967 LR: 0.0000214911 Loss content:  0.1040 Loss fft:  4.2118\n",
      "Time:  1.0682 Epoch: 022 Iter: 30500/40967 LR: 0.0000214911 Loss content:  0.0908 Loss fft:  3.7820\n",
      "Time:  1.0650 Epoch: 022 Iter: 31000/40967 LR: 0.0000214911 Loss content:  0.0930 Loss fft:  3.8532\n",
      "Time:  1.0640 Epoch: 022 Iter: 31500/40967 LR: 0.0000214911 Loss content:  0.0958 Loss fft:  3.9343\n",
      "Time:  1.0628 Epoch: 022 Iter: 32000/40967 LR: 0.0000214911 Loss content:  0.0961 Loss fft:  3.9613\n",
      "Time:  1.0640 Epoch: 022 Iter: 32500/40967 LR: 0.0000214911 Loss content:  0.1044 Loss fft:  4.2857\n",
      "Time:  1.0669 Epoch: 022 Iter: 33000/40967 LR: 0.0000214911 Loss content:  0.0983 Loss fft:  4.0716\n",
      "Time:  1.0627 Epoch: 022 Iter: 33500/40967 LR: 0.0000214911 Loss content:  0.0959 Loss fft:  3.9939\n",
      "Time:  1.0635 Epoch: 022 Iter: 34000/40967 LR: 0.0000214911 Loss content:  0.0959 Loss fft:  3.9572\n",
      "Time:  1.0639 Epoch: 022 Iter: 34500/40967 LR: 0.0000214911 Loss content:  0.0915 Loss fft:  3.7488\n",
      "Time:  1.0632 Epoch: 022 Iter: 35000/40967 LR: 0.0000214911 Loss content:  0.0978 Loss fft:  4.0278\n",
      "Time:  1.0670 Epoch: 022 Iter: 35500/40967 LR: 0.0000214911 Loss content:  0.0998 Loss fft:  4.1019\n",
      "Time:  1.0637 Epoch: 022 Iter: 36000/40967 LR: 0.0000214911 Loss content:  0.0976 Loss fft:  4.0045\n",
      "Time:  1.0619 Epoch: 022 Iter: 36500/40967 LR: 0.0000214911 Loss content:  0.1080 Loss fft:  4.3764\n",
      "Time:  1.0619 Epoch: 022 Iter: 37000/40967 LR: 0.0000214911 Loss content:  0.0956 Loss fft:  3.9031\n",
      "Time:  1.0674 Epoch: 022 Iter: 37500/40967 LR: 0.0000214911 Loss content:  0.0958 Loss fft:  3.9907\n",
      "Time:  1.0635 Epoch: 022 Iter: 38000/40967 LR: 0.0000214911 Loss content:  0.1007 Loss fft:  4.0919\n",
      "Time:  1.0629 Epoch: 022 Iter: 38500/40967 LR: 0.0000214911 Loss content:  0.0996 Loss fft:  4.0635\n",
      "Time:  1.0621 Epoch: 022 Iter: 39000/40967 LR: 0.0000214911 Loss content:  0.0956 Loss fft:  3.9219\n",
      "Time:  1.0633 Epoch: 022 Iter: 39500/40967 LR: 0.0000214911 Loss content:  0.0908 Loss fft:  3.7381\n",
      "Time:  1.0669 Epoch: 022 Iter: 40000/40967 LR: 0.0000214911 Loss content:  0.0977 Loss fft:  3.9908\n",
      "Time:  1.0633 Epoch: 022 Iter: 40500/40967 LR: 0.0000214911 Loss content:  0.0938 Loss fft:  3.8368\n",
      "EPOCH: 22\n",
      "Elapsed time: 87.22 Epoch Pixel Loss:  0.0958 Epoch FFT Loss:  3.9525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0741 Epoch: 023 Iter:  500/40967 LR: 0.0000170658 Loss content:  0.0985 Loss fft:  4.0598\n",
      "Time:  1.0688 Epoch: 023 Iter: 1000/40967 LR: 0.0000170658 Loss content:  0.0995 Loss fft:  4.1169\n",
      "Time:  1.0639 Epoch: 023 Iter: 1500/40967 LR: 0.0000170658 Loss content:  0.0981 Loss fft:  4.0084\n",
      "Time:  1.0623 Epoch: 023 Iter: 2000/40967 LR: 0.0000170658 Loss content:  0.0910 Loss fft:  3.7625\n",
      "Time:  1.0627 Epoch: 023 Iter: 2500/40967 LR: 0.0000170658 Loss content:  0.0956 Loss fft:  3.9853\n",
      "Time:  1.0644 Epoch: 023 Iter: 3000/40967 LR: 0.0000170658 Loss content:  0.1009 Loss fft:  4.1596\n",
      "Time:  1.0667 Epoch: 023 Iter: 3500/40967 LR: 0.0000170658 Loss content:  0.0947 Loss fft:  3.9535\n",
      "Time:  1.0643 Epoch: 023 Iter: 4000/40967 LR: 0.0000170658 Loss content:  0.1111 Loss fft:  4.5189\n",
      "Time:  1.0626 Epoch: 023 Iter: 4500/40967 LR: 0.0000170658 Loss content:  0.0970 Loss fft:  4.0262\n",
      "Time:  1.0623 Epoch: 023 Iter: 5000/40967 LR: 0.0000170658 Loss content:  0.0954 Loss fft:  3.9634\n",
      "Time:  1.0633 Epoch: 023 Iter: 5500/40967 LR: 0.0000170658 Loss content:  0.0976 Loss fft:  3.9832\n",
      "Time:  1.0669 Epoch: 023 Iter: 6000/40967 LR: 0.0000170658 Loss content:  0.0977 Loss fft:  3.9946\n",
      "Time:  1.0638 Epoch: 023 Iter: 6500/40967 LR: 0.0000170658 Loss content:  0.0989 Loss fft:  4.1418\n",
      "Time:  1.0631 Epoch: 023 Iter: 7000/40967 LR: 0.0000170658 Loss content:  0.0975 Loss fft:  4.0455\n",
      "Time:  1.0625 Epoch: 023 Iter: 7500/40967 LR: 0.0000170658 Loss content:  0.0929 Loss fft:  3.8436\n",
      "Time:  1.0654 Epoch: 023 Iter: 8000/40967 LR: 0.0000170658 Loss content:  0.0966 Loss fft:  3.9857\n",
      "Time:  1.0628 Epoch: 023 Iter: 8500/40967 LR: 0.0000170658 Loss content:  0.0945 Loss fft:  3.9051\n",
      "Time:  1.0631 Epoch: 023 Iter: 9000/40967 LR: 0.0000170658 Loss content:  0.0946 Loss fft:  3.9716\n",
      "Time:  1.0630 Epoch: 023 Iter: 9500/40967 LR: 0.0000170658 Loss content:  0.0891 Loss fft:  3.7353\n",
      "Time:  1.0612 Epoch: 023 Iter: 10000/40967 LR: 0.0000170658 Loss content:  0.0946 Loss fft:  3.9498\n",
      "Time:  1.0668 Epoch: 023 Iter: 10500/40967 LR: 0.0000170658 Loss content:  0.0997 Loss fft:  4.1356\n",
      "Time:  1.0630 Epoch: 023 Iter: 11000/40967 LR: 0.0000170658 Loss content:  0.0888 Loss fft:  3.7050\n",
      "Time:  1.0632 Epoch: 023 Iter: 11500/40967 LR: 0.0000170658 Loss content:  0.0941 Loss fft:  3.8743\n",
      "Time:  1.0615 Epoch: 023 Iter: 12000/40967 LR: 0.0000170658 Loss content:  0.0959 Loss fft:  3.9650\n",
      "Time:  1.0667 Epoch: 023 Iter: 12500/40967 LR: 0.0000170658 Loss content:  0.0961 Loss fft:  3.9873\n",
      "Time:  1.0646 Epoch: 023 Iter: 13000/40967 LR: 0.0000170658 Loss content:  0.1022 Loss fft:  4.1927\n",
      "Time:  1.0622 Epoch: 023 Iter: 13500/40967 LR: 0.0000170658 Loss content:  0.0970 Loss fft:  4.0342\n",
      "Time:  1.0629 Epoch: 023 Iter: 14000/40967 LR: 0.0000170658 Loss content:  0.0959 Loss fft:  4.0127\n",
      "Time:  1.0617 Epoch: 023 Iter: 14500/40967 LR: 0.0000170658 Loss content:  0.0965 Loss fft:  4.0827\n",
      "Time:  1.0667 Epoch: 023 Iter: 15000/40967 LR: 0.0000170658 Loss content:  0.0947 Loss fft:  3.9205\n",
      "Time:  1.0636 Epoch: 023 Iter: 15500/40967 LR: 0.0000170658 Loss content:  0.0989 Loss fft:  4.0483\n",
      "Time:  1.0633 Epoch: 023 Iter: 16000/40967 LR: 0.0000170658 Loss content:  0.0911 Loss fft:  3.7848\n",
      "Time:  1.0627 Epoch: 023 Iter: 16500/40967 LR: 0.0000170658 Loss content:  0.0893 Loss fft:  3.7282\n",
      "Time:  1.0633 Epoch: 023 Iter: 17000/40967 LR: 0.0000170658 Loss content:  0.0876 Loss fft:  3.7025\n",
      "Time:  1.0673 Epoch: 023 Iter: 17500/40967 LR: 0.0000170658 Loss content:  0.0886 Loss fft:  3.7116\n",
      "Time:  1.0628 Epoch: 023 Iter: 18000/40967 LR: 0.0000170658 Loss content:  0.0931 Loss fft:  3.8764\n",
      "Time:  1.0633 Epoch: 023 Iter: 18500/40967 LR: 0.0000170658 Loss content:  0.1051 Loss fft:  4.2193\n",
      "Time:  1.0637 Epoch: 023 Iter: 19000/40967 LR: 0.0000170658 Loss content:  0.0957 Loss fft:  3.9523\n",
      "Time:  1.0665 Epoch: 023 Iter: 19500/40967 LR: 0.0000170658 Loss content:  0.0825 Loss fft:  3.4735\n",
      "Time:  1.0633 Epoch: 023 Iter: 20000/40967 LR: 0.0000170658 Loss content:  0.0938 Loss fft:  3.8829\n",
      "Time:  1.0633 Epoch: 023 Iter: 20500/40967 LR: 0.0000170658 Loss content:  0.0896 Loss fft:  3.7102\n",
      "Time:  1.0639 Epoch: 023 Iter: 21000/40967 LR: 0.0000170658 Loss content:  0.0940 Loss fft:  3.9205\n",
      "Time:  1.0627 Epoch: 023 Iter: 21500/40967 LR: 0.0000170658 Loss content:  0.0963 Loss fft:  3.9728\n",
      "Time:  1.0676 Epoch: 023 Iter: 22000/40967 LR: 0.0000170658 Loss content:  0.0991 Loss fft:  4.1113\n",
      "Time:  1.0632 Epoch: 023 Iter: 22500/40967 LR: 0.0000170658 Loss content:  0.0893 Loss fft:  3.7454\n",
      "Time:  1.0625 Epoch: 023 Iter: 23000/40967 LR: 0.0000170658 Loss content:  0.0976 Loss fft:  4.0186\n",
      "Time:  1.0625 Epoch: 023 Iter: 23500/40967 LR: 0.0000170658 Loss content:  0.1029 Loss fft:  4.2096\n",
      "Time:  1.0623 Epoch: 023 Iter: 24000/40967 LR: 0.0000170658 Loss content:  0.0962 Loss fft:  3.9588\n",
      "Time:  1.0659 Epoch: 023 Iter: 24500/40967 LR: 0.0000170658 Loss content:  0.0985 Loss fft:  4.0446\n",
      "Time:  1.0622 Epoch: 023 Iter: 25000/40967 LR: 0.0000170658 Loss content:  0.0924 Loss fft:  3.8411\n",
      "Time:  1.0624 Epoch: 023 Iter: 25500/40967 LR: 0.0000170658 Loss content:  0.0931 Loss fft:  3.8634\n",
      "Time:  1.0627 Epoch: 023 Iter: 26000/40967 LR: 0.0000170658 Loss content:  0.1058 Loss fft:  4.3091\n",
      "Time:  1.0671 Epoch: 023 Iter: 26500/40967 LR: 0.0000170658 Loss content:  0.0923 Loss fft:  3.7968\n",
      "Time:  1.0641 Epoch: 023 Iter: 27000/40967 LR: 0.0000170658 Loss content:  0.0837 Loss fft:  3.5677\n",
      "Time:  1.0643 Epoch: 023 Iter: 27500/40967 LR: 0.0000170658 Loss content:  0.0940 Loss fft:  3.9143\n",
      "Time:  1.0631 Epoch: 023 Iter: 28000/40967 LR: 0.0000170658 Loss content:  0.0947 Loss fft:  3.9180\n",
      "Time:  1.0619 Epoch: 023 Iter: 28500/40967 LR: 0.0000170658 Loss content:  0.0962 Loss fft:  4.0025\n",
      "Time:  1.0663 Epoch: 023 Iter: 29000/40967 LR: 0.0000170658 Loss content:  0.1030 Loss fft:  4.2668\n",
      "Time:  1.0643 Epoch: 023 Iter: 29500/40967 LR: 0.0000170658 Loss content:  0.0963 Loss fft:  4.0554\n",
      "Time:  1.0627 Epoch: 023 Iter: 30000/40967 LR: 0.0000170658 Loss content:  0.0941 Loss fft:  3.8765\n",
      "Time:  1.0631 Epoch: 023 Iter: 30500/40967 LR: 0.0000170658 Loss content:  0.0958 Loss fft:  3.9778\n",
      "Time:  1.0665 Epoch: 023 Iter: 31000/40967 LR: 0.0000170658 Loss content:  0.0931 Loss fft:  3.8539\n",
      "Time:  1.0630 Epoch: 023 Iter: 31500/40967 LR: 0.0000170658 Loss content:  0.0895 Loss fft:  3.7100\n",
      "Time:  1.0622 Epoch: 023 Iter: 32000/40967 LR: 0.0000170658 Loss content:  0.0872 Loss fft:  3.6387\n",
      "Time:  1.0619 Epoch: 023 Iter: 32500/40967 LR: 0.0000170658 Loss content:  0.1040 Loss fft:  4.2068\n",
      "Time:  1.0623 Epoch: 023 Iter: 33000/40967 LR: 0.0000170658 Loss content:  0.0963 Loss fft:  4.0564\n",
      "Time:  1.0663 Epoch: 023 Iter: 33500/40967 LR: 0.0000170658 Loss content:  0.1000 Loss fft:  4.1338\n",
      "Time:  1.0631 Epoch: 023 Iter: 34000/40967 LR: 0.0000170658 Loss content:  0.0951 Loss fft:  3.9730\n",
      "Time:  1.0628 Epoch: 023 Iter: 34500/40967 LR: 0.0000170658 Loss content:  0.0973 Loss fft:  4.0545\n",
      "Time:  1.0634 Epoch: 023 Iter: 35000/40967 LR: 0.0000170658 Loss content:  0.1042 Loss fft:  4.2568\n",
      "Time:  1.0638 Epoch: 023 Iter: 35500/40967 LR: 0.0000170658 Loss content:  0.0993 Loss fft:  4.0981\n",
      "Time:  1.0671 Epoch: 023 Iter: 36000/40967 LR: 0.0000170658 Loss content:  0.1003 Loss fft:  4.0906\n",
      "Time:  1.0626 Epoch: 023 Iter: 36500/40967 LR: 0.0000170658 Loss content:  0.0960 Loss fft:  3.9431\n",
      "Time:  1.0642 Epoch: 023 Iter: 37000/40967 LR: 0.0000170658 Loss content:  0.1080 Loss fft:  4.4192\n",
      "Time:  1.0632 Epoch: 023 Iter: 37500/40967 LR: 0.0000170658 Loss content:  0.1004 Loss fft:  4.1447\n",
      "Time:  1.0687 Epoch: 023 Iter: 38000/40967 LR: 0.0000170658 Loss content:  0.0967 Loss fft:  3.9811\n",
      "Time:  1.0649 Epoch: 023 Iter: 38500/40967 LR: 0.0000170658 Loss content:  0.0892 Loss fft:  3.7706\n",
      "Time:  1.0628 Epoch: 023 Iter: 39000/40967 LR: 0.0000170658 Loss content:  0.0960 Loss fft:  3.9501\n",
      "Time:  1.0627 Epoch: 023 Iter: 39500/40967 LR: 0.0000170658 Loss content:  0.0881 Loss fft:  3.7127\n",
      "Time:  1.0634 Epoch: 023 Iter: 40000/40967 LR: 0.0000170658 Loss content:  0.0966 Loss fft:  4.0411\n",
      "Time:  1.0665 Epoch: 023 Iter: 40500/40967 LR: 0.0000170658 Loss content:  0.0917 Loss fft:  3.8303\n",
      "EPOCH: 23\n",
      "Elapsed time: 87.19 Epoch Pixel Loss:  0.0959 Epoch FFT Loss:  3.9715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0760 Epoch: 024 Iter:  500/40967 LR: 0.0000130966 Loss content:  0.0939 Loss fft:  3.9208\n",
      "Time:  1.0632 Epoch: 024 Iter: 1000/40967 LR: 0.0000130966 Loss content:  0.0975 Loss fft:  4.0377\n",
      "Time:  1.0670 Epoch: 024 Iter: 1500/40967 LR: 0.0000130966 Loss content:  0.0976 Loss fft:  4.0558\n",
      "Time:  1.0622 Epoch: 024 Iter: 2000/40967 LR: 0.0000130966 Loss content:  0.1028 Loss fft:  4.1693\n",
      "Time:  1.0632 Epoch: 024 Iter: 2500/40967 LR: 0.0000130966 Loss content:  0.0759 Loss fft:  3.2709\n",
      "Time:  1.0618 Epoch: 024 Iter: 3000/40967 LR: 0.0000130966 Loss content:  0.0997 Loss fft:  4.1493\n",
      "Time:  1.0614 Epoch: 024 Iter: 3500/40967 LR: 0.0000130966 Loss content:  0.1010 Loss fft:  4.1537\n",
      "Time:  1.0669 Epoch: 024 Iter: 4000/40967 LR: 0.0000130966 Loss content:  0.0919 Loss fft:  3.8778\n",
      "Time:  1.0628 Epoch: 024 Iter: 4500/40967 LR: 0.0000130966 Loss content:  0.1005 Loss fft:  4.1604\n",
      "Time:  1.0638 Epoch: 024 Iter: 5000/40967 LR: 0.0000130966 Loss content:  0.1031 Loss fft:  4.2996\n",
      "Time:  1.0621 Epoch: 024 Iter: 5500/40967 LR: 0.0000130966 Loss content:  0.0995 Loss fft:  4.1034\n",
      "Time:  1.0632 Epoch: 024 Iter: 6000/40967 LR: 0.0000130966 Loss content:  0.0954 Loss fft:  3.9940\n",
      "Time:  1.0671 Epoch: 024 Iter: 6500/40967 LR: 0.0000130966 Loss content:  0.0941 Loss fft:  3.9291\n",
      "Time:  1.0627 Epoch: 024 Iter: 7000/40967 LR: 0.0000130966 Loss content:  0.0970 Loss fft:  4.0377\n",
      "Time:  1.0629 Epoch: 024 Iter: 7500/40967 LR: 0.0000130966 Loss content:  0.0883 Loss fft:  3.7284\n",
      "Time:  1.0630 Epoch: 024 Iter: 8000/40967 LR: 0.0000130966 Loss content:  0.0908 Loss fft:  3.8235\n",
      "Time:  1.0665 Epoch: 024 Iter: 8500/40967 LR: 0.0000130966 Loss content:  0.1018 Loss fft:  4.2595\n",
      "Time:  1.0634 Epoch: 024 Iter: 9000/40967 LR: 0.0000130966 Loss content:  0.0956 Loss fft:  4.0284\n",
      "Time:  1.0625 Epoch: 024 Iter: 9500/40967 LR: 0.0000130966 Loss content:  0.0992 Loss fft:  4.1305\n",
      "Time:  1.0638 Epoch: 024 Iter: 10000/40967 LR: 0.0000130966 Loss content:  0.0943 Loss fft:  4.0250\n",
      "Time:  1.0631 Epoch: 024 Iter: 10500/40967 LR: 0.0000130966 Loss content:  0.0882 Loss fft:  3.7259\n",
      "Time:  1.0667 Epoch: 024 Iter: 11000/40967 LR: 0.0000130966 Loss content:  0.1022 Loss fft:  4.2489\n",
      "Time:  1.0648 Epoch: 024 Iter: 11500/40967 LR: 0.0000130966 Loss content:  0.1010 Loss fft:  4.1559\n",
      "Time:  1.0623 Epoch: 024 Iter: 12000/40967 LR: 0.0000130966 Loss content:  0.0982 Loss fft:  4.1258\n",
      "Time:  1.0644 Epoch: 024 Iter: 12500/40967 LR: 0.0000130966 Loss content:  0.0970 Loss fft:  4.0013\n",
      "Time:  1.0670 Epoch: 024 Iter: 13000/40967 LR: 0.0000130966 Loss content:  0.0908 Loss fft:  3.8065\n",
      "Time:  1.0643 Epoch: 024 Iter: 13500/40967 LR: 0.0000130966 Loss content:  0.0913 Loss fft:  3.8399\n",
      "Time:  1.0632 Epoch: 024 Iter: 14000/40967 LR: 0.0000130966 Loss content:  0.0940 Loss fft:  3.9115\n",
      "Time:  1.0630 Epoch: 024 Iter: 14500/40967 LR: 0.0000130966 Loss content:  0.0934 Loss fft:  3.9160\n",
      "Time:  1.0635 Epoch: 024 Iter: 15000/40967 LR: 0.0000130966 Loss content:  0.0945 Loss fft:  3.9263\n",
      "Time:  1.0660 Epoch: 024 Iter: 15500/40967 LR: 0.0000130966 Loss content:  0.1010 Loss fft:  4.1862\n",
      "Time:  1.0619 Epoch: 024 Iter: 16000/40967 LR: 0.0000130966 Loss content:  0.0825 Loss fft:  3.5190\n",
      "Time:  1.0627 Epoch: 024 Iter: 16500/40967 LR: 0.0000130966 Loss content:  0.0996 Loss fft:  4.1284\n",
      "Time:  1.0658 Epoch: 024 Iter: 17000/40967 LR: 0.0000130966 Loss content:  0.0882 Loss fft:  3.7109\n",
      "Time:  1.0632 Epoch: 024 Iter: 17500/40967 LR: 0.0000130966 Loss content:  0.0981 Loss fft:  4.0806\n",
      "Time:  1.0663 Epoch: 024 Iter: 18000/40967 LR: 0.0000130966 Loss content:  0.0868 Loss fft:  3.6625\n",
      "Time:  1.0622 Epoch: 024 Iter: 18500/40967 LR: 0.0000130966 Loss content:  0.0950 Loss fft:  3.9550\n",
      "Time:  1.0631 Epoch: 024 Iter: 19000/40967 LR: 0.0000130966 Loss content:  0.0899 Loss fft:  3.7131\n",
      "Time:  1.0646 Epoch: 024 Iter: 19500/40967 LR: 0.0000130966 Loss content:  0.0983 Loss fft:  4.0139\n",
      "Time:  1.0675 Epoch: 024 Iter: 20000/40967 LR: 0.0000130966 Loss content:  0.0879 Loss fft:  3.7336\n",
      "Time:  1.0634 Epoch: 024 Iter: 20500/40967 LR: 0.0000130966 Loss content:  0.0939 Loss fft:  3.9072\n",
      "Time:  1.0634 Epoch: 024 Iter: 21000/40967 LR: 0.0000130966 Loss content:  0.0953 Loss fft:  3.9164\n",
      "Time:  1.0624 Epoch: 024 Iter: 21500/40967 LR: 0.0000130966 Loss content:  0.0950 Loss fft:  3.9420\n",
      "Time:  1.0626 Epoch: 024 Iter: 22000/40967 LR: 0.0000130966 Loss content:  0.0943 Loss fft:  3.9243\n",
      "Time:  1.0667 Epoch: 024 Iter: 22500/40967 LR: 0.0000130966 Loss content:  0.0900 Loss fft:  3.8000\n",
      "Time:  1.0626 Epoch: 024 Iter: 23000/40967 LR: 0.0000130966 Loss content:  0.0906 Loss fft:  3.7911\n",
      "Time:  1.0637 Epoch: 024 Iter: 23500/40967 LR: 0.0000130966 Loss content:  0.0979 Loss fft:  4.0530\n",
      "Time:  1.0637 Epoch: 024 Iter: 24000/40967 LR: 0.0000130966 Loss content:  0.0997 Loss fft:  4.1076\n",
      "Time:  1.0633 Epoch: 024 Iter: 24500/40967 LR: 0.0000130966 Loss content:  0.0973 Loss fft:  4.0483\n",
      "Time:  1.0674 Epoch: 024 Iter: 25000/40967 LR: 0.0000130966 Loss content:  0.0919 Loss fft:  3.8532\n",
      "Time:  1.0658 Epoch: 024 Iter: 25500/40967 LR: 0.0000130966 Loss content:  0.0883 Loss fft:  3.6906\n",
      "Time:  1.0632 Epoch: 024 Iter: 26000/40967 LR: 0.0000130966 Loss content:  0.0914 Loss fft:  3.8467\n",
      "Time:  1.0640 Epoch: 024 Iter: 26500/40967 LR: 0.0000130966 Loss content:  0.0972 Loss fft:  4.0457\n",
      "Time:  1.0669 Epoch: 024 Iter: 27000/40967 LR: 0.0000130966 Loss content:  0.1077 Loss fft:  4.4050\n",
      "Time:  1.0619 Epoch: 024 Iter: 27500/40967 LR: 0.0000130966 Loss content:  0.0927 Loss fft:  3.8929\n",
      "Time:  1.0625 Epoch: 024 Iter: 28000/40967 LR: 0.0000130966 Loss content:  0.1013 Loss fft:  4.1432\n",
      "Time:  1.0631 Epoch: 024 Iter: 28500/40967 LR: 0.0000130966 Loss content:  0.0943 Loss fft:  3.9293\n",
      "Time:  1.0631 Epoch: 024 Iter: 29000/40967 LR: 0.0000130966 Loss content:  0.0892 Loss fft:  3.7557\n",
      "Time:  1.0672 Epoch: 024 Iter: 29500/40967 LR: 0.0000130966 Loss content:  0.0870 Loss fft:  3.7064\n",
      "Time:  1.0630 Epoch: 024 Iter: 30000/40967 LR: 0.0000130966 Loss content:  0.0983 Loss fft:  4.1106\n",
      "Time:  1.0619 Epoch: 024 Iter: 30500/40967 LR: 0.0000130966 Loss content:  0.1001 Loss fft:  4.1024\n",
      "Time:  1.0616 Epoch: 024 Iter: 31000/40967 LR: 0.0000130966 Loss content:  0.0953 Loss fft:  3.9724\n",
      "Time:  1.0673 Epoch: 024 Iter: 31500/40967 LR: 0.0000130966 Loss content:  0.0937 Loss fft:  3.9556\n",
      "Time:  1.0634 Epoch: 024 Iter: 32000/40967 LR: 0.0000130966 Loss content:  0.1026 Loss fft:  4.2452\n",
      "Time:  1.0630 Epoch: 024 Iter: 32500/40967 LR: 0.0000130966 Loss content:  0.0994 Loss fft:  4.1170\n",
      "Time:  1.0642 Epoch: 024 Iter: 33000/40967 LR: 0.0000130966 Loss content:  0.0906 Loss fft:  3.7686\n",
      "Time:  1.0637 Epoch: 024 Iter: 33500/40967 LR: 0.0000130966 Loss content:  0.0949 Loss fft:  3.9405\n",
      "Time:  1.0670 Epoch: 024 Iter: 34000/40967 LR: 0.0000130966 Loss content:  0.0947 Loss fft:  3.9231\n",
      "Time:  1.0635 Epoch: 024 Iter: 34500/40967 LR: 0.0000130966 Loss content:  0.0967 Loss fft:  3.9930\n",
      "Time:  1.0628 Epoch: 024 Iter: 35000/40967 LR: 0.0000130966 Loss content:  0.0911 Loss fft:  3.7934\n",
      "Time:  1.0632 Epoch: 024 Iter: 35500/40967 LR: 0.0000130966 Loss content:  0.0950 Loss fft:  4.0095\n",
      "Time:  1.0638 Epoch: 024 Iter: 36000/40967 LR: 0.0000130966 Loss content:  0.0972 Loss fft:  4.0306\n",
      "Time:  1.0662 Epoch: 024 Iter: 36500/40967 LR: 0.0000130966 Loss content:  0.1002 Loss fft:  4.1410\n",
      "Time:  1.0625 Epoch: 024 Iter: 37000/40967 LR: 0.0000130966 Loss content:  0.0938 Loss fft:  3.8941\n",
      "Time:  1.0636 Epoch: 024 Iter: 37500/40967 LR: 0.0000130966 Loss content:  0.0921 Loss fft:  3.8312\n",
      "Time:  1.0632 Epoch: 024 Iter: 38000/40967 LR: 0.0000130966 Loss content:  0.0859 Loss fft:  3.6124\n",
      "Time:  1.0675 Epoch: 024 Iter: 38500/40967 LR: 0.0000130966 Loss content:  0.0884 Loss fft:  3.7197\n",
      "Time:  1.0627 Epoch: 024 Iter: 39000/40967 LR: 0.0000130966 Loss content:  0.0942 Loss fft:  3.9593\n",
      "Time:  1.0624 Epoch: 024 Iter: 39500/40967 LR: 0.0000130966 Loss content:  0.0926 Loss fft:  3.8534\n",
      "Time:  1.0643 Epoch: 024 Iter: 40000/40967 LR: 0.0000130966 Loss content:  0.0952 Loss fft:  3.9742\n",
      "Time:  1.0643 Epoch: 024 Iter: 40500/40967 LR: 0.0000130966 Loss content:  0.1027 Loss fft:  4.2278\n",
      "EPOCH: 24\n",
      "Elapsed time: 87.20 Epoch Pixel Loss:  0.0947 Epoch FFT Loss:  3.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0784 Epoch: 025 Iter:  500/40967 LR: 0.0000096353 Loss content:  0.0927 Loss fft:  3.9021\n",
      "Time:  1.0636 Epoch: 025 Iter: 1000/40967 LR: 0.0000096353 Loss content:  0.0973 Loss fft:  4.0440\n",
      "Time:  1.0636 Epoch: 025 Iter: 1500/40967 LR: 0.0000096353 Loss content:  0.0961 Loss fft:  3.9951\n",
      "Time:  1.0685 Epoch: 025 Iter: 2000/40967 LR: 0.0000096353 Loss content:  0.0931 Loss fft:  3.9061\n",
      "Time:  1.0639 Epoch: 025 Iter: 2500/40967 LR: 0.0000096353 Loss content:  0.1011 Loss fft:  4.2187\n",
      "Time:  1.0640 Epoch: 025 Iter: 3000/40967 LR: 0.0000096353 Loss content:  0.0912 Loss fft:  3.8203\n",
      "Time:  1.0635 Epoch: 025 Iter: 3500/40967 LR: 0.0000096353 Loss content:  0.0895 Loss fft:  3.7638\n",
      "Time:  1.0638 Epoch: 025 Iter: 4000/40967 LR: 0.0000096353 Loss content:  0.0948 Loss fft:  3.9415\n",
      "Time:  1.0664 Epoch: 025 Iter: 4500/40967 LR: 0.0000096353 Loss content:  0.0949 Loss fft:  3.9814\n",
      "Time:  1.0631 Epoch: 025 Iter: 5000/40967 LR: 0.0000096353 Loss content:  0.0926 Loss fft:  3.9004\n",
      "Time:  1.0628 Epoch: 025 Iter: 5500/40967 LR: 0.0000096353 Loss content:  0.0953 Loss fft:  4.0047\n",
      "Time:  1.0627 Epoch: 025 Iter: 6000/40967 LR: 0.0000096353 Loss content:  0.1033 Loss fft:  4.3373\n",
      "Time:  1.0634 Epoch: 025 Iter: 6500/40967 LR: 0.0000096353 Loss content:  0.0924 Loss fft:  3.8927\n",
      "Time:  1.0671 Epoch: 025 Iter: 7000/40967 LR: 0.0000096353 Loss content:  0.0964 Loss fft:  4.0046\n",
      "Time:  1.0642 Epoch: 025 Iter: 7500/40967 LR: 0.0000096353 Loss content:  0.0959 Loss fft:  4.0359\n",
      "Time:  1.0637 Epoch: 025 Iter: 8000/40967 LR: 0.0000096353 Loss content:  0.0895 Loss fft:  3.7828\n",
      "Time:  1.0631 Epoch: 025 Iter: 8500/40967 LR: 0.0000096353 Loss content:  0.0956 Loss fft:  3.9777\n",
      "Time:  1.0681 Epoch: 025 Iter: 9000/40967 LR: 0.0000096353 Loss content:  0.0877 Loss fft:  3.6864\n",
      "Time:  1.0631 Epoch: 025 Iter: 9500/40967 LR: 0.0000096353 Loss content:  0.0992 Loss fft:  4.1385\n",
      "Time:  1.0630 Epoch: 025 Iter: 10000/40967 LR: 0.0000096353 Loss content:  0.0874 Loss fft:  3.7115\n",
      "Time:  1.0630 Epoch: 025 Iter: 10500/40967 LR: 0.0000096353 Loss content:  0.0867 Loss fft:  3.6886\n",
      "Time:  1.0638 Epoch: 025 Iter: 11000/40967 LR: 0.0000096353 Loss content:  0.0892 Loss fft:  3.7269\n",
      "Time:  1.0685 Epoch: 025 Iter: 11500/40967 LR: 0.0000096353 Loss content:  0.0923 Loss fft:  3.8832\n",
      "Time:  1.0644 Epoch: 025 Iter: 12000/40967 LR: 0.0000096353 Loss content:  0.1008 Loss fft:  4.2159\n",
      "Time:  1.0623 Epoch: 025 Iter: 12500/40967 LR: 0.0000096353 Loss content:  0.1008 Loss fft:  4.1555\n",
      "Time:  1.0647 Epoch: 025 Iter: 13000/40967 LR: 0.0000096353 Loss content:  0.0917 Loss fft:  3.8542\n",
      "Time:  1.0671 Epoch: 025 Iter: 13500/40967 LR: 0.0000096353 Loss content:  0.0910 Loss fft:  3.8500\n",
      "Time:  1.0633 Epoch: 025 Iter: 14000/40967 LR: 0.0000096353 Loss content:  0.0961 Loss fft:  3.9814\n",
      "Time:  1.0639 Epoch: 025 Iter: 14500/40967 LR: 0.0000096353 Loss content:  0.0983 Loss fft:  4.1381\n",
      "Time:  1.0642 Epoch: 025 Iter: 15000/40967 LR: 0.0000096353 Loss content:  0.0973 Loss fft:  4.0893\n",
      "Time:  1.0642 Epoch: 025 Iter: 15500/40967 LR: 0.0000096353 Loss content:  0.0911 Loss fft:  3.8130\n",
      "Time:  1.0675 Epoch: 025 Iter: 16000/40967 LR: 0.0000096353 Loss content:  0.0936 Loss fft:  3.9266\n",
      "Time:  1.0636 Epoch: 025 Iter: 16500/40967 LR: 0.0000096353 Loss content:  0.0949 Loss fft:  3.9516\n",
      "Time:  1.0639 Epoch: 025 Iter: 17000/40967 LR: 0.0000096353 Loss content:  0.0920 Loss fft:  3.9103\n",
      "Time:  1.0632 Epoch: 025 Iter: 17500/40967 LR: 0.0000096353 Loss content:  0.0998 Loss fft:  4.1281\n",
      "Time:  1.0628 Epoch: 025 Iter: 18000/40967 LR: 0.0000096353 Loss content:  0.0954 Loss fft:  3.9663\n",
      "Time:  1.0676 Epoch: 025 Iter: 18500/40967 LR: 0.0000096353 Loss content:  0.0939 Loss fft:  3.9129\n",
      "Time:  1.0631 Epoch: 025 Iter: 19000/40967 LR: 0.0000096353 Loss content:  0.0940 Loss fft:  3.9018\n",
      "Time:  1.0634 Epoch: 025 Iter: 19500/40967 LR: 0.0000096353 Loss content:  0.0939 Loss fft:  3.9045\n",
      "Time:  1.0626 Epoch: 025 Iter: 20000/40967 LR: 0.0000096353 Loss content:  0.1001 Loss fft:  4.1412\n",
      "Time:  1.0665 Epoch: 025 Iter: 20500/40967 LR: 0.0000096353 Loss content:  0.0912 Loss fft:  3.8301\n",
      "Time:  1.0628 Epoch: 025 Iter: 21000/40967 LR: 0.0000096353 Loss content:  0.0980 Loss fft:  4.1687\n",
      "Time:  1.0633 Epoch: 025 Iter: 21500/40967 LR: 0.0000096353 Loss content:  0.0915 Loss fft:  3.8655\n",
      "Time:  1.0638 Epoch: 025 Iter: 22000/40967 LR: 0.0000096353 Loss content:  0.0990 Loss fft:  4.1680\n",
      "Time:  1.0635 Epoch: 025 Iter: 22500/40967 LR: 0.0000096353 Loss content:  0.0881 Loss fft:  3.7358\n",
      "Time:  1.0686 Epoch: 025 Iter: 23000/40967 LR: 0.0000096353 Loss content:  0.0836 Loss fft:  3.5503\n",
      "Time:  1.0655 Epoch: 025 Iter: 23500/40967 LR: 0.0000096353 Loss content:  0.0944 Loss fft:  3.9606\n",
      "Time:  1.0628 Epoch: 025 Iter: 24000/40967 LR: 0.0000096353 Loss content:  0.0903 Loss fft:  3.8336\n",
      "Time:  1.0655 Epoch: 025 Iter: 24500/40967 LR: 0.0000096353 Loss content:  0.0831 Loss fft:  3.5580\n",
      "Time:  1.0676 Epoch: 025 Iter: 25000/40967 LR: 0.0000096353 Loss content:  0.0969 Loss fft:  4.0039\n",
      "Time:  1.0633 Epoch: 025 Iter: 25500/40967 LR: 0.0000096353 Loss content:  0.0965 Loss fft:  4.0551\n",
      "Time:  1.0632 Epoch: 025 Iter: 26000/40967 LR: 0.0000096353 Loss content:  0.0920 Loss fft:  3.8416\n",
      "Time:  1.0635 Epoch: 025 Iter: 26500/40967 LR: 0.0000096353 Loss content:  0.0934 Loss fft:  3.9532\n",
      "Time:  1.0627 Epoch: 025 Iter: 27000/40967 LR: 0.0000096353 Loss content:  0.0892 Loss fft:  3.7526\n",
      "Time:  1.0661 Epoch: 025 Iter: 27500/40967 LR: 0.0000096353 Loss content:  0.0928 Loss fft:  3.9173\n",
      "Time:  1.0638 Epoch: 025 Iter: 28000/40967 LR: 0.0000096353 Loss content:  0.0919 Loss fft:  3.8748\n",
      "Time:  1.0636 Epoch: 025 Iter: 28500/40967 LR: 0.0000096353 Loss content:  0.0950 Loss fft:  3.9687\n",
      "Time:  1.0637 Epoch: 025 Iter: 29000/40967 LR: 0.0000096353 Loss content:  0.0972 Loss fft:  4.0392\n",
      "Time:  1.0634 Epoch: 025 Iter: 29500/40967 LR: 0.0000096353 Loss content:  0.0942 Loss fft:  3.9524\n",
      "Time:  1.0668 Epoch: 025 Iter: 30000/40967 LR: 0.0000096353 Loss content:  0.0977 Loss fft:  4.0809\n",
      "Time:  1.0635 Epoch: 025 Iter: 30500/40967 LR: 0.0000096353 Loss content:  0.1045 Loss fft:  4.3093\n",
      "Time:  1.0646 Epoch: 025 Iter: 31000/40967 LR: 0.0000096353 Loss content:  0.0845 Loss fft:  3.5775\n",
      "Time:  1.0639 Epoch: 025 Iter: 31500/40967 LR: 0.0000096353 Loss content:  0.0883 Loss fft:  3.7308\n",
      "Time:  1.0668 Epoch: 025 Iter: 32000/40967 LR: 0.0000096353 Loss content:  0.0954 Loss fft:  4.0075\n",
      "Time:  1.0644 Epoch: 025 Iter: 32500/40967 LR: 0.0000096353 Loss content:  0.0922 Loss fft:  3.8567\n",
      "Time:  1.0630 Epoch: 025 Iter: 33000/40967 LR: 0.0000096353 Loss content:  0.1004 Loss fft:  4.1158\n",
      "Time:  1.0630 Epoch: 025 Iter: 33500/40967 LR: 0.0000096353 Loss content:  0.0951 Loss fft:  3.9840\n",
      "Time:  1.0636 Epoch: 025 Iter: 34000/40967 LR: 0.0000096353 Loss content:  0.0918 Loss fft:  3.8438\n",
      "Time:  1.0668 Epoch: 025 Iter: 34500/40967 LR: 0.0000096353 Loss content:  0.0921 Loss fft:  3.8557\n",
      "Time:  1.0633 Epoch: 025 Iter: 35000/40967 LR: 0.0000096353 Loss content:  0.0989 Loss fft:  4.1192\n",
      "Time:  1.0635 Epoch: 025 Iter: 35500/40967 LR: 0.0000096353 Loss content:  0.0926 Loss fft:  3.9022\n",
      "Time:  1.0628 Epoch: 025 Iter: 36000/40967 LR: 0.0000096353 Loss content:  0.0949 Loss fft:  3.9918\n",
      "Time:  1.0636 Epoch: 025 Iter: 36500/40967 LR: 0.0000096353 Loss content:  0.1082 Loss fft:  4.4558\n",
      "Time:  1.0688 Epoch: 025 Iter: 37000/40967 LR: 0.0000096353 Loss content:  0.0912 Loss fft:  3.8672\n",
      "Time:  1.0647 Epoch: 025 Iter: 37500/40967 LR: 0.0000096353 Loss content:  0.0866 Loss fft:  3.6737\n",
      "Time:  1.0633 Epoch: 025 Iter: 38000/40967 LR: 0.0000096353 Loss content:  0.0873 Loss fft:  3.7183\n",
      "Time:  1.0622 Epoch: 025 Iter: 38500/40967 LR: 0.0000096353 Loss content:  0.0995 Loss fft:  4.1033\n",
      "Time:  1.0661 Epoch: 025 Iter: 39000/40967 LR: 0.0000096353 Loss content:  0.0984 Loss fft:  4.1180\n",
      "Time:  1.0622 Epoch: 025 Iter: 39500/40967 LR: 0.0000096353 Loss content:  0.0981 Loss fft:  4.0875\n",
      "Time:  1.0634 Epoch: 025 Iter: 40000/40967 LR: 0.0000096353 Loss content:  0.0948 Loss fft:  3.9505\n",
      "Time:  1.0636 Epoch: 025 Iter: 40500/40967 LR: 0.0000096353 Loss content:  0.0950 Loss fft:  3.9493\n",
      "EPOCH: 25\n",
      "Elapsed time: 87.23 Epoch Pixel Loss:  0.0942 Epoch FFT Loss:  3.9481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0823 Epoch: 026 Iter:  500/40967 LR: 0.0000067262 Loss content:  0.0960 Loss fft:  3.9955\n",
      "Time:  1.0633 Epoch: 026 Iter: 1000/40967 LR: 0.0000067262 Loss content:  0.0916 Loss fft:  3.8390\n",
      "Time:  1.0638 Epoch: 026 Iter: 1500/40967 LR: 0.0000067262 Loss content:  0.0884 Loss fft:  3.7582\n",
      "Time:  1.0641 Epoch: 026 Iter: 2000/40967 LR: 0.0000067262 Loss content:  0.0931 Loss fft:  3.8834\n",
      "Time:  1.0675 Epoch: 026 Iter: 2500/40967 LR: 0.0000067262 Loss content:  0.0919 Loss fft:  3.8855\n",
      "Time:  1.0648 Epoch: 026 Iter: 3000/40967 LR: 0.0000067262 Loss content:  0.1016 Loss fft:  4.1853\n",
      "Time:  1.0655 Epoch: 026 Iter: 3500/40967 LR: 0.0000067262 Loss content:  0.0999 Loss fft:  4.1648\n",
      "Time:  1.0626 Epoch: 026 Iter: 4000/40967 LR: 0.0000067262 Loss content:  0.1095 Loss fft:  4.4757\n",
      "Time:  1.0626 Epoch: 026 Iter: 4500/40967 LR: 0.0000067262 Loss content:  0.0922 Loss fft:  3.9257\n",
      "Time:  1.0678 Epoch: 026 Iter: 5000/40967 LR: 0.0000067262 Loss content:  0.0941 Loss fft:  3.9766\n",
      "Time:  1.0655 Epoch: 026 Iter: 5500/40967 LR: 0.0000067262 Loss content:  0.0871 Loss fft:  3.7055\n",
      "Time:  1.0637 Epoch: 026 Iter: 6000/40967 LR: 0.0000067262 Loss content:  0.0880 Loss fft:  3.7449\n",
      "Time:  1.0642 Epoch: 026 Iter: 6500/40967 LR: 0.0000067262 Loss content:  0.0950 Loss fft:  4.0088\n",
      "Time:  1.0634 Epoch: 026 Iter: 7000/40967 LR: 0.0000067262 Loss content:  0.1002 Loss fft:  4.1717\n",
      "Time:  1.0679 Epoch: 026 Iter: 7500/40967 LR: 0.0000067262 Loss content:  0.0906 Loss fft:  3.8720\n",
      "Time:  1.0635 Epoch: 026 Iter: 8000/40967 LR: 0.0000067262 Loss content:  0.0936 Loss fft:  3.9645\n",
      "Time:  1.0631 Epoch: 026 Iter: 8500/40967 LR: 0.0000067262 Loss content:  0.0883 Loss fft:  3.7522\n",
      "Time:  1.0632 Epoch: 026 Iter: 9000/40967 LR: 0.0000067262 Loss content:  0.0960 Loss fft:  3.9727\n",
      "Time:  1.0670 Epoch: 026 Iter: 9500/40967 LR: 0.0000067262 Loss content:  0.0961 Loss fft:  4.0406\n",
      "Time:  1.0626 Epoch: 026 Iter: 10000/40967 LR: 0.0000067262 Loss content:  0.0891 Loss fft:  3.8055\n",
      "Time:  1.0638 Epoch: 026 Iter: 10500/40967 LR: 0.0000067262 Loss content:  0.0955 Loss fft:  4.0225\n",
      "Time:  1.0637 Epoch: 026 Iter: 11000/40967 LR: 0.0000067262 Loss content:  0.0898 Loss fft:  3.8069\n",
      "Time:  1.0643 Epoch: 026 Iter: 11500/40967 LR: 0.0000067262 Loss content:  0.0954 Loss fft:  4.0196\n",
      "Time:  1.0677 Epoch: 026 Iter: 12000/40967 LR: 0.0000067262 Loss content:  0.0985 Loss fft:  4.1452\n",
      "Time:  1.0632 Epoch: 026 Iter: 12500/40967 LR: 0.0000067262 Loss content:  0.0965 Loss fft:  4.0543\n",
      "Time:  1.0640 Epoch: 026 Iter: 13000/40967 LR: 0.0000067262 Loss content:  0.1011 Loss fft:  4.1778\n",
      "Time:  1.0634 Epoch: 026 Iter: 13500/40967 LR: 0.0000067262 Loss content:  0.0985 Loss fft:  4.1063\n",
      "Time:  1.0667 Epoch: 026 Iter: 14000/40967 LR: 0.0000067262 Loss content:  0.0909 Loss fft:  3.8569\n",
      "Time:  1.0636 Epoch: 026 Iter: 14500/40967 LR: 0.0000067262 Loss content:  0.0976 Loss fft:  4.0762\n",
      "Time:  1.0647 Epoch: 026 Iter: 15000/40967 LR: 0.0000067262 Loss content:  0.0893 Loss fft:  3.7644\n",
      "Time:  1.0646 Epoch: 026 Iter: 15500/40967 LR: 0.0000067262 Loss content:  0.0991 Loss fft:  4.1212\n",
      "Time:  1.0626 Epoch: 026 Iter: 16000/40967 LR: 0.0000067262 Loss content:  0.0971 Loss fft:  4.0295\n",
      "Time:  1.0670 Epoch: 026 Iter: 16500/40967 LR: 0.0000067262 Loss content:  0.0881 Loss fft:  3.7082\n",
      "Time:  1.0631 Epoch: 026 Iter: 17000/40967 LR: 0.0000067262 Loss content:  0.1023 Loss fft:  4.2750\n",
      "Time:  1.0632 Epoch: 026 Iter: 17500/40967 LR: 0.0000067262 Loss content:  0.0932 Loss fft:  3.8969\n",
      "Time:  1.0630 Epoch: 026 Iter: 18000/40967 LR: 0.0000067262 Loss content:  0.0907 Loss fft:  3.8546\n",
      "Time:  1.0638 Epoch: 026 Iter: 18500/40967 LR: 0.0000067262 Loss content:  0.0950 Loss fft:  3.9780\n",
      "Time:  1.0670 Epoch: 026 Iter: 19000/40967 LR: 0.0000067262 Loss content:  0.0958 Loss fft:  4.0166\n",
      "Time:  1.0631 Epoch: 026 Iter: 19500/40967 LR: 0.0000067262 Loss content:  0.0928 Loss fft:  3.9318\n",
      "Time:  1.0635 Epoch: 026 Iter: 20000/40967 LR: 0.0000067262 Loss content:  0.0937 Loss fft:  3.9774\n",
      "Time:  1.0645 Epoch: 026 Iter: 20500/40967 LR: 0.0000067262 Loss content:  0.0950 Loss fft:  3.9775\n",
      "Time:  1.0661 Epoch: 026 Iter: 21000/40967 LR: 0.0000067262 Loss content:  0.0823 Loss fft:  3.5832\n",
      "Time:  1.0654 Epoch: 026 Iter: 21500/40967 LR: 0.0000067262 Loss content:  0.0901 Loss fft:  3.7991\n",
      "Time:  1.0636 Epoch: 026 Iter: 22000/40967 LR: 0.0000067262 Loss content:  0.0943 Loss fft:  3.9770\n",
      "Time:  1.0630 Epoch: 026 Iter: 22500/40967 LR: 0.0000067262 Loss content:  0.0981 Loss fft:  4.1654\n",
      "Time:  1.0646 Epoch: 026 Iter: 23000/40967 LR: 0.0000067262 Loss content:  0.0931 Loss fft:  3.9122\n",
      "Time:  1.0673 Epoch: 026 Iter: 23500/40967 LR: 0.0000067262 Loss content:  0.0925 Loss fft:  3.8859\n",
      "Time:  1.0626 Epoch: 026 Iter: 24000/40967 LR: 0.0000067262 Loss content:  0.0944 Loss fft:  3.9728\n",
      "Time:  1.0641 Epoch: 026 Iter: 24500/40967 LR: 0.0000067262 Loss content:  0.0941 Loss fft:  3.9783\n",
      "Time:  1.0632 Epoch: 026 Iter: 25000/40967 LR: 0.0000067262 Loss content:  0.0921 Loss fft:  3.9241\n",
      "Time:  1.0664 Epoch: 026 Iter: 25500/40967 LR: 0.0000067262 Loss content:  0.0957 Loss fft:  3.9811\n",
      "Time:  1.0634 Epoch: 026 Iter: 26000/40967 LR: 0.0000067262 Loss content:  0.1037 Loss fft:  4.2676\n",
      "Time:  1.0644 Epoch: 026 Iter: 26500/40967 LR: 0.0000067262 Loss content:  0.0905 Loss fft:  3.8108\n",
      "Time:  1.0624 Epoch: 026 Iter: 27000/40967 LR: 0.0000067262 Loss content:  0.0890 Loss fft:  3.7843\n",
      "Time:  1.0632 Epoch: 026 Iter: 27500/40967 LR: 0.0000067262 Loss content:  0.0936 Loss fft:  3.9670\n",
      "Time:  1.0661 Epoch: 026 Iter: 28000/40967 LR: 0.0000067262 Loss content:  0.0911 Loss fft:  3.8401\n",
      "Time:  1.0649 Epoch: 026 Iter: 28500/40967 LR: 0.0000067262 Loss content:  0.0835 Loss fft:  3.4953\n",
      "Time:  1.0635 Epoch: 026 Iter: 29000/40967 LR: 0.0000067262 Loss content:  0.0876 Loss fft:  3.6994\n",
      "Time:  1.0634 Epoch: 026 Iter: 29500/40967 LR: 0.0000067262 Loss content:  0.0931 Loss fft:  3.8659\n",
      "Time:  1.0643 Epoch: 026 Iter: 30000/40967 LR: 0.0000067262 Loss content:  0.0949 Loss fft:  3.9812\n",
      "Time:  1.0666 Epoch: 026 Iter: 30500/40967 LR: 0.0000067262 Loss content:  0.1022 Loss fft:  4.3232\n",
      "Time:  1.0629 Epoch: 026 Iter: 31000/40967 LR: 0.0000067262 Loss content:  0.0891 Loss fft:  3.7749\n",
      "Time:  1.0618 Epoch: 026 Iter: 31500/40967 LR: 0.0000067262 Loss content:  0.0867 Loss fft:  3.7076\n",
      "Time:  1.0618 Epoch: 026 Iter: 32000/40967 LR: 0.0000067262 Loss content:  0.0978 Loss fft:  4.0899\n",
      "Time:  1.0689 Epoch: 026 Iter: 32500/40967 LR: 0.0000067262 Loss content:  0.0893 Loss fft:  3.7967\n",
      "Time:  1.0628 Epoch: 026 Iter: 33000/40967 LR: 0.0000067262 Loss content:  0.1013 Loss fft:  4.1867\n",
      "Time:  1.0646 Epoch: 026 Iter: 33500/40967 LR: 0.0000067262 Loss content:  0.0984 Loss fft:  4.1235\n",
      "Time:  1.0634 Epoch: 026 Iter: 34000/40967 LR: 0.0000067262 Loss content:  0.0950 Loss fft:  3.9589\n",
      "Time:  1.0645 Epoch: 026 Iter: 34500/40967 LR: 0.0000067262 Loss content:  0.0974 Loss fft:  4.0836\n",
      "Time:  1.0662 Epoch: 026 Iter: 35000/40967 LR: 0.0000067262 Loss content:  0.0982 Loss fft:  4.1000\n",
      "Time:  1.0638 Epoch: 026 Iter: 35500/40967 LR: 0.0000067262 Loss content:  0.0962 Loss fft:  4.0059\n",
      "Time:  1.0631 Epoch: 026 Iter: 36000/40967 LR: 0.0000067262 Loss content:  0.0945 Loss fft:  3.9943\n",
      "Time:  1.0641 Epoch: 026 Iter: 36500/40967 LR: 0.0000067262 Loss content:  0.0969 Loss fft:  4.1038\n",
      "Time:  1.0651 Epoch: 026 Iter: 37000/40967 LR: 0.0000067262 Loss content:  0.0954 Loss fft:  3.9714\n",
      "Time:  1.0630 Epoch: 026 Iter: 37500/40967 LR: 0.0000067262 Loss content:  0.0994 Loss fft:  4.1413\n",
      "Time:  1.0621 Epoch: 026 Iter: 38000/40967 LR: 0.0000067262 Loss content:  0.0913 Loss fft:  3.8303\n",
      "Time:  1.0629 Epoch: 026 Iter: 38500/40967 LR: 0.0000067262 Loss content:  0.0978 Loss fft:  4.0759\n",
      "Time:  1.0621 Epoch: 026 Iter: 39000/40967 LR: 0.0000067262 Loss content:  0.0955 Loss fft:  3.9793\n",
      "Time:  1.0672 Epoch: 026 Iter: 39500/40967 LR: 0.0000067262 Loss content:  0.0928 Loss fft:  3.9476\n",
      "Time:  1.0629 Epoch: 026 Iter: 40000/40967 LR: 0.0000067262 Loss content:  0.0872 Loss fft:  3.7367\n",
      "Time:  1.0629 Epoch: 026 Iter: 40500/40967 LR: 0.0000067262 Loss content:  0.0928 Loss fft:  3.9055\n",
      "EPOCH: 26\n",
      "Elapsed time: 87.22 Epoch Pixel Loss:  0.0940 Epoch FFT Loss:  3.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0745 Epoch: 027 Iter:  500/40967 LR: 0.0000044043 Loss content:  0.0900 Loss fft:  3.8262\n",
      "Time:  1.0682 Epoch: 027 Iter: 1000/40967 LR: 0.0000044043 Loss content:  0.0972 Loss fft:  4.0350\n",
      "Time:  1.0630 Epoch: 027 Iter: 1500/40967 LR: 0.0000044043 Loss content:  0.0958 Loss fft:  3.9821\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "# from torch.backends import cudnn # Uncomment if you need it\n",
    "\n",
    "class Args:\n",
    "    model_name = 'IRNeXt'\n",
    "    mode = 'train'\n",
    "    data_dir = './reside-mix/'\n",
    "\n",
    "    # Train\n",
    "    batch_size = 8\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 0\n",
    "    num_epoch = 30\n",
    "    print_freq = 500\n",
    "    num_worker = 8\n",
    "    save_freq = 10\n",
    "    valid_freq = 10\n",
    "    figname = 'mix_30epoch.jpg'\n",
    "    resume = ''\n",
    "    #'/content/drive/MyDrive/results_mix/IRNeXt/OTS/model.pkl'\n",
    "\n",
    "    # Test\n",
    "    test_model = '/content/drive/MyDrive/results_mix/IRNeXt/OTS/Final.pkl'\n",
    "    # save_image = False\n",
    "\n",
    "    # Directories (set these as per your requirement)\n",
    "    model_save_dir = os.path.join('/content/drive/MyDrive/results_mix/', 'IRNeXt', 'OTS/')\n",
    "    result_dir = os.path.join('/content/drive/MyDrive/results_mix/', model_name, 'test')\n",
    "\n",
    "def main(args):\n",
    "    # CUDNN\n",
    "    # cudnn.benchmark = True # Uncomment if you need it\n",
    "\n",
    "    if not os.path.exists('/content/drive/MyDrive/results_mix/'):\n",
    "        os.makedirs(args.model_save_dir)\n",
    "    if not os.path.exists('/content/drive/MyDrive/results_mix/' + args.model_name + '/'):\n",
    "        os.makedirs('/content/drive/MyDrive/results_mix/' + args.model_name + '/')\n",
    "    if not os.path.exists(args.model_save_dir):\n",
    "        os.makedirs(args.model_save_dir)\n",
    "    if not os.path.exists(args.result_dir):\n",
    "        os.makedirs(args.result_dir)\n",
    "\n",
    "    model = build_net()  # Make sure to define build_net or import it if it's defined elsewhere\n",
    "    #print(model)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    if args.mode == 'train':\n",
    "        _train(model, args)  # Make sure to define _train or import it if it's defined elsewhere\n",
    "\n",
    "    elif args.mode == 'test':\n",
    "        _eval(model, args)   # Make sure to define _eval or import it if it's defined elsewhere\n",
    "\n",
    "# Replace parser.parse_args() with an instance of the Args class\n",
    "args = Args()\n",
    "if not os.path.exists(args.model_save_dir):\n",
    "    os.makedirs(args.model_save_dir)\n",
    "# Copying files (make sure these paths are correct)\n",
    "command = 'cp ' + 'models/layers.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "command = 'cp ' + 'models/IRNeXt.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "command = 'cp ' + 'train.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "command = 'cp ' + 'main.py ' + args.model_save_dir\n",
    "os.system(command)\n",
    "print(args)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68pANInIV7kJ",
    "outputId": "472f3d47-cdbc-483e-ec3a-fc05d617d92c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
